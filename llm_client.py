#!/usr/bin/env python3
"""
ç»Ÿä¸€çš„LLMå®¢æˆ·ç«¯
æ”¯æŒä¸¤å¥—APIç³»ç»Ÿï¼š
1. å…¬å¸å†…éƒ¨APIï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
2. AI Builders APIï¼ˆå¤‡ç”¨ï¼‰
"""

import os
import json
import time
import base64
from typing import Optional, List, Dict, Any, Union
from pathlib import Path
import requests

# å°è¯•å¯¼å…¥OpenAI SDKï¼ˆç”¨äºå…¬å¸å†…éƒ¨APIï¼‰
try:
    from openai import OpenAI
    HAS_OPENAI_SDK = True
except ImportError:
    HAS_OPENAI_SDK = False

from core.config_loader import get_config
from logger_utils import get_logger
from metaso_search_client import MetasoSearchClient

logger = get_logger('llm_client')

# ========================================
# é‡è¦ï¼šå¯åŠ¨æ—¶æ¸…é™¤æ‰€æœ‰ä»£ç†ç¯å¢ƒå˜é‡
# åŸå› ï¼šä»£ç†ä¼šå¯¼è‡´å…¬å¸å†…éƒ¨APIè¢«WAFæ‹¦æˆª
# ========================================
def disable_proxy():
    """
    å¼ºåˆ¶ç¦ç”¨æ‰€æœ‰ä»£ç†è®¾ç½®
    ç¡®ä¿å…¬å¸å†…éƒ¨APIå¯ä»¥æ­£å¸¸è®¿é—®
    """
    proxy_vars = [
        "HTTP_PROXY", "HTTPS_PROXY", "http_proxy", "https_proxy",
        "ALL_PROXY", "all_proxy", "NO_PROXY", "no_proxy"
    ]

    disabled_count = 0
    for var in proxy_vars:
        if var in os.environ:
            del os.environ[var]
            disabled_count += 1

    # ä¹Ÿè®¾ç½®ä¸ºç©ºï¼Œé˜²æ­¢ä»£ç ä¸­è¯»å–
    os.environ["HTTP_PROXY"] = ""
    os.environ["HTTPS_PROXY"] = ""
    os.environ["http_proxy"] = ""
    os.environ["https_proxy"] = ""

    if disabled_count > 0:
        logger.info(f"[ğŸ”§ ä»£ç†] å·²æ¸…é™¤ {disabled_count} ä¸ªä»£ç†ç¯å¢ƒå˜é‡ï¼Œç¡®ä¿å…¬å¸APIå¯è®¿é—®")

# åœ¨æ¨¡å—åŠ è½½æ—¶ç«‹å³ç¦ç”¨ä»£ç†
disable_proxy()


def get_proxy_config() -> Dict[str, Optional[str]]:
    """
    ä»ç¯å¢ƒå˜é‡è¯»å–ä»£ç†é…ç½®

    Returns:
        ä»£ç†é…ç½®å­—å…¸ï¼Œæ ¼å¼ä¸º {"http": proxy_url, "https": proxy_url}
        æ³¨æ„ï¼šå½“å‰å·²å¼ºåˆ¶ç¦ç”¨ä»£ç†ä»¥é¿å…è¿æ¥é—®é¢˜
    """
    # å¼ºåˆ¶ç¦ç”¨ä»£ç†ï¼ˆé¿å…ä»£ç†è¿æ¥é—®é¢˜ï¼‰
    print(f"[ğŸ”§ ä»£ç†é…ç½®] å¼ºåˆ¶ç¦ç”¨ä»£ç†ï¼Œç›´æ¥è¿æ¥")
    return {"http": None, "https": None}

    # åŸå§‹ä»£ç å·²æ³¨é‡Šï¼ˆå¦‚æœéœ€è¦å¯ç”¨ä»£ç†ï¼Œå–æ¶ˆä¸‹é¢çš„æ³¨é‡Šï¼‰
    # http_proxy = os.getenv("HTTP_PROXY") or os.getenv("http_proxy")
    # https_proxy = os.getenv("HTTPS_PROXY") or os.getenv("https_proxy")
    #
    # if http_proxy or https_proxy:
    #     proxies = {
    #         "http": http_proxy,
    #         "https": https_proxy or http_proxy
    #     }
    #     print(f"[ğŸ”§ ä»£ç†é…ç½®] ä½¿ç”¨ä»£ç†: HTTP={http_proxy}, HTTPS={https_proxy or http_proxy}")
    #     return proxies
    # else:
    #     print(f"[ğŸ”§ ä»£ç†é…ç½®] æœªè®¾ç½®ä»£ç†ï¼Œç›´æ¥è¿æ¥")
    #     return {"http": None, "https": None}


class InternalAPIClient:
    """å…¬å¸å†…éƒ¨APIå®¢æˆ·ç«¯ï¼ˆä½¿ç”¨OpenAI SDKï¼‰"""

    def __init__(self, api_key: Optional[str] = None, base_url: Optional[str] = None, model_type: str = 'internal_api'):
        """
        åˆå§‹åŒ–å…¬å¸å†…éƒ¨APIå®¢æˆ·ç«¯

        Args:
            api_key: APIå¯†é’¥ï¼Œå¦‚æœä¸æä¾›åˆ™ä»ç¯å¢ƒå˜é‡è¯»å–
            base_url: APIåŸºç¡€URLï¼Œå¦‚æœä¸æä¾›åˆ™ä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œé»˜è®¤ä½¿ç”¨hkç¯å¢ƒ
            model_type: æ¨¡å‹ç±»å‹ï¼Œä»é…ç½®æ–‡ä»¶ä¸­è¯»å–ï¼ˆinternal_api, visionç­‰ï¼‰ï¼Œé»˜è®¤ä¸ºinternal_api
        """
        self.api_key = api_key or os.getenv("INTERNAL_API_KEY")
        if not self.api_key:
            raise ValueError("è¯·è®¾ç½® INTERNAL_API_KEY ç¯å¢ƒå˜é‡")

        # æ”¯æŒé€šè¿‡ç¯å¢ƒå˜é‡é…ç½®base_urlï¼Œé»˜è®¤ä½¿ç”¨hkç¯å¢ƒï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
        # å¯é€‰å€¼ï¼šhk-intra-paasï¼ˆç”Ÿäº§ï¼‰æˆ– uat-intra-paasï¼ˆæµ‹è¯•ï¼‰
        if base_url:
            self.base_url = base_url
        else:
            # ä¼˜å…ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨hkç¯å¢ƒ
            env_base_url = os.getenv("INTERNAL_API_BASE_URL")
            if env_base_url:
                self.base_url = env_base_url
            else:
                # é»˜è®¤ä½¿ç”¨hkç¯å¢ƒï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
                self.base_url = "https://hk-intra-paas.transsion.com/tranai-proxy/v1"

        # ä»é…ç½®æ–‡ä»¶åŠ è½½æ¨¡å‹åç§°ï¼ˆæ ¹æ®model_typeï¼‰
        config = get_config()
        models = config.get_llm_models()
        self.model = models.get(model_type, 'gpt-4o')
        self.model_type = model_type  # è®°å½•æ¨¡å‹ç±»å‹

        if HAS_OPENAI_SDK:
            # OpenAI SDKä¼šè‡ªåŠ¨æ·»åŠ Bearerå‰ç¼€ï¼Œæ‰€ä»¥ç›´æ¥ä¼ å…¥api_keyå³å¯
            # æ·»åŠ è¶…æ—¶è®¾ç½®ä»¥é¿å…é•¿æ—¶é—´æŒ‚èµ·
            import httpx
            timeout_config = httpx.Timeout(
                connect=10.0,  # è¿æ¥è¶…æ—¶10ç§’
                read=60.0,     # è¯»å–è¶…æ—¶60ç§’
                write=30.0,    # å†™å…¥è¶…æ—¶30ç§’
                pool=10.0      # è¿æ¥æ± è¶…æ—¶10ç§’
            )
            self.client = OpenAI(
                api_key=self.api_key,
                base_url=self.base_url,
                timeout=timeout_config,
                max_retries=2,   # æœ€å¤šé‡è¯•2æ¬¡
                http_client=httpx.Client(
                    timeout=timeout_config,
                    limits=httpx.Limits(max_keepalive_connections=5, max_connections=10),
                    proxy=None,  # æ˜ç¡®ç¦ç”¨ä»£ç†
                    trust_env=False  # å…³é”®ï¼šä¸è¯»å–ç¯å¢ƒå˜é‡ä¸­çš„ä»£ç†è®¾ç½®ï¼
                )
            )
            logger.info(f"âœ… å…¬å¸å†…éƒ¨APIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ (è¶…æ—¶: connect=10s, read=60s, ä»£ç†: å·²å¼ºåˆ¶ç¦ç”¨)")
        else:
            self.client = None
    
    def is_available(self) -> bool:
        """æ£€æŸ¥APIæ˜¯å¦å¯ç”¨ï¼ˆéœ€è¦å†…ç½‘ç¯å¢ƒï¼‰"""
        if not HAS_OPENAI_SDK:
            return False
        if not self.client:
            return False
        # å¯ä»¥å°è¯•ä¸€ä¸ªç®€å•çš„å¥åº·æ£€æŸ¥
        # è¿™é‡Œå…ˆè¿”å›Trueï¼Œå®é™…å¯ç”¨æ€§åœ¨è°ƒç”¨æ—¶åˆ¤æ–­
        return True
    
    def call_llm(self, prompt: str, system_prompt: Optional[str] = None,
                 max_tokens: Optional[int] = None, temperature: Optional[float] = None,
                 model: Optional[str] = None) -> str:
        """
        è°ƒç”¨LLM

        Args:
            prompt: ç”¨æˆ·æç¤ºè¯
            system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰
            max_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»é…ç½®åŠ è½½ï¼‰
            temperature: æ¸©åº¦å‚æ•°ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»é…ç½®åŠ è½½ï¼‰
            model: æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨gpt-4oï¼‰

        Returns:
            æ¨¡å‹è¿”å›çš„æ–‡æœ¬å†…å®¹

        Raises:
            ValueError: APIè°ƒç”¨å¤±è´¥
        """
        if not HAS_OPENAI_SDK:
            raise ValueError("OpenAI SDKæœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨å…¬å¸å†…éƒ¨API")

        if not self.client:
            raise ValueError("å…¬å¸å†…éƒ¨APIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")

        # ä»é…ç½®åŠ è½½é»˜è®¤å‚æ•°
        config = get_config()
        if max_tokens is None:
            params = config.get_llm_params('default')
            max_tokens = params.get('max_tokens', 2000)
        if temperature is None:
            params = config.get_llm_params('default')
            temperature = params.get('temperature', 0.3)

        model_name = model or self.model

        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})

        try:
            print(f"\n{'='*80}")
            print(f"[ğŸ¢ å…¬å¸å†…éƒ¨API] å¼€å§‹è°ƒç”¨ {model_name}")
            print(f"{'='*80}")
            print(f"[ğŸ“¤ è¾“å…¥] Base URL: {self.base_url}")
            print(f"[ğŸ“¤ è¾“å…¥] Model: {model_name}")
            print(f"[ğŸ“¤ è¾“å…¥] Max Tokens: {max_tokens}")
            print(f"[ğŸ“¤ è¾“å…¥] Temperature: {temperature}")
            print(f"[ğŸ“¤ è¾“å…¥] System Prompt é•¿åº¦: {len(system_prompt) if system_prompt else 0} å­—ç¬¦")
            print(f"[ğŸ“¤ è¾“å…¥] User Prompt é•¿åº¦: {len(prompt)} å­—ç¬¦")
            if system_prompt:
                print(f"[ğŸ“¤ è¾“å…¥] System Prompt (å‰500å­—ç¬¦):\n{system_prompt[:500]}...")
            print(f"[ğŸ“¤ è¾“å…¥] User Prompt (å‰500å­—ç¬¦):\n{prompt[:500]}...")

            start_time = time.time()

            # æ·»åŠ é¢å¤–çš„è¶…æ—¶ä¿æŠ¤ï¼Œä½¿ç”¨çº¿ç¨‹æ± è¿è¡Œ
            import concurrent.futures
            import signal

            def call_api_with_timeout():
                return self.client.chat.completions.create(
                    model=model_name,
                    messages=messages,
                    max_tokens=max_tokens,
                    temperature=temperature
                )

            # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œï¼Œè®¾ç½®60ç§’è¶…æ—¶
            with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
                future = executor.submit(call_api_with_timeout)
                try:
                    completion = future.result(timeout=60)  # 60ç§’è¶…æ—¶
                except concurrent.futures.TimeoutError:
                    print(f"[âŒ é”™è¯¯] APIè°ƒç”¨è¶…æ—¶ï¼ˆ60ç§’ï¼‰ï¼Œå–æ¶ˆè¯·æ±‚...")
                    future.cancel()
                    raise TimeoutError("å…¬å¸å†…éƒ¨APIè°ƒç”¨è¶…æ—¶ï¼ˆ60ç§’ï¼‰")

            elapsed_time = time.time() - start_time

            print(f"\n[ğŸ“¥ å“åº”] å“åº”æ—¶é—´: {elapsed_time:.2f} ç§’")

            if completion.choices and len(completion.choices) > 0:
                content = completion.choices[0].message.content
                if content and content.strip():
                    print(f"[ğŸ“¥ å“åº”] Content é•¿åº¦: {len(content)} å­—ç¬¦")
                    print(f"[ğŸ“¥ å“åº”] Content (å‰1000å­—ç¬¦):\n{content[:1000]}...")
                    print(f"{'='*80}\n")
                    return content.strip()
                else:
                    raise ValueError("API å“åº”ä¸­ content ä¸ºç©ºå­—ç¬¦ä¸²")
            else:
                raise ValueError("API å“åº”æ ¼å¼å¼‚å¸¸ï¼Œç¼ºå°‘ choices å­—æ®µ")

        except TimeoutError as e:
            error_msg = str(e)
            print(f"[âŒ é”™è¯¯] å…¬å¸å†…éƒ¨APIè°ƒç”¨è¶…æ—¶: {error_msg}")
            print(f"[âŒ é”™è¯¯] å»ºè®®: æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–å‡å°è¯·æ±‚ä½“å¤§å°")
            # è¶…æ—¶é”™è¯¯ä¸åº”è¯¥ç«‹å³å¤±è´¥ï¼Œåº”è¯¥å…è®¸é™çº§åˆ°å¤‡ç”¨API
            raise TimeoutError(f"å…¬å¸å†…éƒ¨APIè°ƒç”¨è¶…æ—¶: {error_msg}")

        except Exception as e:
            error_msg = str(e)
            print(f"[âŒ é”™è¯¯] å…¬å¸å†…éƒ¨APIè°ƒç”¨å¤±è´¥: {error_msg}")
            print(f"[âŒ é”™è¯¯] å¼‚å¸¸ç±»å‹: {type(e).__name__}")

            # æ£€æŸ¥æ˜¯å¦æ˜¯405é”™è¯¯ï¼ˆWAFæ‹¦æˆªï¼‰
            if '405' in error_msg or 'blocked' in error_msg.lower():
                print(f"[âš ï¸ è­¦å‘Š] è¯·æ±‚è¢«WAFæ‹¦æˆªï¼Œå¯èƒ½åŸå› :")
                print(f"  - è¯·æ±‚ä½“è¿‡å¤§ ({len(prompt)} å­—ç¬¦)")
                print(f"  - User-Agentæˆ–è¯·æ±‚å¤´é—®é¢˜")
                print(f"  - è§¦å‘äº†å®‰å…¨è§„åˆ™")
                print(f"[ğŸ’¡ å»ºè®®] å°è¯•å‡å°è¯·æ±‚ä½“æˆ–è”ç³»APIç®¡ç†å‘˜")

            import traceback
            print(f"[âŒ é”™è¯¯] å¼‚å¸¸å †æ ˆ:\n{traceback.format_exc()}")
            raise ValueError(f"å…¬å¸å†…éƒ¨APIè°ƒç”¨å¤±è´¥: {error_msg}")
    
    def _image_to_base64(self, image_path: str) -> str:
        """
        å°†æœ¬åœ°å›¾ç‰‡æ–‡ä»¶è½¬æ¢ä¸ºbase64ç¼–ç çš„data URI
        
        Args:
            image_path: å›¾ç‰‡æ–‡ä»¶è·¯å¾„
        
        Returns:
            base64ç¼–ç çš„data URIå­—ç¬¦ä¸²
        """
        image_path = Path(image_path)
        if not image_path.exists():
            raise FileNotFoundError(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        
        # è¯»å–å›¾ç‰‡æ–‡ä»¶
        with open(image_path, 'rb') as f:
            image_data = f.read()
        
        # è½¬æ¢ä¸ºbase64
        image_base64 = base64.b64encode(image_data).decode('utf-8')
        
        # æ ¹æ®æ–‡ä»¶æ‰©å±•åç¡®å®šMIMEç±»å‹
        ext = image_path.suffix.lower()
        mime_types = {
            '.jpg': 'image/jpeg',
            '.jpeg': 'image/jpeg',
            '.png': 'image/png',
            '.gif': 'image/gif',
            '.webp': 'image/webp'
        }
        mime_type = mime_types.get(ext, 'image/jpeg')
        
        # è¿”å›data URIæ ¼å¼
        return f"data:{mime_type};base64,{image_base64}"
    
    def call_with_vision(self, prompt: str,
                        image_url: Optional[str] = None,
                        image_paths: Optional[List[str]] = None,
                        max_tokens: Optional[int] = None,
                        temperature: Optional[float] = None) -> str:
        """
        è°ƒç”¨è§†è§‰æ¨¡å‹ï¼ˆè§£æå›¾ç‰‡ï¼‰
        æŒ‰ç…§å†…éƒ¨APIç¤ºä¾‹ä»£ç å®ç°ï¼Œæ”¯æŒURLå’Œæœ¬åœ°æ–‡ä»¶

        Args:
            prompt: æ–‡æœ¬æç¤ºè¯
            image_url: å›¾ç‰‡URLï¼ˆå¯é€‰ï¼Œä¸image_pathsäºŒé€‰ä¸€ï¼‰
            image_paths: æœ¬åœ°å›¾ç‰‡æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œä¸image_urläºŒé€‰ä¸€ï¼‰
            max_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»é…ç½®åŠ è½½ï¼‰
            temperature: æ¸©åº¦å‚æ•°ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»é…ç½®åŠ è½½ï¼‰

        Returns:
            æ¨¡å‹è¿”å›çš„æ–‡æœ¬å†…å®¹

        Raises:
            ValueError: å‚æ•°é”™è¯¯æˆ–APIè°ƒç”¨å¤±è´¥
        """
        if not HAS_OPENAI_SDK:
            raise ValueError("OpenAI SDKæœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨å…¬å¸å†…éƒ¨API")

        if not self.client:
            raise ValueError("å…¬å¸å†…éƒ¨APIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")

        # ä»é…ç½®åŠ è½½é»˜è®¤å‚æ•°
        config = get_config()
        if max_tokens is None:
            params = config.get_llm_params('vision')
            max_tokens = params.get('max_tokens', 300)
        if temperature is None:
            params = config.get_llm_params('vision')
            temperature = params.get('temperature', 0.3)

        # æ„å»ºcontentæ•°ç»„
        content = [{"type": "text", "text": prompt}]

        # å¤„ç†å›¾ç‰‡è¾“å…¥
        if image_url:
            # ä½¿ç”¨URLï¼ˆæ”¯æŒHTTP/HTTPS URLæˆ–data URIï¼‰
            content.append({
                "type": "image_url",
                "image_url": {"url": image_url}
            })
        elif image_paths:
            # ä½¿ç”¨æœ¬åœ°æ–‡ä»¶ï¼ˆè½¬æ¢ä¸ºbase64ï¼‰
            for image_path in image_paths:
                base64_data_uri = self._image_to_base64(image_path)
                content.append({
                    "type": "image_url",
                    "image_url": {"url": base64_data_uri}
                })
        else:
            raise ValueError("å¿…é¡»æä¾› image_url æˆ– image_paths å‚æ•°")

        messages = [{"role": "user", "content": content}]

        try:
            print(f"\n{'='*80}")
            print(f"[ğŸ¢ å…¬å¸å†…éƒ¨API] å¼€å§‹è°ƒç”¨è§†è§‰æ¨¡å‹ {self.model}")
            print(f"{'='*80}")
            print(f"[ğŸ“¤ è¾“å…¥] Prompt é•¿åº¦: {len(prompt)} å­—ç¬¦")
            if image_url:
                print(f"[ğŸ“¤ è¾“å…¥] Image URL: {image_url}")
            if image_paths:
                print(f"[ğŸ“¤ è¾“å…¥] å›¾ç‰‡æ•°é‡: {len(image_paths)}")
                for i, path in enumerate(image_paths, 1):
                    print(f"[ğŸ“¤ è¾“å…¥]   å›¾ç‰‡ {i}: {path}")
            print(f"[ğŸ“¤ è¾“å…¥] Max Tokens: {max_tokens}")
            print(f"[ğŸ“¤ è¾“å…¥] Temperature: {temperature}")

            start_time = time.time()
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature
            )
            elapsed_time = time.time() - start_time

            print(f"\n[ğŸ“¥ å“åº”] å“åº”æ—¶é—´: {elapsed_time:.2f} ç§’")

            if response.choices and len(response.choices) > 0:
                content_text = response.choices[0].message.content
                if content_text and content_text.strip():
                    print(f"[ğŸ“¥ å“åº”] Content é•¿åº¦: {len(content_text)} å­—ç¬¦")
                    print(f"[ğŸ“¥ å“åº”] Content (å‰1000å­—ç¬¦):\n{content_text[:1000]}...")
                    print(f"{'='*80}\n")
                    return content_text.strip()
                else:
                    raise ValueError("API å“åº”ä¸­ content ä¸ºç©ºå­—ç¬¦ä¸²")
            else:
                raise ValueError("API å“åº”æ ¼å¼å¼‚å¸¸ï¼Œç¼ºå°‘ choices å­—æ®µ")

        except Exception as e:
            error_msg = str(e)
            print(f"[âŒ é”™è¯¯] å…¬å¸å†…éƒ¨APIè§†è§‰è°ƒç”¨å¤±è´¥: {error_msg}")
            print(f"[âŒ é”™è¯¯] å¼‚å¸¸ç±»å‹: {type(e).__name__}")
            import traceback
            print(f"[âŒ é”™è¯¯] å¼‚å¸¸å †æ ˆ:\n{traceback.format_exc()}")
            raise ValueError(f"å…¬å¸å†…éƒ¨APIè§†è§‰è°ƒç”¨å¤±è´¥: {error_msg}")


class AIBuildersAPIClient:
    """AI Builders APIå®¢æˆ·ç«¯ï¼ˆå¤‡ç”¨ï¼‰"""
    
    def __init__(self, api_token: Optional[str] = None):
        """
        åˆå§‹åŒ–AI Builders APIå®¢æˆ·ç«¯
        
        Args:
            api_token: APIä»¤ç‰Œï¼Œå¦‚æœä¸æä¾›åˆ™ä»ç¯å¢ƒå˜é‡è¯»å–
        """
        self.api_token = api_token or os.getenv("AI_BUILDER_TOKEN")
        if not self.api_token:
            raise ValueError("è¯·è®¾ç½® AI_BUILDER_TOKEN ç¯å¢ƒå˜é‡")
        
        self.base_url = "https://space.ai-builders.com/backend"
        self.headers = {
            "Authorization": f"Bearer {self.api_token}",
            "Content-Type": "application/json"
        }
    
    def call_llm(self, prompt: str, system_prompt: Optional[str] = None,
                 max_tokens: Optional[int] = None, temperature: Optional[float] = None,
                 model: str = "deepseek") -> str:
        """
        è°ƒç”¨LLM

        Args:
            prompt: ç”¨æˆ·æç¤ºè¯
            system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰
            max_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»é…ç½®åŠ è½½ï¼‰
            temperature: æ¸©åº¦å‚æ•°ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»é…ç½®åŠ è½½ï¼‰
            model: æ¨¡å‹åç§°ï¼ˆdeepseek æˆ– gemini-2.5-proï¼‰

        Returns:
            æ¨¡å‹è¿”å›çš„æ–‡æœ¬å†…å®¹
        """
        # ä»é…ç½®åŠ è½½é»˜è®¤å‚æ•°
        config = get_config()
        if max_tokens is None:
            params = config.get_llm_params('default')
            max_tokens = params.get('max_tokens', 2000)
        if temperature is None:
            params = config.get_llm_params('default')
            temperature = params.get('temperature', 0.3)

        endpoint = f"{self.base_url}/v1/chat/completions"

        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})

        payload = {
            "model": model,
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": temperature
        }

        print(f"\n{'='*80}")
        print(f"[ğŸŒ AI Builders API] å¼€å§‹è°ƒç”¨ {model}")
        print(f"{'='*80}")
        print(f"[ğŸ“¤ è¾“å…¥] Endpoint: {endpoint}")
        print(f"[ğŸ“¤ è¾“å…¥] Model: {model}")
        print(f"[ğŸ“¤ è¾“å…¥] Max Tokens: {max_tokens}")
        print(f"[ğŸ“¤ è¾“å…¥] Temperature: {temperature}")
        print(f"[ğŸ“¤ è¾“å…¥] System Prompt é•¿åº¦: {len(system_prompt) if system_prompt else 0} å­—ç¬¦")
        print(f"[ğŸ“¤ è¾“å…¥] User Prompt é•¿åº¦: {len(prompt)} å­—ç¬¦")
        if system_prompt:
            print(f"[ğŸ“¤ è¾“å…¥] System Prompt (å‰500å­—ç¬¦):\n{system_prompt[:500]}...")
        print(f"[ğŸ“¤ è¾“å…¥] User Prompt (å‰500å­—ç¬¦):\n{prompt[:500]}...")

        try:
            start_time = time.time()
            response = requests.post(
                endpoint,
                headers=self.headers,
                json=payload,
                params={"debug": "true"},
                timeout=300,
                proxies=get_proxy_config()
            )
            elapsed_time = time.time() - start_time

            print(f"\n[ğŸ“¥ å“åº”] HTTP çŠ¶æ€ç : {response.status_code}")
            print(f"[ğŸ“¥ å“åº”] å“åº”æ—¶é—´: {elapsed_time:.2f} ç§’")

            if response.status_code == 200:
                result = response.json()
                if "choices" in result and len(result["choices"]) > 0:
                    choice = result["choices"][0]
                    message = choice.get("message", {})
                    content = message.get("content", "")

                    if content and content.strip():
                        print(f"[ğŸ“¥ å“åº”] Content é•¿åº¦: {len(content)} å­—ç¬¦")
                        print(f"[ğŸ“¥ å“åº”] Content (å‰1000å­—ç¬¦):\n{content[:1000]}...")
                        print(f"{'='*80}\n")
                        return content.strip()
                    else:
                        # å¦‚æœ deepseek å¤±è´¥ï¼Œå°è¯• gemini
                        if model == "deepseek":
                            print(f"    [âš ï¸ è­¦å‘Š] DeepSeek è¿”å›ç©ºå†…å®¹ï¼Œå°è¯• Gemini...")
                            return self.call_llm(prompt, system_prompt, max_tokens, temperature, "gemini-2.5-pro")
                        raise ValueError("API å“åº”ä¸­ content ä¸ºç©ºå­—ç¬¦ä¸²")
                else:
                    raise ValueError("API å“åº”æ ¼å¼å¼‚å¸¸ï¼Œç¼ºå°‘ choices å­—æ®µ")
            else:
                error_text = response.text[:500] if hasattr(response, 'text') else 'N/A'
                print(f"[âŒ é”™è¯¯] API è°ƒç”¨å¤±è´¥")
                print(f"[âŒ é”™è¯¯] çŠ¶æ€ç : {response.status_code}")
                print(f"[âŒ é”™è¯¯] é”™è¯¯å“åº”: {error_text}")
                raise ValueError(f"API è°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")

        except requests.exceptions.RequestException as e:
            print(f"[âŒ é”™è¯¯] API è¯·æ±‚å¼‚å¸¸: {str(e)}")
            print(f"[âŒ é”™è¯¯] å¼‚å¸¸ç±»å‹: {type(e).__name__}")
            import traceback
            print(f"[âŒ é”™è¯¯] å¼‚å¸¸å †æ ˆ:\n{traceback.format_exc()}")
            raise ValueError(f"API è¯·æ±‚å¼‚å¸¸: {str(e)}")
    
    def call_gemini(self, prompt: str, system_prompt: Optional[str] = None,
                    max_tokens: int = 8000, temperature: float = 0.3) -> str:
        """
        è°ƒç”¨Geminiæ¨¡å‹
        
        Args:
            prompt: ç”¨æˆ·æç¤ºè¯
            system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰
            max_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°
            temperature: æ¸©åº¦å‚æ•°
        
        Returns:
            æ¨¡å‹è¿”å›çš„æ–‡æœ¬å†…å®¹
        """
        return self.call_llm(prompt, system_prompt, max_tokens, temperature, "gemini-2.5-pro")


class UnifiedLLMClient:
    """
    ç»Ÿä¸€çš„LLMå®¢æˆ·ç«¯
    ä¼˜å…ˆä½¿ç”¨å…¬å¸å†…éƒ¨APIï¼Œå¤±è´¥æ—¶fallbackåˆ°AI Builders API
    """
    
    def __init__(self, internal_api_key: Optional[str] = None,
                 ai_builder_token: Optional[str] = None,
                 internal_base_url: Optional[str] = None):
        """
        åˆå§‹åŒ–ç»Ÿä¸€LLMå®¢æˆ·ç«¯
        
        Args:
            internal_api_key: å…¬å¸å†…éƒ¨APIå¯†é’¥ï¼ˆå¯é€‰ï¼‰
            ai_builder_token: AI Builders APIä»¤ç‰Œï¼ˆå¯é€‰ï¼‰
            internal_base_url: å…¬å¸å†…éƒ¨APIåŸºç¡€URLï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨hkç¯å¢ƒï¼‰
        """
        self.internal_client = None
        self.ai_builders_client = None
        
        # å°è¯•åˆå§‹åŒ–å…¬å¸å†…éƒ¨APIå®¢æˆ·ç«¯
        try:
            self.internal_client = InternalAPIClient(
                api_key=internal_api_key,
                base_url=internal_base_url
            )
            if self.internal_client.is_available():
                print(f"[âœ…] å…¬å¸å†…éƒ¨APIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ (Base URL: {self.internal_client.base_url})")
            else:
                print("[âš ï¸] å…¬å¸å†…éƒ¨APIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼ˆå¯èƒ½ä¸åœ¨å†…ç½‘ç¯å¢ƒï¼‰")
                self.internal_client = None
        except Exception as e:
            print(f"[âš ï¸] å…¬å¸å†…éƒ¨APIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.internal_client = None
        
        # åˆå§‹åŒ–AI Builders APIå®¢æˆ·ç«¯ï¼ˆå¤‡ç”¨ï¼‰
        try:
            self.ai_builders_client = AIBuildersAPIClient(ai_builder_token)
            print("[âœ…] AI Builders APIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"[âš ï¸] AI Builders APIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            # å¦‚æœä¸¤ä¸ªå®¢æˆ·ç«¯éƒ½å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
            if not self.internal_client:
                raise ValueError("æ— æ³•åˆå§‹åŒ–ä»»ä½•APIå®¢æˆ·ç«¯ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡é…ç½®")

        # åˆå§‹åŒ–Metasoæœç´¢å®¢æˆ·ç«¯ï¼ˆä¸»è¦æœç´¢å¼•æ“ï¼‰
        try:
            self.metaso_client = MetasoSearchClient()
            print("[âœ…] Metasoæœç´¢å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            print(f"[ğŸ’° Metaso] å…è´¹é¢åº¦: 5,000 æ¬¡ï¼Œè¶…å‡ºå Â¥0.03/æ¬¡")
        except Exception as e:
            print(f"[âš ï¸] Metasoæœç´¢å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            print(f"[â„¹ï¸] å°†ä½¿ç”¨ AI Builders Tavily ä½œä¸ºä¸»è¦æœç´¢å¼•æ“")
            self.metaso_client = None

        # åˆå§‹åŒ–Googleæœç´¢å®¢æˆ·ç«¯ï¼ˆå…è´¹é¢åº¦ä¼˜å…ˆï¼‰
        try:
            from search_strategist import SearchHunter
            google_api_key = os.getenv("GOOGLE_API_KEY")
            google_cx = os.getenv("GOOGLE_CX")
            if google_api_key and google_cx:
                self.google_hunter = SearchHunter(search_engine="google", llm_client=None)
                self.google_usage = 0  # ä½¿ç”¨è®¡æ•°å™¨ï¼ˆæ¯å¤©é‡ç½®ï¼‰
                print("[âœ…] Googleæœç´¢å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
                print(f"[ğŸ’° Google] å…è´¹é¢åº¦: 10,000 æ¬¡/å¤©ï¼Œå®Œå…¨å…è´¹")
            else:
                self.google_hunter = None
                self.google_usage = 0
                print("[âš ï¸] Googleæœç´¢å®¢æˆ·ç«¯æœªé…ç½®ï¼ˆç¼ºå°‘ GOOGLE_API_KEY æˆ– GOOGLE_CXï¼‰")
        except Exception as e:
            self.google_hunter = None
            self.google_usage = 0
            print(f"[âš ï¸] Googleæœç´¢å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}")

        # åˆå§‹åŒ–Baiduæœç´¢å®¢æˆ·ç«¯ï¼ˆä¸­æ–‡å¤‡ç”¨ï¼‰
        try:
            from baidu_search_client import BaiduSearchClient
            baidu_api_key = os.getenv("BAIDU_API_KEY")
            baidu_secret_key = os.getenv("BAIDU_SECRET_KEY")
            if baidu_api_key and baidu_secret_key:
                self.baidu_hunter = BaiduSearchClient()
                self.baidu_usage = 0  # ä½¿ç”¨è®¡æ•°å™¨ï¼ˆæ¯å¤©é‡ç½®ï¼‰
                print("[âœ…] Baiduæœç´¢å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
                print(f"[ğŸ’° Baidu] å…è´¹é¢åº¦: 100 æ¬¡/å¤©ï¼Œå®Œå…¨å…è´¹")
            else:
                self.baidu_hunter = None
                self.baidu_usage = 0
                print("[âš ï¸] Baiduæœç´¢å®¢æˆ·ç«¯æœªé…ç½®ï¼ˆç¼ºå°‘ BAIDU_API_KEY æˆ– BAIDU_SECRET_KEYï¼‰")
        except Exception as e:
            self.baidu_hunter = None
            self.baidu_usage = 0
            print(f"[âš ï¸] Baiduæœç´¢å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}")

        # åˆå§‹åŒ– Tavily ä½¿ç”¨è®¡æ•°å™¨ï¼ˆæ¯æœˆé‡ç½®ï¼‰
        self.tavily_usage = 0

    def call_llm(self, prompt: str, system_prompt: Optional[str] = None,
                 max_tokens: int = 2000, temperature: float = 0.3,
                 model: str = "deepseek") -> str:
        """
        è°ƒç”¨LLMï¼ˆå¸¦fallbackæœºåˆ¶ï¼‰
        
        Args:
            prompt: ç”¨æˆ·æç¤ºè¯
            system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰
            max_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°
            temperature: æ¸©åº¦å‚æ•°
            model: æ¨¡å‹åç§°ï¼ˆå¯¹äºå…¬å¸å†…éƒ¨APIï¼Œä¼šä½¿ç”¨gpt-4oï¼›å¯¹äºAI Buildersï¼Œä½¿ç”¨ä¼ å…¥çš„modelï¼‰
        
        Returns:
            æ¨¡å‹è¿”å›çš„æ–‡æœ¬å†…å®¹
        
        Raises:
            ValueError: æ‰€æœ‰APIè°ƒç”¨éƒ½å¤±è´¥
        """
        # ä¼˜å…ˆä½¿ç”¨å…¬å¸å†…éƒ¨API
        if self.internal_client:
            try:
                print(f"[ğŸ”„] å°è¯•ä½¿ç”¨å…¬å¸å†…éƒ¨API...")
                return self.internal_client.call_llm(
                    prompt=prompt,
                    system_prompt=system_prompt,
                    max_tokens=max_tokens,
                    temperature=temperature,
                    model=None  # å…¬å¸å†…éƒ¨APIä½¿ç”¨gpt-4o
                )
            except Exception as e:
                print(f"[âš ï¸] å…¬å¸å†…éƒ¨APIè°ƒç”¨å¤±è´¥: {str(e)}")
                print(f"[ğŸ”„] åˆ‡æ¢åˆ°AI Builders API...")
                # Fallbackåˆ°AI Builders API
                if self.ai_builders_client:
                    return self.ai_builders_client.call_llm(
                        prompt=prompt,
                        system_prompt=system_prompt,
                        max_tokens=max_tokens,
                        temperature=temperature,
                        model=model
                    )
                else:
                    raise ValueError("å…¬å¸å†…éƒ¨APIå¤±è´¥ï¼Œä¸”AI Builders APIä¸å¯ç”¨")
        else:
            # å¦‚æœæ²¡æœ‰å…¬å¸å†…éƒ¨APIï¼Œç›´æ¥ä½¿ç”¨AI Builders API
            if self.ai_builders_client:
                print(f"[ğŸ”„] ä½¿ç”¨AI Builders APIï¼ˆå…¬å¸å†…éƒ¨APIä¸å¯ç”¨ï¼‰...")
                return self.ai_builders_client.call_llm(
                    prompt=prompt,
                    system_prompt=system_prompt,
                    max_tokens=max_tokens,
                    temperature=temperature,
                    model=model
                )
            else:
                raise ValueError("æ²¡æœ‰å¯ç”¨çš„APIå®¢æˆ·ç«¯")
    
    def call_gemini(self, prompt: str, system_prompt: Optional[str] = None,
                    max_tokens: int = 8000, temperature: float = 0.3) -> str:
        """
        è°ƒç”¨Geminiæ¨¡å‹ï¼ˆå¸¦fallbackæœºåˆ¶ï¼‰
        
        Args:
            prompt: ç”¨æˆ·æç¤ºè¯
            system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰
            max_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°
            temperature: æ¸©åº¦å‚æ•°
        
        Returns:
            æ¨¡å‹è¿”å›çš„æ–‡æœ¬å†…å®¹
        """
        # ä¼˜å…ˆä½¿ç”¨å…¬å¸å†…éƒ¨APIï¼ˆä½¿ç”¨gpt-4oï¼‰
        if self.internal_client:
            try:
                print(f"[ğŸ”„] å°è¯•ä½¿ç”¨å…¬å¸å†…éƒ¨APIï¼ˆGeminiä»»åŠ¡ï¼‰...")
                return self.internal_client.call_llm(
                    prompt=prompt,
                    system_prompt=system_prompt,
                    max_tokens=max_tokens,
                    temperature=temperature,
                    model=None
                )
            except Exception as e:
                print(f"[âš ï¸] å…¬å¸å†…éƒ¨APIè°ƒç”¨å¤±è´¥: {str(e)}")
                print(f"[ğŸ”„] åˆ‡æ¢åˆ°AI Builders APIï¼ˆGeminiï¼‰...")
                if self.ai_builders_client:
                    return self.ai_builders_client.call_gemini(
                        prompt=prompt,
                        system_prompt=system_prompt,
                        max_tokens=max_tokens,
                        temperature=temperature
                    )
                else:
                    raise ValueError("å…¬å¸å†…éƒ¨APIå¤±è´¥ï¼Œä¸”AI Builders APIä¸å¯ç”¨")
        else:
            if self.ai_builders_client:
                print(f"[ğŸ”„] ä½¿ç”¨AI Builders APIï¼ˆGeminiï¼Œå…¬å¸å†…éƒ¨APIä¸å¯ç”¨ï¼‰...")
                return self.ai_builders_client.call_gemini(
                    prompt=prompt,
                    system_prompt=system_prompt,
                    max_tokens=max_tokens,
                    temperature=temperature
                )
            else:
                raise ValueError("æ²¡æœ‰å¯ç”¨çš„APIå®¢æˆ·ç«¯")
    
    def call_with_vision(self, prompt: str,
                         image_url: Optional[str] = None,
                         image_paths: Optional[List[str]] = None,
                         max_tokens: int = 300, 
                         temperature: float = 0.3) -> str:
        """
        è°ƒç”¨è§†è§‰æ¨¡å‹ï¼ˆè§£æå›¾ç‰‡ï¼‰
        æŒ‰ç…§å†…éƒ¨APIç¤ºä¾‹ä»£ç å®ç°ï¼Œæ”¯æŒURLå’Œæœ¬åœ°æ–‡ä»¶
        
        Args:
            prompt: æ–‡æœ¬æç¤ºè¯
            image_url: å›¾ç‰‡URLï¼ˆå¯é€‰ï¼Œä¸image_pathsäºŒé€‰ä¸€ï¼‰
            image_paths: æœ¬åœ°å›¾ç‰‡æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œä¸image_urläºŒé€‰ä¸€ï¼‰
            max_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°
            temperature: æ¸©åº¦å‚æ•°
        
        Returns:
            æ¨¡å‹è¿”å›çš„æ–‡æœ¬å†…å®¹
        
        Raises:
            ValueError: å‚æ•°é”™è¯¯æˆ–æ‰€æœ‰APIè°ƒç”¨éƒ½å¤±è´¥
        """
        # ä¼˜å…ˆä½¿ç”¨å…¬å¸å†…éƒ¨APIï¼ˆæ”¯æŒè§†è§‰ï¼‰
        if self.internal_client:
            try:
                print(f"[ğŸ”„] å°è¯•ä½¿ç”¨å…¬å¸å†…éƒ¨APIï¼ˆè§†è§‰ä»»åŠ¡ï¼‰...")
                return self.internal_client.call_with_vision(
                    prompt=prompt,
                    image_url=image_url,
                    image_paths=image_paths,
                    max_tokens=max_tokens,
                    temperature=temperature
                )
            except Exception as e:
                print(f"[âš ï¸] å…¬å¸å†…éƒ¨APIè§†è§‰è°ƒç”¨å¤±è´¥: {str(e)}")
                # AI Builders APIä¸æ”¯æŒè§†è§‰ï¼ŒæŠ›å‡ºå¼‚å¸¸
                raise ValueError(f"å…¬å¸å†…éƒ¨APIè§†è§‰è°ƒç”¨å¤±è´¥ï¼Œä¸”AI Builders APIä¸æ”¯æŒè§†è§‰: {str(e)}")
        else:
            raise ValueError("å…¬å¸å†…éƒ¨APIä¸å¯ç”¨ï¼Œæ— æ³•ä½¿ç”¨è§†è§‰åŠŸèƒ½")
    
    def search(self, query: str, max_results: int = 20,
               include_domains: Optional[List[str]] = None,
               country_code: str = "CN") -> List[Dict[str, Any]]:
        """
        æœç´¢åŠŸèƒ½ï¼ˆGoogleä¼˜å…ˆç­–ç•¥ï¼‰

        ä¼˜åŒ–åçš„æœç´¢å¼•æ“é€‰æ‹©ç­–ç•¥ï¼š
        - Googleä¼˜å…ˆï¼ˆ10,000æ¬¡/å¤©å…è´¹ï¼Œä¸»è¦å¼•æ“ï¼‰
        - Metasoè¾…åŠ©ï¼ˆ5,000æ¬¡å…è´¹ï¼Œä¸­æ–‡ä¼˜åŒ–ï¼‰
        - Tavilyè¾…åŠ©ï¼ˆ1,000æ¬¡/æœˆå…è´¹ï¼Œå›½é™…è´¨é‡ï¼‰
        - Baiduè¾…åŠ©ï¼ˆ100æ¬¡/å¤©å…è´¹ï¼Œä¸­æ–‡å¤‡ç”¨ï¼‰

        è°ƒç”¨æ¬¡æ•°ç­–ç•¥ï¼š
        - Google: 3æ¬¡ï¼ˆæ‰€æœ‰æŸ¥è¯¢ï¼‰
        - Tavily/Metaso: 1æ¬¡ï¼ˆä»…ç¬¬ä¸€ä¸ªæŸ¥è¯¢ï¼‰
        - Baidu: 1æ¬¡ï¼ˆä»…ä¸­æ–‡ï¼Œä»…ç¬¬ä¸€ä¸ªæŸ¥è¯¢ï¼‰

        Args:
            query: æœç´¢æŸ¥è¯¢
            max_results: æœ€å¤§ç»“æœæ•°
            include_domains: å¯é€‰çš„åŸŸååˆ—è¡¨
            country_code: å›½å®¶ä»£ç ï¼ˆç”¨äºåŒºåŸŸä¼˜åŒ–ï¼‰

        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        # æ­¥éª¤ 1: æ£€æµ‹æŸ¥è¯¢è¯­è¨€
        is_chinese = self._is_chinese_content(query)

        # æ­¥éª¤ 2: è®¡ç®—å‰©ä½™å…è´¹é¢åº¦
        google_remaining = 10000 - self.google_usage if self.google_hunter else 0
        metaso_remaining = 5000 - self.metaso_client.usage_count if self.metaso_client else 0
        tavily_remaining = 1000 - self.tavily_usage
        baidu_remaining = 100 - self.baidu_usage if self.baidu_hunter else 0

        # æ­¥éª¤ 3: æ ¹æ®è¯­è¨€å’Œå›½å®¶é€‰æ‹©æœç´¢å¼•æ“ï¼ˆGoogleä¼˜å…ˆç­–ç•¥ï¼‰
        if is_chinese:
            # ä¸­æ–‡æŸ¥è¯¢ä¼˜å…ˆçº§: Google > Metaso > Baidu > Tavily âœ… Googleä¼˜å…ˆ
            if google_remaining > 0:
                return self._search_with_google(query, max_results,
                                              reason=f"ä¸­æ–‡å†…å®¹ï¼ˆGoogleä¼˜å…ˆï¼Œå‰©ä½™å…è´¹: {google_remaining:,}ï¼‰")
            elif metaso_remaining > 0:
                return self._search_with_metaso(query, max_results, include_domains,
                                              reason=f"ä¸­æ–‡å†…å®¹ï¼ˆå‰©ä½™å…è´¹: {metaso_remaining:,}ï¼‰")
            elif baidu_remaining > 0:
                return self._search_with_baidu(query, max_results,
                                          reason=f"ä¸­æ–‡å†…å®¹ï¼ˆå‰©ä½™å…è´¹: {baidu_remaining:,}ï¼‰")
            else:
                return self._search_with_tavily(query, max_results, include_domains,
                                               reason="ä¸­æ–‡å†…å®¹ï¼ˆå…¶ä»–å¼•æ“é¢åº¦ç”¨å°½ï¼‰")
        else:
            # å›½é™…æŸ¥è¯¢ä¼˜å…ˆçº§: Google > Tavily > Metaso âœ… Googleä¼˜å…ˆ
            if google_remaining > 0:
                return self._search_with_google(query, max_results,
                                               reason=f"å›½é™…å†…å®¹ï¼ˆGoogleä¼˜å…ˆï¼Œå‰©ä½™å…è´¹: {google_remaining:,}ï¼‰")
            elif tavily_remaining > 0:
                return self._search_with_tavily(query, max_results, include_domains,
                                               reason=f"å›½é™…å†…å®¹ï¼ˆå‰©ä½™å…è´¹: {tavily_remaining:,}ï¼‰")
            elif metaso_remaining > 0:
                return self._search_with_metaso(query, max_results, include_domains,
                                               reason=f"å›½é™…å†…å®¹ï¼ˆå‰©ä½™å…è´¹: {metaso_remaining:,}ï¼‰")
            else:
                raise ValueError("æ‰€æœ‰æœç´¢å¼•æ“å…è´¹é¢åº¦å·²ç”¨å°½")

    def _search_with_metaso(
        self,
        query: str,
        max_results: int,
        include_domains: Optional[List[str]],
        reason: str = ""
    ) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨ Metaso æœç´¢

        Args:
            query: æœç´¢æŸ¥è¯¢
            max_results: æœ€å¤§ç»“æœæ•°
            include_domains: å¯é€‰çš„åŸŸååˆ—è¡¨
            reason: é€‰æ‹© Metaso çš„åŸå› 

        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        if not self.metaso_client:
            print(f"[âš ï¸ Metaso] å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œé™çº§åˆ° Tavily")
            return self._search_with_tavily(query, max_results, include_domains, reason="Metasoä¸å¯ç”¨")

        # æ˜¾ç¤ºé€‰æ‹©åŸå› 
        if self.metaso_client.usage_count < 5000:
            remaining = 5000 - self.metaso_client.usage_count
            print(f"[ğŸ” æœç´¢] ä½¿ç”¨ Metasoï¼ˆ{reason}ï¼Œå…è´¹é¢åº¦å‰©ä½™: {remaining:,} æ¬¡ï¼‰")
        else:
            print(f"[ğŸ” æœç´¢] ä½¿ç”¨ Metasoï¼ˆ{reason}ï¼Œä»˜è´¹æ¨¡å¼ Â¥0.03/æ¬¡ï¼‰")

        try:
            results = self.metaso_client.search(
                query=query,
                max_results=min(max_results, 20),
                include_domains=include_domains
            )
            if results:
                # ğŸ”¥ ä¸ºæ¯ä¸ªç»“æœæ·»åŠ search_engineå­—æ®µ
                for item in results:
                    item["search_engine"] = "Metaso"
                print(f"[âœ… Metaso] æœç´¢æˆåŠŸï¼Œè¿”å› {len(results)} ä¸ªç»“æœ")
                return results
            else:
                print(f"[âš ï¸ Metaso] æœªè¿”å›ç»“æœï¼Œå°è¯• Tavily")
        except Exception as e:
            print(f"[âš ï¸ Metaso] æœç´¢å¤±è´¥: {str(e)}ï¼Œå°è¯• Tavily")

        # é™çº§åˆ° Tavily
        print(f"[ğŸ”„ é™çº§] åˆ‡æ¢åˆ° Tavily")
        return self._search_with_tavily(query, max_results, include_domains, reason="Metasoå¤±è´¥")

    def _search_with_tavily(
        self,
        query: str,
        max_results: int,
        include_domains: Optional[List[str]],
        reason: str = ""
    ) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨ Tavily æœç´¢ï¼ˆAI Builders APIï¼‰

        Args:
            query: æœç´¢æŸ¥è¯¢
            max_results: æœ€å¤§ç»“æœæ•°
            include_domains: å¯é€‰çš„åŸŸååˆ—è¡¨
            reason: é€‰æ‹© Tavily çš„åŸå› 

        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        if not self.ai_builders_client:
            raise ValueError("AI Builders APIä¸å¯ç”¨ï¼Œæ— æ³•ä½¿ç”¨ Tavily æœç´¢")

        # æ›´æ–°ä½¿ç”¨è®¡æ•°å™¨
        self.tavily_usage += 1

        # æ˜¾ç¤ºé€‰æ‹©åŸå› 
        if reason:
            print(f"[ğŸ” æœç´¢] ä½¿ç”¨ Tavilyï¼ˆ{reason}ï¼‰")
        else:
            print(f"[ğŸ” æœç´¢] ä½¿ç”¨ Tavilyï¼ˆAI Buildersï¼‰")

        endpoint = f"{self.ai_builders_client.base_url}/v1/search/"

        payload = {
            "keywords": [query],
            "max_results": min(max_results, 20)
        }

        # å¤„ç†åŸŸåé™åˆ¶
        if include_domains and len(include_domains) > 0:
            selected_domains = include_domains[:5]
            domain_site_clause = " OR ".join([f"site:{domain}" for domain in selected_domains])
            enhanced_query = f"{query} ({domain_site_clause})"
            payload["keywords"] = [enhanced_query]

        try:
            response = requests.post(
                endpoint,
                headers=self.ai_builders_client.headers,
                json=payload,
                timeout=30,
                proxies=get_proxy_config()
            )

            if response.status_code == 200:
                result = response.json()
                if "queries" in result and len(result["queries"]) > 0:
                    query_result = result["queries"][0]
                    if "response" in query_result and "results" in query_result["response"]:
                        # ğŸ”¥ ä¸ºæ¯ä¸ªç»“æœæ·»åŠ search_engineå­—æ®µ
                        results = query_result["response"]["results"]
                        for item in results:
                            item["search_engine"] = "Tavily"
                        print(f"[âœ… Tavily] æœç´¢æˆåŠŸï¼Œè¿”å› {len(results)} ä¸ªç»“æœ")
                        return results

            raise ValueError(f"Tavilyæœç´¢APIè°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")

        except Exception as e:
            raise ValueError(f"Tavilyæœç´¢APIè¯·æ±‚å¼‚å¸¸: {str(e)}")

    def _search_with_google(
        self,
        query: str,
        max_results: int,
        reason: str = ""
    ) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨ Google æœç´¢ï¼ˆå…è´¹é¢åº¦ä¼˜å…ˆï¼‰

        Args:
            query: æœç´¢æŸ¥è¯¢
            max_results: æœ€å¤§ç»“æœæ•°
            reason: é€‰æ‹© Google çš„åŸå› 

        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        if not self.google_hunter:
            raise ValueError("Googleæœç´¢å®¢æˆ·ç«¯ä¸å¯ç”¨")

        # æ›´æ–°ä½¿ç”¨è®¡æ•°å™¨
        self.google_usage += 1

        # æ˜¾ç¤ºé€‰æ‹©åŸå› 
        print(f"[ğŸ” æœç´¢] ä½¿ç”¨ Googleï¼ˆ{reason}ï¼‰")

        try:
            results = self.google_hunter.search(query, max_results=max_results)

            # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
            formatted_results = []
            for item in results:
                formatted_results.append({
                    "title": item.title,
                    "url": item.url,
                    "snippet": item.snippet,
                    "source": "Googleæœç´¢",
                    "search_engine": "Google"
                })

            print(f"[âœ… Google] æœç´¢æˆåŠŸï¼Œè¿”å› {len(formatted_results)} ä¸ªç»“æœ")
            return formatted_results

        except Exception as e:
            print(f"[âš ï¸ Google] æœç´¢å¤±è´¥: {str(e)}")
            return []

    def _search_with_baidu(
        self,
        query: str,
        max_results: int,
        reason: str = ""
    ) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨ Baidu æœç´¢ï¼ˆä¸­æ–‡å¤‡ç”¨ï¼‰

        Args:
            query: æœç´¢æŸ¥è¯¢
            max_results: æœ€å¤§ç»“æœæ•°
            reason: é€‰æ‹© Baidu çš„åŸå› 

        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        if not self.baidu_hunter:
            raise ValueError("Baiduæœç´¢å®¢æˆ·ç«¯ä¸å¯ç”¨")

        # æ›´æ–°ä½¿ç”¨è®¡æ•°å™¨
        self.baidu_usage += 1

        # æ˜¾ç¤ºé€‰æ‹©åŸå› 
        print(f"[ğŸ” æœç´¢] ä½¿ç”¨ Baiduï¼ˆ{reason}ï¼‰")

        try:
            results = self.baidu_hunter.search(query, max_results=max_results)

            # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
            formatted_results = []
            for item in results:
                formatted_results.append({
                    "title": item.title,
                    "url": item.url,
                    "snippet": item.snippet,
                    "source": "Baiduæœç´¢",
                    "search_engine": "Baidu"
                })

            print(f"[âœ… Baidu] æœç´¢æˆåŠŸï¼Œè¿”å› {len(formatted_results)} ä¸ªç»“æœ")
            return formatted_results

        except Exception as e:
            print(f"[âš ï¸ Baidu] æœç´¢å¤±è´¥: {str(e)}")
            return []

    def _is_chinese_content(self, query: str) -> bool:
        """
        æ£€æµ‹æŸ¥è¯¢æ˜¯å¦ä¸ºä¸­æ–‡å†…å®¹

        Args:
            query: æœç´¢æŸ¥è¯¢

        Returns:
            True å¦‚æœä¸­æ–‡å†…å®¹å æ¯”è¶…è¿‡ 30%
        """
        chinese_chars = sum(1 for c in query if '\u4e00' <= c <= '\u9fff')
        return chinese_chars > len(query) * 0.3 if len(query) > 0 else False

    def get_search_stats(self) -> Dict[str, Any]:
        """
        è·å–æœç´¢å¼•æ“ä½¿ç”¨ç»Ÿè®¡ï¼ˆåŒ…å«æ‰€æœ‰å¼•æ“ï¼‰

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        stats = {
            "metaso": None,
            "tavily": None,
            "google": None,
            "baidu": None,
            "enabled_engines": []
        }

        # Metaso ç»Ÿè®¡
        if self.metaso_client:
            stats["metaso"] = {
                "usage_count": self.metaso_client.usage_count,
                "free_tier_limit": 5000,
                "remaining_free": 5000 - self.metaso_client.usage_count,
                "total_cost": max(0, self.metaso_client.usage_count - 5000) * 0.03,
                "tier": "å…è´¹" if self.metaso_client.usage_count < 5000 else "ä»˜è´¹"
            }
            stats["enabled_engines"].append("Metaso")

        # Tavily ç»Ÿè®¡
        if self.ai_builders_client:
            stats["tavily"] = {
                "usage_count": self.tavily_usage,
                "free_tier_limit": 1000,
                "remaining_free": 1000 - self.tavily_usage,
                "total_cost": max(0, self.tavily_usage - 1000) * 0.05,
                "tier": "å…è´¹" if self.tavily_usage < 1000 else "ä»˜è´¹"
            }
            stats["enabled_engines"].append("Tavily (AI Builders)")

        # Google ç»Ÿè®¡
        if self.google_hunter:
            stats["google"] = {
                "usage_count": self.google_usage,
                "free_tier_limit": 10000,
                "remaining_free": 10000 - self.google_usage,
                "total_cost": 0,
                "tier": "å…è´¹"
            }
            stats["enabled_engines"].append("Google")

        # Baidu ç»Ÿè®¡
        if self.baidu_hunter:
            stats["baidu"] = {
                "usage_count": self.baidu_usage,
                "free_tier_limit": 100,
                "remaining_free": 100 - self.baidu_usage,
                "total_cost": 0,
                "tier": "å…è´¹"
            }
            stats["enabled_engines"].append("Baidu")

        return stats

    def check_cost_alert(self) -> Dict[str, Any]:
        """
        æ£€æŸ¥æˆæœ¬é¢„è­¦ï¼ˆç›‘æ§å…è´¹é¢åº¦ä½¿ç”¨æƒ…å†µï¼‰

        Returns:
            é¢„è­¦ä¿¡æ¯å­—å…¸ï¼ŒåŒ…å«ï¼š
            - alerts: é¢„è­¦åˆ—è¡¨
            - stats: å½“å‰ç»Ÿè®¡æ•°æ®
            - total_cost: æ€»æˆæœ¬
        """
        stats = self.get_search_stats()
        alerts = []

        # Metaso é¢„è­¦ï¼ˆ80% å…è´¹é¢åº¦ç”¨å®Œï¼‰
        if stats.get('metaso') and stats['metaso']['usage_count'] > 4000:
            remaining = stats['metaso']['remaining_free']
            alerts.append({
                "level": "WARNING",
                "engine": "Metaso",
                "message": f"Metaso å…è´¹é¢åº¦å³å°†ç”¨å°½: {stats['metaso']['usage_count']:,}/5,000ï¼ˆå‰©ä½™: {remaining:,}ï¼‰",
                "usage": stats['metaso']['usage_count'],
                "remaining": remaining,
                "cost": stats['metaso']['total_cost']
            })

        # Tavily é¢„è­¦ï¼ˆ80% å…è´¹é¢åº¦ç”¨å®Œï¼‰
        if stats.get('tavily') and stats['tavily']['usage_count'] > 800:
            remaining = stats['tavily']['remaining_free']
            alerts.append({
                "level": "WARNING",
                "engine": "Tavily",
                "message": f"Tavily å…è´¹é¢åº¦å³å°†ç”¨å°½: {stats['tavily']['usage_count']:,}/1,000ï¼ˆå‰©ä½™: {remaining:,}ï¼‰",
                "usage": stats['tavily']['usage_count'],
                "remaining": remaining,
                "cost": stats['tavily']['total_cost']
            })

        # Google é¢„è­¦ï¼ˆ80% å½“å¤©é¢åº¦ç”¨å®Œï¼‰
        if stats.get('google') and stats['google']['usage_count'] > 8000:
            remaining = stats['google']['remaining_free']
            alerts.append({
                "level": "INFO",
                "engine": "Google",
                "message": f"Google å½“å¤©é¢åº¦å³å°†ç”¨å°½: {stats['google']['usage_count']:,}/10,000ï¼ˆå‰©ä½™: {remaining:,}ï¼‰",
                "usage": stats['google']['usage_count'],
                "remaining": remaining,
                "cost": 0
            })

        # Baidu é¢„è­¦ï¼ˆ80% å½“å¤©é¢åº¦ç”¨å®Œï¼‰
        if stats.get('baidu') and stats['baidu']['usage_count'] > 80:
            remaining = stats['baidu']['remaining_free']
            alerts.append({
                "level": "INFO",
                "engine": "Baidu",
                "message": f"Baidu å½“å¤©é¢åº¦å³å°†ç”¨å°½: {stats['baidu']['usage_count']:,}/100ï¼ˆå‰©ä½™: {remaining:,}ï¼‰",
                "usage": stats['baidu']['usage_count'],
                "remaining": remaining,
                "cost": 0
            })

        # è®¡ç®—æ€»æˆæœ¬
        metaso_cost = stats['metaso']['total_cost'] if stats.get('metaso') else 0
        tavily_cost = stats['tavily']['total_cost'] if stats.get('tavily') else 0
        total_cost = metaso_cost + tavily_cost

        # æœˆåº¦æˆæœ¬é¢„è­¦ï¼ˆ>Â¥100ï¼‰
        if total_cost > 100:
            alerts.append({
                "level": "CRITICAL",
                "engine": "Total",
                "message": f"âš ï¸ æœˆåº¦æˆæœ¬é¢„è­¦: Â¥{total_cost:.2f}ï¼ˆMetaso: Â¥{metaso_cost:.2f}, Tavily: Â¥{tavily_cost:.2f}ï¼‰",
                "usage": 0,
                "remaining": 0,
                "cost": total_cost
            })

        # æ‰“å°é¢„è­¦
        if alerts:
            print(f"\n{'='*70}")
            print(f"[ğŸ“Š æˆæœ¬ç›‘æ§] æœç´¢å¼•æ“ä½¿ç”¨æƒ…å†µ")
            print(f"{'='*70}")

            for alert in alerts:
                level_icon = {
                    "CRITICAL": "ğŸš¨",
                    "WARNING": "âš ï¸",
                    "INFO": "â„¹ï¸"
                }.get(alert['level'], "â€¢")

                print(f"{level_icon} {alert['message']}")

            print(f"\nğŸ’° æ€»æˆæœ¬: Â¥{total_cost:.2f}")
            print(f"{'='*70}\n")

        return {
            "alerts": alerts,
            "stats": stats,
            "total_cost": total_cost
        }

    def print_search_summary(self):
        """æ‰“å°æœç´¢ä½¿ç”¨æ‘˜è¦ï¼ˆä¾¿äºç›‘æ§ï¼‰"""
        stats = self.get_search_stats()

        print(f"\n{'='*70}")
        print(f"[ğŸ“Š æœç´¢å¼•æ“ç»Ÿè®¡æ‘˜è¦]")
        print(f"{'='*70}")

        if stats.get('metaso'):
            metaso = stats['metaso']
            print(f"\n  ğŸ” Metaso:")
            print(f"     â€¢ ä½¿ç”¨æ¬¡æ•°: {metaso['usage_count']:,}/5,000")
            print(f"     â€¢ å‰©ä½™å…è´¹: {metaso['remaining_free']:,}")
            print(f"     â€¢ å½“å‰æˆæœ¬: Â¥{metaso['total_cost']:.2f}")
            print(f"     â€¢ å½“å‰å±‚çº§: {metaso['tier']}")

        if stats.get('tavily'):
            tavily = stats['tavily']
            print(f"\n  ğŸ” Tavily:")
            print(f"     â€¢ ä½¿ç”¨æ¬¡æ•°: {tavily['usage_count']:,}/1,000")
            print(f"     â€¢ å‰©ä½™å…è´¹: {tavily['remaining_free']:,}")
            print(f"     â€¢ å½“å‰æˆæœ¬: Â¥{tavily['total_cost']:.2f}")
            print(f"     â€¢ å½“å‰å±‚çº§: {tavily['tier']}")

        if stats.get('google'):
            google = stats['google']
            print(f"\n  ğŸ” Google:")
            print(f"     â€¢ ä½¿ç”¨æ¬¡æ•°: {google['usage_count']:,}/10,000")
            print(f"     â€¢ å‰©ä½™å…è´¹: {google['remaining_free']:,}")
            print(f"     â€¢ å½“å‰æˆæœ¬: Â¥{google['total_cost']:.2f}ï¼ˆå…è´¹ï¼‰")

        if stats.get('baidu'):
            baidu = stats['baidu']
            print(f"\n  ğŸ” Baidu:")
            print(f"     â€¢ ä½¿ç”¨æ¬¡æ•°: {baidu['usage_count']:,}/100")
            print(f"     â€¢ å‰©ä½™å…è´¹: {baidu['remaining_free']:,}")
            print(f"     â€¢ å½“å‰æˆæœ¬: Â¥{baidu['total_cost']:.2f}ï¼ˆå…è´¹ï¼‰")

        # æ€»æˆæœ¬
        total_cost = sum(s['total_cost'] for s in [stats.get('metaso'), stats.get('tavily'), stats.get('google'), stats.get('baidu')] if s)
        print(f"\n  ğŸ’° æ€»æˆæœ¬: Â¥{total_cost:.2f}")
        print(f"{'='*70}\n")


# ============================================================================
# å…¨å±€å®¢æˆ·ç«¯å®ä¾‹å’Œå·¥å‚å‡½æ•°
# ============================================================================

_llm_client_instance = None


def get_llm_client() -> UnifiedLLMClient:
    """
    è·å–å…¨å±€LLMå®¢æˆ·ç«¯å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰

    Returns:
        UnifiedLLMClientå®ä¾‹
    """
    global _llm_client_instance
    if _llm_client_instance is None:
        _llm_client_instance = UnifiedLLMClient()
    return _llm_client_instance

