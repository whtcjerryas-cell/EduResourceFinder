#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°å°¼ä¸€å¹´çº§æ•°å­¦æ•™è‚²èµ„æºè¯„ä¼°è„šæœ¬

åŠŸèƒ½ï¼š
1. è¯»å–Excelä¸­çš„æ•™è‚²ç½‘ç«™åˆ—è¡¨
2. ä½¿ç”¨Gemini 2.5 Proè¿›è¡ŒAIåˆ†æè¯„ä¼°
3. å°†è¯„ä¼°åˆ†æ•°å’Œè¯„ä»·å†™å…¥Excelæ–°åˆ—
"""

import os
import json
import time
import re
from typing import Dict, Any
from urllib.parse import urlparse
import pandas as pd
from openai import OpenAI
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# APIé…ç½®
INTERNAL_API_KEY = os.getenv("INTERNAL_API_KEY", "sk_4c34c16af4f8bb4bc102f3d1afd6439127c4d95a2912af34efcbda0")
INTERNAL_API_BASE_URL = os.getenv("INTERNAL_API_BASE_URL", "https://hk-intra-paas.transsion.com/tranai-proxy/v1")

# ç¦ç”¨ä»£ç†ï¼ˆå…¬å¸å†…éƒ¨APIéœ€è¦ï¼‰
def disable_proxy():
    """å¼ºåˆ¶ç¦ç”¨æ‰€æœ‰ä»£ç†è®¾ç½®"""
    proxy_vars = [
        "HTTP_PROXY", "HTTPS_PROXY", "http_proxy", "https_proxy",
        "ALL_PROXY", "all_proxy", "NO_PROXY", "no_proxy"
    ]
    for var in proxy_vars:
        if var in os.environ:
            del os.environ[var]
    os.environ["HTTP_PROXY"] = ""
    os.environ["HTTPS_PROXY"] = ""

disable_proxy()


class ResourceEvaluator:
    """æ•™è‚²èµ„æºè¯„ä¼°å™¨ - ä½¿ç”¨Gemini 2.5 Pro"""

    def __init__(self):
        self.client = OpenAI(
            api_key=INTERNAL_API_KEY,
            base_url=INTERNAL_API_BASE_URL
        )
        self.model = "gemini-2.5-pro"  # ä½¿ç”¨Gemini 2.5 Proè¿›è¡Œé«˜è´¨é‡åˆ†æ

    def identify_platform(self, url: str) -> str:
        """è¯†åˆ«æ•™è‚²å¹³å°ç±»å‹"""
        if 'youtube.com' in url or 'youtu.be' in url:
            return 'YouTube'
        elif 'ruangguru.com' in url:
            return 'Ruangguruï¼ˆå°å°¼é¢†å…ˆåœ¨çº¿æ•™è‚²å¹³å°ï¼‰'
        elif 'khanacademy.org' in url:
            return 'Khan Academy'
        elif 'quipper.com' in url:
            return 'Quipper'
        elif 'zenius.net' in url:
            return 'Zenius'
        elif 'rumahbelajar.com' in url:
            return 'Rumah Belajar'
        else:
            return 'å…¶ä»–å¹³å°'

    def evaluate(self, name: str, url: str) -> Dict[str, Any]:
        """
        è¯„ä¼°æ•™è‚²èµ„æº

        Args:
            name: èµ„æºåç§°
            url: èµ„æºç½‘å€

        Returns:
            åŒ…å«è¯„ä¼°åˆ†æ•°å’Œè¯„ä»·çš„å­—å…¸
        """
        print(f"\nğŸ¤– å¼€å§‹è¯„ä¼°: {name}")

        platform = self.identify_platform(url)

        # è§£æURLè·å–é¢å¤–ä¿¡æ¯
        parsed = urlparse(url)
        is_playlist = 'playlist' in url
        is_kurikulum_merdeka = 'merdeka' in url.lower() or 'merdeka' in name.lower()

        # æ„å»ºè¯¦ç»†çš„è¯„ä¼°æç¤ºè¯
        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ•™è‚²å†…å®¹è¯„ä¼°ä¸“å®¶ï¼Œä¸“é—¨è¯„ä¼°å°å°¼å°å­¦ä¸€å¹´çº§æ•°å­¦æ•™è‚²èµ„æºã€‚è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯è¿›è¡Œä¸“ä¸šè¯„ä¼°ã€‚

**èµ„æºåŸºæœ¬ä¿¡æ¯**:
- èµ„æºåç§°: {name}
- èµ„æºç½‘å€: {url}
- æ‰€å±å¹³å°: {platform}
- URLç‰¹å¾: {'æ’­æ”¾åˆ—è¡¨' if is_playlist else 'å•ä¸ªèµ„æº/è¯¾ç¨‹é¡µé¢'}
- æ•™å­¦å¤§çº²: {'ç¬¦åˆKurikulum Merdekaï¼ˆå°å°¼æœ€æ–°ç‹¬ç«‹è¯¾ç¨‹ï¼‰' if is_kurikulum_merdeka else 'æœªçŸ¥æ•™å­¦å¤§çº²ç‰ˆæœ¬'}

---

**è¯„ä¼°èƒŒæ™¯**:
è¿™æ˜¯ä¸ºå°å°¼å°å­¦ä¸€å¹´çº§å­¦ç”Ÿè®¾è®¡çš„æ•°å­¦æ•™è‚²èµ„æºã€‚ä¸»è¦å—ä¼—æ˜¯6-7å²çš„å„¿ç«¥ï¼Œå†…å®¹åº”è¯¥åŒ…æ‹¬ï¼š
- åŸºç¡€æ•°æ•°å’Œæ•°å­—è®¤çŸ¥
- ç®€å•åŠ å‡æ³•
- å½¢çŠ¶å’Œç©ºé—´è®¤çŸ¥
- æµ‹é‡åŸºç¡€æ¦‚å¿µ
- æ•°æ®æ”¶é›†åŸºç¡€

**å¹³å°èƒŒæ™¯**:
- Ruangguruæ˜¯å°å°¼æœ€å¤§çš„åœ¨çº¿æ•™è‚²å¹³å°ä¹‹ä¸€ï¼Œæä¾›ä»å°å­¦åˆ°é«˜ä¸­çš„å…¨é¢è¯¾ç¨‹
- YouTubeæ˜¯å…¨çƒæœ€å¤§çš„è§†é¢‘å¹³å°ï¼Œæœ‰å¤§é‡ä¼˜è´¨æ•™è‚²èµ„æº

---

è¯·ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œä¸“ä¸šè¯„ä¼°ï¼ˆæ¯ä¸ªç»´åº¦0-10åˆ†ï¼‰ï¼š

**1. èµ„æºä¸°å¯Œç¨‹åº¦ (0-10åˆ†)**
   - å†…å®¹æ•°é‡å’Œè¦†ç›–å¹¿åº¦
   - ä¸»é¢˜å®Œæ•´æ€§
   - é…å¥—èµ„æºï¼ˆç»ƒä¹ é¢˜ã€è®²ä¹‰ç­‰ï¼‰
   - æ›´æ–°é¢‘ç‡

**2. æ—¶æ•ˆæ€§ (0-10åˆ†)**
   - æ˜¯å¦ç¬¦åˆKurikulum Merdekaï¼ˆå°å°¼2022å¹´å®æ–½çš„æœ€æ–°æ•™è‚²å¤§çº²ï¼‰
   - å†…å®¹çš„æ›´æ–°ç»´æŠ¤çŠ¶æ€
   - æ•™è‚²ç†å¿µçš„å…ˆè¿›æ€§

**3. æ•™å­¦æ–¹æ³• (0-10åˆ†)**
   - é’ˆå¯¹6-7å²å„¿ç«¥çš„æ•™å­¦è®¾è®¡
   - è¶£å‘³æ€§å’Œäº’åŠ¨æ€§
   - æ•™å­¦èŠ‚å¥å’Œè®²è§£æ¸…æ™°åº¦
   - æ˜¯å¦ç¬¦åˆå„¿ç«¥è®¤çŸ¥å‘å±•è§„å¾‹
   - è§†è§‰è¾…åŠ©å’ŒåŠ¨ç”»è¿ç”¨

**4. ç”»é¢è´¨é‡ (0-10åˆ†)**
   - è§†é¢‘ç”»è´¨å’Œåˆ¶ä½œæ°´å‡†
   - ç•Œé¢è®¾è®¡å’Œç”¨æˆ·ä½“éªŒ
   - åŠ¨ç”»å’Œè§†è§‰æ•ˆæœ
   - éŸ³é¢‘è´¨é‡

**5. æ•´ä½“æ¨èåº¦ (0-10åˆ†)**
   - ç»¼åˆè´¨é‡å’Œä»·å€¼
   - æ€§ä»·æ¯”ï¼ˆå¦‚æœéœ€è¦ä»˜è´¹ï¼‰
   - é€‚ç”¨æ€§å’Œå®ç”¨æ€§
   - æ˜¯å¦å€¼å¾—é‡‡è´­æ¨è

---

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›è¯„ä¼°ç»“æœï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ï¼š
```json
{{
    "score_richness": 8.5,
    "score_timeliness": 7.0,
    "score_teaching_method": 9.0,
    "score_visual_quality": 8.0,
    "overall_score": 8.1,
    "evaluation_text": "è¯¦ç»†è¯„ä¼°å†…å®¹ï¼ŒåŒ…æ‹¬ï¼š\\n1. èµ„æºç‰¹ç‚¹åˆ†æ\\n2. å„ç»´åº¦è¯„åˆ†ç†ç”±\\n3. ä¼˜ç‚¹\\n4. ä¸è¶³ä¹‹å¤„\\n5. é‡‡è´­å»ºè®®...",
    "recommendation": "å¼ºçƒˆæ¨è"
}}
```

æ¨èåº¦å¯é€‰å€¼: "å¼ºçƒˆæ¨è", "æ¨è", "å¯ä»¥è€ƒè™‘", "ä¸æ¨è"

**è¯„ä¼°æ–‡æœ¬è¦æ±‚**:
- è¯¦ç»†è¯´æ˜æ¯ä¸ªç»´åº¦çš„è¯„åˆ†ç†ç”±
- åˆ†æè¯¥èµ„æºçš„ç‰¹è‰²å’Œä¼˜åŠ¿
- æŒ‡å‡ºå¯èƒ½å­˜åœ¨çš„ä¸è¶³
- ç»™å‡ºå…·ä½“çš„é‡‡è´­æˆ–ä½¿ç”¨å»ºè®®
- ç‰¹åˆ«å…³æ³¨æ˜¯å¦é€‚åˆå°å°¼ä¸€å¹´çº§å­¦ç”Ÿçš„è®¤çŸ¥æ°´å¹³
- ç”¨ä¸­æ–‡æ’°å†™ï¼Œä¸“ä¸šä¸”å…·ä½“"""

        try:
            print(f"   æ­£åœ¨è°ƒç”¨ {self.model} æ¨¡å‹...")

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ•™è‚²å†…å®¹è¯„ä¼°ä¸“å®¶ï¼Œæ‹¥æœ‰10å¹´ä»¥ä¸Šçš„K12æ•°å­¦æ•™è‚²è¯„ä¼°ç»éªŒï¼Œç†Ÿæ‚‰å°å°¼æ•™è‚²ä½“ç³»ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›è¯„ä¼°ç»“æœï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ã€‚"
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=3000,
                timeout=120
            )

            result_text = response.choices[0].message.content.strip()

            # æå–JSONéƒ¨åˆ†
            json_text = self._extract_json(result_text)

            # è§£æJSON
            evaluation = json.loads(json_text)

            print(f"âœ… è¯„ä¼°å®Œæˆ")
            print(f"   æ•´ä½“è¯„åˆ†: {evaluation.get('overall_score', 'N/A')}/10")
            print(f"   æ¨è: {evaluation.get('recommendation', 'N/A')}")

            return evaluation

        except json.JSONDecodeError as e:
            print(f"âŒ JSONè§£æå¤±è´¥: {e}")
            print(f"   åŸå§‹å“åº”: {result_text[:300]}...")
            return self._create_error_evaluation(str(e), result_text[:500] if 'result_text' in locals() else '')
        except Exception as e:
            print(f"âŒ è¯„ä¼°å¤±è´¥: {str(e)}")
            return self._create_error_evaluation(str(e), '')

    def _extract_json(self, text: str) -> str:
        """ä»æ–‡æœ¬ä¸­æå–JSON"""
        # å°è¯•æ‰¾åˆ°JSONä»£ç å—
        patterns = [
            r'```json\s*(\{.*?\})\s*```',
            r'```\s*(\{.*?\})\s*```',
        ]

        for pattern in patterns:
            match = re.search(pattern, text, re.DOTALL)
            if match:
                return match.group(1)

        # å°è¯•æ‰¾åˆ°ç¬¬ä¸€ä¸ªå®Œæ•´çš„JSONå¯¹è±¡
        match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', text, re.DOTALL)
        if match:
            return match.group(0)

        # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•ç›´æ¥è§£ææ•´ä¸ªæ–‡æœ¬
        return text.strip()

    def _create_error_evaluation(self, error_msg: str, raw_text: str) -> Dict[str, Any]:
        """åˆ›å»ºé”™è¯¯è¯„ä¼°ç»“æœ"""
        return {
            "overall_score": 0,
            "evaluation_text": f"è¯„ä¼°å¤±è´¥: {error_msg}",
            "recommendation": "è¯„ä¼°å¤±è´¥",
            "error": error_msg,
            "raw_response": raw_text
        }


def process_excel(input_file: str, output_file: str):
    """
    å¤„ç†Excelæ–‡ä»¶ï¼Œè¯„ä¼°æ‰€æœ‰æ•™è‚²èµ„æº

    Args:
        input_file: è¾“å…¥Excelæ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºExcelæ–‡ä»¶è·¯å¾„
    """
    print("=" * 70)
    print("å°å°¼ä¸€å¹´çº§æ•°å­¦æ•™è‚²èµ„æºè¯„ä¼°ç³»ç»Ÿ")
    print("åŸºäº Gemini 2.5 Pro AIåˆ†æ")
    print("=" * 70)

    # è¯»å–Excelæ–‡ä»¶
    print(f"\nğŸ“‚ è¯»å–Excelæ–‡ä»¶: {input_file}")
    df = pd.read_excel(input_file)
    print(f"âœ… æˆåŠŸè¯»å– {len(df)} æ¡è®°å½•")

    # åˆå§‹åŒ–è¯„ä¼°å™¨
    evaluator = ResourceEvaluator()

    # å‡†å¤‡æ–°åˆ—
    scores = []
    evaluations = []

    # é€è¡Œå¤„ç†
    for idx, row in df.iterrows():
        name = row.get('åç§°', '')
        url = row.get('ç½‘å€', '')

        print(f"\n{'=' * 70}")
        print(f"[{idx + 1}/{len(df)}] è¯„ä¼°èµ„æº")
        print(f"åç§°: {name}")
        print(f"ç½‘å€: {url}")
        print(f"{'=' * 70}")

        # è¯„ä¼°èµ„æº
        evaluation = evaluator.evaluate(name, url)

        # æå–åˆ†æ•°
        overall_score = evaluation.get('overall_score', 0)

        # æ„å»ºè¯„ä¼°æ–‡æœ¬
        eval_text_parts = []

        # æ ‡é¢˜è¡Œ
        eval_text_parts.append(f"ã€æ•´ä½“è¯„åˆ†ã€‘: {overall_score:.1f}/10")
        eval_text_parts.append(f"ã€æ¨èæ„è§ã€‘: {evaluation.get('recommendation', 'N/A')}")

        # åˆ†é¡¹è¯„åˆ†
        if 'score_richness' in evaluation:
            eval_text_parts.append(f"\nã€åˆ†é¡¹è¯„åˆ†ã€‘")
            eval_text_parts.append(f"â€¢ èµ„æºä¸°å¯Œç¨‹åº¦: {evaluation['score_richness']:.1f}/10")
            eval_text_parts.append(f"â€¢ æ—¶æ•ˆæ€§: {evaluation['score_timeliness']:.1f}/10")
            eval_text_parts.append(f"â€¢ æ•™å­¦æ–¹æ³•: {evaluation['score_teaching_method']:.1f}/10")
            eval_text_parts.append(f"â€¢ ç”»é¢è´¨é‡: {evaluation['score_visual_quality']:.1f}/10")

        # è¯¦ç»†è¯„ä¼°
        eval_text_parts.append(f"\nã€è¯¦ç»†è¯„ä¼°ã€‘")
        eval_text_parts.append(evaluation.get('evaluation_text', ''))

        # é”™è¯¯ä¿¡æ¯
        if 'error' in evaluation:
            eval_text_parts.append(f"\nã€é”™è¯¯ä¿¡æ¯ã€‘")
            eval_text_parts.append(f"è¯„ä¼°è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {evaluation['error']}")

        final_eval_text = "\n".join(eval_text_parts)

        scores.append(overall_score)
        evaluations.append(final_eval_text)

        # é¿å…è¯·æ±‚è¿‡å¿«
        if idx < len(df) - 1:  # æœ€åä¸€ä¸ªä¸éœ€è¦ç­‰å¾…
            print(f"\nâ³ ç­‰å¾…3ç§’åå¤„ç†ä¸‹ä¸€ä¸ª...")
            time.sleep(3)

    # æ·»åŠ æ–°åˆ—
    df['è¯„ä¼°åˆ†æ•°'] = scores
    df['è¯„ä¼°å†…å®¹'] = evaluations

    # æŒ‰åˆ†æ•°é™åºæ’åº
    df = df.sort_values('è¯„ä¼°åˆ†æ•°', ascending=False)

    # ä¿å­˜åˆ°Excel
    print(f"\nğŸ’¾ ä¿å­˜è¯„ä¼°ç»“æœåˆ°: {output_file}")
    df.to_excel(output_file, index=False, engine='openpyxl')
    print("âœ… ä¿å­˜æˆåŠŸï¼")

    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 70)
    print("ğŸ“Š è¯„ä¼°ç»Ÿè®¡")
    print("=" * 70)
    print(f"æ€»è¯„ä¼°æ•°: {len(df)}")
    print(f"å¹³å‡åˆ†æ•°: {df['è¯„ä¼°åˆ†æ•°'].mean():.2f}/10")
    print(f"æœ€é«˜åˆ†æ•°: {df['è¯„ä¼°åˆ†æ•°'].max():.1f}/10")
    print(f"æœ€ä½åˆ†æ•°: {df['è¯„ä¼°åˆ†æ•°'].min():.1f}/10")

    # æ¨èåˆ†å¸ƒ
    print("\nã€æ¨èæ„è§åˆ†å¸ƒã€‘")
    recommendations = []
    for eval_text in df['è¯„ä¼°å†…å®¹']:
        match = re.search(r'ã€æ¨èæ„è§ã€‘:\s*(\S+)', eval_text)
        if match:
            recommendations.append(match.group(1))
    if recommendations:
        from collections import Counter
        for rec, count in Counter(recommendations).most_common():
            print(f"  {rec}: {count}ä¸ª")

    # æ˜¾ç¤ºæ‰€æœ‰èµ„æºæŒ‰åˆ†æ•°æ’åº
    print("\nã€èµ„æºæ’åï¼ˆæŒ‰åˆ†æ•°æ’åºï¼‰ã€‘")
    for idx, (name, score, rec) in enumerate(df[['åç§°', 'è¯„ä¼°åˆ†æ•°', 'è¯„ä¼°å†…å®¹']].values, 1):
        match = re.search(r'ã€æ¨èæ„è§ã€‘:\s*(\S+)', rec)
        recommendation = match.group(1) if match else 'N/A'
        print(f"  {idx}. {name}")
        print(f"     è¯„åˆ†: {score:.1f}/10 | æ¨è: {recommendation}")


if __name__ == "__main__":
    # æ–‡ä»¶è·¯å¾„
    input_file = "å°å°¼ä¸€å¹´çº§æ•°å­¦.xlsx"
    output_file = "å°å°¼ä¸€å¹´çº§æ•°å­¦_è¯„ä¼°ç»“æœ.xlsx"

    # æ‰§è¡Œè¯„ä¼°
    process_excel(input_file, output_file)

    print("\n" + "=" * 70)
    print("ğŸ‰ è¯„ä¼°å®Œæˆï¼")
    print(f"ğŸ“Š ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    print("=" * 70)
