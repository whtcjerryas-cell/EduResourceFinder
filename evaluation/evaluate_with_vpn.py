#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°å°¼ä¸€å¹´çº§æ•°å­¦æ•™è‚²èµ„æºè¯„ä¼°è„šæœ¬ï¼ˆä½¿ç”¨VPNç›´æ¥è®¿é—®ï¼‰

åŠŸèƒ½ï¼š
1. è¯»å–Excelä¸­çš„æ•™è‚²ç½‘ç«™åˆ—è¡¨
2. ä½¿ç”¨VPNç›´æ¥è®¿é—®å…¬å¸å†…éƒ¨Gemini 2.5 Proè¿›è¡ŒAIåˆ†æè¯„ä¼°
3. å°†è¯„ä¼°åˆ†æ•°å’Œè¯„ä»·å†™å…¥Excelæ–°åˆ—
"""

import os
import json
import time
import re
from typing import Dict, Any
import pandas as pd
from openai import OpenAI
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# APIé…ç½®
INTERNAL_API_KEY = os.getenv("INTERNAL_API_KEY", "sk_4c34c16af4f8bb4bc102f3d1afd6439127c4d95a2912af34efcbda0")
INTERNAL_API_BASE_URL = os.getenv("INTERNAL_API_BASE_URL", "https://hk-intra-paas.transsion.com/tranai-proxy/v1")

# å¯¼å…¥ç»Ÿä¸€çš„ä»£ç†å·¥å…·ï¼ˆproxy_utils æ¨¡å—å¯¼å…¥æ—¶ä¼šè‡ªåŠ¨ç¦ç”¨ä»£ç†ï¼‰
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from core.proxy_utils import disable_proxy  # å¯¼å…¥å³è‡ªåŠ¨ç¦ç”¨ä»£ç†ï¼ˆè§ proxy_utils.py:78ï¼‰
from utils.json_parser import JSONParser
from utils.platform_detector import PlatformDetector


class ResourceEvaluator:
    """æ•™è‚²èµ„æºè¯„ä¼°å™¨ - ä½¿ç”¨å…¬å¸å†…éƒ¨ Gemini 2.5 Pro"""

    def __init__(self):
        # æ³¨æ„ï¼šæ— éœ€æ‰‹åŠ¨è°ƒç”¨ disable_proxy()ï¼Œå› ä¸ºå¯¼å…¥ core.proxy_utils æ—¶å·²è‡ªåŠ¨æ‰§è¡Œ
        # ç¡®ä¿ä¸ä½¿ç”¨ä»£ç†ï¼Œç›´æ¥é€šè¿‡VPNè®¿é—®
        # disable_proxy()  # å·²åœ¨ proxy_utils æ¨¡å—å¯¼å…¥æ—¶è‡ªåŠ¨æ‰§è¡Œ

        self.client = OpenAI(
            api_key=INTERNAL_API_KEY,
            base_url=INTERNAL_API_BASE_URL,
        )
        self.model = "gemini-2.5-pro"

    def evaluate(self, name: str, url: str) -> Dict[str, Any]:
        """
        ä½¿ç”¨ Gemini 2.5 Pro è¿›è¡Œè¯„ä¼°

        Args:
            name: èµ„æºåç§°
            url: èµ„æºç½‘å€

        Returns:
            åŒ…å«è¯„ä¼°åˆ†æ•°å’Œè¯„ä»·çš„å­—å…¸
        """
        print(f"\nğŸ¤– Gemini 2.5 Pro è¯„ä¼°: {name}")

        platform = PlatformDetector.identify_platform(url)
        is_playlist = 'playlist' in url
        is_kurikulum_merdeka = 'merdeka' in url.lower() or 'merdeka' in name.lower()
        is_ruangguru = 'ruangguru.com' in url
        is_youtube = 'youtube.com' in url

        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ•™è‚²å†…å®¹è¯„ä¼°ä¸“å®¶ï¼Œä¸“é—¨è¯„ä¼°å°å°¼å°å­¦ä¸€å¹´çº§æ•°å­¦æ•™è‚²èµ„æºã€‚

**èµ„æºåŸºæœ¬ä¿¡æ¯**:
- èµ„æºåç§°: {name}
- èµ„æºç½‘å€: {url}
- æ‰€å±å¹³å°: {platform}
- URLç‰¹å¾: {'YouTubeæ’­æ”¾åˆ—è¡¨ï¼ˆåŒ…å«å¤šä¸ªè§†é¢‘ï¼‰' if is_playlist else 'è¯¾ç¨‹é¡µé¢'}
- æ•™å­¦å¤§çº²: {'ç¬¦åˆKurikulum Merdekaï¼ˆå°å°¼2022å¹´æœ€æ–°ç‹¬ç«‹è¯¾ç¨‹å¤§çº²ï¼‰' if is_kurikulum_merdeka else 'éœ€è¦äººå·¥æ ¸å®'}

---

**è¯„ä¼°èƒŒæ™¯**:
è¿™æ˜¯ä¸ºå°å°¼å°å­¦ä¸€å¹´çº§å­¦ç”Ÿï¼ˆ6-7å²ï¼‰è®¾è®¡çš„æ•°å­¦æ•™è‚²èµ„æºã€‚å†…å®¹åº”è¯¥åŒ…æ‹¬ï¼š
- åŸºç¡€æ•°æ•°ï¼ˆ1-100ï¼‰å’Œæ•°å­—è®¤çŸ¥
- ç®€å•åŠ å‡æ³•ï¼ˆ20ä»¥å†…ï¼‰
- å½¢çŠ¶å’Œå‡ ä½•å›¾å½¢è®¤çŸ¥
- æµ‹é‡åŸºç¡€ï¼ˆé•¿åº¦ã€é‡é‡ã€å®¹é‡ï¼‰
- æ•°æ®æ”¶é›†åŸºç¡€
- æ—¶é—´å’Œè´§å¸è®¤çŸ¥

**å¹³å°èƒŒæ™¯**:
- Ruangguru: å°å°¼æœ€å¤§çš„åœ¨çº¿æ•™è‚²å¹³å°ä¹‹ä¸€ï¼Œæä¾›ç³»ç»ŸåŒ–è¯¾ç¨‹ï¼Œä¸“ä¸šæ•™å¸ˆå›¢é˜Ÿï¼Œé€šå¸¸éœ€è¦ä»˜è´¹è®¢é˜…
- YouTube: å…¨çƒæœ€å¤§è§†é¢‘å¹³å°ï¼Œå®Œå…¨å…è´¹ï¼Œå†…å®¹è´¨é‡å‚å·®ä¸é½ï¼Œéœ€è¦ç­›é€‰

---

è¯·ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œä¸“ä¸šè¯„ä¼°ï¼ˆæ¯ä¸ªç»´åº¦0-10åˆ†ï¼Œä¿ç•™ä¸€ä½å°æ•°ï¼‰ï¼š

**1. èµ„æºä¸°å¯Œç¨‹åº¦ (0-10åˆ†)**
   - å†…å®¹æ•°é‡ï¼šè§†é¢‘æ•°é‡ã€è¯¾ç¨‹æ—¶é•¿
   - ä¸»é¢˜è¦†ç›–ï¼šæ˜¯å¦è¦†ç›–ä¸€å¹´çº§æ•°å­¦æ‰€æœ‰æ ¸å¿ƒçŸ¥è¯†ç‚¹
   - é…å¥—èµ„æºï¼šç»ƒä¹ é¢˜ã€è®²ä¹‰ã€äº’åŠ¨ç»ƒä¹ ç­‰
   - æ›´æ–°é¢‘ç‡ï¼šå†…å®¹æ˜¯å¦å®šæœŸæ›´æ–°

**2. æ—¶æ•ˆæ€§ (0-10åˆ†)**
   - æ˜¯å¦ç¬¦åˆKurikulum Merdekaï¼ˆå°å°¼2022å¹´å®æ–½çš„æœ€æ–°æ•™è‚²å¤§çº²ï¼‰
   - å†…å®¹çš„æ›´æ–°ç»´æŠ¤çŠ¶æ€
   - æ•™è‚²ç†å¿µçš„å…ˆè¿›æ€§
   - ä¿¡æ¯å‡†ç¡®æ€§

**3. æ•™å­¦æ–¹æ³• (0-10åˆ†)**
   - é’ˆå¯¹6-7å²å„¿ç«¥çš„æ•™å­¦è®¾è®¡åˆç†æ€§
   - è¶£å‘³æ€§å’Œäº’åŠ¨æ€§
   - æ•™å­¦èŠ‚å¥å’Œè®²è§£æ¸…æ™°åº¦
   - æ˜¯å¦ç¬¦åˆå„¿ç«¥è®¤çŸ¥å‘å±•è§„å¾‹
   - è§†è§‰è¾…åŠ©ã€åŠ¨ç”»ã€å®ç‰©æ¼”ç¤ºçš„è¿ç”¨
   - è¯­è¨€è¡¨è¾¾ï¼ˆå°å°¼è¯­ï¼‰çš„å‡†ç¡®æ€§å’Œäº²å’ŒåŠ›

**4. ç”»é¢è´¨é‡ (0-10åˆ†)**
   - è§†é¢‘ç”»è´¨æ¸…æ™°åº¦ï¼ˆ720p/1080p/4Kï¼‰
   - éŸ³é¢‘è´¨é‡ï¼ˆæ¸…æ™°ã€æ— å™ªéŸ³ï¼‰
   - ç•Œé¢è®¾è®¡å’Œç”¨æˆ·ä½“éªŒ
   - åŠ¨ç”»å’Œè§†è§‰æ•ˆæœ
   - å­—å¹•å’Œè¾…åŠ©ææ–™çš„å®Œæ•´æ€§

**5. æ•´ä½“æ¨èåº¦ (0-10åˆ†)**
   - ç»¼åˆè´¨é‡å’Œæ•™å­¦ä»·å€¼
   - æ€§ä»·æ¯”ï¼ˆå…è´¹vsä»˜è´¹ï¼‰
   - é€‚ç”¨æ€§å’Œå®ç”¨æ€§
   - æ˜¯å¦å€¼å¾—é‡‡è´­æ¨èç”¨äºæ•™å­¦

---

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›è¯„ä¼°ç»“æœï¼ˆåªè¿”å›JSONï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—ï¼‰ï¼š
```json
{{
    "score_richness": 8.5,
    "score_timeliness": 7.0,
    "score_teaching_method": 9.0,
    "score_visual_quality": 8.0,
    "overall_score": 8.1,
    "evaluation_text": "è¯¦ç»†è¯„ä¼°å†…å®¹ï¼ŒåŒ…æ‹¬ï¼š\\n1. èµ„æºç‰¹ç‚¹åˆ†æ\\n2. å„ç»´åº¦è¯„åˆ†ç†ç”±\\n3. ä¸»è¦ä¼˜ç‚¹\\n4. æ½œåœ¨ä¸è¶³\\n5. å…·ä½“çš„é‡‡è´­æˆ–ä½¿ç”¨å»ºè®®",
    "recommendation": "å¼ºçƒˆæ¨è"
}}
```

æ¨èåº¦åªèƒ½é€‰æ‹©: "å¼ºçƒˆæ¨è", "æ¨è", "å¯ä»¥è€ƒè™‘", "ä¸æ¨è"

**è¯„ä¼°æ–‡æœ¬è¦æ±‚**:
- è¯¦ç»†è¯´æ˜æ¯ä¸ªç»´åº¦çš„è¯„åˆ†ç†ç”±ï¼ˆå…·ä½“åˆ°0.1åˆ†ï¼‰
- æ·±å…¥åˆ†æè¯¥èµ„æºçš„ç‰¹è‰²å’Œä¼˜åŠ¿
- å®¢è§‚æŒ‡å‡ºå¯èƒ½å­˜åœ¨çš„ä¸è¶³
- ç»™å‡ºå…·ä½“å¯æ“ä½œçš„é‡‡è´­æˆ–ä½¿ç”¨å»ºè®®
- ç‰¹åˆ«å…³æ³¨æ˜¯å¦é€‚åˆå°å°¼ä¸€å¹´çº§å­¦ç”Ÿçš„è®¤çŸ¥æ°´å¹³å’Œè¯­è¨€ç¯å¢ƒ
- ç”¨ä¸­æ–‡æ’°å†™ï¼Œä¸“ä¸šä¸”å…·ä½“ï¼Œä¸å°‘äº200å­—"""

        try:
            print(f"   æ­£åœ¨è°ƒç”¨ {self.model} æ¨¡å‹...")
            print(f"   é€šè¿‡VPNç›´è¿ï¼Œä¸ä½¿ç”¨ä»£ç†")

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ•™è‚²å†…å®¹è¯„ä¼°ä¸“å®¶ï¼Œæ‹¥æœ‰10å¹´ä»¥ä¸Šçš„K12æ•°å­¦æ•™è‚²è¯„ä¼°ç»éªŒï¼Œç†Ÿæ‚‰å°å°¼æ•™è‚²ä½“ç³»å’ŒKurikulum Merdekaæ•™å­¦å¤§çº²ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›è¯„ä¼°ç»“æœï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—æˆ–è§£é‡Šã€‚"
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=3000,
                timeout=120
            )

            result_text = response.choices[0].message.content.strip()

            # æå–JSONéƒ¨åˆ†
            json_text = JSONParser.extract_json_from_response(result_text)

            # è§£æJSON
            evaluation = json.loads(json_text)

            print(f"âœ… è¯„ä¼°å®Œæˆ")
            print(f"   æ•´ä½“è¯„åˆ†: {evaluation.get('overall_score', 'N/A')}/10")
            print(f"   æ¨è: {evaluation.get('recommendation', 'N/A')}")

            return evaluation

        except json.JSONDecodeError as e:
            print(f"âŒ JSONè§£æå¤±è´¥: {e}")
            print(f"   åŸå§‹å“åº”: {result_text[:300]}...")
            return self._create_error_evaluation(str(e), result_text[:500] if 'result_text' in locals() else '')
        except Exception as e:
            print(f"âŒ è¯„ä¼°å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return self._create_error_evaluation(str(e), '')

    def _create_error_evaluation(self, error_msg: str, raw_text: str) -> Dict[str, Any]:
        """åˆ›å»ºé”™è¯¯è¯„ä¼°ç»“æœ"""
        return {
            "overall_score": 0,
            "evaluation_text": f"è¯„ä¼°å¤±è´¥: {error_msg}",
            "recommendation": "è¯„ä¼°å¤±è´¥",
            "error": error_msg,
            "raw_response": raw_text
        }


def process_excel(input_file: str, output_file: str):
    """å¤„ç†Excelæ–‡ä»¶"""
    print("=" * 70)
    print("å°å°¼ä¸€å¹´çº§æ•°å­¦æ•™è‚²èµ„æºè¯„ä¼°ç³»ç»Ÿ")
    print("åŸºäº Gemini 2.5 Pro AIåˆ†æï¼ˆé€šè¿‡VPNç›´è¿ï¼‰")
    print("=" * 70)

    # è¯»å–Excelæ–‡ä»¶
    print(f"\nğŸ“‚ è¯»å–Excelæ–‡ä»¶: {input_file}")
    df = pd.read_excel(input_file)
    print(f"âœ… æˆåŠŸè¯»å– {len(df)} æ¡è®°å½•")

    # åˆå§‹åŒ–è¯„ä¼°å™¨
    evaluator = ResourceEvaluator()

    # å‡†å¤‡æ–°åˆ—
    scores = []
    evaluations = []

    # é€è¡Œå¤„ç†
    for idx, row in df.iterrows():
        name = row.get('åç§°', '')
        url = row.get('ç½‘å€', '')

        print(f"\n{'=' * 70}")
        print(f"[{idx + 1}/{len(df)}] è¯„ä¼°èµ„æº")
        print(f"åç§°: {name}")
        print(f"ç½‘å€: {url}")
        print(f"{'=' * 70}")

        # è¯„ä¼°èµ„æº
        evaluation = evaluator.evaluate(name, url)

        # æå–åˆ†æ•°
        overall_score = evaluation.get('overall_score', 0)

        # æ„å»ºè¯„ä¼°æ–‡æœ¬
        eval_text_parts = []

        # æ ‡é¢˜è¡Œ
        eval_text_parts.append(f"ã€æ•´ä½“è¯„åˆ†ã€‘: {overall_score:.1f}/10")
        eval_text_parts.append(f"ã€æ¨èæ„è§ã€‘: {evaluation.get('recommendation', 'N/A')}")

        # åˆ†é¡¹è¯„åˆ†
        if 'score_richness' in evaluation:
            eval_text_parts.append(f"\nã€åˆ†é¡¹è¯„åˆ†ã€‘")
            eval_text_parts.append(f"â€¢ èµ„æºä¸°å¯Œç¨‹åº¦: {evaluation['score_richness']:.1f}/10")
            eval_text_parts.append(f"â€¢ æ—¶æ•ˆæ€§: {evaluation['score_timeliness']:.1f}/10")
            eval_text_parts.append(f"â€¢ æ•™å­¦æ–¹æ³•: {evaluation['score_teaching_method']:.1f}/10")
            eval_text_parts.append(f"â€¢ ç”»é¢è´¨é‡: {evaluation['score_visual_quality']:.1f}/10")

        # è¯¦ç»†è¯„ä¼°
        eval_text_parts.append(f"\nã€è¯¦ç»†è¯„ä¼°ã€‘")
        eval_text_parts.append(evaluation.get('evaluation_text', ''))

        # é”™è¯¯ä¿¡æ¯
        if 'error' in evaluation:
            eval_text_parts.append(f"\nã€é”™è¯¯ä¿¡æ¯ã€‘")
            eval_text_parts.append(f"è¯„ä¼°è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {evaluation['error']}")

        final_eval_text = "\n".join(eval_text_parts)

        scores.append(overall_score)
        evaluations.append(final_eval_text)

        # é¿å…è¯·æ±‚è¿‡å¿«
        if idx < len(df) - 1:  # æœ€åä¸€ä¸ªä¸éœ€è¦ç­‰å¾…
            print(f"\nâ³ ç­‰å¾…3ç§’åå¤„ç†ä¸‹ä¸€ä¸ª...")
            time.sleep(3)

    # æ·»åŠ æ–°åˆ—
    df['è¯„ä¼°åˆ†æ•°'] = scores
    df['è¯„ä¼°å†…å®¹'] = evaluations

    # æŒ‰åˆ†æ•°é™åºæ’åº
    df = df.sort_values('è¯„ä¼°åˆ†æ•°', ascending=False)

    # ä¿å­˜åˆ°Excel
    print(f"\nğŸ’¾ ä¿å­˜è¯„ä¼°ç»“æœåˆ°: {output_file}")
    df.to_excel(output_file, index=False, engine='openpyxl')
    print("âœ… ä¿å­˜æˆåŠŸï¼")

    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 70)
    print("ğŸ“Š è¯„ä¼°ç»Ÿè®¡")
    print("=" * 70)
    print(f"æ€»è¯„ä¼°æ•°: {len(df)}")
    print(f"å¹³å‡åˆ†æ•°: {df['è¯„ä¼°åˆ†æ•°'].mean():.2f}/10")
    print(f"æœ€é«˜åˆ†æ•°: {df['è¯„ä¼°åˆ†æ•°'].max():.1f}/10")
    print(f"æœ€ä½åˆ†æ•°: {df['è¯„ä¼°åˆ†æ•°'].min():.1f}/10")

    # æ¨èåˆ†å¸ƒ
    print("\nã€æ¨èæ„è§åˆ†å¸ƒã€‘")
    recommendations = []
    for eval_text in df['è¯„ä¼°å†…å®¹']:
        match = re.search(r'ã€æ¨èæ„è§ã€‘:\s*(\S+)', eval_text)
        if match:
            recommendations.append(match.group(1))
    if recommendations:
        from collections import Counter
        for rec, count in Counter(recommendations).most_common():
            print(f"  {rec}: {count}ä¸ª")

    # æ˜¾ç¤ºæ‰€æœ‰èµ„æºæŒ‰åˆ†æ•°æ’åº
    print("\nã€èµ„æºæ’åï¼ˆæŒ‰åˆ†æ•°æ’åºï¼‰ã€‘")
    for idx, (name, score, rec) in enumerate(df[['åç§°', 'è¯„ä¼°åˆ†æ•°', 'è¯„ä¼°å†…å®¹']].values, 1):
        match = re.search(r'ã€æ¨èæ„è§ã€‘:\s*(\S+)', rec)
        recommendation = match.group(1) if match else 'N/A'
        print(f"  {idx}. {name}")
        print(f"     è¯„åˆ†: {score:.1f}/10 | æ¨è: {recommendation}")


if __name__ == "__main__":
    # æ–‡ä»¶è·¯å¾„
    input_file = "å°å°¼ä¸€å¹´çº§æ•°å­¦.xlsx"
    output_file = "å°å°¼ä¸€å¹´çº§æ•°å­¦_è¯„ä¼°ç»“æœ.xlsx"

    # æ‰§è¡Œè¯„ä¼°
    process_excel(input_file, output_file)

    print("\n" + "=" * 70)
    print("ğŸ‰ è¯„ä¼°å®Œæˆï¼")
    print(f"ğŸ“Š ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    print("=" * 70)
