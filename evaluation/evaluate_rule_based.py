#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°å°¼ä¸€å¹´çº§æ•°å­¦æ•™è‚²èµ„æºè¯„ä¼°è„šæœ¬ï¼ˆåŸºäºè§„åˆ™ + AIåˆ†æï¼‰

åŠŸèƒ½ï¼š
1. è¯»å–Excelä¸­çš„æ•™è‚²ç½‘ç«™åˆ—è¡¨
2. åŸºäºè§„åˆ™è¿›è¡Œåˆæ­¥è¯„ä¼°
3. ç”Ÿæˆè¯¦ç»†çš„è¯„ä¼°æŠ¥å‘Š
4. å°†è¯„ä¼°åˆ†æ•°å’Œè¯„ä»·å†™å…¥Excelæ–°åˆ—
"""

import os
import re
import pandas as pd
from typing import Dict, Any, Tuple
from urllib.parse import urlparse


class RuleBasedEvaluator:
    """åŸºäºè§„åˆ™çš„æ•™è‚²èµ„æºè¯„ä¼°å™¨"""

    def __init__(self):
        # å¹³å°æƒé‡é…ç½®
        self.platform_scores = {
            'youtube': 0.5,  # YouTubeå…è´¹ä½†è´¨é‡å‚å·®ä¸é½
            'ruangguru': 1.5,  # Ruangguruä¸“ä¸šæ•™è‚²å¹³å°
        }

        # ç‰¹å¾æƒé‡é…ç½®
        self.feature_weights = {
            'kurikulum_merdeka': 1.0,  # ç¬¦åˆæœ€æ–°å¤§çº²
            'playlist': 0.3,  # æ’­æ”¾åˆ—è¡¨
            'sd_kelas_1': 0.5,  # æ˜ç¡®æ ‡æ³¨ä¸€å¹´çº§
            'topik': 0.3,  # æŒ‰ä¸»é¢˜ç»„ç»‡
        }

    def identify_platform(self, url: str) -> str:
        """è¯†åˆ«æ•™è‚²å¹³å°ç±»å‹"""
        if 'youtube.com' in url or 'youtu.be' in url:
            return 'YouTubeï¼ˆå…¨çƒæœ€å¤§è§†é¢‘å¹³å°ï¼Œå…è´¹ï¼‰'
        elif 'ruangguru.com' in url:
            return 'Ruangguruï¼ˆå°å°¼é¢†å…ˆåœ¨çº¿æ•™è‚²å¹³å°ï¼‰'
        elif 'dafalulu.ruangguru.com' in url:
            return 'Ruangguru Dafaluluï¼ˆRuangguruå­å“ç‰Œï¼‰'
        else:
            return 'å…¶ä»–å¹³å°'

    def extract_features(self, name: str, url: str) -> Dict[str, bool]:
        """æå–èµ„æºç‰¹å¾"""
        return {
            'is_kurikulum_merdeka': 'merdeka' in url.lower() or 'merdeka' in name.lower(),
            'is_playlist': 'playlist' in url,
            'is_sd_kelas_1': 'sd kelas 1' in name.lower() or 'sd-kelas-1' in url.lower(),
            'is_topik': 'topik' in url.lower() or 'topik' in name.lower(),
            'is_dafalulu': 'dafalulu' in url.lower(),
            'is_youtube': 'youtube.com' in url,
            'is_ruangguru': 'ruangguru.com' in url,
        }

    def calculate_scores(self, name: str, url: str, features: Dict[str, bool]) -> Dict[str, float]:
        """è®¡ç®—å„ç»´åº¦åˆ†æ•°"""
        base_score = 6.0  # åŸºç¡€åˆ†

        # èµ„æºä¸°å¯Œç¨‹åº¦è¯„åˆ†
        richness = base_score
        if features['is_playlist']:
            richness += 1.5  # æ’­æ”¾åˆ—è¡¨é€šå¸¸åŒ…å«å¤šä¸ªè§†é¢‘
        if features['is_ruangguru']:
            richness += 1.0  # Ruangguruæœ‰ç³»ç»ŸåŒ–è¯¾ç¨‹
        if features['is_dafalulu']:
            richness += 0.5
        richness = min(richness, 9.5)

        # æ—¶æ•ˆæ€§è¯„åˆ†
        timeliness = base_score
        if features['is_kurikulum_merdeka']:
            timeliness += 2.0  # Kurikulum Merdekaæ˜¯2022å¹´æœ€æ–°å¤§çº²
        elif features['is_youtube']:
            timeliness += 0.5  # YouTubeå†…å®¹æ›´æ–°è¾ƒé¢‘ç¹
        timeliness = min(timeliness, 9.5)

        # æ•™å­¦æ–¹æ³•è¯„åˆ†
        teaching = base_score + 1.0
        if features['is_topik']:
            teaching += 0.5  # æŒ‰ä¸»é¢˜ç»„ç»‡æœ‰åˆ©äºå­¦ä¹ 
        if features['is_sd_kelas_1']:
            teaching += 0.5  # æ˜ç¡®ç›®æ ‡å¹´çº§
        teaching = min(teaching, 9.0)

        # ç”»é¢è´¨é‡è¯„åˆ†
        visual = base_score + 0.5
        if features['is_ruangguru']:
            visual += 1.0  # ä¸“ä¸šå¹³å°åˆ¶ä½œè´¨é‡è¾ƒé«˜
        if features['is_youtube']:
            visual += 0.3  # YouTubeç”»è´¨æ™®éè¾ƒå¥½
        visual = min(visual, 8.5)

        # æ•´ä½“æ¨èåº¦ï¼ˆåŠ æƒå¹³å‡ï¼‰
        weights = {
            'richness': 0.25,
            'timeliness': 0.25,
            'teaching': 0.30,
            'visual': 0.20,
        }

        overall = (
            richness * weights['richness'] +
            timeliness * weights['timeliness'] +
            teaching * weights['teaching'] +
            visual * weights['visual']
        )

        # é¢å¤–åŠ åˆ†
        if features['is_kurikulum_merdeka'] and features['is_ruangguru']:
            overall += 0.5  # ä¸“ä¸šå¹³å° + æœ€æ–°å¤§çº²
        overall = min(overall, 9.5)

        return {
            'richness': round(richness, 1),
            'timeliness': round(timeliness, 1),
            'teaching': round(teaching, 1),
            'visual': round(visual, 1),
            'overall': round(overall, 1),
        }

    def get_recommendation(self, overall_score: float, features: Dict[str, bool]) -> str:
        """æ ¹æ®åˆ†æ•°å’Œç‰¹å¾ç»™å‡ºæ¨èæ„è§"""
        if overall_score >= 8.5:
            return "å¼ºçƒˆæ¨è"
        elif overall_score >= 7.5:
            return "æ¨è"
        elif overall_score >= 6.5:
            return "å¯ä»¥è€ƒè™‘"
        else:
            return "ä¸æ¨è"

    def generate_evaluation_text(self, name: str, url: str, platform: str,
                                 features: Dict[str, bool], scores: Dict[str, float]) -> str:
        """ç”Ÿæˆè¯¦ç»†è¯„ä¼°æ–‡æœ¬"""
        lines = []

        # èµ„æºæ¦‚è¿°
        lines.append("**èµ„æºæ¦‚è¿°**")
        lines.append(f"- èµ„æºåç§°: {name}")
        lines.append(f"- æ‰€å±å¹³å°: {platform}")
        lines.append(f"- èµ„æºç±»å‹: {'YouTubeæ’­æ”¾åˆ—è¡¨' if features['is_playlist'] else 'åœ¨çº¿è¯¾ç¨‹é¡µé¢'}")
        lines.append(f"- æ•™å­¦å¤§çº²: {'ç¬¦åˆKurikulum Merdekaï¼ˆ2022å¹´å°å°¼æœ€æ–°æ•™è‚²å¤§çº²ï¼‰' if features['is_kurikulum_merdeka'] else 'éœ€è¦äººå·¥æ ¸å®æ˜¯å¦ç¬¦åˆæœ€æ–°å¤§çº²'}")

        # å¹³å°åˆ†æ
        lines.append("\n**å¹³å°åˆ†æ**")
        if features['is_youtube']:
            lines.append("- YouTubeå¹³å°ä¼˜åŠ¿: å®Œå…¨å…è´¹ã€éšæ—¶éšåœ°è®¿é—®ã€å¤§é‡ä¼˜è´¨æ•™è‚²èµ„æº")
            lines.append("- YouTubeå¹³å°åŠ£åŠ¿: å†…å®¹è´¨é‡å‚å·®ä¸é½ã€éœ€è¦äººå·¥ç­›é€‰ã€å¹¿å‘Šå¹²æ‰°")
        if features['is_ruangguru']:
            lines.append("- Ruangguruå¹³å°ä¼˜åŠ¿: å°å°¼é¢†å…ˆçš„åœ¨çº¿æ•™è‚²å¹³å°ã€ç³»ç»ŸåŒ–è¯¾ç¨‹è®¾è®¡ã€ä¸“ä¸šæ•™å¸ˆå›¢é˜Ÿ")
            lines.append("- Ruangguruå¹³å°åŠ£åŠ¿: å¯èƒ½éœ€è¦ä»˜è´¹è®¢é˜…ã€éœ€è¦ç½‘ç»œè¿æ¥")

        # ç»´åº¦åˆ†æ
        lines.append("\n**å„ç»´åº¦è¯„åˆ†ç†ç”±**")

        lines.append(f"\n1. èµ„æºä¸°å¯Œç¨‹åº¦ ({scores['richness']}/10)")
        if features['is_playlist']:
            lines.append("   - æ’­æ”¾åˆ—è¡¨å½¢å¼ï¼ŒåŒ…å«å¤šä¸ªè§†é¢‘è¯¾ç¨‹")
        if features['is_ruangguru']:
            lines.append("   - ä¸“ä¸šæ•™è‚²å¹³å°ï¼Œè¯¾ç¨‹ä½“ç³»å®Œæ•´")
        lines.append("   - é¢„æœŸè¦†ç›–åŸºç¡€æ•°æ•°ã€åŠ å‡æ³•ã€å½¢çŠ¶è®¤çŸ¥ç­‰ä¸€å¹´çº§æ ¸å¿ƒå†…å®¹")

        lines.append(f"\n2. æ—¶æ•ˆæ€§ ({scores['timeliness']}/10)")
        if features['is_kurikulum_merdeka']:
            lines.append("   - æ˜ç¡®ç¬¦åˆKurikulum Merdekaï¼Œæ—¶æ•ˆæ€§ä¼˜ç§€")
            lines.append("   - Kurikulum Merdekaæ˜¯å°å°¼2022å¹´å®æ–½çš„æœ€æ–°æ•™è‚²å¤§çº²")
        else:
            lines.append("   - æœªæ˜ç¡®æ ‡æ³¨æ˜¯å¦ç¬¦åˆæœ€æ–°å¤§çº²ï¼Œå»ºè®®äººå·¥æ ¸å®")
            lines.append("   - éœ€è¦ç¡®è®¤å†…å®¹æ˜¯å¦ç¬¦åˆKurikulum Merdekaè¦æ±‚")

        lines.append(f"\n3. æ•™å­¦æ–¹æ³• ({scores['teaching']}/10)")
        lines.append("   - é’ˆå¯¹6-7å²å„¿ç«¥è®¾è®¡çš„æ•°å­¦è¯¾ç¨‹")
        if features['is_topik']:
            lines.append("   - æŒ‰ä¸»é¢˜ç»„ç»‡æ•™å­¦å†…å®¹ï¼Œä¾¿äºç³»ç»Ÿå­¦ä¹ ")
        lines.append("   - é¢„æœŸé‡‡ç”¨ç›´è§‚æ•™å­¦ã€åŠ¨ç”»æ¼”ç¤ºç­‰é€‚åˆä½é¾„å„¿ç«¥çš„æ–¹æ³•")

        lines.append(f"\n4. ç”»é¢è´¨é‡ ({scores['visual']}/10)")
        if features['is_youtube']:
            lines.append("   - YouTubeå¹³å°è§†é¢‘è´¨é‡æ™®éè¾ƒé«˜")
        if features['is_ruangguru']:
            lines.append("   - ä¸“ä¸šå¹³å°åˆ¶ä½œï¼Œç”»è´¨å’Œåˆ¶ä½œæ°´å‡†æœ‰ä¿éšœ")
        lines.append("   - å»ºè®®äººå·¥æ ¸å®å…·ä½“è§†é¢‘çš„æ¸…æ™°åº¦å’Œåˆ¶ä½œè´¨é‡")

        # ä¼˜ç‚¹
        lines.append("\n**ä¸»è¦ä¼˜ç‚¹**")
        if features['is_kurikulum_merdeka']:
            lines.append("- ç¬¦åˆå°å°¼æœ€æ–°æ•™è‚²å¤§çº²Kurikulum Merdeka")
        if features['is_youtube']:
            lines.append("- å®Œå…¨å…è´¹ï¼Œæ— éœ€ä»˜è´¹è®¢é˜…")
            lines.append("- å¯ä»¥éšæ—¶éšåœ°è®¿é—®ï¼Œçµæ´»æ€§å¥½")
        if features['is_ruangguru']:
            lines.append("- ä¸“ä¸šæ•™è‚²å¹³å°ï¼Œæ•™å­¦è´¨é‡æœ‰ä¿éšœ")
        if features['is_playlist']:
            lines.append("- å†…å®¹ä½“ç³»åŒ–ï¼Œä¾¿äºå¾ªåºæ¸è¿›å­¦ä¹ ")

        # ä¸è¶³
        lines.append("\n**æ½œåœ¨ä¸è¶³**")
        if features['is_youtube']:
            lines.append("- å¯èƒ½åŒ…å«å¹¿å‘Šï¼Œå½±å“å­¦ä¹ ä½“éªŒ")
            lines.append("- å†…å®¹è´¨é‡å¯èƒ½å‚å·®ä¸é½")
        if not features['is_kurikulum_merdeka']:
            lines.append("- æœªæ˜ç¡®æ˜¯å¦ç¬¦åˆæœ€æ–°æ•™å­¦å¤§çº²")
        lines.append("- éœ€è¦äººå·¥æ ¸å®æ•™å­¦æ–¹æ³•å’Œå„¿ç«¥å‹å¥½æ€§")

        # é‡‡è´­å»ºè®®
        lines.append("\n**é‡‡è´­/ä½¿ç”¨å»ºè®®**")
        recommendation = self.get_recommendation(scores['overall'], features)
        if recommendation == "å¼ºçƒˆæ¨è":
            lines.append("- è¯¥èµ„æºç»¼åˆè¡¨ç°ä¼˜ç§€ï¼Œå¼ºçƒˆæ¨èé‡‡è´­æˆ–ä½¿ç”¨")
            lines.append("- å¯ä½œä¸ºä¸»è¦æ•™å­¦èµ„æºä½¿ç”¨")
        elif recommendation == "æ¨è":
            lines.append("- è¯¥èµ„æºæ•´ä½“è¡¨ç°è‰¯å¥½ï¼Œæ¨èä½¿ç”¨")
            lines.append("- å¯ä½œä¸ºè¾…åŠ©æ•™å­¦èµ„æº")
        elif recommendation == "å¯ä»¥è€ƒè™‘":
            lines.append("- è¯¥èµ„æºåŸºæœ¬ç¬¦åˆè¦æ±‚ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨")
            lines.append("- å»ºè®®ä¸å…¶ä»–èµ„æºé…åˆä½¿ç”¨")
        else:
            lines.append("- è¯¥èµ„æºå­˜åœ¨æ˜æ˜¾ä¸è¶³ï¼Œä¸æ¨èä½¿ç”¨")

        lines.append("- å»ºè®®å…ˆè¯•ç”¨å°‘é‡å†…å®¹ï¼Œç¡®è®¤è´¨é‡åå†å…¨é¢é‡‡ç”¨")
        lines.append("- å»ºè®®å®šæœŸæ›´æ–°èµ„æºï¼Œç¡®ä¿å†…å®¹æ—¶æ•ˆæ€§")

        # æ³¨æ„äº‹é¡¹
        lines.append("\n**æ³¨æ„äº‹é¡¹**")
        lines.append("- æœ¬è¯„ä¼°åŸºäºURLå’Œèµ„æºåç§°åˆ†æï¼Œæœªè¿›è¡Œæ·±åº¦å†…å®¹å®¡æŸ¥")
        lines.append("- å»ºè®®äººå·¥è®¿é—®èµ„æºï¼Œæ ¸å®å®é™…å†…å®¹è´¨é‡")
        lines.append("- é‡ç‚¹å…³æ³¨è§†é¢‘ç”»è´¨ã€è®²è§£æ¸…æ™°åº¦ã€æ•™å­¦æ–¹æ³•å„¿ç«¥å‹å¥½æ€§")
        lines.append("- ç¡®è®¤å†…å®¹å®Œå…¨è¦†ç›–å°å°¼ä¸€å¹´çº§æ•°å­¦æ•™å­¦å¤§çº²è¦æ±‚")

        return "\n".join(lines)

    def evaluate(self, name: str, url: str) -> Dict[str, Any]:
        """å®Œæ•´è¯„ä¼°æµç¨‹"""
        print(f"\nğŸ” è¯„ä¼°: {name}")

        platform = self.identify_platform(url)
        features = self.extract_features(name, url)
        scores = self.calculate_scores(name, url, features)
        recommendation = self.get_recommendation(scores['overall'], features)
        evaluation_text = self.generate_evaluation_text(name, url, platform, features, scores)

        print(f"âœ… è¯„åˆ†: {scores['overall']}/10 | {recommendation}")

        return {
            "score_richness": scores['richness'],
            "score_timeliness": scores['timeliness'],
            "score_teaching_method": scores['teaching'],
            "score_visual_quality": scores['visual'],
            "overall_score": scores['overall'],
            "evaluation_text": evaluation_text,
            "recommendation": recommendation,
        }


def process_excel(input_file: str, output_file: str):
    """å¤„ç†Excelæ–‡ä»¶"""
    print("=" * 70)
    print("å°å°¼ä¸€å¹´çº§æ•°å­¦æ•™è‚²èµ„æºè¯„ä¼°ç³»ç»Ÿ")
    print("åŸºäºè§„åˆ™çš„ä¸“ä¸šè¯„ä¼°")
    print("=" * 70)

    df = pd.read_excel(input_file)
    print(f"\nâœ… è¯»å– {len(df)} æ¡è®°å½•")

    evaluator = RuleBasedEvaluator()
    scores = []
    evaluations = []

    for idx, row in df.iterrows():
        name = row.get('åç§°', '')
        url = row.get('ç½‘å€', '')

        print(f"\n{'=' * 70}")
        print(f"[{idx + 1}/{len(df)}] {name}")
        print(f"ç½‘å€: {url}")
        print(f"{'=' * 70}")

        evaluation = evaluator.evaluate(name, url)
        overall_score = evaluation.get('overall_score', 0)

        # æ„å»ºè¯„ä¼°æ–‡æœ¬
        eval_text_parts = [
            f"ã€æ•´ä½“è¯„åˆ†ã€‘: {overall_score:.1f}/10",
            f"ã€æ¨èæ„è§ã€‘: {evaluation.get('recommendation', 'N/A')}",
        ]

        if 'score_richness' in evaluation:
            eval_text_parts.extend([
                f"\nã€åˆ†é¡¹è¯„åˆ†ã€‘",
                f"â€¢ èµ„æºä¸°å¯Œç¨‹åº¦: {evaluation['score_richness']:.1f}/10",
                f"â€¢ æ—¶æ•ˆæ€§: {evaluation['score_timeliness']:.1f}/10",
                f"â€¢ æ•™å­¦æ–¹æ³•: {evaluation['score_teaching_method']:.1f}/10",
                f"â€¢ ç”»é¢è´¨é‡: {evaluation['score_visual_quality']:.1f}/10",
            ])

        eval_text_parts.extend([
            f"\nã€è¯¦ç»†è¯„ä¼°ã€‘",
            evaluation.get('evaluation_text', '')
        ])

        final_eval_text = "\n".join(eval_text_parts)
        scores.append(overall_score)
        evaluations.append(final_eval_text)

    df['è¯„ä¼°åˆ†æ•°'] = scores
    df['è¯„ä¼°å†…å®¹'] = evaluations
    df = df.sort_values('è¯„ä¼°åˆ†æ•°', ascending=False)

    df.to_excel(output_file, index=False, engine='openpyxl')
    print(f"\nğŸ’¾ å·²ä¿å­˜åˆ°: {output_file}")

    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 70)
    print("ğŸ“Š è¯„ä¼°ç»Ÿè®¡")
    print("=" * 70)
    print(f"æ€»è¯„ä¼°æ•°: {len(df)}")
    print(f"å¹³å‡åˆ†æ•°: {df['è¯„ä¼°åˆ†æ•°'].mean():.2f}/10")
    print(f"æœ€é«˜åˆ†æ•°: {df['è¯„ä¼°åˆ†æ•°'].max():.1f}/10")
    print(f"æœ€ä½åˆ†æ•°: {df['è¯„ä¼°åˆ†æ•°'].min():.1f}/10")

    print("\nã€æ¨èæ„è§åˆ†å¸ƒã€‘")
    from collections import Counter
    recommendations = []
    for eval_text in df['è¯„ä¼°å†…å®¹']:
        match = re.search(r'ã€æ¨èæ„è§ã€‘:\s*(\S+)', eval_text)
        if match:
            recommendations.append(match.group(1))
    for rec, count in Counter(recommendations).most_common():
        print(f"  {rec}: {count}ä¸ª")

    print("\nã€èµ„æºæ’åï¼ˆæŒ‰åˆ†æ•°æ’åºï¼‰ã€‘")
    for idx, (name, score, eval_text) in enumerate(df[['åç§°', 'è¯„ä¼°åˆ†æ•°', 'è¯„ä¼°å†…å®¹']].values, 1):
        match = re.search(r'ã€æ¨èæ„è§ã€‘:\s*(\S+)', eval_text)
        rec = match.group(1) if match else 'N/A'
        print(f"  {idx}. {name}")
        print(f"     è¯„åˆ†: {score:.1f}/10 | æ¨è: {rec}")


if __name__ == "__main__":
    input_file = "å°å°¼ä¸€å¹´çº§æ•°å­¦.xlsx"
    output_file = "å°å°¼ä¸€å¹´çº§æ•°å­¦_è¯„ä¼°ç»“æœ.xlsx"
    process_excel(input_file, output_file)
    print("\n" + "=" * 70)
    print("ğŸ‰ è¯„ä¼°å®Œæˆï¼")
    print(f"ğŸ“Š ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    print("=" * 70)
