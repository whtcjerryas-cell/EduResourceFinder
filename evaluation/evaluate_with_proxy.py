#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°å°¼ä¸€å¹´çº§æ•°å­¦æ•™è‚²èµ„æºè¯„ä¼°è„šæœ¬ï¼ˆä½¿ç”¨å…¬å¸å†…éƒ¨API + ä»£ç†ï¼‰

åŠŸèƒ½ï¼š
1. è¯»å–Excelä¸­çš„æ•™è‚²ç½‘ç«™åˆ—è¡¨
2. ä½¿ç”¨ä»£ç†è®¿é—®å…¬å¸å†…éƒ¨Gemini 2.5 Proè¿›è¡ŒAIåˆ†æè¯„ä¼°
3. å°†è¯„ä¼°åˆ†æ•°å’Œè¯„ä»·å†™å…¥Excelæ–°åˆ—
"""

import os
import json
import time
import re
from typing import Dict, Any
import pandas as pd
from openai import OpenAI
from dotenv import load_dotenv
import httpx

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# APIé…ç½®
INTERNAL_API_KEY = os.getenv("INTERNAL_API_KEY", "sk_4c34c16af4f8bb4bc102f3d1afd6439127c4d95a2912af34efcbda0")
INTERNAL_API_BASE_URL = os.getenv("INTERNAL_API_BASE_URL", "https://hk-intra-paas.transsion.com/tranai-proxy/v1")

# ä»£ç†é…ç½®
PROXY_URL = "http://127.0.0.1:7897"

# å¯¼å…¥JSONè§£æå·¥å…·
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from utils.json_parser import JSONParser
from utils.platform_detector import PlatformDetector


def setup_environment():
    """é…ç½®ç¯å¢ƒå˜é‡å’Œä»£ç†"""
    # è®¾ç½®ä»£ç†ç¯å¢ƒå˜é‡
    os.environ["HTTP_PROXY"] = PROXY_URL
    os.environ["HTTPS_PROXY"] = PROXY_URL
    print(f"âœ… å·²è®¾ç½®ä»£ç†: {PROXY_URL}")


class ResourceEvaluator:
    """æ•™è‚²èµ„æºè¯„ä¼°å™¨ - ä½¿ç”¨å…¬å¸å†…éƒ¨ Gemini 2.5 Pro"""

    def __init__(self):
        # ä½¿ç”¨ httpx ä½œä¸º HTTP å®¢æˆ·ç«¯ï¼Œæ”¯æŒä»£ç†
        self.client = OpenAI(
            api_key=INTERNAL_API_KEY,
            base_url=INTERNAL_API_BASE_URL,
            http_client=httpx.Client(
                proxy=PROXY_URL,
                timeout=120.0,
                verify=False  # å¦‚æœæœ‰SSLè¯ä¹¦é—®é¢˜å¯ä»¥ç¦ç”¨éªŒè¯
            )
        )
        self.model = "gemini-2.5-pro"

    def evaluate(self, name: str, url: str) -> Dict[str, Any]:
        """
        ä½¿ç”¨ Gemini 2.5 Pro è¿›è¡Œè¯„ä¼°

        Args:
            name: èµ„æºåç§°
            url: èµ„æºç½‘å€

        Returns:
            åŒ…å«è¯„ä¼°åˆ†æ•°å’Œè¯„ä»·çš„å­—å…¸
        """
        print(f"\nğŸ¤– Gemini 2.5 Pro è¯„ä¼°: {name}")

        platform = PlatformDetector.identify_platform(url)
        is_playlist = 'playlist' in url
        is_kurikulum_merdeka = 'merdeka' in url.lower() or 'merdeka' in name.lower()

        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ•™è‚²å†…å®¹è¯„ä¼°ä¸“å®¶ï¼Œä¸“é—¨è¯„ä¼°å°å°¼å°å­¦ä¸€å¹´çº§æ•°å­¦æ•™è‚²èµ„æºã€‚

**èµ„æºåŸºæœ¬ä¿¡æ¯**:
- èµ„æºåç§°: {name}
- èµ„æºç½‘å€: {url}
- æ‰€å±å¹³å°: {platform}
- URLç‰¹å¾: {'YouTubeæ’­æ”¾åˆ—è¡¨' if is_playlist else 'è¯¾ç¨‹é¡µé¢'}
- æ•™å­¦å¤§çº²: {'ç¬¦åˆKurikulum Merdekaï¼ˆå°å°¼æœ€æ–°ç‹¬ç«‹è¯¾ç¨‹ï¼‰' if is_kurikulum_merdeka else 'éœ€è¦äººå·¥æ ¸å®'}

---

**è¯„ä¼°èƒŒæ™¯**:
è¿™æ˜¯ä¸ºå°å°¼å°å­¦ä¸€å¹´çº§å­¦ç”Ÿï¼ˆ6-7å²ï¼‰è®¾è®¡çš„æ•°å­¦æ•™è‚²èµ„æºã€‚å†…å®¹åº”è¯¥åŒ…æ‹¬åŸºç¡€æ•°æ•°ã€ç®€å•åŠ å‡æ³•ã€å½¢çŠ¶è®¤çŸ¥ã€æµ‹é‡åŸºç¡€ã€æ•°æ®æ”¶é›†åŸºç¡€ç­‰ã€‚

**å¹³å°èƒŒæ™¯**:
- Ruangguru: å°å°¼æœ€å¤§çš„åœ¨çº¿æ•™è‚²å¹³å°ï¼Œæä¾›ç³»ç»ŸåŒ–è¯¾ç¨‹ï¼Œä¸“ä¸šæ•™å¸ˆå›¢é˜Ÿ
- YouTube: å…¨çƒæœ€å¤§è§†é¢‘å¹³å°ï¼Œæœ‰å¤§é‡å…è´¹æ•™è‚²èµ„æºï¼Œè®¿é—®ä¾¿åˆ©

---

è¯·ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œä¸“ä¸šè¯„ä¼°ï¼ˆæ¯ä¸ªç»´åº¦0-10åˆ†ï¼‰ï¼š

**1. èµ„æºä¸°å¯Œç¨‹åº¦ (0-10åˆ†)**
   - å†…å®¹æ•°é‡å’Œè¦†ç›–å¹¿åº¦
   - ä¸»é¢˜å®Œæ•´æ€§
   - é…å¥—èµ„æºï¼ˆç»ƒä¹ é¢˜ã€è®²ä¹‰ç­‰ï¼‰
   - æ›´æ–°é¢‘ç‡

**2. æ—¶æ•ˆæ€§ (0-10åˆ†)**
   - æ˜¯å¦ç¬¦åˆKurikulum Merdekaï¼ˆå°å°¼2022å¹´å®æ–½çš„æœ€æ–°æ•™è‚²å¤§çº²ï¼‰
   - å†…å®¹çš„æ›´æ–°ç»´æŠ¤çŠ¶æ€
   - æ•™è‚²ç†å¿µçš„å…ˆè¿›æ€§

**3. æ•™å­¦æ–¹æ³• (0-10åˆ†)**
   - é’ˆå¯¹6-7å²å„¿ç«¥çš„æ•™å­¦è®¾è®¡
   - è¶£å‘³æ€§å’Œäº’åŠ¨æ€§
   - æ•™å­¦èŠ‚å¥å’Œè®²è§£æ¸…æ™°åº¦
   - æ˜¯å¦ç¬¦åˆå„¿ç«¥è®¤çŸ¥å‘å±•è§„å¾‹
   - è§†è§‰è¾…åŠ©å’ŒåŠ¨ç”»è¿ç”¨

**4. ç”»é¢è´¨é‡ (0-10åˆ†)**
   - è§†é¢‘ç”»è´¨å’Œåˆ¶ä½œæ°´å‡†
   - ç•Œé¢è®¾è®¡å’Œç”¨æˆ·ä½“éªŒ
   - åŠ¨ç”»å’Œè§†è§‰æ•ˆæœ
   - éŸ³é¢‘è´¨é‡

**5. æ•´ä½“æ¨èåº¦ (0-10åˆ†)**
   - ç»¼åˆè´¨é‡å’Œä»·å€¼
   - æ€§ä»·æ¯”ï¼ˆå¦‚æœéœ€è¦ä»˜è´¹ï¼‰
   - é€‚ç”¨æ€§å’Œå®ç”¨æ€§
   - æ˜¯å¦å€¼å¾—é‡‡è´­æ¨è

---

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›è¯„ä¼°ç»“æœï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ï¼š
```json
{{
    "score_richness": 8.5,
    "score_timeliness": 7.0,
    "score_teaching_method": 9.0,
    "score_visual_quality": 8.0,
    "overall_score": 8.1,
    "evaluation_text": "è¯¦ç»†è¯„ä¼°å†…å®¹ï¼ŒåŒ…æ‹¬ï¼š\\n1. èµ„æºç‰¹ç‚¹åˆ†æ\\n2. å„ç»´åº¦è¯„åˆ†ç†ç”±\\n3. ä¼˜ç‚¹\\n4. ä¸è¶³ä¹‹å¤„\\n5. é‡‡è´­å»ºè®®...",
    "recommendation": "å¼ºçƒˆæ¨è"
}}
```

æ¨èåº¦å¯é€‰å€¼: "å¼ºçƒˆæ¨è", "æ¨è", "å¯ä»¥è€ƒè™‘", "ä¸æ¨è"

**è¯„ä¼°æ–‡æœ¬è¦æ±‚**:
- è¯¦ç»†è¯´æ˜æ¯ä¸ªç»´åº¦çš„è¯„åˆ†ç†ç”±
- åˆ†æè¯¥èµ„æºçš„ç‰¹è‰²å’Œä¼˜åŠ¿
- æŒ‡å‡ºå¯èƒ½å­˜åœ¨çš„ä¸è¶³
- ç»™å‡ºå…·ä½“çš„é‡‡è´­æˆ–ä½¿ç”¨å»ºè®®
- ç‰¹åˆ«å…³æ³¨æ˜¯å¦é€‚åˆå°å°¼ä¸€å¹´çº§å­¦ç”Ÿçš„è®¤çŸ¥æ°´å¹³
- ç”¨ä¸­æ–‡æ’°å†™ï¼Œä¸“ä¸šä¸”å…·ä½“"""

        try:
            print(f"   æ­£åœ¨é€šè¿‡ä»£ç†è°ƒç”¨ {self.model} æ¨¡å‹...")

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ•™è‚²å†…å®¹è¯„ä¼°ä¸“å®¶ï¼Œæ‹¥æœ‰10å¹´ä»¥ä¸Šçš„K12æ•°å­¦æ•™è‚²è¯„ä¼°ç»éªŒï¼Œç†Ÿæ‚‰å°å°¼æ•™è‚²ä½“ç³»ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›è¯„ä¼°ç»“æœï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ã€‚"
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=3000,
                timeout=120
            )

            result_text = response.choices[0].message.content.strip()

            # æå–JSONéƒ¨åˆ†
            json_text = JSONParser.extract_json_from_response(result_text)

            # è§£æJSON
            evaluation = json.loads(json_text)

            print(f"âœ… è¯„ä¼°å®Œæˆ")
            print(f"   æ•´ä½“è¯„åˆ†: {evaluation.get('overall_score', 'N/A')}/10")
            print(f"   æ¨è: {evaluation.get('recommendation', 'N/A')}")

            return evaluation

        except json.JSONDecodeError as e:
            print(f"âŒ JSONè§£æå¤±è´¥: {e}")
            print(f"   åŸå§‹å“åº”: {result_text[:300]}...")
            return self._create_error_evaluation(str(e), result_text[:500] if 'result_text' in locals() else '')
        except Exception as e:
            print(f"âŒ è¯„ä¼°å¤±è´¥: {str(e)}")
            # å¦‚æœä»£ç†è°ƒç”¨å¤±è´¥ï¼Œè¿”å›åŸºäºè§„åˆ™çš„åå¤‡è¯„ä¼°
            return self._create_rule_based_fallback(name, url, platform, str(e))

    def _create_error_evaluation(self, error_msg: str, raw_text: str) -> Dict[str, Any]:
        """åˆ›å»ºé”™è¯¯è¯„ä¼°ç»“æœ"""
        return {
            "overall_score": 0,
            "evaluation_text": f"è¯„ä¼°å¤±è´¥: {error_msg}",
            "recommendation": "è¯„ä¼°å¤±è´¥",
            "error": error_msg,
            "raw_response": raw_text
        }

    def _create_rule_based_fallback(self, name: str, url: str, platform: str, error_msg: str) -> Dict[str, Any]:
        """åˆ›å»ºåŸºäºè§„åˆ™çš„åå¤‡è¯„ä¼°"""
        is_kurikulum_merdeka = 'merdeka' in url.lower() or 'merdeka' in name.lower()
        is_youtube = 'youtube.com' in url
        is_ruangguru = 'ruangguru.com' in url

        # åŸºäºè§„åˆ™çš„ç®€å•è¯„åˆ†
        base_score = 7.0

        if is_ruangguru:
            base_score += 1.0  # Ruangguruæ˜¯ä¸“ä¸šæ•™è‚²å¹³å°
        if is_kurikulum_merdeka:
            base_score += 0.5  # ç¬¦åˆæœ€æ–°å¤§çº²
        if is_youtube:
            base_score += 0.5  # YouTubeå…è´¹ä¸”æ˜“äºè®¿é—®

        base_score = min(base_score, 9.0)

        evaluation_text = f"""âš ï¸ æ³¨æ„ï¼šç”±äºç½‘ç»œåŸå› ï¼ŒAIè¯„ä¼°æš‚æ—¶ä¸å¯ç”¨ã€‚ä»¥ä¸‹æ˜¯åŸºäºè§„åˆ™çš„åå¤‡è¯„ä¼°ï¼š

**èµ„æºåˆ†æ**:
- å¹³å°: {platform}
- ç±»å‹: {'YouTubeæ’­æ”¾åˆ—è¡¨ï¼ˆå…è´¹è§†é¢‘èµ„æºï¼‰' if is_youtube else 'åœ¨çº¿è¯¾ç¨‹å¹³å°'}
- æ•™å­¦å¤§çº²: {'ç¬¦åˆKurikulum Merdekaï¼ˆ2022å¹´å°å°¼æœ€æ–°æ•™è‚²å¤§çº²ï¼‰' if is_kurikulum_merdeka else 'éœ€è¦äººå·¥æ ¸å®æ˜¯å¦ç¬¦åˆæœ€æ–°å¤§çº²'}

**è¯„ä¼°è¯´æ˜**:
{f"- Ruangguruæ˜¯å°å°¼é¢†å…ˆçš„åœ¨çº¿æ•™è‚²å¹³å°ï¼Œè¯¾ç¨‹ç³»ç»Ÿæ€§å¼º" if is_ruangguru else "- YouTubeæä¾›å…è´¹è§†é¢‘èµ„æºï¼Œè®¿é—®ä¾¿åˆ©"}
{f"- æ˜ç¡®æ ‡æ³¨ç¬¦åˆKurikulum Merdekaï¼Œæ—¶æ•ˆæ€§è¾ƒå¥½" if is_kurikulum_merdeka else "- å»ºè®®äººå·¥æ ¸å®æ˜¯å¦ç¬¦åˆKurikulum Merdeka"}
- {'è§†é¢‘æ’­æ”¾åˆ—è¡¨å½¢å¼ï¼Œé€‚åˆå­¦ç”Ÿè‡ªä¸»å­¦ä¹ ' if is_youtube else '- ç»“æ„åŒ–è¯¾ç¨‹ï¼Œå¯èƒ½æœ‰é…å¥—ç»ƒä¹ '}

**æŠ€æœ¯è¯´æ˜**:
- APIè°ƒç”¨é‡åˆ°é—®é¢˜: {error_msg[:100]}
- å»ºè®®æ£€æŸ¥ä»£ç†è®¾ç½®æˆ–ç½‘ç»œè¿æ¥
- æ­¤è¯„ä¼°ä¸ºåå¤‡æ–¹æ¡ˆï¼Œå»ºè®®äººå·¥æ ¸å®

**å»ºè®®**:
1. äººå·¥è®¿é—®èµ„æºæŸ¥çœ‹å®é™…å†…å®¹è´¨é‡
2. æ ¸å®æ˜¯å¦å®Œå…¨ç¬¦åˆå°å°¼ä¸€å¹´çº§æ•™å­¦å¤§çº²
3. æ£€æŸ¥è§†é¢‘ç”»è´¨å’Œåˆ¶ä½œæ°´å‡†"""

        return {
            "overall_score": base_score,
            "score_richness": base_score - 0.5,
            "score_timeliness": base_score - 0.2 if is_kurikulum_merdeka else base_score - 1.0,
            "score_teaching_method": base_score,
            "score_visual_quality": base_score - 0.3,
            "evaluation_text": evaluation_text,
            "recommendation": "å¯ä»¥è€ƒè™‘" if base_score >= 7.5 else "å¾…äººå·¥è¯„ä¼°",
            "fallback": True
        }


def process_excel(input_file: str, output_file: str):
    """å¤„ç†Excelæ–‡ä»¶"""
    print("=" * 70)
    print("å°å°¼ä¸€å¹´çº§æ•°å­¦æ•™è‚²èµ„æºè¯„ä¼°ç³»ç»Ÿ")
    print("åŸºäº Gemini 2.5 Pro AIåˆ†æï¼ˆé€šè¿‡ä»£ç†è®¿é—®ï¼‰")
    print("=" * 70)

    # é…ç½®ç¯å¢ƒ
    setup_environment()

    # è¯»å–Excelæ–‡ä»¶
    print(f"\nğŸ“‚ è¯»å–Excelæ–‡ä»¶: {input_file}")
    df = pd.read_excel(input_file)
    print(f"âœ… æˆåŠŸè¯»å– {len(df)} æ¡è®°å½•")

    # åˆå§‹åŒ–è¯„ä¼°å™¨
    evaluator = ResourceEvaluator()

    # å‡†å¤‡æ–°åˆ—
    scores = []
    evaluations = []

    # é€è¡Œå¤„ç†
    for idx, row in df.iterrows():
        name = row.get('åç§°', '')
        url = row.get('ç½‘å€', '')

        print(f"\n{'=' * 70}")
        print(f"[{idx + 1}/{len(df)}] è¯„ä¼°èµ„æº")
        print(f"åç§°: {name}")
        print(f"ç½‘å€: {url}")
        print(f"{'=' * 70}")

        # è¯„ä¼°èµ„æº
        evaluation = evaluator.evaluate(name, url)

        # æå–åˆ†æ•°
        overall_score = evaluation.get('overall_score', 0)

        # æ„å»ºè¯„ä¼°æ–‡æœ¬
        eval_text_parts = []

        # æ ‡é¢˜è¡Œ
        eval_text_parts.append(f"ã€æ•´ä½“è¯„åˆ†ã€‘: {overall_score:.1f}/10")
        eval_text_parts.append(f"ã€æ¨èæ„è§ã€‘: {evaluation.get('recommendation', 'N/A')}")

        # åˆ†é¡¹è¯„åˆ†
        if 'score_richness' in evaluation:
            eval_text_parts.append(f"\nã€åˆ†é¡¹è¯„åˆ†ã€‘")
            eval_text_parts.append(f"â€¢ èµ„æºä¸°å¯Œç¨‹åº¦: {evaluation['score_richness']:.1f}/10")
            eval_text_parts.append(f"â€¢ æ—¶æ•ˆæ€§: {evaluation['score_timeliness']:.1f}/10")
            eval_text_parts.append(f"â€¢ æ•™å­¦æ–¹æ³•: {evaluation['score_teaching_method']:.1f}/10")
            eval_text_parts.append(f"â€¢ ç”»é¢è´¨é‡: {evaluation['score_visual_quality']:.1f}/10")

        # è¯¦ç»†è¯„ä¼°
        eval_text_parts.append(f"\nã€è¯¦ç»†è¯„ä¼°ã€‘")
        eval_text_parts.append(evaluation.get('evaluation_text', ''))

        # å¦‚æœæ˜¯åå¤‡è¯„ä¼°ï¼Œæ·»åŠ è¯´æ˜
        if evaluation.get('fallback'):
            eval_text_parts.append(f"\nã€âš ï¸ è¯´æ˜ã€‘")
            eval_text_parts.append("æ­¤è¯„ä¼°ä½¿ç”¨åå¤‡è§„åˆ™ç”Ÿæˆï¼ŒAIæ·±åº¦è¯„ä¼°æš‚æ—¶ä¸å¯ç”¨ã€‚å»ºè®®äººå·¥æ ¸å®èµ„æºè´¨é‡ã€‚")

        # é”™è¯¯ä¿¡æ¯
        if 'error' in evaluation and not evaluation.get('fallback'):
            eval_text_parts.append(f"\nã€é”™è¯¯ä¿¡æ¯ã€‘")
            eval_text_parts.append(f"è¯„ä¼°è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {evaluation['error']}")

        final_eval_text = "\n".join(eval_text_parts)

        scores.append(overall_score)
        evaluations.append(final_eval_text)

        # é¿å…è¯·æ±‚è¿‡å¿«
        if idx < len(df) - 1:  # æœ€åä¸€ä¸ªä¸éœ€è¦ç­‰å¾…
            print(f"\nâ³ ç­‰å¾…3ç§’åå¤„ç†ä¸‹ä¸€ä¸ª...")
            time.sleep(3)

    # æ·»åŠ æ–°åˆ—
    df['è¯„ä¼°åˆ†æ•°'] = scores
    df['è¯„ä¼°å†…å®¹'] = evaluations

    # æŒ‰åˆ†æ•°é™åºæ’åº
    df = df.sort_values('è¯„ä¼°åˆ†æ•°', ascending=False)

    # ä¿å­˜åˆ°Excel
    print(f"\nğŸ’¾ ä¿å­˜è¯„ä¼°ç»“æœåˆ°: {output_file}")
    df.to_excel(output_file, index=False, engine='openpyxl')
    print("âœ… ä¿å­˜æˆåŠŸï¼")

    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 70)
    print("ğŸ“Š è¯„ä¼°ç»Ÿè®¡")
    print("=" * 70)
    print(f"æ€»è¯„ä¼°æ•°: {len(df)}")
    print(f"å¹³å‡åˆ†æ•°: {df['è¯„ä¼°åˆ†æ•°'].mean():.2f}/10")
    print(f"æœ€é«˜åˆ†æ•°: {df['è¯„ä¼°åˆ†æ•°'].max():.1f}/10")
    print(f"æœ€ä½åˆ†æ•°: {df['è¯„ä¼°åˆ†æ•°'].min():.1f}/10")

    # æ¨èåˆ†å¸ƒ
    print("\nã€æ¨èæ„è§åˆ†å¸ƒã€‘")
    recommendations = []
    for eval_text in df['è¯„ä¼°å†…å®¹']:
        match = re.search(r'ã€æ¨èæ„è§ã€‘:\s*(\S+)', eval_text)
        if match:
            recommendations.append(match.group(1))
    if recommendations:
        from collections import Counter
        for rec, count in Counter(recommendations).most_common():
            print(f"  {rec}: {count}ä¸ª")

    # æ˜¾ç¤ºæ‰€æœ‰èµ„æºæŒ‰åˆ†æ•°æ’åº
    print("\nã€èµ„æºæ’åï¼ˆæŒ‰åˆ†æ•°æ’åºï¼‰ã€‘")
    for idx, (name, score, rec) in enumerate(df[['åç§°', 'è¯„ä¼°åˆ†æ•°', 'è¯„ä¼°å†…å®¹']].values, 1):
        match = re.search(r'ã€æ¨èæ„è§ã€‘:\s*(\S+)', rec)
        recommendation = match.group(1) if match else 'N/A'
        print(f"  {idx}. {name}")
        print(f"     è¯„åˆ†: {score:.1f}/10 | æ¨è: {recommendation}")


if __name__ == "__main__":
    # æ–‡ä»¶è·¯å¾„
    input_file = "å°å°¼ä¸€å¹´çº§æ•°å­¦.xlsx"
    output_file = "å°å°¼ä¸€å¹´çº§æ•°å­¦_è¯„ä¼°ç»“æœ.xlsx"

    # æ‰§è¡Œè¯„ä¼°
    process_excel(input_file, output_file)

    print("\n" + "=" * 70)
    print("ğŸ‰ è¯„ä¼°å®Œæˆï¼")
    print(f"ğŸ“Š ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    print("=" * 70)
