#!/usr/bin/env python3
"""
é™çº§ç­–ç•¥å·¥å…·é›†

ç”¨äºå¤„ç†ä½è´¨é‡æœç´¢ç»“æœçš„é™çº§ç­–ç•¥
åŒ…æ‹¬ï¼šæŸ¥è¯¢é‡å†™ã€å¼•æ“åˆ‡æ¢ã€æ”¾å®½ç­›é€‰ã€å†å²ç¼“å­˜ç­‰
"""

from typing import Dict, List, Optional, Any
from logger_utils import get_logger

logger = get_logger('fallback_utils')


def detect_low_quality_results(results: List[Dict], request: Dict) -> bool:
    """
    æ£€æµ‹æœç´¢ç»“æœæ˜¯å¦æ•´ä½“è´¨é‡ä½

    æ£€æµ‹æ–¹æ³•ï¼š
    1. å¹³å‡åˆ†æ£€æµ‹ï¼šå‰20ä¸ªç»“æœå¹³å‡åˆ† < 5.0
    2. é«˜åˆ†ç»“æœæ•°é‡æ£€æµ‹ï¼šå‰20ä¸ªç»“æœä¸­ >= 7.0åˆ†çš„å°‘äº3ä¸ª
    3. æ ‡é¢˜ç›¸å…³æ€§æ£€æµ‹ï¼šå‰10ä¸ªç»“æœä¸­ç›¸å…³æ ‡é¢˜å°‘äº5ä¸ª

    Args:
        results: è¯„åˆ†åçš„ç»“æœåˆ—è¡¨ï¼ˆæ¯ä¸ªç»“æœåŒ…å«'score'å­—æ®µï¼‰
        request: åŸå§‹è¯·æ±‚å­—å…¸ï¼ˆåŒ…å«country, grade, subjectï¼‰

    Returns:
        True if low quality, False otherwise
    """
    if not results:
        logger.warning("[ä½è´¨é‡æ£€æµ‹] ç»“æœåˆ—è¡¨ä¸ºç©º")
        return True

    # æ–¹æ³•1: å¹³å‡åˆ†æ£€æµ‹
    scores = [r.get('score', 0) for r in results[:20]]
    avg_score = sum(scores) / len(scores) if scores else 0.0

    if avg_score < 5.0:
        logger.warning(f"[ä½è´¨é‡æ£€æµ‹] å¹³å‡åˆ† {avg_score:.2f} < 5.0")
        return True

    # æ–¹æ³•2: é«˜åˆ†ç»“æœæ•°é‡æ£€æµ‹
    high_score_count = sum(1 for s in scores if s >= 7.0)

    if high_score_count < 3:
        logger.warning(f"[ä½è´¨é‡æ£€æµ‹] é«˜åˆ†ç»“æœä»… {high_score_count} ä¸ª < 3")
        return True

    # æ–¹æ³•3: æ ‡é¢˜ç›¸å…³æ€§æ£€æµ‹
    subject = request.get('subject', '').lower()
    grade = request.get('grade', '').lower()

    relevant_count = 0
    for r in results[:10]:
        title_lower = r.get('title', '').lower()

        # æ£€æŸ¥æ ‡é¢˜æ˜¯å¦åŒ…å«subjectæˆ–grade
        if subject in title_lower or grade in title_lower:
            relevant_count += 1

    if relevant_count < 5:
        logger.warning(f"[ä½è´¨é‡æ£€æµ‹] ç›¸å…³æ ‡é¢˜ä»… {relevant_count}/10 < 5")
        return True

    logger.info(f"[âœ… è´¨é‡æ£€æµ‹] é€šè¿‡ (å¹³å‡åˆ†: {avg_score:.2f}, é«˜åˆ†: {high_score_count}ä¸ª, ç›¸å…³: {relevant_count}/10)")
    return False


def fallback_query_rewriting(request: Dict, llm_client, strategy_agent) -> List[Dict]:
    """
    é™çº§ç­–ç•¥1: æŸ¥è¯¢é‡å†™

    ä½¿ç”¨ä¸åŒçš„æŸ¥è¯¢å˜ä½“é‡è¯•æœç´¢

    Args:
        request: æœç´¢è¯·æ±‚å­—å…¸
        llm_client: LLMå®¢æˆ·ç«¯
        strategy_agent: æœç´¢ç­–ç•¥ä»£ç†

    Returns:
        æœç´¢ç»“æœåˆ—è¡¨
    """
    logger.warning("[é™çº§ç­–ç•¥1] å°è¯•æŸ¥è¯¢é‡å†™...")

    subject = request.get('subject', '')
    grade = request.get('grade', '')
    country = request.get('country', '')
    semester = request.get('semester')

    # é‡å†™é€‰é¡¹
    rewrite_options = []

    # é€‰é¡¹1: ä½¿ç”¨è‹±æ–‡ï¼ˆå¦‚æœåŸæŸ¥è¯¢ä¸æ˜¯è‹±æ–‡ï¼‰
    rewrite_options.append({
        'query': f"{subject} {grade} playlist",
        'reason': 'è‹±æ–‡é€šç”¨æŸ¥è¯¢'
    })

    # é€‰é¡¹2: æ·»åŠ "video"å…³é”®è¯
    rewrite_options.append({
        'query': f"{subject} {grade} video",
        'reason': 'æ·»åŠ videoå…³é”®è¯'
    })

    # é€‰é¡¹3: ä½¿ç”¨"course"
    rewrite_options.append({
        'query': f"{subject} {grade} complete course",
        'reason': 'ä½¿ç”¨courseå…³é”®è¯'
    })

    # é€‰é¡¹4: ç§»é™¤å¹´çº§ï¼Œåªç”¨å­¦ç§‘
    rewrite_options.append({
        'query': f"{subject} playlist",
        'reason': 'ç§»é™¤å¹´çº§é™åˆ¶'
    })

    # é€‰é¡¹5: ä½¿ç”¨YouTubeç‰¹å®šè¯­æ³•
    rewrite_options.append({
        'query': f"site:youtube.com \"{subject}\" \"{grade}\" playlist",
        'reason': 'YouTubeç²¾ç¡®è¯­æ³•'
    })

    # å°è¯•æ¯ä¸ªé‡å†™é€‰é¡¹
    for idx, option in enumerate(rewrite_options, 1):
        logger.info(f"[é‡è¯• {idx}/{len(rewrite_options)}] {option['reason']}: \"{option['query']}\"")

        try:
            results = llm_client.search(
                query=option['query'],
                max_results=30,
                country_code=country
            )

            if results and len(results) >= 10:  # è‡³å°‘10ä¸ªç»“æœæ‰ç®—æˆåŠŸ
                logger.info(f"[âœ… é™çº§æˆåŠŸ] æŸ¥è¯¢é‡å†™æˆåŠŸ (é€‰é¡¹{idx}): {option['reason']}")
                return results

        except Exception as e:
            logger.warning(f"[âš ï¸ é‡è¯• {idx}] å¤±è´¥: {str(e)}")
            continue

    logger.error("[âŒ é™çº§å¤±è´¥] æ‰€æœ‰æŸ¥è¯¢é‡å†™éƒ½å¤±è´¥")
    return []


def fallback_engine_switching(request: Dict, llm_client, google_hunter=None,
                               baidu_hunter=None) -> List[Dict]:
    """
    é™çº§ç­–ç•¥2: å¼•æ“åˆ‡æ¢

    å°è¯•ä½¿ç”¨ä¸åŒçš„æœç´¢å¼•æ“

    Args:
        request: æœç´¢è¯·æ±‚å­—å…¸
        llm_client: LLMå®¢æˆ·ç«¯ï¼ˆåŒ…å«Tavily/Metasoï¼‰
        google_hunter: Googleæœç´¢å®¢æˆ·ç«¯ï¼ˆå¯é€‰ï¼‰
        baidu_hunter: ç™¾åº¦æœç´¢å®¢æˆ·ç«¯ï¼ˆå¯é€‰ï¼‰

    Returns:
        æœç´¢ç»“æœåˆ—è¡¨
    """
    logger.warning("[é™çº§ç­–ç•¥2] å°è¯•å¼•æ“åˆ‡æ¢...")

    query = f"{request.get('subject', '')} {request.get('grade', '')}"
    country_code = request.get('country', 'CN')

    # å®šä¹‰å¼•æ“åˆ—è¡¨
    engines = []

    # å¼•æ“1: Tavily/Metaso (å·²é€šè¿‡llm_client)
    engines.append({
        'name': 'Tavily/Metaso',
        'func': lambda q: llm_client.search(query=q, max_results=30, country_code=country_code)
    })

    # å¼•æ“2: Google (å¦‚æœå¯ç”¨)
    if google_hunter:
        engines.append({
            'name': 'Google',
            'func': lambda q: google_hunter.search(query=q, max_results=20)
        })

    # å¼•æ“3: Baidu (å¦‚æœå¯ç”¨)
    if baidu_hunter:
        engines.append({
            'name': 'Baidu',
            'func': lambda q: baidu_hunter.search(query=q, max_results=30)
        })

    # å°è¯•æ¯ä¸ªå¼•æ“
    for engine in engines:
        logger.info(f"[é‡è¯•] å°è¯• {engine['name']}...")

        try:
            results = engine['func'](query)

            if results and len(results) >= 5:
                logger.info(f"[âœ… é™çº§æˆåŠŸ] å¼•æ“åˆ‡æ¢æˆåŠŸ: {engine['name']}")
                return results

        except Exception as e:
            logger.warning(f"[âš ï¸ {engine['name']}] å¤±è´¥: {str(e)}")
            continue

    logger.error("[âŒ é™çº§å¤±è´¥] æ‰€æœ‰å¼•æ“éƒ½å¤±è´¥")
    return []


def fallback_relax_filters(request: Dict, llm_client, result_scorer) -> List[Dict]:
    """
    é™çº§ç­–ç•¥3: æ”¾å®½ç­›é€‰æ¡ä»¶

    é™ä½è¯„åˆ†é˜ˆå€¼ï¼Œå…è®¸æ›´å¤šç»“æœé€šè¿‡

    Args:
        request: æœç´¢è¯·æ±‚å­—å…¸
        llm_client: LLMå®¢æˆ·ç«¯
        result_scorer: ç»“æœè¯„åˆ†å™¨

    Returns:
        è¯„åˆ†åçš„ç»“æœåˆ—è¡¨
    """
    logger.warning("[é™çº§ç­–ç•¥3] æ”¾å®½ç­›é€‰æ¡ä»¶...")

    query = f"{request.get('subject', '')} {request.get('grade', '')}"
    country_code = request.get('country', 'CN')

    try:
        # å¢åŠ æœç´¢ç»“æœæ•°é‡
        results = llm_client.search(
            query=query,
            max_results=50,  # å¢åŠ åˆ°50ä¸ª
            country_code=country_code
        )

        if not results:
            logger.error("[âŒ é™çº§å¤±è´¥] æœç´¢æ— ç»“æœ")
            return []

        logger.info(f"[æ”¾å®½ç­›é€‰] è·å–åˆ° {len(results)} ä¸ªåŸå§‹ç»“æœ")

        # ä½¿ç”¨å®½æ¾çš„è¯„åˆ†æ ‡å‡†
        metadata = {
            'country': country_code,
            'grade': request.get('grade', ''),
            'subject': request.get('subject', ''),
            'strict_mode': False,
            'min_score_threshold': 3.0,  # é™ä½åˆ°3.0
            'allow_partial_matches': True
        }

        scored_results = result_scorer.score_results(
            results,
            query,
            metadata=metadata
        )

        logger.info(f"[âœ… é™çº§æˆåŠŸ] æ”¾å®½ç­›é€‰åè¿”å› {len(scored_results)} ä¸ªç»“æœ")

        # è¿”å›å‰30ä¸ªç»“æœï¼ˆæ”¾å®½åˆ°30ä¸ªï¼‰
        return scored_results[:30]

    except Exception as e:
        logger.error(f"[âŒ é™çº§å¤±è´¥] æ”¾å®½ç­›é€‰å¤±è´¥: {str(e)}")
        return []


def fallback_historical_cache(request: Dict, cache_manager) -> List[Dict]:
    """
    é™çº§ç­–ç•¥4: å†å²ç¼“å­˜

    è¿”å›å†å²ç¼“å­˜çš„æœç´¢ç»“æœï¼ˆå³ä½¿æ˜¯è¿‡æœŸçš„ï¼‰

    Args:
        request: æœç´¢è¯·æ±‚å­—å…¸
        cache_manager: ç¼“å­˜ç®¡ç†å™¨ï¼ˆæ”¯æŒå¤šçº§ç¼“å­˜ï¼‰

    Returns:
        æœç´¢ç»“æœåˆ—è¡¨ï¼ˆå¸¦æœ‰é™çº§æ ‡è®°ï¼‰
    """
    logger.warning("[é™çº§ç­–ç•¥4] ä½¿ç”¨å†å²ç¼“å­˜...")

    cache_key = f"{request.get('country', '')}:{request.get('grade', '')}:{request.get('subject', '')}"

    try:
        # æŸ¥æ‰¾å†å²ç¼“å­˜ï¼ˆåŒ…æ‹¬å·²è¿‡æœŸçš„ï¼‰
        historical_results = []

        # å°è¯•ä»L3ç£ç›˜ç¼“å­˜è·å–ï¼ˆåŒ…æ‹¬å·²è¿‡æœŸçš„ï¼‰
        if hasattr(cache_manager, 'get_l3_cache'):
            l3_data = cache_manager.get_l3_cache(cache_key, include_expired=True)
            if l3_data:
                historical_results.append({
                    'source': 'L3_disk_cache',
                    'age_hours': l3_data.get('age_hours', 0),
                    'results': l3_data.get('results', [])
                })

        # æŸ¥æ‰¾ç›¸ä¼¼æŸ¥è¯¢çš„ç¼“å­˜
        if hasattr(cache_manager, 'find_similar'):
            similar_keys = cache_manager.find_similar(cache_key, max_results=5)
            for key in similar_keys:
                data = cache_manager.get(key, include_expired=True)
                if data:
                    historical_results.append({
                        'source': f'similar_cache:{key}',
                        'age_hours': data.get('age_hours', 0),
                        'results': data.get('results', [])
                    })

        if historical_results:
            # è¿”å›æœ€æ–°çš„å†å²ç»“æœ
            best = max(historical_results, key=lambda x: x['age_hours'])

            # æ·»åŠ é™çº§æ ‡è®°
            for r in best['results']:
                if isinstance(r, dict):
                    r['_fallback'] = True
                    r['_fallback_source'] = best['source']
                    r['_fallback_age'] = best['age_hours']

            logger.info(f"[âœ… é™çº§æˆåŠŸ] è¿”å›å†å²ç¼“å­˜ (æ¥æº: {best['source']}, "
                       f"æ—¶æ•ˆ: {best['age_hours']:.1f}å°æ—¶, ç»“æœæ•°: {len(best['results'])})")

            return best['results']

        logger.error("[âŒ é™çº§å¤±è´¥] æ— å¯ç”¨å†å²ç¼“å­˜")
        return []

    except Exception as e:
        logger.error(f"[âŒ é™çº§å¤±è´¥] å†å²ç¼“å­˜å¤±è´¥: {str(e)}")
        return []


def comprehensive_fallback(request: Dict, llm_client, strategy_agent,
                          result_scorer=None, google_hunter=None,
                          baidu_hunter=None, cache_manager=None) -> List[Dict]:
    """
    ç»¼åˆé™çº§æµç¨‹

    ä¾æ¬¡å°è¯•æ‰€æœ‰é™çº§ç­–ç•¥ï¼Œç›´åˆ°æˆåŠŸæˆ–å…¨éƒ¨å¤±è´¥

    Args:
        request: æœç´¢è¯·æ±‚å­—å…¸
        llm_client: LLMå®¢æˆ·ç«¯
        strategy_agent: æœç´¢ç­–ç•¥ä»£ç†
        result_scorer: ç»“æœè¯„åˆ†å™¨ï¼ˆå¯é€‰ï¼Œç”¨äºæ”¾å®½ç­›é€‰ï¼‰
        google_hunter: Googleæœç´¢å®¢æˆ·ç«¯ï¼ˆå¯é€‰ï¼‰
        baidu_hunter: ç™¾åº¦æœç´¢å®¢æˆ·ç«¯ï¼ˆå¯é€‰ï¼‰
        cache_manager: ç¼“å­˜ç®¡ç†å™¨ï¼ˆå¯é€‰ï¼‰

    Returns:
        æœç´¢ç»“æœåˆ—è¡¨ï¼Œæˆ–ç©ºåˆ—è¡¨ï¼ˆå¦‚æœæ‰€æœ‰é™çº§éƒ½å¤±è´¥ï¼‰
    """
    logger.warning("="*80)
    logger.warning("[ğŸš¨ ç»¼åˆé™çº§] å¼€å§‹æ‰§è¡Œé™çº§ç­–ç•¥...")
    logger.warning("="*80)

    # å°è¯•1: æŸ¥è¯¢é‡å†™
    results = fallback_query_rewriting(request, llm_client, strategy_agent)
    if results and len(results) >= 5:
        return results

    # å°è¯•2: å¼•æ“åˆ‡æ¢
    results = fallback_engine_switching(request, llm_client, google_hunter, baidu_hunter)
    if results and len(results) >= 5:
        return results

    # å°è¯•3: æ”¾å®½ç­›é€‰æ¡ä»¶ï¼ˆéœ€è¦è¯„åˆ†å™¨ï¼‰
    if result_scorer:
        results = fallback_relax_filters(request, llm_client, result_scorer)
        if results and len(results) >= 5:
            return results

    # å°è¯•4: å†å²ç¼“å­˜ï¼ˆéœ€è¦ç¼“å­˜ç®¡ç†å™¨ï¼‰
    if cache_manager:
        results = fallback_historical_cache(request, cache_manager)
        if results and len(results) >= 5:
            return results

    # æœ€ç»ˆé™çº§: è¿”å›ç©ºç»“æœ + å»ºè®®
    logger.error("[âŒ æ‰€æœ‰é™çº§å¤±è´¥] è¿”å›ç©ºç»“æœ")
    logger.error("[å»ºè®®] ç”¨æˆ·å¯ä»¥å°è¯•:")
    logger.error("  1. ä½¿ç”¨æ›´é€šç”¨çš„å­¦ç§‘åç§°")
    logger.error("  2. å‡å°‘å¹´çº§é™åˆ¶")
    logger.error("  3. ä½¿ç”¨è‹±æ–‡æœç´¢")

    return []
