#!/usr/bin/env python3
"""
å¿«é€Ÿé˜¿æ‹‰ä¼¯è¯­ç†è§£æµ‹è¯•
å¯¹æ¯”3ä¸ªæ ¸å¿ƒæ¨¡å‹çš„å…³é”®ç”¨ä¾‹
"""

import os
import sys
import json
import time
from dotenv import load_dotenv
from openai import OpenAI

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = OpenAI(
    api_key=os.getenv("INTERNAL_API_KEY"),
    base_url=os.getenv("INTERNAL_API_BASE_URL", "https://hk-intra-paas.transsion.com/tranai-proxy/v1")
)

# å…³é”®æµ‹è¯•ç”¨ä¾‹
critical_tests = [
    {
        "title": "Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª Ø§Ù„ØµÙ Ø§Ù„Ø«Ø§Ù†ÙŠ Ù…ØªÙˆØ³Ø·",
        "question": "è¿™ä¸ªæ ‡é¢˜ä¸­çš„å¹´çº§æ˜¯ä»€ä¹ˆï¼Ÿæ˜¯å°å­¦äºŒå¹´çº§è¿˜æ˜¯åˆä¸­äºŒå¹´çº§ï¼Ÿ",
        "correct_answer": "åˆä¸­äºŒå¹´çº§",
        "common_mistake": "å¾ˆå¤šæ¨¡å‹è¯¯è®¤ä¸ºæ˜¯å°å­¦äºŒå¹´çº§"
    },
    {
        "title": "Ø´Ø±Ø­ Ø±ÙŠØ§Ø¶ÙŠØ§Øª Ø§Ù„ØµÙ Ø§Ù„Ø«Ø§Ù†ÙŠ Ø¹Ø´Ø±",
        "question": "è¿™ä¸ªæ ‡é¢˜ä¸­çš„å¹´çº§æ˜¯ä»€ä¹ˆï¼Ÿæ˜¯äºŒå¹´çº§è¿˜æ˜¯åäºŒå¹´çº§ï¼Ÿ",
        "correct_answer": "åäºŒå¹´çº§ (Grade 12)",
        "common_mistake": "å¾ˆå¤šæ¨¡å‹è¯¯è®¤ä¸ºæ˜¯äºŒå¹´çº§"
    },
    {
        "title": "Ø±ÙŠØ§Ø¶ÙŠØ§Øª Ù„Ù„ØµÙ Ø§Ù„Ø«Ø§Ù†ÙŠ Ø§Ø¨ØªØ¯Ø§Ø¦ÙŠ",
        "question": "è¿™ä¸ªæ ‡é¢˜ä¸­çš„å¹´çº§æ˜¯ä»€ä¹ˆï¼Ÿ",
        "correct_answer": "å°å­¦äºŒå¹´çº§ (Grade 2)",
        "common_mistake": "å¾ˆå¤šæ¨¡å‹è¯¯è®¤ä¸ºä¸åŒ¹é…"
    }
]

# æ ¸å¿ƒæ¨¡å‹åˆ—è¡¨ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰
core_models = [
    "gpt-5.2",              # OpenAI æ——èˆ°
    "gemini-2.5-flash",      # Gemini å¿«é€Ÿ
    "gemini-2.5-pro",        # Gemini é«˜è´¨é‡
    "claude-3-7-sonnet@20250219",  # Claude æœ€æ–°
    "qwen3-max"             # é˜¿é‡Œé€šä¹‰
]

print("=" * 100)
print("ğŸš€ å¿«é€Ÿé˜¿æ‹‰ä¼¯è¯­ç†è§£æµ‹è¯•")
print("=" * 100)

results = []

for model in core_models:
    print(f"\n{'=' * 100}")
    print(f"ğŸ¤– æ¨¡å‹: {model}")
    print(f"{'=' * 100}")

    model_correct = 0

    for i, test in enumerate(critical_tests, 1):
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªå¤šè¯­è¨€æ•™è‚²ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹é˜¿æ‹‰ä¼¯è¯­æ ‡é¢˜ï¼š

æ ‡é¢˜: {test['title']}

é—®é¢˜: {test['question']}

è¯·ç›´æ¥å›ç­”å¹´çº§ï¼Œå¹¶ç®€è¦è¯´æ˜ç†ç”±ã€‚"""

        try:
            start = time.time()
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯æ•™è‚²å†…å®¹åˆ†æä¸“å®¶ï¼Œç²¾é€šé˜¿æ‹‰ä¼¯è¯­ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.0,
                max_tokens=200,
                timeout=30
            )
            elapsed = time.time() - start

            answer = response.choices[0].message.content

            # ç®€å•åˆ¤æ–­æ˜¯å¦æ­£ç¡®
            correct_keywords = test['correct_answer'].replace("(", "").replace(")", "").split()
            is_correct = any(kw in answer for kw in correct_keywords)

            status = "âœ…" if is_correct else "âŒ"
            print(f"\n  [{i}] {test['title'][:60]}")
            print(f"  é—®é¢˜: {test['question']}")
            print(f"  æ­£ç¡®ç­”æ¡ˆ: {test['correct_answer']}")
            print(f"  æ¨¡å‹å›ç­”: {answer[:100]}...")
            print(f"  {status} {'âœ“ æ­£ç¡®' if is_correct else 'âœ— é”™è¯¯'} | è€—æ—¶: {elapsed:.2f}s")

            if is_correct:
                model_correct += 1

            results.append({
                "model": model,
                "test": test['title'][:50],
                "correct": is_correct,
                "time": elapsed,
                "answer": answer[:200]
            })

        except Exception as e:
            print(f"\n  [{i}] {test['title'][:60]}")
            print(f"  âŒ é”™è¯¯: {str(e)[:80]}")

    accuracy = model_correct / len(critical_tests)
    print(f"\n  ğŸ“Š {model} å‡†ç¡®ç‡: {accuracy:.1%} ({model_correct}/{len(critical_tests)})")

# ç”Ÿæˆæ€»ç»“
print("\n\n" + "=" * 100)
print("ğŸ“Š æ€»ç»“")
print("=" * 100)

print(f"\n{'æ¨¡å‹':<35} {'å‡†ç¡®ç‡':<10} {'å¹³å‡è€—æ—¶':<10}")
print("-" * 100)

model_stats = {}
for r in results:
    if r['model'] not in model_stats:
        model_stats[r['model']] = {'correct': 0, 'total': 0, 'time': 0}
    model_stats[r['model']]['total'] += 1
    model_stats[r['model']]['time'] += r['time']
    if r['correct']:
        model_stats[r['model']]['correct'] += 1

for model, stats in model_stats.items():
    accuracy = stats['correct'] / stats['total']
    avg_time = stats['time'] / stats['total']
    print(f"{model:<35} {accuracy:>8.1%} {avg_time:>8.2f}s")

print("\n" + "=" * 100)
print("ğŸ’¡ ç»“è®º")

best_model = max(model_stats.items(), key=lambda x: x[1]['correct'] / x[1]['total'])
best_accuracy = best_model[1]['correct'] / best_model[1]['total']

if best_accuracy >= 0.8:
    print(f"âœ… æ‰¾åˆ°ä¼˜ç§€æ¨¡å‹: {best_model[0]} (å‡†ç¡®ç‡ {best_accuracy:.1%})")
    print("   å»ºè®®: ä¼˜å…ˆä½¿ç”¨æ­¤æ¨¡å‹ï¼Œå¯èƒ½ä¸éœ€è¦çŸ¥è¯†åº“è¾…åŠ©")
elif best_accuracy >= 0.6:
    print(f"âš ï¸  ä¸­ç­‰è¡¨ç°: {best_model[0]} (å‡†ç¡®ç‡ {best_accuracy:.1%})")
    print("   å»ºè®®: æ­¤æ¨¡å‹ + çŸ¥è¯†åº“è¾…åŠ© = æœ€ä½³æ–¹æ¡ˆ")
else:
    print(f"âŒ è¡¨ç°ä¸ä½³: æœ€ä½³æ¨¡å‹å‡†ç¡®ç‡ä»… {best_accuracy:.1%}")
    print("   å»ºè®®: çŸ¥è¯†åº“æ–¹æ¡ˆæ˜¯å¿…è¦çš„ï¼Œå½“å‰æ¨¡å‹éƒ½ä¸å¤Ÿå¯é ")

print("\n" + "=" * 100)
