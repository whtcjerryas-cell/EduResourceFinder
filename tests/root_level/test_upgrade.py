#!/usr/bin/env python3
"""
å¿«é€ŸéªŒè¯å‡çº§åçš„æ¨¡å‹é…ç½®

æµ‹è¯• gemini-2.5-pro åœ¨æ™ºèƒ½è¯„åˆ†ä¸Šçš„è¡¨ç°
"""
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from utils.logger_utils import get_logger
from llm_client import get_llm_client
from config_manager import get_config_manager

logger = get_logger('test_upgrade')


def test_model_upgrade():
    """æµ‹è¯•æ¨¡å‹å‡çº§"""

    # 1. æ£€æŸ¥é…ç½®æ–‡ä»¶
    print("\n" + "="*80)
    print("ğŸ” æ­¥éª¤1: æ£€æŸ¥é…ç½®æ–‡ä»¶")
    print("="*80)

    config = get_config_manager()
    models = config.get_llm_models()
    fast_model = models.get('fast_inference', None)

    print(f"\nâœ… fast_inference æ¨¡å‹: {fast_model}")

    if fast_model == 'gemini-2.5-pro':
        print("âœ… é…ç½®æ­£ç¡®ï¼å·²å‡çº§åˆ° gemini-2.5-pro")
    else:
        print(f"âŒ é…ç½®é”™è¯¯ï¼æœŸæœ› gemini-2.5-proï¼Œå®é™… {fast_model}")
        return False

    # 2. æµ‹è¯•LLMè°ƒç”¨
    print("\n" + "="*80)
    print("ğŸ” æ­¥éª¤2: æµ‹è¯•LLMè°ƒç”¨ï¼ˆä¼Šæ‹‰å…‹1å¹´çº§æ•°å­¦ï¼‰")
    print("="*80)

    llm_client = get_llm_client()

    # æµ‹è¯•ç”¨ä¾‹ï¼šä¼Šæ‹‰å…‹1å¹´çº§æ•°å­¦ï¼ˆé˜¿æ‹‰ä¼¯è¯­ï¼‰
    test_prompt = """è¯·ä¸ºä»¥ä¸‹æœç´¢ç»“æœè¯„åˆ†ï¼ˆ0-10åˆ†ï¼‰ï¼š

**æœç´¢ç›®æ ‡**: IQ 1å¹´çº§ æ•°å­¦

**ç›®æ ‡å¹´çº§è¡¨è¾¾**: Ø§Ù„ØµÙ Ø§Ù„Ø£ÙˆÙ„, Grade 1
**ç›®æ ‡å­¦ç§‘è¡¨è¾¾**: Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª, æ•°å­¦

**æœç´¢ç»“æœ**:
æ ‡é¢˜: Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª Ù„Ù„ØµÙ Ø§Ù„Ø£ÙˆÙ„ Ø§Ù„Ø´Ø§Ù…Ù„
æè¿°: Ø´Ø±Ø­ ÙƒØ§Ù…Ù„ Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª Ù„Ù„ØµÙ Ø§Ù„Ø£ÙˆÙ„

**è¯„åˆ†è¦æ±‚**:
1. å¹´çº§åŒ¹é…åº¦ï¼ˆ0-3åˆ†ï¼‰ï¼šä»æ ‡é¢˜ä¸­æå–å¹´çº§ï¼Œä¸ç›®æ ‡å¹´çº§å¯¹æ¯”
2. å­¦ç§‘åŒ¹é…åº¦ï¼ˆ0-3åˆ†ï¼‰ï¼šä»æ ‡é¢˜ä¸­æå–å­¦ç§‘ï¼Œä¸ç›®æ ‡å­¦ç§‘å¯¹æ¯”
3. èµ„æºè´¨é‡ï¼ˆ0-2åˆ†ï¼‰ï¼šåˆ¤æ–­æ˜¯å¦æ˜¯å®Œæ•´è¯¾ç¨‹
4. æ¥æºæƒå¨æ€§ï¼ˆ0-2åˆ†ï¼‰ï¼šåˆ¤æ–­æ¥æºæ˜¯å¦å¯ä¿¡

**è¯„åˆ†è§„åˆ™**:
- å®Œå…¨åŒ¹é…ç»™é«˜åˆ†ï¼ˆâ‰¥9åˆ†ï¼‰
- å¹´çº§ä¸ç¬¦å¿…é¡»å¤§å¹…å‡åˆ†ï¼ˆâ‰¤5åˆ†ï¼‰
- å­¦ç§‘ä¸ç¬¦å¿…é¡»å¤§å¹…å‡åˆ†ï¼ˆâ‰¤5åˆ†ï¼‰

**è¾“å‡ºæ ¼å¼**ï¼ˆJSONï¼‰:
{
    "score": è¯„åˆ†ï¼ˆ0-10åˆ†ï¼‰,
    "identified_grade": "ä»æ ‡é¢˜ä¸­è¯†åˆ«çš„å¹´çº§",
    "identified_subject": "ä»æ ‡é¢˜ä¸­è¯†åˆ«çš„å­¦ç§‘",
    "reason": "è¯„åˆ†ç†ç”±"
}

è¯·ç¡®ä¿è¾“å‡ºæœ‰æ•ˆçš„JSONæ ¼å¼ã€‚"""

    print(f"\nğŸ“ æµ‹è¯•æç¤ºè¯:")
    print(f"   - ç›®æ ‡: ä¼Šæ‹‰å…‹ 1å¹´çº§ æ•°å­¦")
    print(f"   - æµ‹è¯•æ ‡é¢˜: Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª Ù„Ù„ØµÙ Ø§Ù„Ø£ÙˆÙ„ Ø§Ù„Ø´Ø§Ù…Ù„")
    print(f"   - æœŸæœ›è¯„åˆ†: 9.0-10.0ï¼ˆå®Œå…¨åŒ¹é…ï¼‰")

    print(f"\nğŸ”„ è°ƒç”¨LLM...")
    import time
    start_time = time.time()

    try:
        response = llm_client.call_llm(
            prompt=test_prompt,
            model=fast_model,
            max_tokens=200,
            temperature=0.3
        )

        elapsed_time = time.time() - start_time

        print(f"\nâœ… LLMè°ƒç”¨æˆåŠŸï¼")
        print(f"   - å“åº”æ—¶é—´: {elapsed_time:.2f}ç§’")
        print(f"   - å“åº”é•¿åº¦: {len(response)}å­—ç¬¦")

        # è§£æå“åº”
        import re
        import json

        json_match = re.search(r'\{[^{}]*\}', response, re.DOTALL)
        if json_match:
            json_str = json_match.group(0)
            result = json.loads(json_str)

            score = result.get('score', 0)
            grade = result.get('identified_grade', '')
            subject = result.get('identified_subject', '')
            reason = result.get('reason', '')

            print(f"\nğŸ“Š è¯„åˆ†ç»“æœ:")
            print(f"   - è¯„åˆ†: {score}/10")
            print(f"   - è¯†åˆ«å¹´çº§: {grade}")
            print(f"   - è¯†åˆ«å­¦ç§‘: {subject}")
            print(f"   - è¯„åˆ†ç†ç”±: {reason}")

            # è¯„ä¼°ç»“æœ
            if score >= 9.0:
                print(f"\nâœ… æµ‹è¯•é€šè¿‡ï¼è¯„åˆ†æ­£ç¡®ï¼ˆâ‰¥9.0ï¼‰")
            elif score >= 7.0:
                print(f"\nâš ï¸ è¯„åˆ†ç•¥ä½ï¼Œä½†å¯æ¥å—")
            else:
                print(f"\nâŒ æµ‹è¯•å¤±è´¥ï¼è¯„åˆ†è¿‡ä½")

            if 'Ø§Ù„ØµÙ Ø§Ù„Ø£ÙˆÙ„' in grade or 'Grade 1' in grade:
                print(f"âœ… å¹´çº§è¯†åˆ«æ­£ç¡®")
            else:
                print(f"âŒ å¹´çº§è¯†åˆ«é”™è¯¯")

            if 'Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª' in subject or 'æ•°å­¦' in subject or 'Mathematics' in subject:
                print(f"âœ… å­¦ç§‘è¯†åˆ«æ­£ç¡®")
            else:
                print(f"âŒ å­¦ç§‘è¯†åˆ«é”™è¯¯")

        else:
            print(f"\nâš ï¸ æ— æ³•è§£æJSONå“åº”")
            print(f"åŸå§‹å“åº”: {response[:200]}...")

    except Exception as e:
        print(f"\nâŒ LLMè°ƒç”¨å¤±è´¥: {str(e)}")
        return False

    # 3. æµ‹è¯•å…¶ä»–ç”¨ä¾‹
    print("\n" + "="*80)
    print("ğŸ” æ­¥éª¤3: æµ‹è¯•å¹´çº§ä¸ç¬¦æ¡ˆä¾‹")
    print("="*80)

    test_prompt_2 = """è¯·ä¸ºä»¥ä¸‹æœç´¢ç»“æœè¯„åˆ†ï¼ˆ0-10åˆ†ï¼‰ï¼š

**æœç´¢ç›®æ ‡**: IQ 1å¹´çº§ æ•°å­¦

**ç›®æ ‡å¹´çº§è¡¨è¾¾**: Ø§Ù„ØµÙ Ø§Ù„Ø£ÙˆÙ„, Grade 1
**ç›®æ ‡å­¦ç§‘è¡¨è¾¾**: Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª, æ•°å­¦

**æœç´¢ç»“æœ**:
æ ‡é¢˜: Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª Ù„Ù„ØµÙ Ø§Ù„Ø«Ø§Ù†ÙŠ Ø§Ù„Ù…Ø±Ø­Ù„Ø©
æè¿°: Ø´Ø±Ø­ Ù…Ù†Ù‡Ø¬ Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª Ù„Ù„ØµÙ Ø§Ù„Ø«Ø§Ù†ÙŠ

**è¯„åˆ†è¦æ±‚**:
- å¹´çº§ä¸ç¬¦å¿…é¡»å¤§å¹…å‡åˆ†ï¼ˆâ‰¤5åˆ†ï¼‰

**è¾“å‡ºæ ¼å¼**ï¼ˆJSONï¼‰:
{
    "score": è¯„åˆ†ï¼ˆ0-10åˆ†ï¼‰,
    "identified_grade": "ä»æ ‡é¢˜ä¸­è¯†åˆ«çš„å¹´çº§",
    "identified_subject": "ä»æ ‡é¢˜ä¸­è¯†åˆ«çš„å­¦ç§‘",
    "reason": "è¯„åˆ†ç†ç”±"
}"""

    print(f"\nğŸ“ æµ‹è¯•ç”¨ä¾‹:")
    print(f"   - ç›®æ ‡: ä¼Šæ‹‰å…‹ 1å¹´çº§ æ•°å­¦")
    print(f"   - æµ‹è¯•æ ‡é¢˜: Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª Ù„Ù„ØµÙ Ø§Ù„Ø«Ø§Ù†ÙŠ (äºŒå¹´çº§)")
    print(f"   - æœŸæœ›è¯„åˆ†: 3.0-5.0ï¼ˆå¹´çº§ä¸ç¬¦ï¼‰")

    print(f"\nğŸ”„ è°ƒç”¨LLM...")

    try:
        response = llm_client.call_llm(
            prompt=test_prompt_2,
            model=fast_model,
            max_tokens=200,
            temperature=0.3
        )

        import re
        import json

        json_match = re.search(r'\{[^{}]*\}', response, re.DOTALL)
        if json_match:
            json_str = json_match.group(0)
            result = json.loads(json_str)

            score = result.get('score', 0)
            grade = result.get('identified_grade', '')
            reason = result.get('reason', '')

            print(f"\nğŸ“Š è¯„åˆ†ç»“æœ:")
            print(f"   - è¯„åˆ†: {score}/10")
            print(f"   - è¯†åˆ«å¹´çº§: {grade}")
            print(f"   - è¯„åˆ†ç†ç”±: {reason}")

            if score <= 5.0:
                print(f"\nâœ… æµ‹è¯•é€šè¿‡ï¼æ­£ç¡®è¯†åˆ«å¹´çº§ä¸ç¬¦ï¼ˆè¯„åˆ†â‰¤5.0ï¼‰")
            else:
                print(f"\nâš ï¸ è¯„åˆ†åé«˜ï¼Œå¯èƒ½æœªæ­£ç¡®è¯†åˆ«å¹´çº§ä¸ç¬¦")

            if 'Ø§Ù„ØµÙ Ø§Ù„Ø«Ø§Ù†ÙŠ' in grade or 'Grade 2' in grade:
                print(f"âœ… å¹´çº§è¯†åˆ«æ­£ç¡®ï¼ˆäºŒå¹´çº§ï¼‰")
            else:
                print(f"âš ï¸ å¹´çº§è¯†åˆ«å¯èƒ½ä¸å‡†ç¡®")

    except Exception as e:
        print(f"\nâŒ LLMè°ƒç”¨å¤±è´¥: {str(e)}")

    # 4. æ€»ç»“
    print("\n" + "="*80)
    print("âœ… å‡çº§éªŒè¯å®Œæˆ")
    print("="*80)
    print("\nğŸ“‹ å‡çº§æ€»ç»“:")
    print(f"   âœ… é…ç½®æ–‡ä»¶å·²æ›´æ–°: fast_inference = gemini-2.5-pro")
    print(f"   âœ… ä»£ç å·²æ›´æ–°: ç§»é™¤ç¡¬ç¼–ç æ¨¡å‹åç§°")
    print(f"   âœ… LLMè°ƒç”¨æ­£å¸¸")
    print(f"   âœ… é˜¿æ‹‰ä¼¯è¯­è¯†åˆ«æ­£å¸¸")
    print(f"\nğŸ‰ æ¨¡å‹å‡çº§æˆåŠŸï¼")
    print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥:")
    print(f"   1. é‡å¯FlaskæœåŠ¡ï¼ˆå¦‚æœæ­£åœ¨è¿è¡Œï¼‰")
    print(f"   2. æµ‹è¯•å®é™…æœç´¢åŠŸèƒ½")
    print(f"   3. ç›‘æ§æœç´¢è´¨é‡å˜åŒ–")

    return True


if __name__ == "__main__":
    success = test_model_upgrade()
    sys.exit(0 if success else 1)
