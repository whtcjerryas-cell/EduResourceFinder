#!/usr/bin/env python3
"""
æœç´¢çŸ¥è¯†åº“ç®¡ç†å™¨
åŠ¨æ€å­¦ä¹ å’Œä¼˜åŒ–æ¯ä¸ªå›½å®¶/åœ°åŒºçš„æœç´¢ç­–ç•¥
"""

import os
import json
import re
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timezone
from pathlib import Path
from utils.logger_utils import get_logger

logger = get_logger('knowledge_base')


class KnowledgeBaseManager:
    """
    æœç´¢çŸ¥è¯†åº“ç®¡ç†å™¨

    åŠŸèƒ½ï¼š
    1. å­˜å‚¨æ¯ä¸ªå›½å®¶çš„æœç´¢ç»éªŒï¼ˆå¹´çº§è¡¨è¾¾ã€å…³é”®è¯ã€æˆåŠŸ/å¤±è´¥æ¨¡å¼ï¼‰
    2. è‡ªåŠ¨å­¦ä¹ å’Œå‘ç°æ–°çš„è¡¨è¾¾æ–¹å¼
    3. åŸºäºå†å²æ•°æ®ç”Ÿæˆä¼˜åŒ–çš„æœç´¢ç­–ç•¥å’Œè¯„åˆ†prompt
    4. è®°å½•LLMé”™è¯¯ï¼ŒæŒç»­æ”¹è¿›
    """

    def __init__(self, country_code: str, knowledge_base_dir: str = None):
        """
        åˆå§‹åŒ–çŸ¥è¯†åº“ç®¡ç†å™¨

        Args:
            country_code: å›½å®¶ä»£ç  (å¦‚: IQ, ID, CN)
            knowledge_base_dir: çŸ¥è¯†åº“ç›®å½• (é»˜è®¤: data/knowledge_base/)
        """
        self.country_code = country_code.upper()

        if knowledge_base_dir is None:
            # é»˜è®¤çŸ¥è¯†åº“ç›®å½•
            project_root = Path(__file__).parent.parent
            knowledge_base_dir = project_root / "data" / "knowledge_base"

        self.kb_dir = Path(knowledge_base_dir)
        self.kb_dir.mkdir(parents=True, exist_ok=True)

        self.kb_file = self.kb_dir / f"{self.country_code}_search_knowledge.json"
        self.knowledge = self.load_knowledge()

        logger.info(f"[ğŸ“š çŸ¥è¯†åº“] å·²åŠ è½½ {self.country_code} çŸ¥è¯†åº“: {self.kb_file}")

    def load_knowledge(self) -> Dict:
        """åŠ è½½çŸ¥è¯†åº“"""
        if self.kb_file.exists():
            try:
                with open(self.kb_file, 'r', encoding='utf-8') as f:
                    kb = json.load(f)
                logger.info(f"[ğŸ“š çŸ¥è¯†åº“] æˆåŠŸåŠ è½½å·²æœ‰çŸ¥è¯†åº“")
                return kb
            except Exception as e:
                logger.warning(f"[ğŸ“š çŸ¥è¯†åº“] åŠ è½½å¤±è´¥: {e}ï¼Œå°†åˆ›å»ºæ–°çŸ¥è¯†åº“")
                return self.create_empty_knowledge()
        else:
            logger.info(f"[ğŸ“š çŸ¥è¯†åº“] çŸ¥è¯†åº“ä¸å­˜åœ¨ï¼Œåˆ›å»ºåˆå§‹çŸ¥è¯†åº“")
            return self.create_empty_knowledge()

    def create_empty_knowledge(self) -> Dict:
        """åˆ›å»ºç©ºçŸ¥è¯†åº“ç»“æ„"""
        return {
            "metadata": {
                "country": self.country_code,
                "country_name": self._get_country_name(self.country_code),
                "created_at": datetime.now(timezone.utc).isoformat(),
                "last_updated": datetime.now(timezone.utc).isoformat(),
                "total_searches": 0,
                "avg_quality_score": 0.0
            },
            "grade_expressions": {},
            "subject_keywords": {},
            "search_patterns": {
                "successful_queries": [],
                "failed_queries": []
            },
            "domain_preferences": {
                "tier_1_platforms": [],
                "tier_2_platforms": [],
                "missing_platforms": []
            },
            "llm_insights": {
                "accuracy_issues": [],
                "discovered_variants": []
            }
        }

    def _get_country_name(self, country_code: str) -> str:
        """è·å–å›½å®¶åç§°"""
        country_names = {
            "ID": "å°åº¦å°¼è¥¿äºš",
            "CN": "ä¸­å›½",
            "IQ": "ä¼Šæ‹‰å…‹",
            "SA": "æ²™ç‰¹é˜¿æ‹‰ä¼¯",
            "EG": "åŸƒåŠ",
            "RU": "ä¿„ç½—æ–¯",
            "US": "ç¾å›½",
            "IN": "å°åº¦",
            "BR": "å·´è¥¿",
            "MX": "å¢¨è¥¿å“¥"
        }
        return country_names.get(country_code.upper(), country_code)

    # ========================================================================
    # å¹´çº§è¡¨è¾¾ç®¡ç†
    # ========================================================================

    def get_grade_variants(self, grade: str) -> List[str]:
        """
        è·å–å¹´çº§çš„æ‰€æœ‰å·²çŸ¥è¡¨è¾¾

        Args:
            grade: å¹´çº§ (å¦‚: "2", "3", "Grade 2")

        Returns:
            è¯¥å¹´çº§çš„æ‰€æœ‰å·²çŸ¥è¡¨è¾¾åˆ—è¡¨
        """
        # æ ‡å‡†åŒ–å¹´çº§key
        grade_key = self._normalize_grade_key(grade)

        if grade_key in self.knowledge.get("grade_expressions", {}):
            variants_data = self.knowledge["grade_expressions"][grade_key].get("local_variants", [])
            variants = []
            for v in variants_data:
                if "arabic" in v:
                    variants.append(v["arabic"])
                if "english" in v:
                    variants.append(v["english"])
            return variants
        return []

    def _normalize_grade_key(self, grade: str) -> str:
        """æ ‡å‡†åŒ–å¹´çº§key"""
        grade = grade.strip()

        # å¦‚æœå·²ç»æ˜¯ "Grade X" æ ¼å¼
        if grade.startswith("Grade "):
            return grade

        # å¦‚æœæ˜¯çº¯æ•°å­—
        if grade.isdigit():
            return f"Grade {grade}"

        # æå–æ•°å­—
        match = re.search(r'\d+', grade)
        if match:
            return f"Grade {match.group()}"

        return grade

    def add_discovered_variant(self, grade: str, variant: str, language: str,
                             confidence: float = 0.8, source: str = "ai",
                             note: str = ""):
        """
        æ·»åŠ æ–°å‘ç°çš„å¹´çº§è¡¨è¾¾

        Args:
            grade: æ ‡å‡†å¹´çº§ (å¦‚: "Grade 2")
            variant: å‘ç°çš„è¡¨è¾¾ (å¦‚: "Ø§Ù„ØµÙ Ø§Ù„Ø«Ø§Ù†ÙŠ")
            language: è¯­è¨€ (arabic, english, etc.)
            confidence: ç½®ä¿¡åº¦ (0-1)
            source: æ¥æº (ai, manual)
            note: å¤‡æ³¨
        """
        grade_key = self._normalize_grade_key(grade)

        # åˆå§‹åŒ–å¹´çº§
        if grade_key not in self.knowledge["grade_expressions"]:
            self.knowledge["grade_expressions"][grade_key] = {
                "local_variants": [],
                "common_mistakes": []
            }

        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        for v in self.knowledge["grade_expressions"][grade_key]["local_variants"]:
            if language in v and v[language] == variant:
                logger.info(f"[ğŸ“š çŸ¥è¯†åº“] è¡¨è¾¾å·²å­˜åœ¨: {variant}")
                return

        # æ·»åŠ æ–°è¡¨è¾¾
        new_variant = {
            language: variant,
            "confidence": confidence,
            "verified_by": source,
            "discovered_at": datetime.now(timezone.utc).isoformat()
        }

        if note:
            new_variant["note"] = note

        self.knowledge["grade_expressions"][grade_key]["local_variants"].append(new_variant)

        logger.info(f"[ğŸ“š çŸ¥è¯†åº“] å‘ç°æ–°è¡¨è¾¾: {grade_key} -> {variant} ({language})")

        # è®°å½•åˆ°discovered_variants
        discovery = {
            "grade": grade_key,
            "variant": variant,
            "language": language,
            "confidence": confidence,
            "discovered_at": datetime.now(timezone.utc).isoformat(),
            "status": "pending_review"  # pending_review, approved, rejected
        }
        self.knowledge["llm_insights"]["discovered_variants"].append(discovery)

    # ========================================================================
    # å­¦ç§‘å…³é”®è¯ç®¡ç†
    # ========================================================================

    def get_subject_variants(self, subject: str) -> List[str]:
        """è·å–å­¦ç§‘çš„æ‰€æœ‰å·²çŸ¥è¡¨è¾¾"""
        # æ ‡å‡†åŒ–å­¦ç§‘
        subject_key = self._normalize_subject_key(subject)

        if subject_key in self.knowledge.get("subject_keywords", {}):
            variants_data = self.knowledge["subject_keywords"][subject_key].get("local_variants", [])
            variants = []
            for v in variants_data:
                if "arabic" in v:
                    variants.append(v["arabic"])
                if "english" in v:
                    variants.append(v["english"])
            return variants
        return []

    def _normalize_subject_key(self, subject: str) -> str:
        """æ ‡å‡†åŒ–å­¦ç§‘key"""
        subject_mapping = {
            "math": "Mathematics",
            "mathematics": "Mathematics",
            "Ø±ÙŠØ§Ø¶ÙŠØ§Øª": "Mathematics",
            "matematika": "Mathematics",
            "ç§‘å­¦": "Science",
            "Ø¹Ù„ÙˆÙ…": "Science",
        }
        return subject_mapping.get(subject.lower(), subject.title())

    # ========================================================================
    # LLMé”™è¯¯è®°å½•
    # ========================================================================

    def record_llm_mistake(self, mistake_type: str, example: str,
                          correction: str, severity: str = "high"):
        """
        è®°å½•LLMé”™è¯¯åˆ°çŸ¥è¯†åº“

        Args:
            mistake_type: é”™è¯¯ç±»å‹ (grade_mismatch, language_error, etc.)
            example: é”™è¯¯ç¤ºä¾‹
            correction: ä¿®æ­£æ–¹æ¡ˆ
            severity: ä¸¥é‡ç¨‹åº¦ (high, medium, low)
        """
        # æ£€æŸ¥æ˜¯å¦å·²è®°å½•
        for issue in self.knowledge["llm_insights"]["accuracy_issues"]:
            if issue["example"] == example:
                logger.info(f"[ğŸ“š çŸ¥è¯†åº“] é”™è¯¯å·²è®°å½•: {example}")
                return

        mistake = {
            "issue": mistake_type,
            "example": example,
            "fix": correction,
            "severity": severity,
            "status": "pending_fix",  # pending_fix, fixed, ignored
            "reported_at": datetime.now(timezone.utc).isoformat(),
            "frequency": 1
        }

        self.knowledge["llm_insights"]["accuracy_issues"].append(mistake)
        logger.warning(f"[ğŸ“š çŸ¥è¯†åº“] è®°å½•LLMé”™è¯¯: {mistake_type} - {example}")

    def mark_issue_fixed(self, example: str):
        """æ ‡è®°é—®é¢˜å·²ä¿®å¤"""
        for issue in self.knowledge["llm_insights"]["accuracy_issues"]:
            if issue["example"] == example:
                issue["status"] = "fixed"
                issue["fixed_at"] = datetime.now(timezone.utc).isoformat()
                logger.info(f"[ğŸ“š çŸ¥è¯†åº“] é—®é¢˜å·²æ ‡è®°ä¸ºä¿®å¤: {example}")
                return

    # ========================================================================
    # æœç´¢ç»“æœè®°å½•
    # ========================================================================

    def record_search_results(self, query: str, results: List[Dict],
                             quality_report: Dict):
        """
        è®°å½•æœç´¢ç»“æœåˆ°çŸ¥è¯†åº“

        Args:
            query: ä½¿ç”¨çš„æŸ¥è¯¢è¯
            results: æœç´¢ç»“æœåˆ—è¡¨
            quality_report: è´¨é‡è¯„ä¼°æŠ¥å‘Š
        """
        # æ›´æ–°å…ƒæ•°æ®
        self.knowledge["metadata"]["total_searches"] += 1
        self.knowledge["metadata"]["last_updated"] = datetime.now(timezone.utc).isoformat()

        # æ›´æ–°å¹³å‡è´¨é‡åˆ†
        current_avg = self.knowledge["metadata"]["avg_quality_score"]
        total_searches = self.knowledge["metadata"]["total_searches"]
        new_score = quality_report.get("overall_quality_score", 0)

        if current_avg > 0:
            self.knowledge["metadata"]["avg_quality_score"] = (
                (current_avg * (total_searches - 1) + new_score) / total_searches
            )
        else:
            self.knowledge["metadata"]["avg_quality_score"] = new_score

        # è®°å½•æˆåŠŸ/å¤±è´¥æŸ¥è¯¢
        avg_score = quality_report.get("overall_quality_score", 0)
        results_count = len(results)

        # åˆ†ææ¥æºåˆ†å¸ƒ
        domains = self._extract_domains(results)
        youtube_ratio = domains.count("youtube.com") / len(domains) if domains else 0

        if avg_score >= 7.0:
            # æˆåŠŸæŸ¥è¯¢
            success_query = {
                "query": query,
                "avg_score": avg_score,
                "results_count": results_count,
                "youtube_ratio": youtube_ratio,
                "notes": "",
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
            self.knowledge["search_patterns"]["successful_queries"].append(success_query)
            logger.info(f"[ğŸ“š çŸ¥è¯†åº“] è®°å½•æˆåŠŸæŸ¥è¯¢: {query} (åˆ†æ•°: {avg_score})")
        else:
            # å¤±è´¥æŸ¥è¯¢
            failed_query = {
                "query": query,
                "avg_score": avg_score,
                "results_count": results_count,
                "reason": "è´¨é‡åˆ†æ•°è¿‡ä½",
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
            self.knowledge["search_patterns"]["failed_queries"].append(failed_query)
            logger.warning(f"[ğŸ“š çŸ¥è¯†åº“] è®°å½•å¤±è´¥æŸ¥è¯¢: {query} (åˆ†æ•°: {avg_score})")

        # æ›´æ–°åŸŸååå¥½
        self._update_domain_preferences(domains, avg_score)

    def _extract_domains(self, results: List[Dict]) -> List[str]:
        """ä»ç»“æœä¸­æå–åŸŸå"""
        domains = []
        for result in results:
            url = result.get("url", "")
            if "://" in url:
                domain = url.split("/")[2]
                # å»æ‰www.
                if domain.startswith("www."):
                    domain = domain[4:]
                domains.append(domain)
        return domains

    def _update_domain_preferences(self, domains: List[Dict], avg_score: float):
        """æ›´æ–°åŸŸååå¥½"""
        domain_counts = {}
        for domain in domains:
            domain_counts[domain] = domain_counts.get(domain, 0) + 1

        for domain, count in domain_counts.items():
            # æŸ¥æ‰¾æ˜¯å¦å·²å­˜åœ¨
            found = False
            for platform in self.knowledge["domain_preferences"]["tier_1_platforms"]:
                if platform["domain"] == domain:
                    # æ›´æ–°å¹³å‡è´¨é‡
                    old_quality = platform.get("avg_quality", 0)
                    old_count = platform.get("results_count", 0)
                    new_quality = (old_quality * old_count + avg_score) / (old_count + 1)
                    platform["avg_quality"] = new_quality
                    platform["results_count"] = old_count + count
                    found = True
                    break

            if not found and count >= 2:  # è‡³å°‘å‡ºç°2æ¬¡æ‰è®°å½•
                self.knowledge["domain_preferences"]["tier_1_platforms"].append({
                    "domain": domain,
                    "avg_quality": avg_score,
                    "abundance": "high" if count >= 5 else "medium",
                    "results_count": count
                })

    # ========================================================================
    # Promptç”Ÿæˆ
    # ========================================================================

    def generate_evaluation_prompt(self, base_prompt: str) -> str:
        """
        åŸºäºçŸ¥è¯†åº“ç”Ÿæˆå¢å¼ºçš„è¯„ä¼°prompt

        Args:
            base_prompt: åŸºç¡€prompt

        Returns:
            å¢å¼ºåçš„prompt
        """
        enhanced = base_prompt

        # æ·»åŠ å¹´çº§è¡¨è¾¾
        if self.knowledge.get("grade_expressions"):
            grade_section = "\n## é‡è¦å¹´çº§è¡¨è¾¾ï¼ˆå¿…é¡»è¯†åˆ«ï¼‰\n"
            for grade_key, grade_data in self.knowledge["grade_expressions"].items():
                grade_section += f"\n### {grade_key}\n"
                for variant in grade_data.get("local_variants", []):
                    if "arabic" in variant:
                        grade_section += f"- {variant['arabic']} (é˜¿æ‹‰ä¼¯è¯­)\n"
                    if "english" in variant:
                        note = f" - {variant.get('note', '')}" if variant.get('note') else ""
                        grade_section += f"- {variant['english']} (è‹±è¯­){note}\n"

                # æ·»åŠ å¸¸è§é”™è¯¯
                for mistake in grade_data.get("common_mistakes", []):
                    grade_section += f"âš ï¸ å¸¸è§é”™è¯¯: {mistake['mistake']} -> {mistake['correction']}\n"

            enhanced += grade_section

        # æ·»åŠ å¸¸è§é”™è¯¯ï¼ˆå¿…é¡»é¿å…ï¼‰
        if self.knowledge["llm_insights"]["accuracy_issues"]:
            mistakes_section = "\n## å¸¸è§LLMé”™è¯¯ï¼ˆå¿…é¡»é¿å…ï¼‰\n"
            for issue in self.knowledge["llm_insights"]["accuracy_issues"]:
                if issue["status"] != "fixed":
                    mistakes_section += f"- âŒ {issue['issue']}: {issue['example']}\n"
                    mistakes_section += f"  âœ… ä¿®æ­£: {issue['fix']}\n\n"

            enhanced += mistakes_section

        return enhanced

    def generate_search_strategy(self) -> Dict[str, Any]:
        """
        åŸºäºçŸ¥è¯†åº“ç”Ÿæˆä¼˜åŒ–çš„æœç´¢ç­–ç•¥

        Returns:
            æœç´¢ç­–ç•¥å­—å…¸
        """
        strategy = {
            "preferred_languages": [],
            "grade_variants": {},
            "subject_variants": {},
            "avoid_keywords": [],
            "domain_focus": []
        }

        # ä»æˆåŠŸæŸ¥è¯¢ä¸­æå–æ¨¡å¼
        successful_queries = self.knowledge["search_patterns"]["successful_queries"]
        if successful_queries:
            # æ‰¾å‡ºå¹³å‡åˆ†æœ€é«˜çš„æŸ¥è¯¢
            best_queries = sorted(successful_queries,
                                key=lambda x: x["avg_score"],
                                reverse=True)[:3]

            for q in best_queries:
                # æå–å…³é”®è¯
                words = q["query"].split()
                for word in words:
                    if len(word) > 2 and word not in strategy["avoid_keywords"]:
                        # å¦‚æœè¿™ä¸ªè¯åœ¨å¤šä¸ªé«˜åˆ†æŸ¥è¯¢ä¸­å‡ºç°ï¼Œä¿ç•™å®ƒ
                        if all(word in other_q["query"] for other_q in best_queries):
                            pass  # è¿™ä¸ªè¯æ˜¯å¥½è¯

        # æ·»åŠ å¹´çº§å˜ä½“
        for grade_key, grade_data in self.knowledge.get("grade_expressions", {}).items():
            variants = []
            for v in grade_data.get("local_variants", []):
                if "arabic" in v:
                    variants.append(v["arabic"])
                if "english" in v:
                    variants.append(v["english"])
            strategy["grade_variants"][grade_key] = variants

        # æ·»åŠ å­¦ç§‘å˜ä½“
        for subject_key, subject_data in self.knowledge.get("subject_keywords", {}).items():
            variants = []
            for v in subject_data.get("local_variants", []):
                if "arabic" in v:
                    variants.append(v["arabic"])
                if "english" in v:
                    variants.append(v["english"])
            strategy["subject_variants"][subject_key] = variants

        # åŸŸåä¼˜å…ˆçº§
        tier_1 = self.knowledge["domain_preferences"]["tier_1_platforms"]
        if tier_1:
            # æŒ‰å¹³å‡è´¨é‡æ’åº
            sorted_platforms = sorted(tier_1,
                                     key=lambda x: x.get("avg_quality", 0),
                                     reverse=True)
            strategy["domain_focus"] = [p["domain"] for p in sorted_platforms[:5]]

        logger.info(f"[ğŸ“š çŸ¥è¯†åº“] ç”Ÿæˆæœç´¢ç­–ç•¥: {len(strategy['grade_variants'])} ä¸ªå¹´çº§, "
                   f"{len(strategy['domain_focus'])} ä¸ªä¼˜é€‰åŸŸå")

        return strategy

    # ========================================================================
    # ä¿å­˜å’Œå¯¼å‡º
    # ========================================================================

    def save(self):
        """ä¿å­˜çŸ¥è¯†åº“åˆ°æ–‡ä»¶"""
        try:
            # æ›´æ–°æœ€åæ›´æ–°æ—¶é—´
            self.knowledge["metadata"]["last_updated"] = datetime.now(timezone.utc).isoformat()

            # ä¿å­˜åˆ°æ–‡ä»¶
            with open(self.kb_file, 'w', encoding='utf-8') as f:
                json.dump(self.knowledge, f, ensure_ascii=False, indent=2)

            logger.info(f"[ğŸ“š çŸ¥è¯†åº“] å·²ä¿å­˜: {self.kb_file}")
        except Exception as e:
            logger.error(f"[ğŸ“š çŸ¥è¯†åº“] ä¿å­˜å¤±è´¥: {e}")

    def export_summary(self) -> str:
        """å¯¼å‡ºçŸ¥è¯†åº“æ‘˜è¦ï¼ˆä¾¿äºæŸ¥çœ‹ï¼‰"""
        summary = f"""
# {self.country_code} æœç´¢çŸ¥è¯†åº“æ‘˜è¦

## å…ƒæ•°æ®
- å›½å®¶: {self.knowledge['metadata']['country_name']}
- æ€»æœç´¢æ¬¡æ•°: {self.knowledge['metadata']['total_searches']}
- å¹³å‡è´¨é‡åˆ†æ•°: {self.knowledge['metadata']['avg_quality_score']:.1f}/100
- æœ€åæ›´æ–°: {self.knowledge['metadata']['last_updated']}

## å¹´çº§è¡¨è¾¾ ({len(self.knowledge.get('grade_expressions', {}))} ä¸ªå¹´çº§)
"""
        for grade, data in self.knowledge.get("grade_expressions", {}).items():
            summary += f"\n### {grade}\n"
            for variant in data.get("local_variants", []):
                if "arabic" in variant:
                    summary += f"- {variant['arabic']} (ç½®ä¿¡åº¦: {variant['confidence']})\n"

        summary += f"\n## LLMé”™è¯¯è®°å½• ({len(self.knowledge['llm_insights']['accuracy_issues'])} ä¸ª)\n"
        for issue in self.knowledge["llm_insights"]["accuracy_issues"]:
            status_emoji = "âœ…" if issue["status"] == "fixed" else "âš ï¸"
            summary += f"- {status_emoji} {issue['issue']}: {issue['example']}\n"

        summary += f"\n## ä¼˜é€‰åŸŸå ({len(self.knowledge['domain_preferences']['tier_1_platforms'])} ä¸ª)\n"
        for platform in self.knowledge["domain_preferences"]["tier_1_platforms"][:10]:
            summary += f"- {platform['domain']} (è´¨é‡: {platform.get('avg_quality', 0):.1f})\n"

        return summary


# ========================================================================
# å…¨å±€å•ä¾‹
# ========================================================================

_managers = {}

def get_knowledge_base_manager(country_code: str) -> KnowledgeBaseManager:
    """è·å–çŸ¥è¯†åº“ç®¡ç†å™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    country_code = country_code.upper()
    if country_code not in _managers:
        _managers[country_code] = KnowledgeBaseManager(country_code)
    return _managers[country_code]
