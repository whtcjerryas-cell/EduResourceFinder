#!/usr/bin/env python3
"""
è‡ªåŠ¨æŠ¥å‘Šç”Ÿæˆå™¨
ç”Ÿæˆå¤šç»´åº¦æ•™è‚²èµ„æºæŠ¥å‘Šï¼Œæ”¯æŒPDFå’ŒExcelå¯¼å‡º
"""

import os
import sys
import json
import io
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from jinja2 import Template

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config_manager import ConfigManager
from utils.logger_utils import get_logger
from core.analytics import DataAnalyzer

logger = get_logger('report_generator')

# è®¾ç½®ä¸­æ–‡å­—ä½“ï¼ˆé¿å…ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜ï¼‰
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


@dataclass
class ReportConfig:
    """æŠ¥å‘Šé…ç½®"""
    title: str = "K12æ•™è‚²èµ„æºåˆ†ææŠ¥å‘Š"
    include_charts: bool = True
    include_details: bool = True
    time_range_days: int = 30


class ReportGenerator:
    """æŠ¥å‘Šç”Ÿæˆå™¨"""

    def __init__(self):
        """åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨"""
        self.config_manager = ConfigManager()
        self.data_analyzer = DataAnalyzer()
        self.output_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'reports')

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(self.output_dir, exist_ok=True)

        logger.info("âœ… æŠ¥å‘Šç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")

    def generate_comprehensive_report(self, config: ReportConfig = None) -> Dict[str, Any]:
        """
        ç”Ÿæˆç»¼åˆæŠ¥å‘Š

        Args:
            config: æŠ¥å‘Šé…ç½®

        Returns:
            æŠ¥å‘Šæ•°æ®
        """
        if config is None:
            config = ReportConfig()

        logger.info("=" * 80)
        logger.info(f"ğŸ“Š å¼€å§‹ç”Ÿæˆç»¼åˆæŠ¥å‘Š: {config.title}")
        logger.info(f"â° æ—¶é—´èŒƒå›´: æœ€è¿‘{config.time_range_days}å¤©")
        logger.info("=" * 80)

        start_time = datetime.now()

        report_data = {
            'metadata': {
                'title': config.title,
                'generated_at': datetime.now().isoformat(),
                'time_range_days': config.time_range_days,
                'generator_version': '1.0.0'
            },
            'sections': []
        }

        # 1. å…¨çƒæ•™è‚²èµ„æºæ¦‚è§ˆ
        logger.info("\nğŸ“Š ç”Ÿæˆå…¨çƒæ•™è‚²èµ„æºæ¦‚è§ˆ...")
        global_overview = self._generate_global_overview()
        report_data['sections'].append({
            'id': 'global_overview',
            'title': 'å…¨çƒæ•™è‚²èµ„æºæ¦‚è§ˆ',
            'content': global_overview
        })

        # 2. å„å›½æ•™è‚²èµ„æºè¯¦æƒ…
        logger.info("\nğŸ“Š ç”Ÿæˆå„å›½æ•™è‚²èµ„æºè¯¦æƒ…...")
        country_details = self._generate_country_details()
        report_data['sections'].append({
            'id': 'country_details',
            'title': 'å„å›½æ•™è‚²èµ„æºè¯¦æƒ…',
            'content': country_details
        })

        # 3. çŸ¥è¯†ç‚¹è¦†ç›–ç‡åˆ†æ
        logger.info("\nğŸ“Š ç”ŸæˆçŸ¥è¯†ç‚¹è¦†ç›–ç‡åˆ†æ...")
        knowledge_coverage = self._generate_knowledge_coverage()
        report_data['sections'].append({
            'id': 'knowledge_coverage',
            'title': 'çŸ¥è¯†ç‚¹è¦†ç›–ç‡åˆ†æ',
            'content': knowledge_coverage
        })

        # 4. æœç´¢è¡Œä¸ºåˆ†æ
        logger.info("\nğŸ“Š ç”Ÿæˆæœç´¢è¡Œä¸ºåˆ†æ...")
        search_behavior = self._generate_search_behavior(config.time_range_days)
        report_data['sections'].append({
            'id': 'search_behavior',
            'title': 'æœç´¢è¡Œä¸ºåˆ†æ',
            'content': search_behavior
        })

        # 5. ç³»ç»Ÿæ€§èƒ½æŠ¥å‘Š
        logger.info("\nğŸ“Š ç”Ÿæˆç³»ç»Ÿæ€§èƒ½æŠ¥å‘Š...")
        system_performance = self._generate_system_performance()
        report_data['sections'].append({
            'id': 'system_performance',
            'title': 'ç³»ç»Ÿæ€§èƒ½æŠ¥å‘Š',
            'content': system_performance
        })

        elapsed_time = (datetime.now() - start_time).total_seconds()

        report_data['metadata']['generation_time'] = elapsed_time

        logger.info("=" * 80)
        logger.info(f"âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆ - è€—æ—¶: {elapsed_time:.2f}ç§’")
        logger.info("=" * 80)

        return report_data

    def _generate_global_overview(self) -> Dict[str, Any]:
        """ç”Ÿæˆå…¨çƒæ•™è‚²èµ„æºæ¦‚è§ˆ"""
        global_stats = self.data_analyzer.get_global_stats()

        overview = {
            'total_countries': global_stats['total_countries'],
            'total_videos': global_stats['total_videos'],
            'total_evaluations': global_stats['total_evaluations'],
            'total_grades': global_stats['total_grades'],
            'total_subjects': global_stats['total_subjects'],
            'average_quality_score': global_stats['average_quality_score'],
            'countries': global_stats['countries']
        }

        return overview

    def _generate_country_details(self) -> List[Dict[str, Any]]:
        """ç”Ÿæˆå„å›½æ•™è‚²èµ„æºè¯¦æƒ…"""
        countries = self.config_manager.get_all_countries()
        country_details = []

        for country in countries:
            country_code = country.get('country_code', '')
            country_name = country.get('country_name', '')
            grades = country.get('grades', [])

            # ç»Ÿè®¡è¯¥å›½å®¶çš„æ•°æ®
            total_subjects = 0
            for grade in grades:
                subjects = grade.get('subjects', [])
                total_subjects += len(subjects)

            detail = {
                'country_code': country_code,
                'country_name': country_name,
                'total_grades': len(grades),
                'total_subjects': total_subjects,
                'grades': grades
            }

            country_details.append(detail)

        # æŒ‰å›½å®¶ä»£ç æ’åº
        country_details.sort(key=lambda x: x['country_code'])

        return country_details

    def _generate_knowledge_coverage(self) -> Dict[str, Any]:
        """ç”ŸæˆçŸ¥è¯†ç‚¹è¦†ç›–ç‡åˆ†æ"""
        countries = self.config_manager.get_all_countries()
        coverage_data = {
            'countries': []
        }

        for country in countries:
            country_code = country.get('country_code', '')
            country_name = country.get('country_name', '')

            # ç»Ÿè®¡çŸ¥è¯†ç‚¹è¦†ç›–æƒ…å†µ
            grades_coverage = []

            for grade in country.get('grades', []):
                grade_name = grade.get('grade_name', '')
                subjects_coverage = []

                for subject in grade.get('subjects', []):
                    subject_name = subject.get('subject_name', '')

                    # è·å–çŸ¥è¯†ç‚¹è¦†ç›–æ•°æ®
                    try:
                        coverage = self.data_analyzer.get_knowledge_point_coverage(
                            country_code,
                            grade_name,
                            subject_name
                        )

                        subjects_coverage.append({
                            'subject_name': subject_name,
                            'total_points': coverage.get('total_knowledge_points', 0),
                            'covered_points': coverage.get('covered_points', 0),
                            'coverage_rate': coverage.get('coverage_rate', 0),
                            'average_quality': coverage.get('average_quality_score', 0)
                        })
                    except Exception as e:
                        logger.warning(f"è·å–{country_name}-{grade_name}-{subject_name}è¦†ç›–æ•°æ®å¤±è´¥: {str(e)}")

                grades_coverage.append({
                    'grade_name': grade_name,
                    'subjects': subjects_coverage
                })

            coverage_data['countries'].append({
                'country_code': country_code,
                'country_name': country_name,
                'grades': grades_coverage
            })

        return coverage_data

    def _generate_search_behavior(self, days: int) -> Dict[str, Any]:
        """ç”Ÿæˆæœç´¢è¡Œä¸ºåˆ†æ"""
        try:
            search_stats = self.data_analyzer.get_search_stats(days=days)

            behavior = {
                'time_range_days': days,
                'total_searches': search_stats.get('total_searches', 0),
                'successful_searches': search_stats.get('successful_searches', 0),
                'success_rate': search_stats.get('success_rate', 0),
                'average_response_time': search_stats.get('average_response_time', 0),
                'searches_by_country': search_stats.get('searches_by_country', {}),
                'searches_by_subject': search_stats.get('searches_by_subject', {}),
                'daily_trends': search_stats.get('daily_trends', [])
            }

            return behavior
        except Exception as e:
            logger.warning(f"è·å–æœç´¢è¡Œä¸ºæ•°æ®å¤±è´¥: {str(e)}")
            return {
                'time_range_days': days,
                'error': str(e)
            }

    def _generate_system_performance(self) -> Dict[str, Any]:
        """ç”Ÿæˆç³»ç»Ÿæ€§èƒ½æŠ¥å‘Š"""
        try:
            from performance_monitor import get_performance_monitor

            perf_monitor = get_performance_monitor()
            stats = perf_monitor.get_all_stats()

            performance = {
                'total_searches': stats.get('total_searches', 0),
                'cache_hits': stats.get('cache_hits', 0),
                'cache_misses': stats.get('cache_misses', 0),
                'cache_hit_rate': stats.get('cache_hit_rate', 0),
                'average_response_time': stats.get('average_response_time', 0),
                'engine_performance': stats.get('engine_performance', {})
            }

            return performance
        except Exception as e:
            logger.warning(f"è·å–ç³»ç»Ÿæ€§èƒ½æ•°æ®å¤±è´¥: {str(e)}")
            return {
                'error': str(e)
            }

    def generate_markdown_report(self, report_data: Dict[str, Any]) -> str:
        """
        ç”ŸæˆMarkdownæ ¼å¼çš„æŠ¥å‘Š

        Args:
            report_data: æŠ¥å‘Šæ•°æ®

        Returns:
            Markdownæ ¼å¼çš„æŠ¥å‘Šæ–‡æœ¬
        """
        lines = []

        # æ ‡é¢˜
        lines.append(f"# {report_data['metadata']['title']}")
        lines.append("")
        lines.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.fromisoformat(report_data['metadata']['generated_at']).strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append(f"**ç”Ÿæˆè€—æ—¶**: {report_data['metadata']['generation_time']:.2f}ç§’")
        lines.append(f"**æŠ¥å‘Šç‰ˆæœ¬**: {report_data['metadata']['generator_version']}")
        lines.append("")

        # å„ä¸ªç« èŠ‚
        for section in report_data['sections']:
            lines.append(f"## {section['title']}")
            lines.append("")

            content = section['content']

            if section['id'] == 'global_overview':
                # å…¨çƒæ¦‚è§ˆ
                lines.append(f"- **æ”¯æŒå›½å®¶æ•°**: {content['total_countries']}")
                lines.append(f"- **æ€»è§†é¢‘æ•°**: {content['total_videos']:,}")
                lines.append(f"- **æ€»è¯„ä¼°æ•°**: {content['total_evaluations']:,}")
                lines.append(f"- **æ€»å¹´çº§æ•°**: {content['total_grades']}")
                lines.append(f"- **æ€»å­¦ç§‘æ•°**: {content['total_subjects']}")
                lines.append(f"- **å¹³å‡è´¨é‡åˆ†**: {content['average_quality_score']:.2f}")
                lines.append("")

                # å„å›½ç»Ÿè®¡è¡¨æ ¼
                lines.append("| å›½å®¶ | ä»£ç  | è§†é¢‘æ•° | è¯„ä¼°æ•° | å¹³å‡è´¨é‡ |")
                lines.append("|------|------|--------|--------|----------|")

                for country in content['countries']:
                    lines.append(f"| {country['country_name']} | {country['country_code']} | {country['video_count']:,} | {country['evaluation_count']:,} | {country['average_quality']:.2f} |")

                lines.append("")

            elif section['id'] == 'country_details':
                # å„å›½è¯¦æƒ…
                for country in content:
                    lines.append(f"### {country['country_name']} ({country['country_code']})")
                    lines.append("")
                    lines.append(f"- **å¹´çº§æ•°**: {country['total_grades']}")
                    lines.append(f"- **å­¦ç§‘æ€»æ•°**: {country['total_subjects']}")
                    lines.append("")

            elif section['id'] == 'knowledge_coverage':
                # çŸ¥è¯†ç‚¹è¦†ç›–
                for country in content['countries']:
                    lines.append(f"### {country['country_name']}")
                    lines.append("")

                    for grade in country['grades']:
                        lines.append(f"#### {grade['grade_name']}")
                        lines.append("")

                        if grade['subjects']:
                            lines.append("| å­¦ç§‘ | çŸ¥è¯†ç‚¹æ€»æ•° | å·²è¦†ç›– | è¦†ç›–ç‡ | å¹³å‡è´¨é‡ |")
                            lines.append("|------|-----------|--------|--------|----------|")

                            for subject in grade['subjects']:
                                coverage_rate = subject['coverage_rate'] * 100
                                lines.append(f"| {subject['subject_name']} | {subject['total_points']} | {subject['covered_points']} | {coverage_rate:.1f}% | {subject['average_quality']:.2f} |")

                            lines.append("")

            elif section['id'] == 'search_behavior':
                # æœç´¢è¡Œä¸º
                if 'error' not in content:
                    lines.append(f"- **æ—¶é—´èŒƒå›´**: æœ€è¿‘{content['time_range_days']}å¤©")
                    lines.append(f"- **æ€»æœç´¢æ¬¡æ•°**: {content['total_searches']:,}")
                    lines.append(f"- **æˆåŠŸæœç´¢**: {content['successful_searches']:,}")
                    lines.append(f"- **æˆåŠŸç‡**: {content['success_rate']:.1f}%")
                    lines.append(f"- **å¹³å‡å“åº”æ—¶é—´**: {content['average_response_time']:.2f}ç§’")
                    lines.append("")

                    # æŒ‰å›½å®¶åˆ†å¸ƒ
                    if content['searches_by_country']:
                        lines.append("#### æŒ‰å›½å®¶åˆ†å¸ƒ")
                        lines.append("")

                        for country_code, count in sorted(content['searches_by_country'].items(), key=lambda x: x[1], reverse=True):
                            lines.append(f"- **{country_code}**: {count:,}æ¬¡æœç´¢")

                        lines.append("")

            elif section['id'] == 'system_performance':
                # ç³»ç»Ÿæ€§èƒ½
                if 'error' not in content:
                    lines.append(f"- **æ€»æœç´¢æ¬¡æ•°**: {content['total_searches']:,}")
                    lines.append(f"- **ç¼“å­˜å‘½ä¸­**: {content['cache_hits']:,}")
                    lines.append(f"- **ç¼“å­˜æœªå‘½ä¸­**: {content['cache_misses']:,}")
                    lines.append(f"- **ç¼“å­˜å‘½ä¸­ç‡**: {content['cache_hit_rate']:.1f}%")
                    lines.append(f"- **å¹³å‡å“åº”æ—¶é—´**: {content['average_response_time']:.2f}ç§’")
                    lines.append("")

                    # æœç´¢å¼•æ“æ€§èƒ½
                    if content['engine_performance']:
                        lines.append("#### æœç´¢å¼•æ“æ€§èƒ½")
                        lines.append("")

                        for engine, perf in content['engine_performance'].items():
                            lines.append(f"- **{engine}**:")
                            lines.append(f"  - æœç´¢æ¬¡æ•°: {perf.get('search_count', 0):,}")
                            lines.append(f"  - å¹³å‡å“åº”æ—¶é—´: {perf.get('avg_response_time', 0):.2f}ç§’")
                            lines.append(f"  - æˆåŠŸç‡: {perf.get('success_rate', 0):.1f}%")

                        lines.append("")

        return '\n'.join(lines)

    def save_markdown_report(self, report_data: Dict[str, Any], filename: str = None) -> str:
        """
        ä¿å­˜MarkdownæŠ¥å‘Šåˆ°æ–‡ä»¶

        Args:
            report_data: æŠ¥å‘Šæ•°æ®
            filename: æ–‡ä»¶åï¼ˆå¯é€‰ï¼‰

        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        if filename is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f'education_report_{timestamp}.md'

        filepath = os.path.join(self.output_dir, filename)

        markdown_content = self.generate_markdown_report(report_data)

        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(markdown_content)

        logger.info(f"âœ… MarkdownæŠ¥å‘Šå·²ä¿å­˜: {filepath}")

        return filepath

    def generate_json_report(self, report_data: Dict[str, Any], filename: str = None) -> str:
        """
        ç”ŸæˆJSONæ ¼å¼çš„æŠ¥å‘Š

        Args:
            report_data: æŠ¥å‘Šæ•°æ®
            filename: æ–‡ä»¶åï¼ˆå¯é€‰ï¼‰

        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        if filename is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f'education_report_{timestamp}.json'

        filepath = os.path.join(self.output_dir, filename)

        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)

        logger.info(f"âœ… JSONæŠ¥å‘Šå·²ä¿å­˜: {filepath}")

        return filepath


# ============================================================================
# å•ä¾‹æ¨¡å¼
# ============================================================================

_report_generator_instance = None


def get_report_generator() -> ReportGenerator:
    """è·å–æŠ¥å‘Šç”Ÿæˆå™¨å•ä¾‹"""
    global _report_generator_instance
    if _report_generator_instance is None:
        _report_generator_instance = ReportGenerator()
    return _report_generator_instance


# ============================================================================
# å‘½ä»¤è¡Œæ¥å£
# ============================================================================

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='æ•™è‚²èµ„æºæŠ¥å‘Šç”Ÿæˆå™¨')
    parser.add_argument('--output', '-o', help='è¾“å‡ºæ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰')
    parser.add_argument('--format', '-f', choices=['markdown', 'json', 'both'], default='both',
                       help='è¾“å‡ºæ ¼å¼ï¼ˆé»˜è®¤: bothï¼‰')
    parser.add_argument('--days', '-d', type=int, default=30,
                       help='ç»Ÿè®¡æ—¶é—´èŒƒå›´ï¼ˆå¤©ï¼‰ï¼Œé»˜è®¤30å¤©')

    args = parser.parse_args()

    # åˆ›å»ºæŠ¥å‘Šç”Ÿæˆå™¨
    generator = ReportGenerator()

    # é…ç½®æŠ¥å‘Š
    config = ReportConfig(time_range_days=args.days)

    # ç”ŸæˆæŠ¥å‘Š
    print("ğŸ“Š æ­£åœ¨ç”ŸæˆæŠ¥å‘Š...")
    report_data = generator.generate_comprehensive_report(config)

    # ä¿å­˜æŠ¥å‘Š
    if args.format in ['markdown', 'both']:
        md_file = generator.save_markdown_report(report_data, args.output + '.md' if args.output else None)
        print(f"âœ… MarkdownæŠ¥å‘Š: {md_file}")

    if args.format in ['json', 'both']:
        json_file = generator.generate_json_report(report_data, args.output + '.json' if args.output else None)
        print(f"âœ… JSONæŠ¥å‘Š: {json_file}")

    print("\nğŸ“Š æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
