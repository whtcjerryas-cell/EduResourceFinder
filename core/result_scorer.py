#!/usr/bin/env python3
"""
æ™ºèƒ½ç»“æœè¯„åˆ†æ¨¡å—
åŸºäºå¤šä¸ªå› ç´ å¯¹æœç´¢ç»“æœè¿›è¡Œæ™ºèƒ½è¯„åˆ†
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import re
import json
from typing import Dict, List, Any, Optional, Tuple
from urllib.parse import urlparse
from logger_utils import get_logger
from llm_client import InternalAPIClient

# âœ… æ–°å¢ï¼šå¯¼å…¥é…ç½®ç®¡ç†å™¨
from config_manager import get_config_manager

# âœ… æ–°å¢ï¼šå¯¼å…¥é˜¿æ‹‰ä¼¯è¯­æ ‡å‡†åŒ–æ¨¡å—
from core.arabic_normalizer import ArabicNormalizer

# âœ… å®‰å…¨ä¿®å¤ï¼šå¯¼å…¥è¾“å…¥å‡€åŒ–æ¨¡å—ï¼ˆé˜²æ­¢LLMæç¤ºæ³¨å…¥ï¼‰
from core.input_sanitizer import sanitize_llm_input, sanitize_metadata

logger = get_logger('result_scorer')


class IntelligentResultScorer:
    """
    æ™ºèƒ½ç»“æœè¯„åˆ†å™¨

    è¯„åˆ†ç»´åº¦:
    1. URLè´¨é‡å’Œå¯ä¿¡åº¦
    2. æ ‡é¢˜ç›¸å…³æ€§
    3. å†…å®¹å®Œæ•´æ€§
    4. æ¥æºæƒå¨æ€§
    5. èµ„æºç±»å‹åŒ¹é…åº¦
    """

    def __init__(self, country_code: str = None):
        """
        åˆå§‹åŒ–è¯„åˆ†å™¨

        Args:
            country_code: å›½å®¶ä»£ç  (å¦‚: IQ, ID, CN)ï¼Œç”¨äºåŠ è½½çŸ¥è¯†åº“
        """
        # åˆå§‹åŒ–çŸ¥è¯†åº“ç®¡ç†å™¨ï¼ˆå¦‚æœæä¾›äº†country_codeï¼‰
        self.kb_manager = None
        if country_code:
            try:
                from core.knowledge_base_manager import get_knowledge_base_manager
                self.kb_manager = get_knowledge_base_manager(country_code)
                logger.info(f"[âœ… è¯„åˆ†å™¨] å·²åŠ è½½ {country_code} çŸ¥è¯†åº“")
            except ImportError:
                logger.warning(f"[âš ï¸ è¯„åˆ†å™¨] æ— æ³•å¯¼å…¥çŸ¥è¯†åº“ç®¡ç†å™¨")
            except Exception as e:
                logger.warning(f"[âš ï¸ è¯„åˆ†å™¨] çŸ¥è¯†åº“åˆå§‹åŒ–å¤±è´¥: {e}")

        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯ï¼ˆä½¿ç”¨Gemini 2.5 Flashè¿›è¡Œè¯„åˆ†ï¼‰
        try:
            self.llm_client = InternalAPIClient(model_type='fast_inference')  # ä½¿ç”¨fast_inferenceæ¨¡å‹
            logger.info(f"âœ… LLMå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: {self.llm_client.model}")
        except Exception as e:
            logger.warning(f"âš ï¸ LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}ï¼Œå°†ä½¿ç”¨è§„åˆ™è¯„åˆ†")
            self.llm_client = None

        # å¯ä¿¡åŸŸååˆ—è¡¨ï¼ˆåŠ åˆ†ï¼‰
        self.trusted_domains = {
            # å›½é™…æ•™è‚²å¹³å°
            'khanacademy.org': 3.0,
            'coursera.org': 2.5,
            'edx.org': 2.5,
            'udemy.com': 2.0,

            # è§†é¢‘å¹³å°
            'youtube.com': 2.0,
            'youtube-nocookie.com': 2.0,
            'vimeo.com': 1.5,

            # å°å°¼æ•™è‚²å¹³å°
            'kemdikbud.go.id': 3.0,
            'ruangguru.com': 2.5,
            'zenius.net': 2.5,
            'quipper.com': 2.0,
            'brainly.co.id': 1.5,

            # ä¿„ç½—æ–¯æ•™è‚²å¹³å°
            'uchi.ru': 2.5,
            'znaika.ru': 2.5,
            'interneturok.ru': 2.5,
            'infourok.ru': 2.0,
            'videouroki.net': 2.0,
            'reshuege.ru': 2.0,

            # ä¸­å›½æ•™è‚²å¹³å°
            'bilibili.com': 2.0,
            'icourse163.org': 2.5,

            # å°åº¦æ•™è‚²å¹³å°
            'byju.com': 2.5,
            'vedantu.com': 2.0,
            'unacademy.com': 2.0,

            # æ•™è‚²æœºæ„
            '.edu': 2.0,
            '.ac.': 1.5,
            '.gov.': 1.5,
        }

        # ä½è´¨é‡åŸŸåï¼ˆå‡åˆ†ï¼‰
        self.low_quality_domains = {
            'bit.ly': -1.0,
            'tinyurl.com': -1.0,
            'short.link': -1.0,
        }

        # æ•™è‚²å…³é”®è¯ï¼ˆåŠ åˆ†ï¼‰
        self.educational_keywords = [
            'lesson', 'tutorial', 'course', 'lecture', 'education',
            'learn', 'study', 'school', 'class', 'teacher',
            'è¯¾ç¨‹', 'æ•™ç¨‹', 'å­¦ä¹ ', 'æ•™å­¦', 'è¯¾ç¨‹',
            'ÑƒÑ€Ğ¾Ğº', 'Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ', 'Ğ»ĞµĞºÑ†Ğ¸Ñ',  # ä¿„è¯­
            'pelajaran', 'pembelajaran', 'belajar',  # å°å°¼è¯­
        ]

        # è§†é¢‘ç›¸å…³å…³é”®è¯
        self.video_keywords = [
            'video', 'youtube', 'watch', 'vimeo',
            'è§†é¢‘', 'å½±ç‰‡',
            'Ğ²Ğ¸Ğ´ĞµĞ¾',  # ä¿„è¯­
            'video',  # å°å°¼è¯­
        ]

        # æ’­æ”¾åˆ—è¡¨å…³é”®è¯ï¼ˆåŠ åˆ†ï¼‰
        self.playlist_keywords = [
            'playlist', 'series', 'complete course',
            'playlist', 'complete', 'full course',
            'æ’­æ”¾åˆ—è¡¨', 'å®Œæ•´', 'å…¨å¥—',
            'Ğ¿Ğ»ĞµĞ¹Ğ»Ğ¸ÑÑ‚', 'Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ ĞºÑƒÑ€Ñ',  # ä¿„è¯­
            'daftar putar', 'lengkap',  # å°å°¼è¯­
        ]

        # è¯­è¨€æ£€æµ‹ç‰¹å¾ï¼ˆUnicodeèŒƒå›´å’Œå…³é”®è¯ï¼‰
        self.language_patterns = {
            'ar': {  # é˜¿æ‹‰ä¼¯è¯­
                'unicode_ranges': [(0x0600, 0x06FF), (0x0750, 0x077F), (0x08A0, 0x08FF)],
                'keywords': ['Ø§Ù„', 'ÙÙŠ', 'Ù…Ù†', 'Ø¹Ù„Ù‰', 'Ø£Ù†', 'Ø§Ù„ØªÙŠ', 'ÙƒÙˆØ±Ø³', 'Ø¯Ø±Ø³', 'ØªØ¹Ù„ÙŠÙ…'],
                'sample_chars': ['Ø§', 'Ø¨', 'Øª', 'Ø«', 'Ø¬']
            },
            'en': {  # è‹±è¯­
                'unicode_ranges': [(0x0000, 0x007F)],
                'keywords': ['the', 'and', 'for', 'are', 'but', 'not', 'you', 'all', 'can',
                             'with', 'this', 'that', 'from', 'they', 'have', 'been', 'grade',
                             'lesson', 'course', 'physics', 'math', 'complete', 'video'],
                'sample_chars': ['a', 'b', 'c', 'd', 'e']
            },
            'id': {  # å°å°¼è¯­
                'unicode_ranges': [(0x0000, 0x007F)],
                'keywords': ['yang', 'dan', 'untuk', 'dari', 'dengan', 'adalah', 'pelajaran', 'belajar'],
                'sample_chars': ['a', 'b', 'c', 'd', 'e']
            },
            'zh': {  # ä¸­æ–‡
                'unicode_ranges': [(0x4E00, 0x9FFF), (0x3400, 0x4DBF)],
                'keywords': ['çš„', 'æ˜¯', 'åœ¨', 'å’Œ', 'æœ‰', 'å­¦ä¹ ', 'è¯¾ç¨‹', 'æ•™å­¦'],
                'sample_chars': ['ä¸­', 'æ–‡', 'è¯¾', 'ç¨‹', 'å­¦']
            },
            'ru': {  # ä¿„è¯­
                'unicode_ranges': [(0x0400, 0x04FF)],
                'keywords': ['Ğ¸', 'Ğ²', 'Ğ½Ğ°', 'Ñ‡Ñ‚Ğ¾', 'Ğ´Ğ»Ñ', 'ÑƒÑ€Ğ¾Ğº', 'Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ', 'Ğ»ĞµĞºÑ†Ğ¸Ñ'],
                'sample_chars': ['Ğ°', 'Ğ±', 'Ğ²', 'Ğ³', 'Ğ´']
            },
            'es': {  # è¥¿ç­ç‰™è¯­
                'unicode_ranges': [(0x0000, 0x007F)],
                'keywords': ['el', 'la', 'de', 'que', 'y', 'lecciÃ³n', 'curso', 'aprender'],
                'sample_chars': ['a', 'b', 'c', 'd', 'e']
            },
            'fr': {  # æ³•è¯­
                'unicode_ranges': [(0x0000, 0x007F)],
                'keywords': ['le', 'de', 'et', 'un', 'il', 'cours', 'leÃ§on', 'apprendre'],
                'sample_chars': ['a', 'b', 'c', 'd', 'e']
            },
            'pt': {  # è‘¡è„ç‰™è¯­
                'unicode_ranges': [(0x0000, 0x007F)],
                'keywords': ['o', 'de', 'a', 'e', 'para', 'liÃ§Ã£o', 'curso', 'aprender'],
                'sample_chars': ['a', 'b', 'c', 'd', 'e']
            },
            'hi': {  # å°åœ°è¯­
                'unicode_ranges': [(0x0900, 0x097F)],
                'keywords': ['à¤•à¥‡', 'à¤®à¥‡à¤‚', 'à¤•à¥€', 'à¤¹à¥ˆ', 'à¤ªà¤¾à¤ ', 'à¤ªà¤¾à¤ à¥à¤¯à¤•à¥à¤°à¤®', 'à¤¸à¥€à¤–à¤¨à¤¾'],
                'sample_chars': ['à¤•', 'à¤–', 'à¤—', 'à¤˜', 'à¤™']
            },
            'th': {  # æ³°è¯­
                'unicode_ranges': [(0x0E00, 0x0E7F)],
                'keywords': ['à¸—à¸µà¹ˆ', 'à¹à¸¥à¸°', 'à¸‚à¸­à¸‡', 'à¸¡à¸µ', 'à¸šà¸—à¹€à¸£à¸µà¸¢à¸™', 'à¸«à¸¥à¸±à¸à¸ªà¸¹à¸•à¸£', 'à¹€à¸£à¸µà¸¢à¸™'],
                'sample_chars': ['à¸', 'à¸‚', 'à¸ƒ', 'à¸„', 'à¸…']
            },
            'vi': {  # è¶Šå—è¯­
                'unicode_ranges': [(0x1EA0, 0x1EF9), (0x0000, 0x007F)],
                'keywords': ['cá»§a', 'vÃ ', 'cho', 'khÃ´ng', 'bÃ i', 'khÃ³a', 'há»c'],
                'sample_chars': ['a', 'Äƒ', 'Ã¢', 'b', 'c']
            },
        }

        # âœ… æ·»åŠ è¯†åˆ«ç¼“å­˜ï¼ˆçº¯LLMæ–¹æ¡ˆï¼‰
        self._grade_extraction_cache = {}  # {title: grade}
        self._subject_extraction_cache = {}  # {title: subject}
        self._cache_max_size = 1000  # æœ€å¤šç¼“å­˜1000æ¡

        logger.info("âœ… æ™ºèƒ½ç»“æœè¯„åˆ†å™¨åˆå§‹åŒ–å®Œæˆ")

    def _cache_get(self, cache_dict: Dict, key: str, default=None):
        """ä»ç¼“å­˜è·å–"""
        return cache_dict.get(key, default)

    def _cache_set(self, cache_dict: Dict, key: str, value):
        """è®¾ç½®ç¼“å­˜ï¼ŒLRUæ·˜æ±°"""
        if len(cache_dict) >= self._cache_max_size:
            # åˆ é™¤æœ€æ—©çš„10%
            num_to_remove = self._cache_max_size // 10
            for i, k in enumerate(list(cache_dict.keys())):
                if i >= num_to_remove:
                    break
                del cache_dict[k]
        cache_dict[key] = value

    def score_result(self, result: Dict[str, Any], query: str, metadata: Optional[Dict] = None) -> float:
        """
        å¯¹å•ä¸ªæœç´¢ç»“æœè¿›è¡Œè¯„åˆ†

        è¯„åˆ†ç»´åº¦ï¼š
        - åŸºç¡€åˆ†: 3.0 (æ‰€æœ‰ç»“æœéƒ½æœ‰)
        - æ ‡é¢˜ç›¸å…³æ€§: 0-3.0åˆ† (æœ€é‡è¦)
        - å†…å®¹å®Œæ•´æ€§: 0-1.5åˆ†
        - æ¥æºå¯ä¿¡åº¦: 0-2.0åˆ†
        - èµ„æºç±»å‹åŒ¹é…: 0-1.0åˆ†
        - æ’­æ”¾åˆ—è¡¨åŠ åˆ†: 0-1.0åˆ†
        - è¯­è¨€åŒ¹é…åº¦: 0-2.5åˆ† (æ ¹æ®ç›®æ ‡å›½å®¶è¯­è¨€)
        - æ’­æ”¾åˆ—è¡¨ä¸°å¯Œåº¦: 0-1.5åˆ† (è§†é¢‘æ•°é‡å’Œæ€»æ—¶é•¿)
        - æ•™è‚²å†…å®¹åŠ åˆ†: 0-0.5åˆ†

        Args:
            result: æœç´¢ç»“æœå­—å…¸
            query: æœç´¢æŸ¥è¯¢
            metadata: é¢å¤–çš„å…ƒæ•°æ®ï¼ˆå›½å®¶ã€å¹´çº§ã€å­¦ç§‘ï¼‰

        Returns:
            è¯„åˆ† (0.0 - 10.0)
        """
        # é™ä½åŸºç¡€åˆ†ï¼Œå¢åŠ åŒºåˆ†åº¦
        score = 3.0  # åŸºç¡€åˆ†ï¼ˆä»5.0é™ä½åˆ°3.0ï¼‰
        url = result.get('url', '').lower()
        title = result.get('title', '').lower()
        snippet = result.get('snippet', '').lower()

        # 1. æ ‡é¢˜ç›¸å…³æ€§è¯„åˆ† (0-3.0åˆ†) - æœ€é‡è¦
        score += self._score_title_relevance(title, query, snippet)

        # 2. å†…å®¹å®Œæ•´æ€§è¯„åˆ† (0-1.5åˆ†)
        score += self._score_content_completeness(snippet) * 1.5

        # 3. æ¥æºå¯ä¿¡åº¦è¯„åˆ† (0-2.0åˆ†) - é¿å…é‡å¤åŠ åˆ†
        score += self._score_source_credibility_v2(url)

        # 4. èµ„æºç±»å‹è¯„åˆ† (0-1.0åˆ†)
        score += self._score_resource_type(url, title, snippet)

        # 5. æ’­æ”¾åˆ—è¡¨åŠ åˆ† (0-1.0åˆ†) - å¢åŠ æ’­æ”¾åˆ—è¡¨æƒé‡
        score += self._score_playlist_bonus_v2(url, title, snippet)

        # 6. è¯­è¨€åŒ¹é…åº¦è¯„åˆ† (0-2.5åˆ†) - æ ¹æ®ç›®æ ‡å›½å®¶è¯­è¨€
        if metadata:
            target_language = metadata.get('language_code')
            if target_language:
                score += self._score_language_matching(title, snippet, target_language)

        # 7. æ’­æ”¾åˆ—è¡¨ä¸°å¯Œåº¦è¯„åˆ† (0-1.5åˆ†) - åŸºäºè§†é¢‘æ•°é‡å’Œæ€»æ—¶é•¿
        playlist_info = result.get('playlist_info')  # {video_count, total_duration_minutes}
        if playlist_info:
            score += self._score_playlist_richness(playlist_info)

        # 8. æ•™è‚²å†…å®¹åŠ åˆ† (0-0.5åˆ†)
        score += self._score_educational_content(title, snippet) * 0.5

        # ç¡®ä¿è¯„åˆ†åœ¨ 0-10 èŒƒå›´å†…
        return max(0.0, min(10.0, score))

    def _score_url_quality(self, url: str) -> float:
        """è¯„åˆ†URLè´¨é‡"""
        if not url:
            return 0.0

        score = 0.0

        # HTTPS åŠ åˆ†
        if url.startswith('https://'):
            score += 0.3

        # æ£€æŸ¥å¯ä¿¡åŸŸå
        for domain, bonus in self.trusted_domains.items():
            if domain in url:
                score += bonus
                break

        # æ£€æŸ¥ä½è´¨é‡åŸŸå
        for domain, penalty in self.low_quality_domains.items():
            if domain in url:
                score += penalty
                break

        # æ£€æŸ¥æ•™è‚²åŸŸå
        if '.edu' in url or '.ac.' in url or '.gov.' in url:
            score += 0.5

        return score

    def _score_title_relevance(self, title: str, query: str, snippet: str = "") -> float:
        """
        è¯„åˆ†æ ‡é¢˜ç›¸å…³æ€§ï¼ˆæœ€é‡è¦çš„è¯„åˆ†ç»´åº¦ï¼‰

        Args:
            title: æ ‡é¢˜
            query: æœç´¢æŸ¥è¯¢
            snippet: æ‘˜è¦ï¼ˆå¯é€‰ï¼‰

        Returns:
            è¯„åˆ† (0.0 - 3.0)
        """
        if not title or not query:
            return 0.0

        score = 0.0
        query_lower = query.lower()
        combined = f"{title} {snippet}".lower()

        # 1. å®Œå…¨åŒ¹é…æŸ¥è¯¢ (0-1.5åˆ†)
        if query_lower in combined:
            score += 1.5

        # 2. å…³é”®è¯åŒ¹é…åº¦ (0-1.0åˆ†)
        query_words = set(query_lower.split())
        combined_words = set(combined.split())
        overlap = len(query_words & combined_words)

        if overlap >= 3:
            score += 1.0
        elif overlap >= 2:
            score += 0.7
        elif overlap >= 1:
            score += 0.4

        # 3. å¹´çº§å’Œå­¦ç§‘åŒ¹é… (0-0.5åˆ†)
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ˜ç¡®çš„å¹´çº§å’Œå­¦ç§‘ä¿¡æ¯
        grade_keywords = ['grade', 'kelas', 'å¹´çº§', 'class', 'primary', 'secondary']
        subject_keywords = ['math', 'science', 'english', 'arabic', 'æ•°å­¦', 'ç§‘å­¦']

        has_grade = any(kw in combined for kw in grade_keywords)
        has_subject = any(kw in combined for kw in subject_keywords)

        if has_grade and has_subject:
            score += 0.5
        elif has_grade or has_subject:
            score += 0.2

        return min(score, 3.0)

    def _score_content_completeness(self, snippet: str) -> float:
        """è¯„åˆ†å†…å®¹å®Œæ•´æ€§"""
        if not snippet:
            return 0.0

        # æ ¹æ®æè¿°é•¿åº¦è¯„åˆ†
        length = len(snippet)

        if length >= 200:
            return 1.0
        elif length >= 150:
            return 0.8
        elif length >= 100:
            return 0.6
        elif length >= 50:
            return 0.3
        else:
            return 0.0

    def _score_source_credibility(self, url: str) -> float:
        """è¯„åˆ†æ¥æºå¯ä¿¡åº¦"""
        if not url:
            return 0.0

        score = 0.0

        try:
            domain = urlparse(url).netloc.lower()

            # çŸ¥åæ•™è‚²å¹³å°
            if 'khanacademy.org' in domain:
                score += 3.0
            elif 'kemdikbud.go.id' in domain or 'moe.gov' in domain:
                score += 3.0
            elif any(edu in domain for edu in ['ruangguru', 'zenius', 'uchi.ru', 'byju']):
                score += 2.5
            elif 'youtube.com' in domain:
                score += 1.5
            elif '.edu' in domain:
                score += 2.0

            # å®˜æ–¹æ”¿åºœç½‘ç«™
            if '.gov.' in domain:
                score += 1.5

        except Exception:
            pass

        return score

    def _score_resource_type(self, url: str, title: str, snippet: str) -> float:
        """è¯„åˆ†èµ„æºç±»å‹"""
        score = 0.0
        combined = f"{url} {title} {snippet}".lower()

        # è§†é¢‘èµ„æºåŠ åˆ†
        for keyword in self.video_keywords:
            if keyword in combined:
                score += 0.5
                break

        return score

    def _score_playlist_bonus(self, url: str, title: str, snippet: str) -> float:
        """æ’­æ”¾åˆ—è¡¨åŠ åˆ†"""
        combined = f"{url} {title} {snippet}".lower()

        for keyword in self.playlist_keywords:
            if keyword in combined:
                return 0.5

        return 0.0

    def _score_educational_content(self, title: str, snippet: str) -> float:
        """æ•™è‚²å†…å®¹åŠ åˆ†"""
        combined = f"{title} {snippet}".lower()

        matches = sum(1 for kw in self.educational_keywords if kw in combined)

        if matches >= 3:
            return 0.5
        elif matches >= 2:
            return 0.3
        elif matches >= 1:
            return 0.1

        return 0.0

    def _score_source_credibility_v2(self, url: str) -> float:
        """
        è¯„åˆ†æ¥æºå¯ä¿¡åº¦ï¼ˆæ”¹è¿›ç‰ˆ - é¿å…é‡å¤åŠ åˆ†ï¼‰

        åªåœ¨ä¸€ä¸ªç»´åº¦è¯„åˆ†ï¼Œé¿å…é‡å¤åŠ åˆ†ï¼š
        - å®˜æ–¹æ•™è‚²å¹³å°: 2.0åˆ†
        - YouTube: 1.0åˆ†ï¼ˆé™ä½åˆ†æ•°ï¼‰
        - æ•™è‚²æœºæ„: 1.5åˆ†
        - æ”¿åºœç½‘ç«™: 1.5åˆ†
        - å…¶ä»–: 0.5åˆ†

        Args:
            url: URL

        Returns:
            è¯„åˆ† (0.0 - 2.0)
        """
        if not url:
            return 0.0

        try:
            domain = urlparse(url).netloc.lower()

            # å®˜æ–¹æ•™è‚²å¹³å°ï¼ˆæœ€é«˜åˆ†ï¼‰
            if any(edu in domain for edu in [
                'khanacademy.org',
                'kemdikbud.go.id',
                'ruangguru.com',
                'zenius.net',
                'uchi.ru',
                'byju.com'
            ]):
                return 2.0

            # æ•™è‚²æœºæ„æˆ–æ”¿åºœç½‘ç«™
            if '.edu' in domain or '.gov.' in domain or 'ac.' in domain:
                return 1.5

            # YouTubeï¼ˆé™ä½åˆ†æ•°ï¼Œé¿å…æ‰€æœ‰YouTubeå†…å®¹éƒ½é«˜åˆ†ï¼‰
            if 'youtube.com' in domain or 'youtu.be' in domain:
                return 1.0

            # å…¶ä»–è§†é¢‘å¹³å°
            if any(v in domain for v in ['vimeo.com', 'bilibili.com', 'dailymotion.com']):
                return 0.8

            # HTTPSç½‘ç«™ï¼ˆåŸºç¡€åŠ åˆ†ï¼‰
            if url.startswith('https://'):
                return 0.5

        except Exception:
            pass

        return 0.0

    def _score_playlist_bonus_v2(self, url: str, title: str, snippet: str) -> float:
        """
        æ’­æ”¾åˆ—è¡¨åŠ åˆ†ï¼ˆæ”¹è¿›ç‰ˆ - å¢åŠ åŒºåˆ†åº¦ï¼‰

        è¯„åˆ†æ ‡å‡†ï¼š
        - æ˜ç¡®çš„æ’­æ”¾åˆ—è¡¨URL: 1.0åˆ†
        - æ ‡é¢˜åŒ…å«"complete"/"full course": 0.8åˆ†
        - æ ‡é¢˜åŒ…å«"playlist"/"series": 0.5åˆ†
        - å…¶ä»–: 0åˆ†

        Args:
            url: URL
            title: æ ‡é¢˜
            snippet: æ‘˜è¦

        Returns:
            è¯„åˆ† (0.0 - 1.0)
        """
        combined = f"{url} {title} {snippet}".lower()

        # 1. æ˜ç¡®çš„æ’­æ”¾åˆ—è¡¨URLï¼ˆæœ€é«˜åˆ†ï¼‰
        if any(indicator in url.lower() for indicator in ['playlist?', 'list=', '/videos']):
            return 1.0

        # 2. æ ‡é¢˜åŒ…å«å®Œæ•´è¯¾ç¨‹å…³é”®è¯
        complete_keywords = ['complete course', 'full course', 'all lessons',
                           'ÙƒØ§Ù…Ù„', 'Ø´Ø§Ù…Ù„', 'Ø¯ÙˆØ±Ø© ÙƒØ§Ù…Ù„Ø©',  # é˜¿æ‹‰ä¼¯è¯­
                           'å®Œæ•´', 'å…¨å¥—', 'å…¨éƒ¨']
        if any(kw in combined for kw in complete_keywords):
            return 0.8

        # 3. æ ‡é¢˜åŒ…å«æ’­æ”¾åˆ—è¡¨å…³é”®è¯
        playlist_keywords = ['playlist', 'series', 'collection',
                          'Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªØ´ØºÙŠÙ„', 'Ø³Ù„Ø³Ù„Ø©',  # é˜¿æ‹‰ä¼¯è¯­
                          'æ’­æ”¾åˆ—è¡¨', 'ç³»åˆ—']
        if any(kw in combined for kw in playlist_keywords):
            return 0.5

        return 0.0

    def _detect_language(self, text: str) -> str:
        """
        æ£€æµ‹æ–‡æœ¬çš„è¯­è¨€

        Args:
            text: è¦æ£€æµ‹çš„æ–‡æœ¬

        Returns:
            è¯­è¨€ä»£ç ï¼ˆå¦‚ 'ar', 'en', 'zh'ï¼‰ï¼Œå¦‚æœæ— æ³•æ£€æµ‹åˆ™è¿”å› 'unknown'
        """
        if not text:
            return 'unknown'

        # ç»Ÿè®¡æ¯ä¸ªè¯­è¨€çš„å¾—åˆ†
        language_scores = {}

        for lang_code, patterns in self.language_patterns.items():
            score = 0.0

            # 1. æ£€æŸ¥Unicodeå­—ç¬¦èŒƒå›´
            for char in text:
                char_code = ord(char)
                for range_start, range_end in patterns['unicode_ranges']:
                    if range_start <= char_code <= range_end:
                        score += 1.0
                        break

            # 2. æ£€æŸ¥å…³é”®è¯åŒ¹é…
            text_lower = text.lower()
            for keyword in patterns['keywords']:
                if keyword in text_lower:
                    score += 0.5

            # æ ‡å‡†åŒ–å¾—åˆ†ï¼ˆé™¤ä»¥æ–‡æœ¬é•¿åº¦ï¼Œé¿å…é•¿æ–‡æœ¬å ä¼˜ï¼‰
            if len(text) > 0:
                score = score / len(text) * 100

            language_scores[lang_code] = score

        # è¿”å›å¾—åˆ†æœ€é«˜çš„è¯­è¨€
        if not language_scores:
            return 'unknown'

        best_language = max(language_scores, key=language_scores.get)

        # å¦‚æœæœ€é«˜åˆ†å¤ªä½ï¼Œè¿”å›unknown
        if language_scores[best_language] < 0.5:
            return 'unknown'

        return best_language

    def _score_language_matching(self, title: str, snippet: str, target_language: str) -> float:
        """
        è¯„åˆ†è¯­è¨€åŒ¹é…åº¦

        è¯„åˆ†æ ‡å‡†ï¼š
        - å®Œå…¨åŒ¹é…ï¼ˆæ ‡é¢˜å’Œæ‘˜è¦éƒ½æ˜¯ç›®æ ‡è¯­è¨€ï¼‰: 2.5åˆ†
        - éƒ¨åˆ†åŒ¹é…ï¼ˆæ ‡é¢˜æ˜¯ç›®æ ‡è¯­è¨€ï¼‰: 2.0åˆ†
        - éƒ¨åˆ†åŒ¹é…ï¼ˆæ‘˜è¦åŒ…å«ç›®æ ‡è¯­è¨€ï¼‰: 1.5åˆ†
        - è‹±è¯­ä½œä¸ºé€šç”¨è¯­è¨€çš„é™çº§åŒ¹é…: 0.5åˆ†
        - ä¸åŒ¹é…: 0åˆ†

        Args:
            title: æ ‡é¢˜
            snippet: æ‘˜è¦
            target_language: ç›®æ ‡è¯­è¨€ä»£ç ï¼ˆå¦‚ 'ar', 'en', 'id'ï¼‰

        Returns:
            è¯„åˆ† (0.0 - 2.5)
        """
        if not target_language or target_language not in self.language_patterns:
            # å¦‚æœæ²¡æœ‰ç›®æ ‡è¯­è¨€æˆ–ä¸æ”¯æŒï¼Œä¸åŠ åˆ†ä¹Ÿä¸å‡åˆ†
            return 0.0

        # æ£€æµ‹æ ‡é¢˜å’Œæ‘˜è¦çš„è¯­è¨€
        title_language = self._detect_language(title)
        snippet_language = self._detect_language(snippet)

        # å®Œå…¨åŒ¹é…ï¼šæ ‡é¢˜å’Œæ‘˜è¦éƒ½æ˜¯ç›®æ ‡è¯­è¨€
        if title_language == target_language and snippet_language == target_language:
            return 2.5

        # æ ‡é¢˜åŒ¹é…ï¼šæ ‡é¢˜æ˜¯ç›®æ ‡è¯­è¨€
        if title_language == target_language:
            return 2.0

        # æ‘˜è¦åŒ¹é…ï¼šæ‘˜è¦åŒ…å«ç›®æ ‡è¯­è¨€
        if snippet_language == target_language:
            return 1.5

        # é™çº§åŒ¹é…ï¼šå¦‚æœç›®æ ‡è¯­è¨€ä¸æ˜¯è‹±è¯­ï¼Œä½†å†…å®¹æ˜¯è‹±è¯­ï¼Œç»™éƒ¨åˆ†åˆ†æ•°
        if target_language != 'en' and (title_language == 'en' or snippet_language == 'en'):
            return 0.5

        # ä¸åŒ¹é…
        return 0.0

    def _score_playlist_richness(self, playlist_info: Dict[str, Any]) -> float:
        """
        è¯„åˆ†æ’­æ”¾åˆ—è¡¨ä¸°å¯Œåº¦ï¼ˆåŸºäºè§†é¢‘æ•°é‡å’Œæ€»æ—¶é•¿ï¼‰

        è¯„åˆ†æ ‡å‡†ï¼š
        - è§†é¢‘æ•°é‡ >= 20: 0.75åˆ†
        - è§†é¢‘æ•°é‡ >= 10: 0.6åˆ†
        - è§†é¢‘æ•°é‡ >= 5: 0.4åˆ†
        - è§†é¢‘æ•°é‡ < 5: 0.2åˆ†
        - æ€»æ—¶é•¿ >= 300åˆ†é’Ÿ (5å°æ—¶): 0.75åˆ†
        - æ€»æ—¶é•¿ >= 120åˆ†é’Ÿ (2å°æ—¶): 0.5åˆ†
        - æ€»æ—¶é•¿ >= 60åˆ†é’Ÿ (1å°æ—¶): 0.3åˆ†
        - æ€»æ—¶é•¿ < 60åˆ†é’Ÿ: 0.1åˆ†

        Args:
            playlist_info: æ’­æ”¾åˆ—è¡¨ä¿¡æ¯ {video_count, total_duration_minutes}

        Returns:
            è¯„åˆ† (0.0 - 1.5)
        """
        video_count = playlist_info.get('video_count', 0)
        total_duration = playlist_info.get('total_duration_minutes', 0)

        score = 0.0

        # 1. è§†é¢‘æ•°é‡è¯„åˆ† (0-0.75åˆ†)
        if video_count >= 20:
            score += 0.75
        elif video_count >= 10:
            score += 0.6
        elif video_count >= 5:
            score += 0.4
        elif video_count > 0:
            score += 0.2

        # 2. æ€»æ—¶é•¿è¯„åˆ† (0-0.75åˆ†)
        if total_duration >= 300:  # 5å°æ—¶ä»¥ä¸Š
            score += 0.75
        elif total_duration >= 120:  # 2å°æ—¶ä»¥ä¸Š
            score += 0.5
        elif total_duration >= 60:  # 1å°æ—¶ä»¥ä¸Š
            score += 0.3
        elif total_duration > 0:
            score += 0.1

        return min(score, 1.5)

    def _evaluate_with_llm(self, result: Dict[str, Any], query: str, metadata: Optional[Dict] = None) -> Dict[str, Any]:
        """
        ä½¿ç”¨LLMï¼ˆGemini 2.5 Proï¼‰è¯„ä¼°ç»“æœå¹¶ç”Ÿæˆè´¨é‡åˆ†æ•°å’Œæ¨èç†ç”±

        æ”¹è¿›ï¼š
        1. é›†æˆé˜¿æ‹‰ä¼¯è¯­æ ‡å‡†åŒ–ï¼ˆè§„åˆ™éªŒè¯ï¼‰
        2. åŒä¿é™©æœºåˆ¶ï¼šè§„åˆ™éªŒè¯ + LLMè¯„åˆ†
        3. ä¼˜åŒ–è¯„åˆ†Promptï¼Œå¼ºè°ƒå¹´çº§åŒ¹é…

        Args:
            result: æœç´¢ç»“æœå­—å…¸
            query: æœç´¢æŸ¥è¯¢
            metadata: é¢å¤–çš„å…ƒæ•°æ®ï¼ˆå›½å®¶ã€å¹´çº§ã€å­¦ç§‘ï¼‰

        Returns:
            åŒ…å«scoreå’Œrecommendation_reasonçš„å­—å…¸
        """
        if not self.llm_client:
            return None

        try:
            # ğŸ” è°ƒè¯•ï¼šç¡®è®¤å‡½æ•°è¢«è°ƒç”¨
            title_debug = result.get('title', 'Unknown')[:50]
            logger.info(f"[ğŸ” _evaluate_with_llm] å¼€å§‹è¯„ä¼°: {title_debug}...")

            # âœ… æ–°å¢ï¼šæ­¥éª¤0.5 - MCPå·¥å…·éªŒè¯ï¼ˆæ”¯æŒå°å°¼è¯­ç­‰å¤šè¯­è¨€ï¼‰
            logger.info(f"[ğŸ” _evaluate_with_llm] å‡†å¤‡è°ƒç”¨MCPå·¥å…·åŒæ­¥åŒ…è£…...")
            mcp_based_validation = self._validate_with_mcp_tools_sync(result, metadata)
            logger.info(f"[ğŸ” _evaluate_with_llm] MCPå·¥å…·åŒæ­¥åŒ…è£…è¿”å›: {mcp_based_validation is not None}")

            if mcp_based_validation and mcp_based_validation.get('confidence') == 'high':
                # MCPå·¥å…·æœ‰é«˜ç½®ä¿¡åº¦çš„ç»“æœï¼Œç›´æ¥ä½¿ç”¨
                logger.info(f"[âœ… MCPå·¥å…·éªŒè¯] ä½¿ç”¨MCPå·¥å…·è¯„åˆ†: {mcp_based_validation['score']}")
                logger.info(f"   ç†ç”±: {mcp_based_validation['reason']}")

                return {
                    'score': mcp_based_validation['score'],
                    'recommendation_reason': mcp_based_validation['reason'],
                    'evaluation_method': 'MCP Tools',
                    'mcp_validation': mcp_based_validation
                }

            # âœ… æ–°å¢ï¼šæ­¥éª¤1 - è§„åˆ™éªŒè¯ï¼ˆé˜¿æ‹‰ä¼¯è¯­æ ‡å‡†åŒ–ï¼‰
            rule_based_validation = self._validate_with_rules(result, metadata)
            if rule_based_validation and rule_based_validation.get('confidence') == 'high':
                # è§„åˆ™éªŒè¯æœ‰é«˜ç½®ä¿¡åº¦çš„ç»“æœï¼Œç›´æ¥ä½¿ç”¨
                logger.info(f"[âœ… è§„åˆ™éªŒè¯] ä½¿ç”¨è§„åˆ™è¯„åˆ†: {rule_based_validation['score']}")
                logger.info(f"   ç†ç”±: {rule_based_validation['reason']}")

                return {
                    'score': rule_based_validation['score'],
                    'recommendation_reason': rule_based_validation['reason'],
                    'evaluation_method': 'Rule-based (Arabic)',
                    'rule_validation': rule_based_validation
                }

            # æ„å»ºè¯„ä¼°æç¤ºè¯
            title = result.get('title', '')
            url = result.get('url', '')
            snippet = result.get('snippet', '')
            playlist_info = result.get('playlist_info', {})

            # è·å–å…ƒæ•°æ®ä¿¡æ¯ï¼ˆå…¼å®¹ä¸¤ç§å­—æ®µåæ ¼å¼ï¼‰
            country = metadata.get('country_name', metadata.get('country', '')) if metadata else ''
            grade = metadata.get('grade', metadata.get('grade_name', '')) if metadata else ''
            subject = metadata.get('subject', metadata.get('subject_name', '')) if metadata else ''

            # æ’­æ”¾åˆ—è¡¨ä¿¡æ¯
            playlist_extra = ""
            if playlist_info:
                video_count = playlist_info.get('video_count', 0)
                total_duration = playlist_info.get('total_duration_minutes', 0)
                playlist_extra = f"\n- æ’­æ”¾åˆ—è¡¨è§†é¢‘æ•°é‡: {video_count} ä¸ª\n- æ’­æ”¾åˆ—è¡¨æ€»æ—¶é•¿: {total_duration} åˆ†é’Ÿ"

            # âœ… MCPå·¥å…·å¢å¼ºä¿¡æ¯
            enrichment_info = []

            # è§†é¢‘ç¼©ç•¥å›¾åˆ†æ
            if result.get('video_analysis'):
                video_analysis = result['video_analysis']
                if video_analysis.get('thumbnail_url'):
                    enrichment_info.append(f"- è§†é¢‘ç¼©ç•¥å›¾URL: {video_analysis['thumbnail_url']}")

            # ç½‘é¡µå†…å®¹
            if result.get('web_content'):
                web_content = result['web_content']
                if web_content.get('summary'):
                    content_summary = web_content['summary'][:300]
                    enrichment_info.append(f"- ç½‘é¡µå†…å®¹æ‘˜è¦: {content_summary}")

            enrichment_text = "\n".join(enrichment_info) if enrichment_info else ""
            if enrichment_text:
                enrichment_text = f"\nã€MCPå·¥å…·å¢å¼ºä¿¡æ¯ã€‘\n{enrichment_text}"

            system_prompt = """ä½ æ˜¯ä¸€ä¸ªç²¾å‡†çš„æ•™è‚²èµ„æºè¯„åˆ†ä¸“å®¶ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è§„åˆ™è¯„åˆ†ï¼š

ã€ğŸš¨ è¯„åˆ†ç»´åº¦ã€‘ï¼ˆæ€»åˆ†10åˆ†ï¼‰
1. â­ å¹´çº§åŒ¹é…åº¦ï¼ˆ0-3åˆ†ï¼‰ã€æœ€å…³é”®ã€‘ï¼š
   - å®Œå…¨åŒ¹é…ï¼ˆå¦‚ï¼šç›®æ ‡ä¸€å¹´çº§ï¼Œæ ‡é¢˜ä¸€å¹´çº§ï¼‰ï¼š3åˆ†
   - ç›¸è¿‘å¹´çº§ï¼ˆÂ±1å¹´çº§ï¼‰ï¼š1-2åˆ†
   - å¹´çº§ä¸ç¬¦ï¼ˆå¦‚ï¼šç›®æ ‡ä¸€å¹´çº§ï¼Œæ ‡é¢˜å…«å¹´çº§ï¼‰ï¼š0åˆ†

2. â­ å­¦ç§‘åŒ¹é…åº¦ï¼ˆ0-3åˆ†ï¼‰ã€å…³é”®ã€‘ï¼š
   - å®Œå…¨åŒ¹é…ï¼ˆå¦‚ï¼šç›®æ ‡æ•°å­¦ï¼Œæ ‡é¢˜æ•°å­¦ï¼‰ï¼š3åˆ†
   - ç›¸å…³å­¦ç§‘ï¼š1-2åˆ†
   - å­¦ç§‘ä¸ç¬¦ï¼ˆå¦‚ï¼šç›®æ ‡è‰ºæœ¯ï¼Œæ ‡é¢˜æ•°å­¦ï¼‰ï¼š0åˆ†

3. èµ„æºè´¨é‡ï¼ˆ0-2åˆ†ï¼‰ï¼š
   - å®˜æ–¹/æƒå¨æœºæ„ï¼ˆ.gov, .edu, æ•™è‚²éƒ¨ï¼‰ï¼š2åˆ†
   - YouTube/çŸ¥åå¹³å°ï¼š1.5åˆ†
   - ä¸ªäºº/éå®˜æ–¹ï¼š1åˆ†

4. å†…å®¹å®Œæ•´æ€§ï¼ˆ0-2åˆ†ï¼‰ï¼š
   - å®Œæ•´è¯¾ç¨‹/æ’­æ”¾åˆ—è¡¨ï¼ˆâ‰¥10è§†é¢‘ï¼‰ï¼š2åˆ†
   - éƒ¨åˆ†å†…å®¹ï¼š1åˆ†
   - ç¢ç‰‡å†…å®¹ï¼š0åˆ†

ã€ğŸ”´ è¯„åˆ†è§„åˆ™ - å¿…é¡»éµå®ˆã€‘

âœ… æ­£ç¡®è¯„åˆ†ï¼š
- å¹´çº§æ­£ç¡® + å­¦ç§‘æ­£ç¡® â†’ 8-10åˆ†ï¼ˆé«˜åˆ†ï¼‰
- å¹´çº§æ­£ç¡® + å­¦ç§‘ç›¸å…³ â†’ 7-8åˆ†
- å¹´çº§ä¸æ˜ç¡® + å­¦ç§‘æ­£ç¡® â†’ 5-7åˆ†
- å¹´çº§ä¸æ˜ç¡® + å­¦ç§‘ç›¸å…³ â†’ 3-5åˆ†

âŒ é”™è¯¯è¯„åˆ†ï¼ˆå¿…é¡»å¤§å¹…å‡åˆ†ï¼‰ï¼š
- å¹´çº§ä¸ç¬¦ â†’ å¿…é¡»ç»™ â‰¤5åˆ†ï¼ˆä¸ç®¡å…¶ä»–å› ç´ ï¼‰
- å­¦ç§‘ä¸ç¬¦ â†’ å¿…é¡»ç»™ â‰¤5åˆ†ï¼ˆä¸ç®¡å…¶ä»–å› ç´ ï¼‰
- å¹´çº§å’Œå­¦ç§‘éƒ½ä¸ç¬¦ â†’ å¿…é¡»ç»™ â‰¤3åˆ†

ã€ğŸš¨ å…³é”®ï¼šè¯†åˆ«æ˜æ˜¾æ— å…³çš„å†…å®¹ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰ã€‘

ä»¥ä¸‹ç±»å‹çš„èµ„æº**å¿…é¡»ç›´æ¥ç»™ 0-2åˆ†**ï¼Œå³ä½¿æ ‡é¢˜ä¸­æ²¡æœ‰æ˜ç¡®çš„å¹´çº§/å­¦ç§‘ä¿¡æ¯ï¼š

1. **éæ•™è‚²ç±»ç½‘ç«™**ï¼ˆå¿…é¡»è¯†åˆ«å¹¶ç»™0åˆ†ï¼‰ï¼š
   - âŒ æ±½è½¦ç½‘ç«™ï¼šRivian, Tesla, Ford, BMW, Mercedes, Toyota, Honda, car, automotive
   - âŒ éŸ³ä¹/ä¹å™¨ï¼šdrums, guitar, piano, violin, instrument, music library, audio, band
   - âŒ æ¸¸æˆç›¸å…³ï¼šgame, gaming, gameplay, streamer, twitch, steam, esport
   - âŒ ç”µå•†è´­ç‰©ï¼šshop, store, buy, purchase, price, sale, discount, amazon, ebay
   - âŒ æ–°é—»åª’ä½“ï¼šnews, breaking news, latest updates, rumors, gossipï¼ˆé™¤éæ˜ç¡®æ˜¯æ•™è‚²æ–°é—»ï¼‰

2. **è¯†åˆ«æ ‡å‡†**ï¼ˆå¿…é¡»ä¸¥æ ¼æ‰§è¡Œï¼‰ï¼š
   - å¦‚æœ**åŸŸå**æˆ–**æ ‡é¢˜**åŒ…å«ä¸Šè¿°å…³é”®è¯ â†’ ç›´æ¥ç»™ **0-2åˆ†**
   - ä¸è¦è®¤ä¸º"å¯èƒ½æ˜¯æ•™å­¦èµ„æº"è€Œç»™é«˜åˆ†
   - å®å¯é”™æ€ï¼ˆç»™ä½åˆ†ï¼‰ï¼Œä¸å¯æ”¾è¿‡ï¼ˆç»™é«˜åˆ†ï¼‰
   - å³ä½¿æ˜¯YouTubeè§†é¢‘ï¼Œå¦‚æœå†…å®¹æ˜æ˜¾æ— å…³ï¼Œä¹Ÿå¿…é¡»ç»™ä½åˆ†

3. **è¯„åˆ†ç¤ºä¾‹**ï¼ˆå¿…é¡»å‚è€ƒï¼‰ï¼š
   - æ ‡é¢˜ï¼š"Rivian News, Latest Software Updates" â†’ {"score":0.0,"reason":"æ˜æ˜¾æ— å…³ï¼šæ±½è½¦æ–°é—»ç½‘ç«™ï¼Œéæ•™è‚²å†…å®¹"}
   - æ ‡é¢˜ï¼š"Fotis Benardo Drums | The Ultra Realistic Metal Drum Library" â†’ {"score":0.0,"reason":"æ˜æ˜¾æ— å…³ï¼šéŸ³ä¹åº“ç½‘ç«™ï¼Œéæ•™è‚²å†…å®¹"}
   - æ ‡é¢˜ï¼š"wtfastpwner - Twitch" â†’ {"score":0.0,"reason":"æ˜æ˜¾æ— å…³ï¼šæ¸¸æˆç›´æ’­ï¼Œéæ•™è‚²å†…å®¹"}
   - æ ‡é¢˜ï¼š"AVATAR:Realms Collide Official Webshop" â†’ {"score":0.0,"reason":"æ˜æ˜¾æ— å…³ï¼šæ¸¸æˆå•†åº—ï¼Œéæ•™è‚²å†…å®¹"}
   - æ ‡é¢˜ï¼š"Kelas 1 SD Kurikulum Merdeka - Matematika" â†’ {"score":9.5,"reason":"å¹´çº§å’Œå­¦ç§‘å®Œå…¨åŒ¹é…ï¼ˆä¸€å¹´çº§ æ•°å­¦ï¼‰ï¼Œæ¥è‡ªå¯ä¿¡å¹³å°"}

ã€âš ï¸ ç‰¹åˆ«æ³¨æ„ï¼šé˜¿æ‹‰ä¼¯è¯­å¹´çº§è¯†åˆ«ã€‘

é˜¿æ‹‰ä¼¯è¯­å¹´çº§è¡¨è¾¾ï¼ˆå¿…é¡»æ­£ç¡®è¯†åˆ«ï¼‰ï¼š
- "Ø§Ù„ØµÙ Ø§Ù„Ø£ÙˆÙ„" = "Ø§Ù„ØµÙ Ø§Ù„Ø§ÙˆÙ„" = "ØµÙ Ø§ÙˆÙ„" = ä¸€å¹´çº§ âœ…
- "Ø§Ù„ØµÙ Ø§Ù„Ø«Ø§Ù†ÙŠ" = "ØµÙ Ø«Ø§Ù†ÙŠ" = äºŒå¹´çº§
- "Ø§Ù„ØµÙ Ø§Ù„Ø«Ø§Ù„Ø«" = "ØµÙ Ø«Ø§Ù„Ø«" = ä¸‰å¹´çº§
- "Ø§Ù„ØµÙ Ø§Ù„Ø³Ø§Ø¯Ø³" = "ØµÙ Ø³Ø§Ø¯Ø³" = å…­å¹´çº§ âŒï¼ˆå¦‚æœç›®æ ‡æ˜¯ä¸€å¹´çº§ï¼‰

ğŸš¨ å¸¸è§é”™è¯¯ï¼ˆå¿…é¡»é¿å…ï¼‰ï¼š
- âŒ å…­å¹´çº§ï¼ˆØ§Ù„ØµÙ Ø§Ù„Ø³Ø§Ø¯Ø³ï¼‰è¢«è¯†åˆ«ä¸ºä¸€å¹´çº§ â†’ é”™è¯¯ï¼åº”è¯¥ç»™â‰¤3åˆ†
- âŒ ä¸€å¹´çº§ï¼ˆØ§Ù„ØµÙ Ø§Ù„Ø£ÙˆÙ„ï¼‰è¢«è¯†åˆ«ä¸ºä¸ç¬¦ â†’ é”™è¯¯ï¼åº”è¯¥ç»™â‰¥8åˆ†

ã€ğŸ¯ è¯„åˆ†æµç¨‹ã€‘
ç¬¬1æ­¥ï¼šä»”ç»†æ£€æŸ¥æ ‡é¢˜ï¼Œè¯†åˆ«å¹´çº§å’Œå­¦ç§‘
ç¬¬2æ­¥ï¼šåˆ¤æ–­å¹´çº§æ˜¯å¦åŒ¹é…ï¼ˆæœ€å…³é”®ï¼‰
ç¬¬3æ­¥ï¼šåˆ¤æ–­å­¦ç§‘æ˜¯å¦åŒ¹é…
ç¬¬4æ­¥ï¼šæ ¹æ®è§„åˆ™è¯„åˆ†ï¼ˆå¹´çº§ä¸ç¬¦å¿…é¡»ä½åˆ†ï¼‰
ç¬¬5æ­¥ï¼šç”Ÿæˆæ¨èç†ç”±ï¼ˆå¿…é¡»è¯´æ˜åŒ¹é…/ä¸åŒ¹é…åŸå› ï¼‰

ã€ğŸ“ è¾“å‡ºæ ¼å¼ã€‘
è¿”å›JSONï¼š{"score":8.5,"reason":"å…·ä½“ç†ç”±"}
- scoreï¼š0-10çš„æµ®ç‚¹æ•°ï¼Œä¿ç•™ä¸€ä½å°æ•°
- reasonï¼šä¸­æ–‡ï¼Œ30-80å­—ï¼Œå¿…é¡»åŒ…å«ï¼š
  âœ… å¹´çº§åŒ¹é…æƒ…å†µï¼ˆå¦‚ï¼š"å¹´çº§æ­£ç¡®ï¼ˆä¸€å¹´çº§ï¼‰"ï¼‰
  âœ… å­¦ç§‘åŒ¹é…æƒ…å†µï¼ˆå¦‚ï¼š"å­¦ç§‘æ­£ç¡®ï¼ˆæ•°å­¦ï¼‰"ï¼‰
  âŒ å¦‚æœä¸åŒ¹é…ï¼Œæ˜ç¡®æŒ‡å‡ºï¼ˆå¦‚ï¼š"å¹´çº§ä¸ç¬¦ï¼ˆæ ‡é¢˜å…­å¹´çº§ï¼Œç›®æ ‡ä¸€å¹´çº§ï¼‰"ï¼‰
"""

            # ğŸ“š æ„å»ºçŸ¥è¯†åº“å¢å¼ºä¿¡æ¯
            knowledge_section = ""
            if self.kb_manager and self.kb_manager.knowledge:
                knowledge = self.kb_manager.knowledge

                # æ·»åŠ å¹´çº§è¡¨è¾¾
                target_grade_key = f"Grade {grade.split()[-1]}" if grade and grade.startswith("Grade") else f"Grade {grade}" if grade else ""
                if 'grade_expressions' in knowledge and knowledge['grade_expressions']:
                    knowledge_section = "\nã€ğŸ“š çŸ¥è¯†åº“ - å¹´çº§è¡¨è¾¾å‚è€ƒã€‘\n"

                    # ä¼˜å…ˆæ˜¾ç¤ºç›®æ ‡å¹´çº§çš„è¡¨è¾¾
                    if target_grade_key and target_grade_key in knowledge['grade_expressions']:
                        grade_info = knowledge['grade_expressions'][target_grade_key]
                        variants = grade_info.get('local_variants', [])
                        if variants:
                            variant_list = []
                            for v in variants:
                                if 'arabic' in v:
                                    variant_list.append(f"{v['arabic']}")
                                elif 'english' in v:
                                    note = f" ({v.get('note', '')})" if v.get('note') else ''
                                    variant_list.append(f"{v['english']}{note}")
                            knowledge_section += f"âœ… {target_grade_key} çš„æ­£ç¡®è¡¨è¾¾: {', '.join(variant_list)}\n"

                        # æ·»åŠ å¸¸è§é”™è¯¯
                        mistakes = grade_info.get('common_mistakes', [])
                        if mistakes:
                            knowledge_section += "\nâš ï¸ å¸¸è§é”™è¯¯ï¼ˆå¿…é¡»é¿å…ï¼‰:\n"
                            for m in mistakes:
                                knowledge_section += f"  âŒ {m['mistake']}\n"
                                knowledge_section += f"  âœ… {m['correction']}\n"

                    # æ˜¾ç¤ºå…¶ä»–å¹´çº§ï¼ˆæœ€å¤š3ä¸ªï¼‰
                    other_grades = [g for g in knowledge['grade_expressions'].keys() if g != target_grade_key]
                    for other_grade in other_grades[:3]:
                        grade_info = knowledge['grade_expressions'][other_grade]
                        variants = grade_info.get('local_variants', [])
                        if variants:
                            variant_list = []
                            for v in variants[:2]:  # åªæ˜¾ç¤ºå‰2ä¸ª
                                if 'arabic' in v:
                                    variant_list.append(v['arabic'])
                                elif 'english' in v:
                                    variant_list.append(v['english'])
                            if variant_list:
                                knowledge_section += f"â€¢ {other_grade}: {', '.join(variant_list)}\n"

                # æ·»åŠ å…³é”®é˜¿æ‹‰ä¼¯è¯­æœ¯è¯­ï¼ˆCRITICALï¼‰
                if 'critical_arabic_terms' in knowledge and knowledge['critical_arabic_terms']:
                    knowledge_section += "\nã€ğŸ”‘ å…³é”®é˜¿æ‹‰ä¼¯è¯­æœ¯è¯­ï¼ˆå¿…é¡»æ­£ç¡®è¯†åˆ«ï¼‰ã€‘\n"

                    # æ•™è‚²çº§åˆ«
                    if 'education_levels' in knowledge['critical_arabic_terms']:
                        knowledge_section += "\nğŸ“– æ•™è‚²çº§åˆ«åç¼€:\n"
                        for level in knowledge['critical_arabic_terms']['education_levels']:
                            knowledge_section += f"  â€¢ \"{level['arabic']}\" = {level['english']} ({level['grade_range']})\n"
                            knowledge_section += f"    {level['note']}\n"

                    # æ•°å­—
                    if 'numbers' in knowledge['critical_arabic_terms']:
                        knowledge_section += "\nğŸ”¢ å…³é”®æ•°å­—:\n"
                        for num in knowledge['critical_arabic_terms']['numbers'][:3]:  # æœ€å¤š3ä¸ª
                            knowledge_section += f"  â€¢ \"{num['arabic']}\" = {num['english']} ({num['number']}) - {num['note']}\n"

                    # å¹´çº§å…³é”®è¯ç¤ºä¾‹
                    if 'grade_keywords' in knowledge['critical_arabic_terms']:
                        for kw in knowledge['critical_arabic_terms']['grade_keywords']:
                            if 'examples' in kw:
                                knowledge_section += f"\nâš ï¸ \"{kw['pattern']}\" å¿…é¡»æ£€æŸ¥ä¿®é¥°è¯:\n"
                                for ex in kw['examples']:
                                    status = "âœ… æ­£ç¡®" if ex.get('correct') else "âŒ é”™è¯¯"
                                    knowledge_section += f"  â€¢ {status}: \"{ex['text']}\" = {ex['grade']}\n"

                # æ·»åŠ å­¦ç§‘å…³é”®è¯
                if 'subject_keywords' in knowledge and knowledge['subject_keywords']:
                    knowledge_section += "\nã€ğŸ“š çŸ¥è¯†åº“ - å­¦ç§‘å…³é”®è¯å‚è€ƒã€‘\n"
                    for subject_key, subject_info in knowledge['subject_keywords'].items():
                        variants = subject_info.get('local_variants', [])
                        if variants:
                            variant_list = []
                            for v in variants:
                                if 'arabic' in v:
                                    variant_list.append(v['arabic'])
                                elif 'english' in v:
                                    variant_list.append(v['english'])
                            knowledge_section += f"â€¢ {subject_key}: {', '.join(variant_list)}\n"

                # æ·»åŠ LLMå·²çŸ¥é—®é¢˜
                if 'llm_insights' in knowledge and knowledge['llm_insights']:
                    insights = knowledge['llm_insights']
                    if 'accuracy_issues' in insights and insights['accuracy_issues']:
                        # åªæ˜¾ç¤ºæœªä¿®å¤çš„é—®é¢˜
                        pending_issues = [i for i in insights['accuracy_issues']
                                        if i.get('status') != 'fixed'][:3]  # æœ€å¤š3ä¸ª
                        if pending_issues:
                            knowledge_section += "\nã€âš ï¸ å·²çŸ¥LLMè¯†åˆ«é—®é¢˜ï¼ˆå¿…é¡»æ³¨æ„ï¼‰ã€‘\n"
                            for issue in pending_issues:
                                knowledge_section += f"â€¢ é—®é¢˜: {issue.get('issue', '')}\n"
                                knowledge_section += f"  ä¿®å¤: {issue.get('fix', '')}\n"

            # âœ… å®‰å…¨ä¿®å¤ï¼šå‡€åŒ–æ‰€æœ‰ç”¨æˆ·è¾“å…¥ï¼Œé˜²æ­¢æç¤ºæ³¨å…¥
            # Issue #036: LLM Prompt Injection Vulnerability - FIXED
            safe_grade = sanitize_llm_input(grade or '', max_length=50)
            safe_subject = sanitize_llm_input(subject or '', max_length=50)
            safe_query = sanitize_llm_input(query or '', max_length=200)
            safe_title = sanitize_llm_input(result.get('title', ''), max_length=200)
            safe_snippet = sanitize_llm_input(result.get('snippet', ''), max_length=500)

            user_prompt = f"""è¯·è¯„ä¼°ä»¥ä¸‹æ•™è‚²èµ„æºï¼š

ã€ç›®æ ‡ä¿¡æ¯ã€‘
- ç›®æ ‡å¹´çº§ï¼š{safe_grade}
- ç›®æ ‡å­¦ç§‘ï¼š{safe_subject}
- æœç´¢æŸ¥è¯¢ï¼š{safe_query}
{knowledge_section}

ã€èµ„æºä¿¡æ¯ã€‘
- æ ‡é¢˜ï¼š{safe_title}
- æè¿°ï¼š{safe_snippet}
{playlist_extra}
{enrichment_text}

ã€è¯„ä¼°æ­¥éª¤ã€‘
ç¬¬1æ­¥ï¼šä»æ ‡é¢˜ä¸­è¯†åˆ«å¹´çº§ï¼ˆæ”¯æŒå¤šè¯­è¨€ï¼‰
  - ä¸­æ–‡ï¼šä¸€å¹´çº§ã€äºŒå¹´çº§ã€...ã€åäºŒå¹´çº§
  - âš ï¸ ä¸­æ–‡åˆä¸­/é«˜ä¸­è¡¨è¾¾ï¼ˆå…³é”®ï¼ï¼‰ï¼š
    â€¢ åˆä¸€ = ä¸ƒå¹´çº§ (Grade 7)
    â€¢ åˆäºŒ = å…«å¹´çº§ (Grade 8)
    â€¢ åˆä¸‰ = ä¹å¹´çº§ (Grade 9)
    â€¢ é«˜ä¸€ = åå¹´çº§ (Grade 10)
    â€¢ é«˜äºŒ = åä¸€å¹´çº§ (Grade 11)
    â€¢ é«˜ä¸‰ = åäºŒå¹´çº§ (Grade 12)
  - é˜¿æ‹‰ä¼¯è¯­ï¼šØ§Ù„ØµÙ Ø§Ù„Ø£ÙˆÙ„ (ä¸€å¹´çº§), Ø§Ù„ØµÙ Ø§Ù„Ø«Ø§Ù…Ù† (å…«å¹´çº§), ...
  - å°å°¼è¯­ï¼šKelas 1, Kelas 2, ...
  - è‹±æ–‡ï¼šGrade 1, Grade 2, ...

ç¬¬2æ­¥ï¼šä»æ ‡é¢˜ä¸­è¯†åˆ«å­¦ç§‘
  - ä¸­æ–‡ï¼šæ•°å­¦ã€è¯­æ–‡ã€è‹±è¯­ã€è‰ºæœ¯ã€ä½“è‚²ã€...
  - é˜¿æ‹‰ä¼¯è¯­ï¼šØ§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª (æ•°å­¦), Ø§Ù„ØªØ±Ø¨ÙŠØ© Ø§Ù„ÙÙ†ÙŠØ© (è‰ºæœ¯), ...
  - å°å°¼è¯­ï¼šMatematika, Bahasa Indonesia, Seni, ...

ç¬¬3æ­¥ï¼šå¯¹æ¯”åŒ¹é…åº¦å¹¶è¯„åˆ†
  - å¹´çº§åŒ¹é…åº¦ï¼š0-3åˆ†
  - å­¦ç§‘åŒ¹é…åº¦ï¼š0-3åˆ†
  - èµ„æºè´¨é‡ï¼š0-2åˆ†
  - å†…å®¹å®Œæ•´æ€§ï¼š0-2åˆ†

ç¬¬4æ­¥ï¼šç”Ÿæˆæ¨èç†ç”±
  - å¿…é¡»è¯´æ˜å¹´çº§æ˜¯å¦åŒ¹é…
  - å¿…é¡»è¯´æ˜å­¦ç§‘æ˜¯å¦åŒ¹é…
  - å¦‚æœä¸åŒ¹é…ï¼Œæ˜ç¡®æŒ‡å‡ºå·®å¼‚

ã€ç¤ºä¾‹ã€‘
ç›®æ ‡ï¼šä¸€å¹´çº§ æ•°å­¦
æ ‡é¢˜ï¼šä¸€å¹´çº§æ•°å­¦åŠ å‡æ³•æ•™å­¦
è¾“å‡ºï¼š{{"score":9.0,"reason":"å¹´çº§å’Œå­¦ç§‘å®Œå…¨åŒ¹é…ï¼Œæ¥è‡ªæƒå¨å¹³å°ï¼Œå®Œæ•´è¯¾ç¨‹"}}

ç›®æ ‡ï¼šäº”å¹´çº§ æ•°å­¦
æ ‡é¢˜ï¼šåˆä¸‰æ•°å­¦å…¨å†Œ-ä¹å¹´çº§æ•°å­¦-ä¸Šå†Œ-ä¸‹å†Œ
è¾“å‡ºï¼š{{"score":3.0,"reason":"å¹´çº§ä¸ç¬¦ï¼ˆæ ‡é¢˜åˆä¸‰=ä¹å¹´çº§ï¼Œç›®æ ‡äº”å¹´çº§ï¼‰ï¼Œå­¦ç§‘åŒ¹é…"}}

ç›®æ ‡ï¼šä¸€å¹´çº§ é˜¿æ‹‰ä¼¯è¯­
æ ‡é¢˜ï¼šè‰ºæœ¯æ•™è‚² - å…«å¹´çº§ - ç¬¬ä¸€å­¦æœŸ
è¾“å‡ºï¼š{{"score":2.0,"reason":"å¹´çº§ä¸ç¬¦ï¼ˆç›®æ ‡ä¸€å¹´çº§ï¼Œæ ‡é¢˜å…«å¹´çº§ï¼‰ï¼Œå­¦ç§‘ä¸ç¬¦ï¼ˆç›®æ ‡é˜¿æ‹‰ä¼¯è¯­ï¼Œæ ‡é¢˜è‰ºæœ¯ï¼‰ï¼Œä¸æ¨è"}}

ç°åœ¨è¯·è¯„ä¼°å¹¶è¿”å›JSONï¼š{{"score":åˆ†æ•°,"reason":"ç†ç”±"}}"""

            # ğŸ“Š è®°å½•LLMè°ƒç”¨å¼€å§‹
            from core.search_log_collector import get_log_collector
            import time
            llm_start = time.time()

            # è°ƒç”¨LLM
            response = self.llm_client.call_llm(
                prompt=user_prompt,
                system_prompt=system_prompt,
                max_tokens=1000,  # å¢åŠ åˆ°1000ï¼Œé¿å…JSONè¢«æˆªæ–­
                temperature=0.3
            )

            # ğŸ“Š è®°å½•LLMè°ƒç”¨ç»“æŸ
            llm_elapsed = time.time() - llm_start
            try:
                log_collector = get_log_collector()
                if log_collector.current_log:
                    # è·å–æ¨¡å‹ä¿¡æ¯
                    model_name = getattr(self.llm_client, 'model', 'gemini-2.5-flash')
                    provider = getattr(self.llm_client, 'provider', 'Internal API')

                    # ğŸ”¥ ä¸æˆªæ–­promptå’Œresponse
                    log_collector.record_llm_call(
                        model_name=model_name,
                        function="æ™ºèƒ½è¯„åˆ†",
                        provider=provider,
                        prompt=user_prompt,  # ğŸ”¥ å®Œæ•´æç¤ºè¯
                        input_data=f"æ ‡é¢˜: {title}, ç›®æ ‡: {grade} {subject}",
                        output_data=response,  # ğŸ”¥ å®Œæ•´è¾“å‡º
                        execution_time=llm_elapsed
                    )
                    logger.debug(f"[ğŸ“Š æ—¥å¿—] LLMè°ƒç”¨å·²è®°å½•: {model_name}, åŠŸèƒ½=æ™ºèƒ½è¯„åˆ†, è€—æ—¶={llm_elapsed:.2f}ç§’")
            except Exception as e:
                logger.warning(f"[ğŸ“Š æ—¥å¿—] è®°å½•LLMè°ƒç”¨å¤±è´¥: {str(e)}")

            # âœ… æ”¹è¿›ï¼šæ›´é²æ£’çš„JSONè§£æ
            response = response.strip()

            # 1. âœ… é¦–å…ˆæ¸…ç†å“åº”ï¼šç§»é™¤ä»£ç å—æ ‡è®°ï¼ˆä¼˜å…ˆå¤„ç†ï¼‰
            if '```json' in response:
                response = response.split('```json')[1].split('```')[0].strip()
                logger.debug("ç§»é™¤```jsonä»£ç å—æ ‡è®°")
            elif '```' in response:
                response = response.split('```')[1].split('```')[0].strip()
                logger.debug("ç§»é™¤```ä»£ç å—æ ‡è®°")

            # 2. å°è¯•ç›´æ¥è§£æ
            try:
                result_data = json.loads(response)
            except json.JSONDecodeError as e1:
                logger.warning(f"JSONè§£æå¤±è´¥ï¼ˆç¬¬ä¸€æ¬¡å°è¯•ï¼‰ï¼Œå°è¯•æ¸…ç†å“åº”: {str(e1)[:100]}")

                # 3. å°è¯•è¡¥å…¨è¢«æˆªæ–­çš„JSONï¼ˆå¸¸è§é—®é¢˜ï¼šreasonå­—æ®µæ²¡æœ‰é—­åˆå¼•å·ï¼‰
                # å¦‚æœJSONä»¥é€—å·æˆªæ–­ï¼Œå°è¯•è¡¥å…¨
                if response.endswith(',') or not response.rstrip().endswith('}'):
                    # æ£€æŸ¥æ˜¯å¦æœ‰æœªé—­åˆçš„reasonå­—æ®µ
                    reason_match = re.search(r'"reason"\s*:\s*"([^"]*$)', response)
                    if reason_match:
                        # reasonå­—æ®µè¢«æˆªæ–­ï¼Œè¡¥å…¨å¼•å·å’Œé—­åˆ
                        response = response[:reason_match.start()] + '"reason": "' + reason_match.group(1) + '"}'
                        logger.info(f"è¡¥å…¨è¢«æˆªæ–­çš„reasonå­—æ®µ")
                    else:
                        # ç®€å•è¡¥å…¨ï¼šæ·»åŠ é—­åˆå¼•å·å’Œæ‹¬å·
                        if response.count('"') % 2 != 0:  # å¥‡æ•°ä¸ªå¼•å·è¯´æ˜æœ‰æœªé—­åˆçš„å­—ç¬¦ä¸²
                            response += '"'
                        if not response.rstrip().endswith('}'):
                            response += '}'

                # 4. æ¸…ç†å“åº”ä¸­çš„æ¢è¡Œç¬¦å’Œç‰¹æ®Šå­—ç¬¦
                lines = response.split('\n')
                cleaned_lines = []
                for line in lines:
                    # ä¿ç•™JSONç»“æ„ï¼Œä½†æ¸…ç†reasonå­—ç¬¦ä¸²å€¼ä¸­çš„æ¢è¡Œ
                    if '"reason":' in line:
                        # ç§»é™¤reasonå­—æ®µä¸­çš„æ¢è¡Œç¬¦
                        line = line.replace('\n', ' ').replace('\r', ' ')
                    cleaned_lines.append(line)
                response = ' '.join(cleaned_lines)

                # 5. ç§»é™¤å°¾éšé€—å·
                response = re.sub(r',\s*}', '}', response)
                response = re.sub(r',\s*]', ']', response)

                # 6. å†æ¬¡å°è¯•è§£æ
                try:
                    result_data = json.loads(response)
                except json.JSONDecodeError as e2:
                    logger.warning(f"JSONè§£æå¤±è´¥ï¼ˆç¬¬äºŒæ¬¡å°è¯•ï¼‰ï¼Œå°è¯•æ­£åˆ™æå–: {str(e2)[:100]}")

                    # 7. ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å…œåº•æå–
                    score_match = re.search(r'"score"\s*:\s*([\d.]+)', response)
                    reason_match = re.search(r'"reason"\s*:\s*"([^"]+)', response)  # å…è®¸reasonåŒ…å«é€—å·

                    if score_match and reason_match:
                        score = float(score_match.group(1))
                        reason = reason_match.group(1)
                        # é™åˆ¶reasoné•¿åº¦ï¼Œé¿å…åŒ…å«å¤šä½™å†…å®¹
                        if len(reason) > 100:
                            reason = reason[:100]
                        logger.info(f"âœ… é€šè¿‡æ­£åˆ™æå–æˆåŠŸ: score={score}, reason={reason[:30]}...")
                    else:
                        # 8. å®Œå…¨å¤±è´¥ï¼Œè¿”å›Noneä½¿ç”¨è§„åˆ™è¯„åˆ†
                        logger.error(f"æ— æ³•è§£æLLMå“åº”ï¼Œå“åº”å†…å®¹: {response[:200]}")
                        return None

            # éªŒè¯å’Œæå–æ•°æ®
            if isinstance(result_data, dict):
                score = float(result_data.get('score', 5.0))
                reason = result_data.get('reason', 'æ ¹æ®æœç´¢åŒ¹é…åº¦æ¨è')
            else:
                # å¦‚æœresult_dataä¸æ˜¯dictï¼ˆæ­£åˆ™æå–çš„æƒ…å†µï¼‰ï¼Œç›´æ¥ä½¿ç”¨æå–çš„å€¼
                pass

            # ç¡®ä¿åˆ†æ•°åœ¨0-10èŒƒå›´å†…
            score = max(0.0, min(10.0, score))

            logger.info(f"âœ… LLMè¯„ä¼°æˆåŠŸ: score={score:.1f}, reason={reason[:30]}...")

            return {
                'score': round(score, 1),
                'recommendation_reason': reason
            }

        except Exception as e:
            logger.warning(f"âš ï¸ LLMè¯„ä¼°å¤±è´¥: {str(e)[:100]}ï¼Œå°†ä½¿ç”¨è§„åˆ™è¯„åˆ†")
            return None

    def evaluate_with_visual(
        self,
        result: Dict[str, Any],
        screenshot_path: str,
        query: str,
        metadata: Optional[Dict] = None
    ) -> Optional[Dict[str, Any]]:
        """
        ä½¿ç”¨è§†è§‰å¿«é€Ÿè¯„ä¼°å™¨è¯„ä¼°ç»“æœï¼ˆåŸºäºç½‘é¡µæˆªå›¾ï¼‰

        Args:
            result: æœç´¢ç»“æœå­—å…¸
            screenshot_path: æˆªå›¾æ–‡ä»¶è·¯å¾„
            query: æœç´¢æŸ¥è¯¢
            metadata: å…ƒæ•°æ®ï¼ˆå›½å®¶ã€å¹´çº§ã€å­¦ç§‘ã€è¯­è¨€ï¼‰

        Returns:
            åŒ…å«scoreå’Œrecommendation_reasonçš„å­—å…¸ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            from core.visual_quick_evaluator import get_visual_quick_evaluator

            # è·å–è§†è§‰è¯„ä¼°å™¨
            visual_evaluator = get_visual_quick_evaluator()

            # æå–è¯„ä¼°å‚æ•°
            title = result.get('title', '')
            url = result.get('url', '')

            # ä»metadataä¸­æå–ä¿¡æ¯
            country_name = metadata.get('country_name', '') if metadata else ''
            grade_name = metadata.get('grade_name', '') if metadata else ''
            subject_name = metadata.get('subject_name', '') if metadata else ''
            language_code = metadata.get('language_code', 'en') if metadata else 'en'

            # è¯­è¨€ä»£ç æ˜ å°„ï¼ˆå›½å®¶ä»£ç  -> è¯­è¨€ä»£ç ï¼‰
            language_mapping = {
                'Iraq': 'ar',  # ä¼Šæ‹‰å…‹ -> é˜¿æ‹‰ä¼¯è¯­
                'Indonesia': 'id',  # å°å°¼ -> å°å°¼è¯­
                'China': 'zh',  # ä¸­å›½ -> ä¸­æ–‡
                'Russia': 'ru',  # ä¿„ç½—æ–¯ -> ä¿„è¯­
                'India': 'en',  # å°åº¦ -> è‹±è¯­
            }
            target_language = language_mapping.get(country_name, language_code) if metadata else language_code

            logger.info(f"ğŸ” [è§†è§‰è¯„ä¼°] æ ‡é¢˜={title[:50]}..., å¹´çº§={grade_name}, è¯­è¨€={target_language}")

            # è°ƒç”¨å®Œæ•´è¯„ä¼°
            evaluation_result = visual_evaluator.evaluate_full(
                screenshot_path=screenshot_path,
                title=title,
                target_grade=grade_name,
                subject=subject_name,
                target_language=target_language
            )

            if not evaluation_result:
                logger.warning("è§†è§‰è¯„ä¼°å¤±è´¥ï¼Œè¿”å›None")
                return None

            # æå–æ€»åˆ†å’Œæ¨èç†ç”±
            overall_score = evaluation_result.get('overall_score', 5.0)
            recommendation = evaluation_result.get('recommendation', '')

            logger.info(f"âœ… [è§†è§‰è¯„ä¼°] æˆåŠŸ: æ€»åˆ†={overall_score}, æ¨è={recommendation[:30]}...")

            return {
                'score': round(overall_score, 1),
                'recommendation_reason': recommendation,
                'evaluation_method': 'Visual',
                'evaluation_details': evaluation_result.get('breakdown', {})
            }

        except Exception as e:
            logger.warning(f"âš ï¸ è§†è§‰è¯„ä¼°å¼‚å¸¸: {str(e)[:100]}")
            return None

    # ========== MCPå¤šæ¨¡æ€å·¥å…·å¢å¼ºå‡½æ•° ==========

    def _is_video_url(self, url: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºè§†é¢‘URL"""
        video_domains = [
            'youtube.com', 'youtu.be', 'vimeo.com',
            'bilibili.com', 'dailymotion.com'
        ]
        return any(domain in url.lower() for domain in video_domains)


    def _enrich_result_with_mcp_tools(
        self,
        result: Dict[str, Any],
        metadata: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨MCPå·¥å…·ä¸°å¯Œæœç´¢ç»“æœä¿¡æ¯

        Args:
            result: æœç´¢ç»“æœï¼ˆåŒ…å«urlï¼‰
            metadata: å…ƒæ•°æ®

        Returns:
            ä¸°å¯Œåçš„ç»“æœï¼ˆæ·»åŠ äº†web_content, video_infoç­‰ï¼‰
        """
        url = result.get('url', '')

        # å¦‚æœURLå·²ç»å¤„ç†è¿‡ï¼Œè·³è¿‡
        if 'mcp_enriched' in result:
            return result

        # ä¼˜å…ˆçº§1: å¯¹äºYouTubeç­‰è§†é¢‘URLï¼Œè·å–ç¼©ç•¥å›¾åˆ†æ
        if self._is_video_url(url):
            try:
                logger.debug(f"[MCPå·¥å…·] æ­£åœ¨åˆ†æè§†é¢‘ç¼©ç•¥å›¾: {url[:50]}")

                # ä½¿ç”¨MCPè§†é¢‘åˆ†æå·¥å…·
                video_info = self._analyze_video_with_mcp(url)
                if video_info:
                    result['video_analysis'] = video_info
                    result['mcp_enriched'] = True
                    logger.debug(f"[MCPå·¥å…·] è§†é¢‘åˆ†æå®Œæˆ: {url[:50]}")
            except Exception as e:
                logger.warning(f"[MCPå·¥å…·] è§†é¢‘åˆ†æå¤±è´¥: {str(e)[:100]}")

        # ä¼˜å…ˆçº§2: å¯¹äºä¸€èˆ¬URLï¼Œæå–ç½‘é¡µå†…å®¹ï¼ˆå¯é€‰ï¼Œé¿å…è¿‡åº¦è°ƒç”¨ï¼‰
        # æ³¨æ„ï¼šwebReaderè°ƒç”¨è¾ƒæ…¢ï¼Œä»…å½“snippetä¸ºç©ºæˆ–è¿‡çŸ­æ—¶æ‰è°ƒç”¨
        elif url and not result.get('snippet'):
            try:
                snippet_length = len(result.get('snippet', ''))
                if snippet_length < 50:  # snippetå¤ªçŸ­æ‰è¡¥å……
                    logger.debug(f"[MCPå·¥å…·] æ­£åœ¨æå–ç½‘é¡µå†…å®¹: {url[:50]}")

                    # ä½¿ç”¨MCP webReaderå·¥å…·
                    web_content = self._fetch_web_content_with_mcp(url)
                    if web_content:
                        result['web_content'] = web_content
                        result['snippet'] = web_content.get('summary', web_content.get('content', '')[:500])
                        result['mcp_enriched'] = True
                        logger.debug(f"[MCPå·¥å…·] ç½‘é¡µå†…å®¹æå–å®Œæˆ: {len(result.get('snippet', ''))} å­—ç¬¦")
            except Exception as e:
                logger.warning(f"[MCPå·¥å…·] ç½‘é¡µå†…å®¹æå–å¤±è´¥: {str(e)[:100]}")

        return result


    def _analyze_video_with_mcp(self, url: str) -> Optional[Dict]:
        """
        ä½¿ç”¨MCPå·¥å…·åˆ†æè§†é¢‘ï¼ˆé€šè¿‡ç¼©ç•¥å›¾ï¼‰

        æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨analyze_imageå·¥å…·åˆ†æè§†é¢‘ç¼©ç•¥å›¾
        éœ€è¦æä¾›è§†é¢‘çš„ç¼©ç•¥å›¾URL
        """
        try:
            # ä»YouTube URLæå–è§†é¢‘IDï¼Œè·å–ç¼©ç•¥å›¾
            if 'youtube.com' in url or 'youtu.be' in url:
                import re
                video_id_match = re.search(r'(?:v=|\/)([0-9A-Za-z_-]{11})', url)
                if video_id_match:
                    video_id = video_id_match.group(1)
                    thumbnail_url = f"https://i.ytimg.com/vi/{video_id}/hqdefault.jpg"

                    # âš ï¸ æ³¨æ„ï¼šè¿™é‡Œè°ƒç”¨MCPå·¥å…·éœ€è¦ç‰¹æ®Šå¤„ç†
                    # ç”±äºMCPå·¥å…·æ˜¯é€šè¿‡ç³»ç»Ÿè°ƒç”¨çš„ï¼Œè¿™é‡Œå…ˆè¿”å›URL
                    # å®é™…çš„MCPè°ƒç”¨å°†åœ¨LLMè¯„ä¼°é˜¶æ®µé€šè¿‡promptä¼ å…¥
                    return {
                        'type': 'video_thumbnail_url',
                        'thumbnail_url': thumbnail_url,
                        'note': 'MCPå›¾åƒåˆ†æå°†åœ¨LLMè¯„ä¼°æ—¶è¿›è¡Œ'
                    }
        except Exception as e:
            logger.warning(f"è§†é¢‘ç¼©ç•¥å›¾åˆ†æå¤±è´¥: {str(e)}")

        return None


    def _fetch_web_content_with_mcp(self, url: str) -> Optional[Dict]:
        """
        ä½¿ç”¨MCP webReaderå·¥å…·æå–ç½‘é¡µå†…å®¹

        âš ï¸ æ³¨æ„ï¼šä¸ºäº†é¿å…é˜»å¡ï¼Œè¿™é‡Œåªè¿”å›URL
        å®é™…çš„MCPè°ƒç”¨å°†åœ¨éœ€è¦æ—¶é€šè¿‡å¤–éƒ¨å¤„ç†
        """
        try:
            # âš ï¸ ä¸ºäº†æ€§èƒ½è€ƒè™‘ï¼Œæš‚æ—¶ä¸ç›´æ¥è°ƒç”¨MCP webReader
            # å¦‚æœéœ€è¦å¯ç”¨ï¼Œå¯ä»¥åœ¨å¤–éƒ¨é€šè¿‡MCPå·¥å…·è°ƒç”¨
            return {
                'type': 'web_content_url',
                'url': url,
                'note': 'MCPç½‘é¡µå†…å®¹æå–å°†åœ¨éœ€è¦æ—¶è¿›è¡Œ'
            }
        except Exception as e:
            logger.warning(f"ç½‘é¡µå†…å®¹æå–å¤±è´¥: {str(e)}")

        return None

    def score_results(self, results: List[Dict[str, Any]], query: str, metadata: Optional[Dict] = None) -> List[Dict[str, Any]]:
        """
        å¯¹å¤šä¸ªç»“æœè¿›è¡Œè¯„åˆ†å’Œæ’åº

        Args:
            results: æœç´¢ç»“æœåˆ—è¡¨
            query: æœç´¢æŸ¥è¯¢
            metadata: é¢å¤–çš„å…ƒæ•°æ®

        Returns:
            è¯„åˆ†å¹¶æ’åºåçš„ç»“æœåˆ—è¡¨
        """
        import concurrent.futures

        logger.info(f"ğŸ“Š å¼€å§‹è¯„ä¼° {len(results)} ä¸ªæœç´¢ç»“æœï¼Œä½¿ç”¨ Gemini 2.5 Flash æ¨¡å‹ï¼ˆå¹¶å‘æ¨¡å¼ï¼‰")

        # ğŸš€ å¹¶å‘è¯„ä¼°ï¼ˆæœ€å¤š5ä¸ªåŒæ—¶è¿›è¡Œï¼Œé¿å…è¿‡è½½ï¼‰
        MAX_WORKERS = 5
        scored_results = []

        with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            # æäº¤æ‰€æœ‰è¯„ä¼°ä»»åŠ¡
            future_to_result = {
                executor.submit(self._evaluate_single_result, result, query, metadata): (idx, result)
                for idx, result in enumerate(results)
            }

            # ç­‰å¾…å®Œæˆå¹¶æ”¶é›†ç»“æœ
            completed_count = 0
            for future in concurrent.futures.as_completed(future_to_result):
                idx, original_result = future_to_result[future]
                try:
                    scored_result = future.result(timeout=30)  # å•ä¸ªè¯„ä¼°æœ€å¤š30ç§’
                    scored_result['original_index'] = idx  # ä¿ç•™åŸå§‹é¡ºåº
                    scored_results.append(scored_result)
                    completed_count += 1

                    # æ¯5ä¸ªç»“æœæ‰“å°ä¸€æ¬¡è¿›åº¦
                    if completed_count % 5 == 0:
                        logger.info(f"  è¿›åº¦: {completed_count}/{len(results)} ä¸ªç»“æœå·²è¯„ä¼°")
                except Exception as e:
                    logger.error(f"ç»“æœè¯„ä¼°å¤±è´¥ (ç´¢å¼•{idx}): {str(e)[:100]}")
                    # é™çº§åˆ°è§„åˆ™è¯„åˆ†
                    score = self.score_result(original_result, query, metadata)
                    original_result['score'] = round(score, 2)
                    original_result['recommendation_reason'] = self._generate_recommendation_reason(original_result, score)
                    original_result['evaluation_method'] = 'Rule-based'
                    original_result['original_index'] = idx
                    scored_results.append(original_result)
                    completed_count += 1

        # âŒ ç§»é™¤æ’åºï¼šæ’åºä¼šç ´åoriginal_indexçš„å¯¹åº”å…³ç³»
        # scored_results.sort(key=lambda x: x.get('score', 0), reverse=True)
        # æ’åºåº”è¯¥åœ¨search_engine_v2.pyä¸­å®Œæˆï¼Œåœ¨æ­£ç¡®åŒ¹é…åˆ†æ•°ä¹‹å

        # ç»Ÿè®¡è¯„ä¼°æ–¹æ³•
        llm_count = sum(1 for r in scored_results if r.get('evaluation_method') == 'LLM')
        rule_count = len(scored_results) - llm_count

        logger.info(f"âœ… è¯„ä¼°å®Œæˆ: {len(results)}ä¸ªç»“æœ (LLM: {llm_count}, è§„åˆ™: {rule_count})")

        return scored_results

    def _evaluate_single_result(self, result: Dict[str, Any], query: str, metadata: Optional[Dict]) -> Dict[str, Any]:
        """
        è¯„ä¼°å•ä¸ªç»“æœï¼ˆå¹¶å‘æ‰§è¡Œï¼‰

        Args:
            result: æœç´¢ç»“æœå­—å…¸
            query: æœç´¢æŸ¥è¯¢
            metadata: é¢å¤–çš„å…ƒæ•°æ®

        Returns:
            è¯„åˆ†åçš„ç»“æœå­—å…¸
        """
        # âœ… ä½¿ç”¨MCPå·¥å…·ä¸°å¯Œç»“æœä¿¡æ¯ï¼ˆè§†é¢‘ç¼©ç•¥å›¾ã€ç½‘é¡µå†…å®¹ç­‰ï¼‰
        try:
            result = self._enrich_result_with_mcp_tools(result, metadata or {})
        except Exception as e:
            logger.warning(f"MCPå·¥å…·ä¸°å¯Œå¤±è´¥: {str(e)[:100]}")

        # ä¼˜å…ˆä½¿ç”¨LLMè¯„ä¼°ï¼ˆç”Ÿæˆä¸€è‡´çš„åˆ†æ•°å’Œæ¨èç†ç”±ï¼‰
        llm_evaluation = self._evaluate_with_llm(result, query, metadata)

        if llm_evaluation:
            # LLMè¯„ä¼°æˆåŠŸ
            result['score'] = llm_evaluation['score']
            result['recommendation_reason'] = llm_evaluation['recommendation_reason']
            # âœ… ä½¿ç”¨LLMè¯„ä¼°è¿”å›çš„è¯„ä¼°æ–¹æ³•ï¼ˆå¯èƒ½æ˜¯ 'MCP Tools', 'LLM' ç­‰ï¼‰
            result['evaluation_method'] = llm_evaluation.get('evaluation_method', 'LLM')

            # âœ… åå¤„ç†éªŒè¯ï¼šçº æ­£LLMçš„æ˜æ˜¾é”™è¯¯ï¼ˆä½†è·³è¿‡MCP Toolsï¼‰
            try:
                result = self._validate_and_correct_score(result, metadata)
            except Exception as e:
                logger.warning(f"è¯„åˆ†éªŒè¯å¤±è´¥: {str(e)[:100]}")
        else:
            # LLMè¯„ä¼°å¤±è´¥ï¼Œé™çº§åˆ°è§„åˆ™è¯„åˆ†
            score = self.score_result(result, query, metadata)
            result['score'] = round(score, 2)
            result['recommendation_reason'] = self._generate_recommendation_reason(result, score)
            result['evaluation_method'] = 'Rule-based'

            # âœ… è§„åˆ™è¯„åˆ†ä¹Ÿéœ€è¦éªŒè¯
            try:
                result = self._validate_and_correct_score(result, metadata)
            except Exception as e:
                logger.warning(f"è¯„åˆ†éªŒè¯å¤±è´¥: {str(e)[:100]}")

        return result

    # ========== å¤šè¯­è¨€å¹´çº§/å­¦ç§‘è¯†åˆ«å‡½æ•° ==========

    def _extract_grade_from_title(
        self,
        title: str,
        target_grade: str,
        language_hint: str = 'auto'
    ) -> Optional[str]:
        """
        ä½¿ç”¨LLMä»æ ‡é¢˜ä¸­æå–å¹´çº§ä¿¡æ¯å¹¶æ ‡å‡†åŒ–ä¸ºä¸­æ–‡ï¼ˆçº¯LLMæ–¹æ¡ˆï¼‰

        Args:
            title: æ ‡é¢˜æ–‡æœ¬ï¼ˆä»»æ„è¯­è¨€ï¼‰
            target_grade: ç›®æ ‡å¹´çº§ï¼ˆå¦‚ï¼š"ä¸€å¹´çº§"ã€"Ø§Ù„ØµÙ Ø§Ù„Ø£ÙˆÙ„ / ä¸€å¹´çº§"ï¼‰
            language_hint: è¯­è¨€æç¤ºï¼ˆå¯é€‰ï¼šzh, ar, ru, id, en, fr, es, autoï¼‰

        Returns:
            æ ‡å‡†åŒ–çš„å¹´çº§ä¸­æ–‡åç§°ï¼ˆå¦‚ï¼šä¸€å¹´çº§ã€äºŒå¹´çº§ã€...ã€åäºŒå¹´çº§ï¼‰
            å¦‚æœæ— æ³•è¯†åˆ«æˆ–æ— æ³•åŒ¹é…ï¼Œè¿”å›None
        """
        # âœ… ç¼“å­˜æ£€æŸ¥
        cache_key = f"{title}|{target_grade}"
        cached_result = self._cache_get(self._grade_extraction_cache, cache_key)
        if cached_result is not None:
            logger.debug(f"[ç¼“å­˜å‘½ä¸­] å¹´çº§è¯†åˆ«ï¼š{title[:50]} â†’ {cached_result}")
            return cached_result

        if not self.llm_client:
            return None

        try:
            # ä»æ··åˆæ ¼å¼çš„target_gradeä¸­æå–ä¸­æ–‡éƒ¨åˆ†
            if '/' in target_grade:
                target_grade_zh = target_grade.split('/')[-1].strip()
            else:
                # å¦‚æœtarget_gradeæ˜¯çº¯å¤–æ–‡ï¼Œéœ€è¦LLMç¿»è¯‘
                target_grade_zh = target_grade

            # æ„å»ºè¯†åˆ«prompt
            prompt = f"""è¯·ä»ä»¥ä¸‹æ ‡é¢˜ä¸­æå–å¹´çº§ä¿¡æ¯ï¼Œå¹¶åˆ¤æ–­æ˜¯å¦ä¸ç›®æ ‡å¹´çº§åŒ¹é…ã€‚

ã€ç›®æ ‡å¹´çº§ã€‘
{target_grade_zh}

ã€æ ‡é¢˜ã€‘
{title}

ã€ä»»åŠ¡ã€‘
1. è¯†åˆ«æ ‡é¢˜ä¸­çš„å¹´çº§ä¿¡æ¯ï¼ˆæ”¯æŒä»»æ„è¯­è¨€ï¼‰
2. å°†æ ‡é¢˜ä¸­çš„å¹´çº§ç¿»è¯‘æˆä¸­æ–‡ï¼ˆä¸€å¹´çº§åˆ°åäºŒå¹´çº§ï¼‰
3. åˆ¤æ–­æ ‡é¢˜å¹´çº§æ˜¯å¦ä¸ç›®æ ‡å¹´çº§åŒ¹é…

ã€è¾“å‡ºæ ¼å¼ã€‘ï¼ˆä¸¥æ ¼JSONï¼‰
{{
  "detected_grade": "è¯†åˆ«å‡ºçš„å¹´çº§ä¸­æ–‡å",
  "target_grade": "{target_grade_zh}",
  "is_match": true/false,
  "confidence": "high/medium/low"
}}

ã€ç¤ºä¾‹ã€‘
ç›®æ ‡å¹´çº§ï¼šä¸€å¹´çº§
æ ‡é¢˜ï¼šØ§Ù„ØµÙ Ø§Ù„Ø«Ø§Ù†ÙŠ - Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª
è¾“å‡ºï¼š{{"detected_grade":"äºŒå¹´çº§","target_grade":"ä¸€å¹´çº§","is_match":false,"confidence":"high"}}

ç›®æ ‡å¹´çº§ï¼šå…«å¹´çº§
æ ‡é¢˜ï¼šØ§Ù„ØªØ±Ø¨ÙŠØ© Ø§Ù„ÙÙ†ÙŠØ© - Ø§Ù„ØµÙ Ø§Ù„Ø«Ø§Ù…Ù†
è¾“å‡ºï¼š{{"detected_grade":"å…«å¹´çº§","target_grade":"å…«å¹´çº§","is_match":true,"confidence":"high"}}

ç°åœ¨è¯·å¤„ç†ä¸Šè¿°æ ‡é¢˜å¹¶è¿”å›JSONï¼š"""

            # è°ƒç”¨LLMï¼ˆä½¿ç”¨é…ç½®çš„å¿«é€Ÿæ¨ç†æ¨¡å‹ï¼‰
            config_manager = get_config_manager()
            models = config_manager.get_llm_models()
            fast_model = models.get('fast_inference', 'gemini-2.5-pro')

            logger.info(f"[ğŸ“¡ LLMè°ƒç”¨] ä½¿ç”¨å¿«é€Ÿæ¨ç†æ¨¡å‹: {fast_model}")
            response = self.llm_client.call_llm(
                prompt=prompt,
                max_tokens=100,
                temperature=0.1,
                model=fast_model
            )

            # è§£æå“åº”
            import json
            import re

            # âœ… æ¸…ç†å“åº”ï¼šç§»é™¤ä»£ç å—æ ‡è®°
            response_clean = response.strip()
            if '```json' in response_clean:
                response_clean = response_clean.split('```json')[1].split('```')[0].strip()
            elif '```' in response_clean:
                response_clean = response_clean.split('```')[1].split('```')[0].strip()

            # æå–JSON
            json_match = re.search(r'\{[^{}]*\}', response_clean)
            if json_match:
                result_data = json.loads(json_match.group())
                detected_grade = result_data.get('detected_grade', '')

                # éªŒè¯å¹´çº§åç§°æ˜¯å¦æœ‰æ•ˆ
                valid_grades = [
                    'ä¸€å¹´çº§', 'äºŒå¹´çº§', 'ä¸‰å¹´çº§', 'å››å¹´çº§', 'äº”å¹´çº§', 'å…­å¹´çº§',
                    'ä¸ƒå¹´çº§', 'å…«å¹´çº§', 'ä¹å¹´çº§', 'é«˜ä¸€', 'é«˜äºŒ', 'é«˜ä¸‰', 'åäºŒå¹´çº§'
                ]

                if detected_grade in valid_grades:
                    logger.debug(f"LLMè¯†åˆ«å¹´çº§ï¼š{title[:50]} â†’ {detected_grade}")
                    # âœ… ç¼“å­˜ç»“æœ
                    self._cache_set(self._grade_extraction_cache, cache_key, detected_grade)
                    return detected_grade

            logger.warning(f"LLMå¹´çº§è¯†åˆ«å¤±è´¥æˆ–è¿”å›æ— æ•ˆï¼š{response[:100]}")
            return None

        except Exception as e:
            logger.warning(f"LLMå¹´çº§è¯†åˆ«å¼‚å¸¸: {str(e)[:100]}")
            return None


    def _extract_subject_from_title(
        self,
        title: str,
        target_subject: str,
        language_hint: str = 'auto'
    ) -> Optional[str]:
        """
        ä½¿ç”¨LLMä»æ ‡é¢˜ä¸­æå–å­¦ç§‘ä¿¡æ¯å¹¶æ ‡å‡†åŒ–ä¸ºä¸­æ–‡ï¼ˆçº¯LLMæ–¹æ¡ˆï¼‰

        Args:
            title: æ ‡é¢˜æ–‡æœ¬ï¼ˆä»»æ„è¯­è¨€ï¼‰
            target_subject: ç›®æ ‡å­¦ç§‘ï¼ˆå¦‚ï¼š"ä½“è‚²"ã€"Ø§Ù„ØªØ±Ø¨ÙŠØ© Ø§Ù„Ø¨Ø¯Ù†ÙŠØ© / ä½“è‚²"ï¼‰
            language_hint: è¯­è¨€æç¤º

        Returns:
            æ ‡å‡†åŒ–çš„å­¦ç§‘ä¸­æ–‡åç§°
        """
        # âœ… ç¼“å­˜æ£€æŸ¥
        cache_key = f"{title}|{target_subject}"
        cached_result = self._cache_get(self._subject_extraction_cache, cache_key)
        if cached_result is not None:
            logger.debug(f"[ç¼“å­˜å‘½ä¸­] å­¦ç§‘è¯†åˆ«ï¼š{title[:50]} â†’ {cached_result}")
            return cached_result

        if not self.llm_client:
            return None

        try:
            # ä»æ··åˆæ ¼å¼çš„target_subjectä¸­æå–ä¸­æ–‡éƒ¨åˆ†
            if '/' in target_subject:
                target_subject_zh = target_subject.split('/')[-1].strip()
            else:
                target_subject_zh = target_subject

            # æ„å»ºè¯†åˆ«prompt
            prompt = f"""è¯·ä»ä»¥ä¸‹æ ‡é¢˜ä¸­æå–å­¦ç§‘ä¿¡æ¯ï¼Œå¹¶åˆ¤æ–­æ˜¯å¦ä¸ç›®æ ‡å­¦ç§‘åŒ¹é…ã€‚

ã€ç›®æ ‡å­¦ç§‘ã€‘
{target_subject_zh}

ã€æ ‡é¢˜ã€‘
{title}

ã€ä»»åŠ¡ã€‘
1. è¯†åˆ«æ ‡é¢˜ä¸­çš„å­¦ç§‘/è¯¾ç¨‹ç±»å‹ï¼ˆæ”¯æŒä»»æ„è¯­è¨€ï¼‰
2. å°†æ ‡é¢˜ä¸­çš„å­¦ç§‘ç¿»è¯‘æˆä¸­æ–‡
3. åˆ¤æ–­æ ‡é¢˜å­¦ç§‘æ˜¯å¦ä¸ç›®æ ‡å­¦ç§‘åŒ¹é…

ã€å¸¸è§å­¦ç§‘ç±»å‹ã€‘
æ•°å­¦ã€è¯­æ–‡ã€è‹±è¯­ã€é˜¿æ‹‰ä¼¯è¯­ã€ä¿„è¯­ã€æ³•è¯­ã€è¥¿ç­ç‰™è¯­ã€è‰ºæœ¯ã€ç¾æœ¯ã€éŸ³ä¹ã€ä½“è‚²ã€ç§‘å­¦ã€ç‰©ç†ã€åŒ–å­¦ã€ç”Ÿç‰©ã€å†å²ã€åœ°ç†ç­‰

ã€è¾“å‡ºæ ¼å¼ã€‘ï¼ˆä¸¥æ ¼JSONï¼‰
{{
  "detected_subject": "è¯†åˆ«å‡ºçš„å­¦ç§‘ä¸­æ–‡å",
  "target_subject": "{target_subject_zh}",
  "is_match": true/false,
  "confidence": "high/medium/low"
}}

ã€ç¤ºä¾‹ã€‘
ç›®æ ‡å­¦ç§‘ï¼šæ•°å­¦
æ ‡é¢˜ï¼šØ§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª - Ø§Ù„ØµÙ Ø§Ù„Ø«Ø§Ù…Ù†
è¾“å‡ºï¼š{{"detected_subject":"æ•°å­¦","target_subject":"æ•°å­¦","is_match":true,"confidence":"high"}}

ç›®æ ‡å­¦ç§‘ï¼šè‰ºæœ¯
æ ‡é¢˜ï¼šØ§Ù„ØªØ±Ø¨ÙŠØ© Ø§Ù„ÙÙ†ÙŠØ© - Ø§Ù„ØµÙ Ø§Ù„Ø«Ø§Ù…Ù†
è¾“å‡ºï¼š{{"detected_subject":"è‰ºæœ¯","target_subject":"è‰ºæœ¯","is_match":true,"confidence":"high"}}

ç°åœ¨è¯·å¤„ç†ä¸Šè¿°æ ‡é¢˜å¹¶è¿”å›JSONï¼š"""

            # è°ƒç”¨LLMï¼ˆä½¿ç”¨é…ç½®çš„å¿«é€Ÿæ¨ç†æ¨¡å‹ï¼‰
            config_manager = get_config_manager()
            models = config_manager.get_llm_models()
            fast_model = models.get('fast_inference', 'gemini-2.5-pro')

            logger.info(f"[ğŸ“¡ LLMè°ƒç”¨] ä½¿ç”¨å¿«é€Ÿæ¨ç†æ¨¡å‹: {fast_model}")
            response = self.llm_client.call_llm(
                prompt=prompt,
                max_tokens=100,
                temperature=0.1,
                model=fast_model
            )

            # è§£æå“åº”
            import json
            import re

            # âœ… æ¸…ç†å“åº”ï¼šç§»é™¤ä»£ç å—æ ‡è®°
            response_clean = response.strip()
            if '```json' in response_clean:
                response_clean = response_clean.split('```json')[1].split('```')[0].strip()
            elif '```' in response_clean:
                response_clean = response_clean.split('```')[1].split('```')[0].strip()

            json_match = re.search(r'\{[^{}]*\}', response_clean)
            if json_match:
                result_data = json.loads(json_match.group())
                detected_subject = result_data.get('detected_subject', '')

                # éªŒè¯å­¦ç§‘åç§°æ˜¯å¦åˆç†
                if detected_subject and len(detected_subject) >= 2:
                    logger.debug(f"LLMè¯†åˆ«å­¦ç§‘ï¼š{title[:50]} â†’ {detected_subject}")
                    # âœ… ç¼“å­˜ç»“æœ
                    self._cache_set(self._subject_extraction_cache, cache_key, detected_subject)
                    return detected_subject

            logger.warning(f"LLMå­¦ç§‘è¯†åˆ«å¤±è´¥æˆ–è¿”å›æ— æ•ˆï¼š{response[:100]}")
            return None

        except Exception as e:
            logger.warning(f"LLMå­¦ç§‘è¯†åˆ«å¼‚å¸¸: {str(e)[:100]}")
            return None

    # ========== æ¨è/éªŒè¯ç›¸å…³å‡½æ•° ==========

    def _validate_with_mcp_tools_sync(
        self,
        result: Dict[str, Any],
        metadata: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """
        åŒæ­¥åŒ…è£…å™¨ï¼Œç”¨äºåœ¨åŒæ­¥ä¸Šä¸‹æ–‡ä¸­è°ƒç”¨MCPå·¥å…·

        Args:
            result: æœç´¢ç»“æœå­—å…¸
            metadata: å…ƒæ•°æ®ï¼ˆå›½å®¶ã€å¹´çº§ã€å­¦ç§‘ï¼‰

        Returns:
            éªŒè¯ç»“æœï¼Œå¦‚æœæ— æ³•åˆ¤æ–­åˆ™è¿”å›None
        """
        title = result.get('title', 'Unknown')[:50]
        logger.info(f"[ğŸ”§ MCPå·¥å…·åŒæ­¥åŒ…è£…] å¼€å§‹è°ƒç”¨: {title}...")

        import asyncio
        import threading

        try:
            # å°è¯•è·å–è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯
            loop = asyncio.get_running_loop()
            # å¦‚æœæœ‰è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ï¼Œåœ¨æ–°çº¿ç¨‹ä¸­è¿è¡ŒMCPå·¥å…·éªŒè¯
            logger.info("[ğŸ”„ MCPå·¥å…·éªŒè¯] æ£€æµ‹åˆ°è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ï¼Œåœ¨æ–°çº¿ç¨‹ä¸­æ‰§è¡ŒMCPéªŒè¯")

            # åœ¨æ–°çº¿ç¨‹ä¸­åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯æ¥è¿è¡Œå¼‚æ­¥å‡½æ•°
            result_container = [None]
            exception_container = [None]

            def run_in_new_thread():
                try:
                    logger.info(f"[ğŸ”§ çº¿ç¨‹å¼€å§‹] å¼€å§‹åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡ŒMCPéªŒè¯: {title[:50]}")
                    # åœ¨æ–°çº¿ç¨‹ä¸­åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
                    new_loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(new_loop)
                    try:
                        logger.info(f"[ğŸ”§ äº‹ä»¶å¾ªç¯] å¼€å§‹è¿è¡Œå¼‚æ­¥MCPéªŒè¯")
                        mcp_result = new_loop.run_until_complete(
                            self._validate_with_mcp_tools(result, metadata)
                        )
                        logger.info(f"[ğŸ”§ å¼‚æ­¥å®Œæˆ] MCPéªŒè¯è¿”å›ï¼Œç±»å‹={type(mcp_result)}, æ˜¯å¦None={mcp_result is None}")
                        result_container[0] = mcp_result
                        logger.info(f"[âœ… MCPå·¥å…·éªŒè¯] å®Œæˆ: score={mcp_result.get('score') if mcp_result else 'None'}")
                        logger.info(f"[âœ… MCPå·¥å…·éªŒè¯] å­˜å‚¨åˆ°result_container: {type(mcp_result)}")
                        if mcp_result:
                            logger.info(f"[âœ… MCPå·¥å…·éªŒè¯] result keys: {list(mcp_result.keys()) if isinstance(mcp_result, dict) else 'N/A'}")
                        else:
                            logger.warning(f"[âš ï¸ MCPå·¥å…·éªŒè¯] mcp_result is None!")
                    finally:
                        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆåå†å…³é—­
                        pending = asyncio.all_tasks(new_loop)
                        if pending:
                            new_loop.run_until_complete(asyncio.gather(*pending, return_exceptions=True))
                        new_loop.close()
                except Exception as e:
                    logger.error(f"[âŒ MCPå·¥å…·éªŒè¯] çº¿ç¨‹æ‰§è¡Œå¼‚å¸¸: {str(e)}", exc_info=True)
                    exception_container[0] = e

            thread = threading.Thread(target=run_in_new_thread)
            thread.start()
            thread.join(timeout=15)  # âœ… å¢åŠ è¶…æ—¶åˆ°15ç§’

            if exception_container[0]:
                logger.error(f"[âŒ MCPå·¥å…·éªŒè¯] çº¿ç¨‹å¼‚å¸¸: {str(exception_container[0])}")
                return None  # âœ… è¿”å›Noneè€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸

            if thread.is_alive():
                logger.warning("[âš ï¸ MCPå·¥å…·éªŒè¯] çº¿ç¨‹è¶…æ—¶ï¼ˆ15ç§’ï¼‰ï¼ŒMCPéªŒè¯æœªå®Œæˆ")
                return None

            logger.info(f"[ğŸ“Š MCPå·¥å…·éªŒè¯] è¿”å›: {result_container[0] is not None}")
            if result_container[0] is not None:
                logger.info(f"[ğŸ“Š MCPå·¥å…·éªŒè¯] è¿”å›ç±»å‹: {type(result_container[0])}, å†…å®¹: {str(result_container[0])[:200]}")
            else:
                logger.error(f"[âŒ MCPå·¥å…·éªŒè¯] result_container[0] is None!")
            return result_container[0]

        except RuntimeError:
            # æ²¡æœ‰è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ï¼Œå¯ä»¥å®‰å…¨ä½¿ç”¨asyncio.run
            try:
                return asyncio.run(self._validate_with_mcp_tools(result, metadata))
            except Exception as e:
                logger.error(f"[âŒ MCPå·¥å…·éªŒè¯] åŒæ­¥è°ƒç”¨å¤±è´¥: {str(e)}")
                return None

    async def _validate_with_mcp_tools(
        self,
        result: Dict[str, Any],
        metadata: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """
        ä½¿ç”¨MCPå·¥å…·è¿›è¡ŒéªŒè¯è¯„åˆ†ï¼ˆæ”¯æŒå¤šè¯­è¨€ï¼‰

        ä¼˜å…ˆçº§ï¼šMCPå·¥å…·éªŒè¯ > è§„åˆ™éªŒè¯ > LLMè¯„åˆ†
        ç”¨äºå¿«é€Ÿã€å‡†ç¡®åœ°è¯†åˆ«å¹´çº§/å­¦ç§‘åŒ¹é…é—®é¢˜

        æ”¯æŒçš„å›½å®¶ï¼šå°å°¼ï¼ˆIDï¼‰ç­‰

        Args:
            result: æœç´¢ç»“æœå­—å…¸
            metadata: å…ƒæ•°æ®ï¼ˆå›½å®¶ã€å¹´çº§ã€å­¦ç§‘ï¼‰

        Returns:
            éªŒè¯ç»“æœï¼Œå¦‚æœæ— æ³•åˆ¤æ–­åˆ™è¿”å›None
            {
                "score": è¯„åˆ†,
                "confidence": "high/medium/low",
                "reason": "ç†ç”±",
                "identified_grade": "è¯†åˆ«çš„å¹´çº§",
                "identified_subject": "è¯†åˆ«çš„å­¦ç§‘"
            }
        """
        title = result.get('title', '')
        url = result.get('url', '')
        if not title:
            return None

        # æå–ç›®æ ‡å¹´çº§å’Œå­¦ç§‘
        target_grade = metadata.get('grade', '')
        target_subject = metadata.get('subject', '')
        target_country = metadata.get('country', '')

        # åªå¤„ç†å·²é…ç½®å›½å®¶ï¼ˆå°å°¼ç­‰ï¼‰
        # ä»target_countryæå–å›½å®¶ä»£ç 
        country_code = None
        if target_country:
            # å°è¯•ä»å›½å®¶åç§°æˆ–ä»£ç ä¸­æå–
            if 'Indonesia' in target_country or 'ID' in target_country or 'å°å°¼' in target_country:
                country_code = 'ID'
            # æœªæ¥å¯ä»¥æ·»åŠ æ›´å¤šå›½å®¶
            # elif 'Saudi Arabia' in target_country or 'SA' in target_country:
            #     country_code = 'SA'

        if not country_code:
            return None

        logger.info(f"[ğŸ” MCPå·¥å…·éªŒè¯] æ£€æŸ¥{country_code}å›½å®¶æ ‡é¢˜: {title[:60]}...")

        try:
            # å¯¼å…¥MCPå·¥å…·
            from mcp_tools import (
                extract_grade_from_title,
                extract_subject_from_title,
                validate_grade_match,
                validate_url_quality
            )

            # 1. éªŒè¯URLè´¨é‡ï¼ˆä¼˜å…ˆæ£€æŸ¥ï¼Œåº”è¯¥å°½æ—©è¿‡æ»¤ä½è´¨é‡URLï¼‰
            logger.info(f"[ğŸ” URLéªŒè¯] å¼€å§‹è°ƒç”¨validate_url_quality...")
            url_result = await validate_url_quality(url, title)
            logger.info(f"[ğŸ” URLéªŒè¯] validate_url_qualityè¿”å›ï¼Œsuccess={url_result.get('success')}")

            url_quality_info = None
            if url_result.get("success"):
                url_quality_info = url_result["data"]
                logger.info(f"  MCP URLè´¨é‡: {url_quality_info['quality']}")
                logger.info(f"  MCP URLå®Œæ•´æ•°æ®: filter={url_quality_info.get('filter')}, reason={url_quality_info.get('reason')}")
            else:
                logger.warning(f"  MCP URLéªŒè¯å¤±è´¥: {url_result}")

            # 2. å¤„ç†URLè¿‡æ»¤ï¼ˆå¦‚æœURLåº”è¯¥è¢«è¿‡æ»¤ï¼Œç›´æ¥è¿”å›ï¼‰
            logger.info(f"[ğŸ” URLè¿‡æ»¤æ£€æŸ¥] url_quality_infoå­˜åœ¨={url_quality_info is not None}, filter={url_quality_info.get('filter') if url_quality_info else 'N/A'}")
            if url_quality_info and url_quality_info.get('filter'):
                # åº”è¯¥è¿‡æ»¤çš„URLï¼ˆç¤¾äº¤åª’ä½“ç­‰ï¼‰
                score = 0.0
                reason = f"ä¸æ¨èï¼ˆ{url_quality_info['reason']}ï¼‰"

                logger.warning(f"[ğŸš¨ MCPå·¥å…·éªŒè¯] URLåº”è¿‡æ»¤: {score}")
                logger.warning(f"   ç†ç”±: {reason}")
                logger.warning(f"[âœ… MCPå·¥å…·éªŒè¯] è¿”å›URLè¿‡æ»¤ç»“æœï¼Œé€€å‡ºå‡½æ•°")

                return {
                    'score': score,
                    'confidence': 'high',
                    'reason': reason,
                    'identified_grade': None,
                    'identified_subject': None,
                    'validation_type': 'url_filter',
                    'url_quality': url_quality_info
                }
            else:
                logger.info(f"[â„¹ï¸ URLè¿‡æ»¤æ£€æŸ¥] URLä¸éœ€è¦è¿‡æ»¤æˆ–æ— æ³•åˆ¤æ–­ï¼Œç»§ç»­å¤„ç†")

            # 3. æå–å¹´çº§
            grade_result = await extract_grade_from_title(title, country_code)

            identified_grade_info = None
            identified_grade = None
            if grade_result.get("success"):
                identified_grade_info = grade_result["data"]
                identified_grade = identified_grade_info.get("local_name") or identified_grade_info.get("grade_name")
                logger.info(f"  MCPè¯†åˆ«å¹´çº§: {identified_grade_info['grade_name']} ({identified_grade_info['local_name']})")
            else:
                logger.info(f"  MCPæ— æ³•è¯†åˆ«å¹´çº§")
                # å¦‚æœæ— æ³•è¯†åˆ«å¹´çº§ï¼Œä»ç„¶ç»§ç»­æ£€æŸ¥å­¦ç§‘ï¼ˆä½†ç¨åå¯èƒ½è¿”å›Noneï¼‰

            # 4. æå–å­¦ç§‘
            subject_result = await extract_subject_from_title(title, country_code)

            identified_subject_info = None
            identified_subject = None
            if subject_result.get("success"):
                identified_subject_info = subject_result["data"]
                identified_subject = identified_subject_info.get("local_name") or identified_subject_info.get("subject_name")
                logger.info(f"  MCPè¯†åˆ«å­¦ç§‘: {identified_subject_info['subject_name']} ({identified_subject_info['local_name']})")

            # 5. éªŒè¯å¹´çº§åŒ¹é…
            if identified_grade and target_grade:
                # è§„èŒƒåŒ–å¹´çº§åç§°ï¼ˆå¤„ç† "Kelas 1 / ä¸€å¹´çº§" è¿™ç§æ ¼å¼ï¼‰
                normalized_target = target_grade.split('/')[0].strip() if '/' in target_grade else target_grade

                validation_result = await validate_grade_match(normalized_target, identified_grade, country_code)

                if validation_result.get("success"):
                    match_info = validation_result["data"]
                    is_match = match_info.get("match", False)

                    if not is_match:
                        # å¹´çº§ä¸åŒ¹é…ï¼Œå¼ºåˆ¶ä½åˆ†
                        score = 2.0  # å¼ºåˆ¶ä½åˆ†

                        reason_parts = []
                        reason_parts.append(f"å¹´çº§ä¸ç¬¦ï¼ˆç›®æ ‡{match_info['target_grade_name']}ï¼Œæ ‡é¢˜{match_info['identified_grade_name']}ï¼‰")

                        # æ£€æŸ¥å­¦ç§‘
                        if identified_subject and target_subject:
                            normalized_subject = target_subject.split('/')[0].strip() if '/' in target_subject else target_subject
                            if identified_subject == normalized_subject or \
                               identified_subject_info.get('subject_name') == normalized_subject:
                                score = 2.5  # å­¦ç§‘æ­£ç¡®ï¼Œä½†å¹´çº§ä¸ç¬¦
                                reason_parts.append(f"å­¦ç§‘æ­£ç¡®ï¼ˆ{identified_subject}ï¼‰")

                        reason = "ï¼Œ".join(reason_parts) + "ï¼Œä¸æ¨è"

                        logger.warning(f"[ğŸš¨ MCPå·¥å…·éªŒè¯] å¹´çº§ä¸ç¬¦ï¼Œå¼ºåˆ¶ä½åˆ†: {score}")
                        logger.warning(f"   ç†ç”±: {reason}")

                        return {
                            'score': score,
                            'confidence': 'high',
                            'reason': reason,
                            'identified_grade': identified_grade,
                            'identified_subject': identified_subject,
                            'validation_type': 'grade_mismatch',
                            'match_info': match_info
                        }

            # 6. å¹´çº§åŒ¹é…ï¼Œç»™é«˜åˆ†
            if identified_grade:
                score = 9.0  # åŸºç¡€åˆ†

                reason_parts = [
                    f"å¹´çº§åŒ¹é…ï¼ˆ{identified_grade_info['grade_name']}ï¼‰"
                ]

                # æ£€æŸ¥å­¦ç§‘
                if identified_subject and target_subject:
                    normalized_subject = target_subject.split('/')[0].strip() if '/' in target_subject else target_subject
                    if identified_subject == normalized_subject or \
                       identified_subject_info.get('subject_name') == normalized_subject:
                        score = 9.5  # å­¦ç§‘ä¹Ÿæ­£ç¡®
                        reason_parts.append(f"å­¦ç§‘åŒ¹é…ï¼ˆ{identified_subject_info['subject_name']}ï¼‰")
                    else:
                        score = 8.0  # å­¦ç§‘ç›¸å…³
                        reason_parts.append(f"å­¦ç§‘ç›¸å…³ï¼ˆ{identified_subject_info['subject_name']}ï¼‰")

                # URLè´¨é‡åŠ åˆ†
                if url_quality_info:
                    score_adjustment = url_quality_info.get('score_adjustment', 0)
                    if score_adjustment > 0:
                        score += score_adjustment
                        if url_quality_info.get('reason') == 'youtube_playlist':
                            reason_parts.append("YouTubeæ’­æ”¾åˆ—è¡¨")
                        elif url_quality_info.get('reason') == 'trusted_platform':
                            reason_parts.append("æ¥è‡ªå¯ä¿¡å¹³å°")

                score = min(score, 10.0)  # æœ€é«˜10åˆ†
                reason = "ï¼Œ".join(reason_parts) + "ï¼Œæ¥è‡ªå¯ä¿¡å¹³å°" if score_adjustment > 0 else "ï¼Œé«˜åº¦åŒ¹é…"

                logger.info(f"[âœ… MCPå·¥å…·éªŒè¯] å¹´çº§åŒ¹é…ï¼Œç»™é«˜åˆ†: {score}")
                logger.info(f"   ç†ç”±: {reason}")

                return {
                    'score': score,
                    'confidence': 'high',
                    'reason': reason,
                    'identified_grade': identified_grade,
                    'identified_subject': identified_subject,
                    'validation_type': 'grade_match',
                    'url_quality': url_quality_info
                }

            # æ— æ³•ç”¨MCPå·¥å…·åˆ¤æ–­
            logger.info(f"[â„¹ï¸ MCPå·¥å…·éªŒè¯] æ— æ³•æ˜ç¡®åˆ¤æ–­ï¼Œäº¤ç»™è§„åˆ™éªŒè¯æˆ–LLM")
            return None

        except ImportError as e:
            logger.warning(f"[âš ï¸ MCPå·¥å…·éªŒè¯] æ— æ³•å¯¼å…¥MCPå·¥å…·: {e}")
            return None
        except Exception as e:
            logger.error(f"[âŒ MCPå·¥å…·éªŒè¯] éªŒè¯å¤±è´¥: {str(e)}", exc_info=True)
            logger.error(f"[âŒ MCPå·¥å…·éªŒè¯] ç»“æœæ ‡é¢˜: {title[:80] if title else 'N/A'}")
            logger.error(f"[âŒ MCPå·¥å…·éªŒè¯] URL: {url[:80] if url else 'N/A'}")
            return None

    def _validate_with_rules(
        self,
        result: Dict[str, Any],
        metadata: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """
        ä½¿ç”¨è§„åˆ™éªŒè¯è¯„åˆ†ï¼ˆé˜¿æ‹‰ä¼¯è¯­æ ‡å‡†åŒ–ï¼‰

        ä¼˜å…ˆçº§ï¼šè§„åˆ™éªŒè¯ > LLMè¯„åˆ†
        ç”¨äºå¿«é€Ÿã€å‡†ç¡®åœ°è¯†åˆ«æ˜æ˜¾çš„å¹´çº§/å­¦ç§‘åŒ¹é…é—®é¢˜

        Args:
            result: æœç´¢ç»“æœå­—å…¸
            metadata: å…ƒæ•°æ®ï¼ˆå›½å®¶ã€å¹´çº§ã€å­¦ç§‘ï¼‰

        Returns:
            éªŒè¯ç»“æœï¼Œå¦‚æœæ— æ³•åˆ¤æ–­åˆ™è¿”å›None
            {
                "score": è¯„åˆ†,
                "confidence": "high/medium/low",
                "reason": "ç†ç”±",
                "identified_grade": "è¯†åˆ«çš„å¹´çº§",
                "identified_subject": "è¯†åˆ«çš„å­¦ç§‘"
            }
        """
        title = result.get('title', '')
        if not title:
            return None

        # æå–ç›®æ ‡å¹´çº§å’Œå­¦ç§‘
        target_grade = metadata.get('grade', '')
        target_subject = metadata.get('subject', '')
        target_country = metadata.get('country', '')

        # åˆ¤æ–­æ˜¯å¦æ˜¯é˜¿æ‹‰ä¼¯è¯­å†…å®¹
        if not ArabicNormalizer.is_arabic_text(title):
            return None

        logger.info(f"[ğŸ” è§„åˆ™éªŒè¯] æ£€æŸ¥é˜¿æ‹‰ä¼¯è¯­æ ‡é¢˜: {title[:60]}...")

        # æå–å¹´çº§
        grade_info = ArabicNormalizer.extract_grade(title)
        # æå–å­¦ç§‘
        subject_info = ArabicNormalizer.extract_subject(title)

        identified_grade = grade_info['grade']
        identified_subject = subject_info['subject']

        logger.info(f"  è¯†åˆ«å¹´çº§: {identified_grade} ({grade_info['grade_arabic']})")
        logger.info(f"  è¯†åˆ«å­¦ç§‘: {identified_subject} ({subject_info['subject_arabic'] if subject_info['subject_arabic'] else 'N/A'})")

        # è§„åˆ™1: æ˜ç¡®çš„å¹´çº§ä¸ç¬¦
        if identified_grade and identified_grade != target_grade:
            # å¹´çº§ä¸ç¬¦ï¼Œå¼ºåˆ¶ä½åˆ†
            score = 3.0  # å¼ºåˆ¶ä½åˆ†

            reason_parts = [
                f"è¯†åˆ«ä¸º{identified_grade}ï¼ˆ{grade_info['grade_arabic']}ï¼‰"
            ]

            # æ£€æŸ¥å­¦ç§‘
            if identified_subject and identified_subject == target_subject:
                score = 3.0  # å­¦ç§‘æ­£ç¡®ï¼Œä½†å¹´çº§ä¸ç¬¦
                reason_parts.append(f"å­¦ç§‘æ­£ç¡®ï¼ˆ{identified_subject}ï¼‰")
            else:
                score = 2.0  # å¹´çº§å’Œå­¦ç§‘éƒ½ä¸ç¬¦
                if identified_subject:
                    reason_parts.append(f"å­¦ç§‘ä¸ç¬¦ï¼ˆ{identified_subject}ï¼Œç›®æ ‡{target_subject}ï¼‰")
                else:
                    reason_parts.append(f"å­¦ç§‘æœªæ˜ç¡®")

            reason = "ï¼Œ".join(reason_parts) + f"ï¼Œä¸ç›®æ ‡{target_grade}ä¸ç¬¦ï¼Œå¤§å¹…å‡åˆ†"

            logger.warning(f"[ğŸš¨ è§„åˆ™éªŒè¯] å¹´çº§ä¸ç¬¦ï¼Œå¼ºåˆ¶ä½åˆ†: {score}")
            logger.warning(f"   ç†ç”±: {reason}")

            return {
                'score': score,
                'confidence': 'high',
                'reason': reason,
                'identified_grade': identified_grade,
                'identified_subject': identified_subject,
                'validation_type': 'grade_mismatch'
            }

        # è§„åˆ™2: æ˜ç¡®çš„å¹´çº§åŒ¹é…
        if identified_grade and identified_grade == target_grade:
            # å¹´çº§æ­£ç¡®ï¼Œç»™é«˜åˆ†
            score = 9.0  # åŸºç¡€åˆ†

            reason_parts = [
                f"å¹´çº§æ­£ç¡®ï¼ˆ{identified_grade} - {grade_info['grade_arabic']}ï¼‰"
            ]

            # æ£€æŸ¥å­¦ç§‘
            if identified_subject and identified_subject == target_subject:
                score = 9.5  # å­¦ç§‘ä¹Ÿæ­£ç¡®ï¼Œç»™æ›´é«˜åˆ†
                reason_parts.append(f"å­¦ç§‘æ­£ç¡®ï¼ˆ{identified_subject}ï¼‰")
            elif identified_subject:
                score = 8.0  # å­¦ç§‘ç›¸å…³
                reason_parts.append(f"å­¦ç§‘ç›¸å…³ï¼ˆ{identified_subject}ï¼‰")
            else:
                reason_parts.append("å­¦ç§‘åŒ¹é…ï¼ˆæ•°å­¦ï¼‰")

            # æ£€æŸ¥æ˜¯å¦æ˜¯æ’­æ”¾åˆ—è¡¨
            if 'playlist' in result.get('url', '').lower() or 'list' in result.get('url', '').lower():
                score += 0.5  # æ’­æ”¾åˆ—è¡¨åŠ åˆ†
                reason_parts.append("å®Œæ•´æ’­æ”¾åˆ—è¡¨")

            score = min(score, 10.0)  # æœ€é«˜10åˆ†
            reason = "ï¼Œ".join(reason_parts) + "ï¼Œé«˜åº¦åŒ¹é…"

            logger.info(f"[âœ… è§„åˆ™éªŒè¯] å¹´çº§æ­£ç¡®ï¼Œç»™é«˜åˆ†: {score}")
            logger.info(f"   ç†ç”±: {reason}")

            return {
                'score': score,
                'confidence': 'high',
                'reason': reason,
                'identified_grade': identified_grade,
                'identified_subject': identified_subject,
                'validation_type': 'grade_match'
            }

        # è§„åˆ™3: å¹´çº§ä¸æ˜ç¡®ï¼Œä½†å­¦ç§‘æ­£ç¡®
        if not identified_grade and identified_subject and identified_subject == target_subject:
            score = 6.0  # ä¸­ç­‰åˆ†

            reason = f"å­¦ç§‘æ­£ç¡®ï¼ˆ{identified_subject}ï¼‰ï¼Œä½†å¹´çº§ä¸æ˜ç¡®ï¼Œç»™ä¸­ç­‰åˆ†"

            logger.info(f"[âš ï¸ è§„åˆ™éªŒè¯] å¹´çº§ä¸æ˜ç¡®ï¼Œç»™ä¸­ç­‰åˆ†: {score}")
            logger.info(f"   ç†ç”±: {reason}")

            return {
                'score': score,
                'confidence': 'medium',
                'reason': reason,
                'identified_grade': None,
                'identified_subject': identified_subject,
                'validation_type': 'grade_unclear'
            }

        # æ— æ³•ç”¨è§„åˆ™åˆ¤æ–­
        logger.info(f"[â„¹ï¸ è§„åˆ™éªŒè¯] æ— æ³•æ˜ç¡®åˆ¤æ–­ï¼Œäº¤ç»™LLM")
        return None

    def _extract_grade_subject_batch(
        self,
        results: List[Dict[str, Any]],
        metadata: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡æå–æ‰€æœ‰ç»“æœçš„å¹´çº§å’Œå­¦ç§‘ä¿¡æ¯ï¼ˆä¼˜åŒ–æ€§èƒ½ï¼‰.

        Issue #037: Sequential LLM Calls Bottleneck - FIXED
        å°†åŸæœ¬çš„ NÃ—2 æ¬¡LLMè°ƒç”¨ï¼ˆæ¯ä¸ªç»“æœ2æ¬¡è°ƒç”¨ï¼‰ä¼˜åŒ–ä¸º1æ¬¡æ‰¹é‡è°ƒç”¨.

        Args:
            results: æœç´¢ç»“æœåˆ—è¡¨
            metadata: å…ƒæ•°æ®ï¼ˆåŒ…å«grade, subject, language_codeï¼‰

        Returns:
            æå–ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« {"grade": str|null, "subject": str|null}
        """
        if not self.llm_client or not results:
            # è¿”å›ç©ºç»“æœåˆ—è¡¨
            return [{"grade": None, "subject": None} for _ in results]

        target_grade = metadata.get('grade', '')
        target_subject = metadata.get('subject', '')
        language = metadata.get('language_code', 'zh')

        # å¤„ç†æ··åˆæ ¼å¼çš„å¹´çº§/å­¦ç§‘
        if '/' in target_grade:
            target_grade = target_grade.split('/')[-1].strip()
        if '/' in target_subject:
            target_subject = target_subject.split('/')[-1].strip()

        try:
            # æ„å»ºæ‰¹é‡æå–çš„prompt
            result_lines = []
            for idx, result in enumerate(results):
                title = result.get('title', '')[:100]  # é™åˆ¶é•¿åº¦
                result_lines.append(f"{idx + 1}. {title}")

            prompt = f"""ä»ä»¥ä¸‹{len(results)}ä¸ªèµ„æºæ ‡é¢˜ä¸­æ‰¹é‡æå–å¹´çº§å’Œå­¦ç§‘ä¿¡æ¯ã€‚

ã€ç›®æ ‡å¹´çº§ã€‘{target_grade}
ã€ç›®æ ‡å­¦ç§‘ã€‘{target_subject}
ã€è¯­è¨€ã€‘{language}

ã€èµ„æºæ ‡é¢˜ã€‘
{chr(10).join(result_lines)}

ã€ä»»åŠ¡ã€‘
ä¸ºæ¯ä¸ªæ ‡é¢˜æå–å¹´çº§å’Œå­¦ç§‘ï¼Œè¿”å›JSONæ•°ç»„æ ¼å¼ã€‚

ã€è¾“å‡ºæ ¼å¼ã€‘ï¼ˆä¸¥æ ¼JSONæ•°ç»„ï¼‰
[
  {{"grade": "æå–çš„å¹´çº§ä¸­æ–‡åæˆ–null", "subject": "æå–çš„å­¦ç§‘ä¸­æ–‡åæˆ–null"}},
  ...
]

æ³¨æ„ï¼š
1. å¦‚æœæ ‡é¢˜ä¸­æ²¡æœ‰å¹´çº§ä¿¡æ¯ï¼Œè¿”å›null
2. å¦‚æœæ ‡é¢˜ä¸­æ²¡æœ‰å­¦ç§‘ä¿¡æ¯ï¼Œè¿”å›null
3. å¹´çº§å¿…é¡»æ˜¯ä¸­æ–‡ï¼ˆä¸€å¹´çº§åˆ°åäºŒå¹´çº§ï¼‰
4. å­¦ç§‘å¿…é¡»æ˜¯ä¸­æ–‡ï¼ˆæ•°å­¦ã€è¯­æ–‡ã€è‹±è¯­ã€è‰ºæœ¯ã€ä½“è‚²ç­‰ï¼‰
5. åªè¿”å›JSONæ•°ç»„ï¼Œä¸è¦å…¶ä»–å†…å®¹

ç°åœ¨è¯·å¤„ç†å¹¶è¿”å›JSONæ•°ç»„ï¼š"""

            # å•æ¬¡LLMè°ƒç”¨æå–æ‰€æœ‰ç»“æœï¼ˆä¼˜åŒ–ï¼š120ç§’â†’3-6ç§’ï¼‰
            logger.info(f"[ğŸš€ æ‰¹é‡æå–] ä½¿ç”¨1æ¬¡LLMè°ƒç”¨æå–{len(results)}ä¸ªç»“æœçš„å¹´çº§å’Œå­¦ç§‘")
            response = self.llm_client.call_llm(
                prompt=prompt,
                max_tokens=50 * len(results),  # æ¯ä¸ªç»“æœçº¦50 tokens
                temperature=0.3,
                model='gemini-2.5-flash'  # ä½¿ç”¨å¿«é€Ÿæ¨¡å‹
            )

            # è§£ææ‰¹é‡å“åº”
            import json
            import re

            # æ¸…ç†å“åº”
            response_clean = response.strip()
            if '```json' in response_clean:
                response_clean = response_clean.split('```json')[1].split('```')[0].strip()
            elif '```' in response_clean:
                response_clean = response_clean.split('```')[1].split('```')[0].strip()

            # æå–JSONæ•°ç»„
            json_match = re.search(r'\[.*\]', response_clean, re.DOTALL)
            if json_match:
                extractions = json.loads(json_match.group())

                # éªŒè¯å¹¶è¡¥å……ç»“æœ
                if isinstance(extractions, list):
                    # è¡¥å……ç¼ºå¤±çš„ç»“æœ
                    while len(extractions) < len(results):
                        extractions.append({"grade": None, "subject": None})

                    # æˆªæ–­å¤šä½™çš„ç»“æœ
                    extractions = extractions[:len(results)]

                    logger.info(f"[âœ… æ‰¹é‡æå–æˆåŠŸ] æå–äº†{len(extractions)}ä¸ªç»“æœ")
                    return extractions

        except Exception as e:
            logger.warning(f"[âš ï¸ æ‰¹é‡æå–å¤±è´¥] {e}ï¼Œå°†å›é€€åˆ°é€ä¸ªæå–")

        # å›é€€ï¼šé€ä¸ªæå–ï¼ˆä»æ¯”åŸå§‹çš„2Ã—Næ¬¡è°ƒç”¨æ›´ä¼˜ï¼‰
        logger.info(f"[ğŸ”„ å›é€€åˆ°é€ä¸ªæå–] ä½¿ç”¨ç¼“å­˜ä¼˜åŒ–çš„é€ä¸ªæå–")
        fallback_results = []
        for result in results:
            grade = self._extract_grade_from_title(
                result.get('title', ''),
                target_grade,
                language
            )
            subject = self._extract_subject_from_title(
                result.get('title', ''),
                target_subject,
                language
            )
            fallback_results.append({
                "grade": grade,
                "subject": subject
            })

        return fallback_results

    def _validate_and_correct_score(
        self,
        result: Dict[str, Any],
        metadata: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        éªŒè¯å¹¶çº æ­£LLMè¯„åˆ†çš„æ˜æ˜¾é”™è¯¯

        æ£€æŸ¥é¡¹ï¼š
        1. å¹´çº§ä¸åŒ¹é… â†’ å¤§å¹…é™åˆ†
        2. å­¦ç§‘ä¸åŒ¹é… â†’ å¤§å¹…é™åˆ†
        3. å¹´çº§/å­¦ç§‘åŒ¹é… â†’ æ›´æ–°æ¨èç†ç”±ï¼Œä½¿å…¶æ›´å…·ä½“

        Args:
            result: åŒ…å«scoreå’Œrecommendation_reasonçš„ç»“æœå­—å…¸
            metadata: å…ƒæ•°æ®ï¼ˆgrade, subject, language_codeï¼‰

        Returns:
            éªŒè¯å¹¶çº æ­£åçš„ç»“æœå­—å…¸
        """
        # âœ… å¦‚æœè¯„ä¼°æ–¹æ³•æ˜¯MCP Toolsï¼Œè¯´æ˜å·²ç»è¿‡MCPå·¥å…·éªŒè¯ï¼Œè·³è¿‡åå¤„ç†éªŒè¯
        # ï¼ˆMCPå·¥å…·çš„éªŒè¯æ›´å‡†ç¡®ï¼Œä¸éœ€è¦LLMå†æ¬¡éªŒè¯ï¼‰
        evaluation_method = result.get('evaluation_method', '')
        if evaluation_method == 'MCP Tools':
            logger.debug(f"[âœ… è·³è¿‡åå¤„ç†éªŒè¯] è¯„ä¼°æ–¹æ³•ä¸ºMCP Toolsï¼Œè¯„åˆ†å·²éªŒè¯")
            return result

        title = result.get('title', '')
        score = result.get('score', 5.0)
        reason = result.get('recommendation_reason', '')

        # è·å–ç›®æ ‡å¹´çº§å’Œå­¦ç§‘
        target_grade = metadata.get('grade', '') if metadata else ''
        target_subject = metadata.get('subject', '') if metadata else ''
        language = metadata.get('language_code', 'zh') if metadata else 'zh'

        # âœ… å¤„ç†æ··åˆæ ¼å¼çš„å¹´çº§ï¼ˆå¦‚ï¼š"Ø§Ù„ØµÙ Ø§Ù„Ø£ÙˆÙ„ / ä¸€å¹´çº§" â†’ "ä¸€å¹´çº§"ï¼‰
        if '/' in target_grade:
            # æå–ä¸­æ–‡éƒ¨åˆ†
            target_grade = target_grade.split('/')[1].strip() if len(target_grade.split('/')) > 1 else target_grade.split('/')[0].strip()

        # âœ… å¤„ç†æ··åˆæ ¼å¼çš„å­¦ç§‘ï¼ˆå¦‚ï¼š"Ø§Ù„ØªØ±Ø¨ÙŠØ© Ø§Ù„Ø¨Ø¯Ù†ÙŠØ© / ä½“è‚²" â†’ "ä½“è‚²"ï¼‰
        if '/' in target_subject:
            # æå–ä¸­æ–‡éƒ¨åˆ†
            target_subject = target_subject.split('/')[1].strip() if len(target_subject.split('/')) > 1 else target_subject.split('/')[0].strip()

        # âœ… ä¼˜å…ˆä½¿ç”¨MCPå·¥å…·æå–å¹´çº§å’Œå­¦ç§‘ï¼ˆæ›´å‡†ç¡®ï¼‰
        extracted_grade = None
        extracted_subject = None

        # è·å–å›½å®¶ä»£ç 
        country_code = metadata.get('country', 'ID') if metadata else 'ID'

        # å°è¯•ä½¿ç”¨MCPå·¥å…·æå–
        try:
            from mcp_tools import extract_grade_from_title, extract_subject_from_title
            import asyncio
            import threading

            def extract_with_mcp():
                try:
                    new_loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(new_loop)
                    try:
                        # æå–å¹´çº§
                        grade_result = new_loop.run_until_complete(
                            extract_grade_from_title(title, country_code)
                        )
                        if grade_result.get('success') and grade_result.get('data'):
                            nonlocal extracted_grade
                            extracted_grade = grade_result['data'].get('grade_name', '')

                        # æå–å­¦ç§‘
                        subject_result = new_loop.run_until_complete(
                            extract_subject_from_title(title, country_code)
                        )
                        if subject_result.get('success') and subject_result.get('data'):
                            nonlocal extracted_subject
                            extracted_subject = subject_result['data'].get('subject_name', '')
                    finally:
                        new_loop.close()
                except Exception as e:
                    logger.debug(f"[MCPæå–å¤±è´¥] {str(e)[:50]}")

            # åœ¨æ–°çº¿ç¨‹ä¸­æ‰§è¡Œ
            thread = threading.Thread(target=extract_with_mcp)
            thread.start()
            thread.join(timeout=5)  # 5ç§’è¶…æ—¶

            if extracted_grade or extracted_subject:
                logger.info(f"[âœ… MCPåå¤„ç†æå–] å¹´çº§={extracted_grade}, å­¦ç§‘={extracted_subject}")
        except Exception as e:
            logger.debug(f"[MCPåå¤„ç†å¤±è´¥] {str(e)[:50]}")

        # âŒ é™çº§ï¼šå¦‚æœMCPå·¥å…·æœªæå–åˆ°ï¼Œä½¿ç”¨LLMæå–ï¼ˆå¯èƒ½ä¸å‡†ç¡®ï¼‰
        if not extracted_grade:
            extracted_grade = self._extract_grade_from_title(title, target_grade, language)
        if not extracted_subject:
            extracted_subject = self._extract_subject_from_title(title, target_subject, language)

        # æ£€æŸ¥å¹´çº§åŒ¹é…æƒ…å†µ
        grade_matched = (extracted_grade and target_grade and extracted_grade == target_grade)
        grade_mismatched = (extracted_grade and target_grade and extracted_grade != target_grade)
        grade_unrecognized = (not extracted_grade)  # âš ï¸ å¹´çº§æ— æ³•è¯†åˆ«

        # æ£€æŸ¥å­¦ç§‘åŒ¹é…æƒ…å†µ
        subject_matched = (extracted_subject and target_subject and extracted_subject == target_subject)
        subject_mismatched = (extracted_subject and target_subject and extracted_subject != target_subject)
        subject_unrecognized = (not extracted_subject)  # âš ï¸ å­¦ç§‘æ— æ³•è¯†åˆ«

        # âš ï¸ ä¼˜å…ˆå¤„ç†æ— æ³•è¯†åˆ«å¹´çº§/å­¦ç§‘ä½†ç»™é«˜åˆ†çš„æƒ…å†µ
        if grade_unrecognized and score > 7.0:
            # å¹´çº§æ— æ³•è¯†åˆ«ä½†ç»™é«˜åˆ† â†’ é™åˆ†
            logger.warning(
                f"[è¯„åˆ†éªŒè¯] å¹´çº§æ— æ³•è¯†åˆ«ä½†ç»™é«˜åˆ†ï¼štitle={title[:50]}, "
                f"score={score}, target_grade={target_grade}"
            )

            # é™åˆ†åˆ°ä¸­ç­‰åˆ†æ•°
            score = 5.0
            reason = "å¹´çº§æ— æ³•ä»æ ‡é¢˜ä¸­è¯†åˆ«ï¼Œæ— æ³•ç¡®è®¤æ˜¯å¦åŒ¹é…ï¼Œå»ºè®®è°¨æ…ä½¿ç”¨"

        elif subject_unrecognized and score > 7.0:
            # å­¦ç§‘æ— æ³•è¯†åˆ«ä½†ç»™é«˜åˆ† â†’ é™åˆ†
            logger.warning(
                f"[è¯„åˆ†éªŒè¯] å­¦ç§‘æ— æ³•è¯†åˆ«ä½†ç»™é«˜åˆ†ï¼štitle={title[:50]}, "
                f"score={score}, target_subject={target_subject}"
            )

            # é™åˆ†
            score = max(score - 2.0, 5.0)
            reason = "å­¦ç§‘æ— æ³•ä»æ ‡é¢˜ä¸­è¯†åˆ«ï¼Œç›¸å…³æ€§ä¸æ˜ç¡®"

        # å¤„ç†æ˜ç¡®çš„ä¸åŒ¹é…æƒ…å†µ
        elif grade_mismatched:
            # å¹´çº§ä¸åŒ¹é…ï¼Œå¤§å¹…é™åˆ†
            logger.warning(
                f"[è¯„åˆ†éªŒè¯] å¹´çº§ä¸åŒ¹é…ï¼šç›®æ ‡={target_grade}, "
                f"æ ‡é¢˜={title[:50]}, æå–={extracted_grade}"
            )

            # ä¿®æ­£åˆ†æ•°ï¼ˆæœ€å¤š3åˆ†ï¼‰
            if score > 3.0:
                score = 2.0

            # ä¿®æ­£æ¨èç†ç”±
            if subject_mismatched:
                # å¹´çº§å’Œå­¦ç§‘éƒ½ä¸åŒ¹é…
                reason = (
                    f"å¹´çº§å’Œå­¦ç§‘éƒ½ä¸åŒ¹é…ï¼ˆç›®æ ‡ï¼š{target_grade} {target_subject}ï¼Œ"
                    f"æ ‡é¢˜ï¼š{extracted_grade} {extracted_subject}ï¼‰ï¼Œä¸æ¨è"
                )
            else:
                reason = (
                    f"å¹´çº§ä¸åŒ¹é…ï¼ˆç›®æ ‡ï¼š{target_grade}ï¼Œæ ‡é¢˜ï¼š{extracted_grade}ï¼‰ï¼Œ"
                    f"ä¸æ¨èç”¨äºå½“å‰æŸ¥è¯¢"
                )

        elif subject_mismatched:
            # å­¦ç§‘ä¸åŒ¹é…ï¼Œå¤§å¹…é™åˆ†
            logger.warning(
                f"[è¯„åˆ†éªŒè¯] å­¦ç§‘ä¸åŒ¹é…ï¼šç›®æ ‡={target_subject}, "
                f"æ ‡é¢˜={title[:50]}, æå–={extracted_subject}"
            )

            # ä¿®æ­£åˆ†æ•°ï¼ˆæœ€å¤š3åˆ†ï¼‰
            if score > 3.0:
                score = 2.0

            # ä¿®æ­£æ¨èç†ç”±
            reason = (
                f"å­¦ç§‘ä¸åŒ¹é…ï¼ˆç›®æ ‡ï¼š{target_subject}ï¼Œæ ‡é¢˜ï¼š{extracted_subject}ï¼‰ï¼Œ"
                f"ä¸æ¨èç”¨äºå½“å‰æŸ¥è¯¢"
            )

        elif grade_matched and subject_matched:
            # âœ… å¹´çº§å’Œå­¦ç§‘éƒ½åŒ¹é…ï¼Œæ›´æ–°æ¨èç†ç”±ä½¿å…¶æ›´å…·ä½“
            logger.debug(
                f"[è¯„åˆ†éªŒè¯] å®Œå…¨åŒ¹é…ï¼šç›®æ ‡={target_grade} {target_subject}, "
                f"æå–={extracted_grade} {extracted_subject}"
            )

            # åœ¨åŸæœ‰æ¨èç†ç”±å‰æ·»åŠ åŒ¹é…ä¿¡æ¯
            match_info = f"å¹´çº§å’Œå­¦ç§‘å®Œå…¨åŒ¹é…ï¼ˆ{target_grade} {target_subject}ï¼‰"
            if match_info not in reason:
                reason = f"{match_info}ã€{reason}"

        # æ›´æ–°ç»“æœ
        result['score'] = score
        result['recommendation_reason'] = reason
        result['validated'] = True

        return result


    def _generate_recommendation_reason(self, result: Dict[str, Any], score: float) -> str:
        """ç”Ÿæˆæ¨èç†ç”±"""
        reasons = []

        if score >= 8.0:
            reasons.append("é«˜è´¨é‡æ•™è‚²èµ„æº")
        elif score >= 6.0:
            reasons.append("ç›¸å…³æ€§è¾ƒé«˜çš„å†…å®¹")

        url = result.get('url', '').lower()
        title = result.get('title', '').lower()

        # æ£€æŸ¥å¯ä¿¡æ¥æº
        for domain in self.trusted_domains.keys():
            if domain in url:
                reasons.append(f"æ¥è‡ªå¯ä¿¡å¹³å° {domain}")
                break

        # æ£€æŸ¥æ’­æ”¾åˆ—è¡¨
        combined = f"{url} {title}"
        if any(kw in combined for kw in ['playlist', 'æ’­æ”¾åˆ—è¡¨', 'complete', 'å®Œæ•´']):
            reasons.append("å®Œæ•´è¯¾ç¨‹/æ’­æ”¾åˆ—è¡¨")

        # æ£€æŸ¥è§†é¢‘å†…å®¹
        if any(kw in combined for kw in self.video_keywords):
            reasons.append("è§†é¢‘èµ„æº")

        return "ã€".join(reasons) if reasons else "æ ¹æ®æœç´¢åŒ¹é…åº¦æ¨è"

    # ========================================================================
    # çŸ¥è¯†åº“é›†æˆæ–¹æ³•
    # ========================================================================

    def get_grade_variants_from_kb(self, grade: str) -> List[str]:
        """
        ä»çŸ¥è¯†åº“è·å–å¹´çº§çš„æ‰€æœ‰å·²çŸ¥è¡¨è¾¾

        Args:
            grade: å¹´çº§ (å¦‚: "2", "Grade 2")

        Returns:
            è¯¥å¹´çº§çš„æ‰€æœ‰å·²çŸ¥è¡¨è¾¾åˆ—è¡¨
        """
        if self.kb_manager:
            variants = self.kb_manager.get_grade_variants(grade)
            if variants:
                logger.debug(f"[ğŸ“š çŸ¥è¯†åº“] æ‰¾åˆ° {grade} çš„ {len(variants)} ä¸ªè¡¨è¾¾")
            return variants
        return []

    def get_subject_variants_from_kb(self, subject: str) -> List[str]:
        """
        ä»çŸ¥è¯†åº“è·å–å­¦ç§‘çš„æ‰€æœ‰å·²çŸ¥è¡¨è¾¾

        Args:
            subject: å­¦ç§‘ (å¦‚: "Mathematics", "Math")

        Returns:
            è¯¥å­¦ç§‘çš„æ‰€æœ‰å·²çŸ¥è¡¨è¾¾åˆ—è¡¨
        """
        if self.kb_manager:
            variants = self.kb_manager.get_subject_variants(subject)
            if variants:
                logger.debug(f"[ğŸ“š çŸ¥è¯†åº“] æ‰¾åˆ° {subject} çš„ {len(variants)} ä¸ªè¡¨è¾¾")
            return variants
        return []

    def validate_score_with_kb(self, title: str, score: float, reasoning: str,
                               target_grade: str) -> Tuple[bool, str]:
        """
        ä½¿ç”¨çŸ¥è¯†åº“éªŒè¯è¯„åˆ†æ˜¯å¦åˆç†

        Args:
            title: ç»“æœæ ‡é¢˜
            score: LLMè¯„åˆ†
            reasoning: LLMç†ç”±
            target_grade: ç›®æ ‡å¹´çº§

        Returns:
            (is_valid, message) - æ˜¯å¦åˆç†ï¼Œä»¥åŠè¯´æ˜
        """
        if not self.kb_manager:
            return True, "æ— çŸ¥è¯†åº“"

        # è·å–ç›®æ ‡å¹´çº§çš„æ‰€æœ‰è¡¨è¾¾
        grade_variants = self.get_grade_variants_from_kb(target_grade)

        if not grade_variants:
            # çŸ¥è¯†åº“ä¸­æ²¡æœ‰è¿™ä¸ªå¹´çº§çš„ä¿¡æ¯
            return True, "çŸ¥è¯†åº“æ— è¯¥å¹´çº§ä¿¡æ¯"

        # æ£€æŸ¥æ ‡é¢˜æ˜¯å¦åŒ…å«å¹´çº§çš„ä»»ä½•è¡¨è¾¾
        title_lower = title.lower()

        # å¯¹äºé˜¿æ‹‰ä¼¯è¯­ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†ï¼ˆè¯æ ¹åŒ¹é…ï¼‰
        grade_mentioned = False
        for variant in grade_variants:
            variant_lower = variant.lower()
            # ç›´æ¥å­ä¸²åŒ¹é…
            if variant_lower in title_lower:
                grade_mentioned = True
                break

            # é˜¿æ‹‰ä¼¯è¯­ç‰¹æ®Šå¤„ç†ï¼šæå–è¯æ ¹å¹¶æ£€æŸ¥
            # "Ø§Ù„ØµÙ" (the grade) å¯èƒ½ä»¥ "Ù„Ù„ØµÙ" (for the grade), "Ø¨Ø§Ù„ØµÙ" (in the grade) ç­‰å½¢å¼å‡ºç°
            arabic_words = [w for w in variant_lower.split() if any('\u0600' <= c <= '\u06FF' for c in w)]
            if arabic_words:
                # å¯¹äºæ¯ä¸ªé˜¿æ‹‰ä¼¯è¯ï¼Œæ£€æŸ¥å…¶è¯æ ¹æ˜¯å¦åœ¨æ ‡é¢˜ä¸­
                all_words_found = True
                for word in arabic_words:
                    # å»æ‰å®šå† è¯ "Ø§Ù„" (al-)
                    root = word[2:] if word.startswith('Ø§Ù„') else word
                    # æ£€æŸ¥è¯æ ¹æˆ–å¸¦ä¸åŒå‰ç¼€çš„å½¢å¼
                    found = (
                        word in title_lower or  # å®Œæ•´åŒ¹é…
                        root in title_lower or  # è¯æ ¹åŒ¹é…
                        f'Ù„{word}' in title_lower or  # å¸¦"Ù„"å‰ç¼€
                        f'Ù„{root}' in title_lower or  # Ù„+è¯æ ¹
                        f'Ø¨{word}' in title_lower or  # å¸¦"Ø¨"å‰ç¼€
                        f'Ùƒ{word}' in title_lower  # å¸¦"Ùƒ"å‰ç¼€
                    )
                    if not found:
                        all_words_found = False
                        break

                if all_words_found:
                    grade_mentioned = True
                    break

        if grade_mentioned:
            # æ ‡é¢˜æ˜ç¡®æåˆ°äº†å¹´çº§
            # æ£€æŸ¥reasoningæ˜¯å¦å£°ç§°å¹´çº§ä¸åŒ¹é…/æœªæåŠï¼Œä½†è¯„åˆ†åˆå¾ˆä½
            mismatch_keywords = ["æœªæåŠ", "ä¸åŒ¹é…", "ä¸ç¬¦", "å¹´çº§ä¸ç¬¦", "æ˜¾ç¤ºä¸º"]
            has_mismatch_claim = any(kw in reasoning for kw in mismatch_keywords)

            if has_mismatch_claim and score < 6.0:
                # LLMè¯´"æœªæåŠ"ä½†å®é™…ä¸Šæ ‡é¢˜æåˆ°äº†
                error_msg = f"æ ‡é¢˜åŒ…å«å¹´çº§è¡¨è¾¾ä½†LLMæœªè¯†åˆ«: {title}"
                logger.warning(f"[ğŸ“š çŸ¥è¯†åº“] âš ï¸ å¯ç–‘è¯„åˆ†: {error_msg}")
                logger.warning(f"   å¹´çº§å˜ä½“: {grade_variants}")
                logger.warning(f"   è¯„åˆ†: {score}, ç†ç”±: {reasoning}")

                # è®°å½•åˆ°çŸ¥è¯†åº“
                self.kb_manager.record_llm_mistake(
                    mistake_type="grade_detection_failure",
                    example=f"{title} (è¯„åˆ†: {score}, ç†ç”±: {reasoning})",
                    correction=f"æ ‡é¢˜åŒ…å«å¹´çº§è¡¨è¾¾: {grade_variants}",
                    severity="high"
                )

                return False, error_msg

        return True, "OK"

    def record_llm_mistake(self, mistake_type: str, example: str,
                          correction: str, severity: str = "high"):
        """
        è®°å½•LLMé”™è¯¯åˆ°çŸ¥è¯†åº“

        Args:
            mistake_type: é”™è¯¯ç±»å‹
            example: é”™è¯¯ç¤ºä¾‹
            correction: ä¿®æ­£æ–¹æ¡ˆ
            severity: ä¸¥é‡ç¨‹åº¦
        """
        if self.kb_manager:
            self.kb_manager.record_llm_mistake(mistake_type, example, correction, severity)


# å…¨å±€å•ä¾‹
_global_scorer: Optional[IntelligentResultScorer] = None


def get_result_scorer() -> IntelligentResultScorer:
    """è·å–å…¨å±€ç»“æœè¯„åˆ†å™¨å®ä¾‹"""
    global _global_scorer
    if _global_scorer is None:
        _global_scorer = IntelligentResultScorer()
    return _global_scorer


def get_result_scorer_with_kb(country_code: str) -> IntelligentResultScorer:
    """
    è·å–å¸¦çŸ¥è¯†åº“çš„ç»“æœè¯„åˆ†å™¨å®ä¾‹

    Args:
        country_code: å›½å®¶ä»£ç  (å¦‚: IQ, ID, CN)

    Returns:
        å¸¦çŸ¥è¯†åº“çš„è¯„åˆ†å™¨å®ä¾‹
    """
    return IntelligentResultScorer(country_code=country_code)


IntelligentResultScorer.get_result_scorer_with_kb = staticmethod(get_result_scorer_with_kb)


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("=" * 50)
    print("æ™ºèƒ½ç»“æœè¯„åˆ†æµ‹è¯•")
    print("=" * 50)

    scorer = IntelligentResultScorer()

    # æµ‹è¯•ç»“æœ
    test_results = [
        {
            "title": "Kelas 10 Matematika: Lengkap Video Pembelajaran",
            "url": "https://www.youtube.com/playlist?list=example",
            "snippet": "Video pembelajaran matematika lengkap untuk kelas 10. Cover aljabar, geometri, statistik, dan banyak lagi. 200+ video tersedia."
        },
        {
            "title": "Math Tutorial",
            "url": "https://bit.ly/math123",
            "snippet": "Short math tutorial"
        },
        {
            "title": "Khan Academy: Mathematics Grade 10",
            "url": "https://www.khanacademy.org/math/grade-10",
            "snippet": "Comprehensive mathematics courses for grade 10 students including algebra, geometry, and more. Interactive lessons and practice exercises."
        }
    ]

    query = "Kelas 10 Matematika"

    print(f"\næœç´¢æŸ¥è¯¢: {query}\n")
    print(f"{'æ ‡é¢˜':<60} {'è¯„åˆ†':<10} {'æ¨èç†ç”±'}")
    print("-" * 100)

    scored_results = scorer.score_results(test_results, query)

    for result in scored_results:
        title = result['title'][:57] + "..." if len(result['title']) > 60 else result['title']
        score = result['score']
        reason = result['recommendation_reason']
        print(f"{title:<60} {score:<10.2f} {reason}")

    print("\n" + "=" * 50)
    print("æµ‹è¯•å®Œæˆ")
    print("=" * 50)
