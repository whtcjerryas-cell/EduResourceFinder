#!/usr/bin/env python3
"""
å°å°¼ K12 è§†é¢‘è¯¾ç¨‹åº“æœç´¢ Agent
æ ¸å¿ƒç­–ç•¥ï¼šé€šè¿‡æ ¸å¿ƒç« èŠ‚æ‰¾åˆ°å®Œæ•´çš„æ’­æ”¾åˆ—è¡¨ (Playlist)ï¼Œè€Œä¸æ˜¯å¯»æ‰¾å•ä¸ªç¢ç‰‡åŒ–è§†é¢‘
"""

import os
import json
import csv
import re
import time
from typing import Dict, List, Optional, Any, Set
from pydantic import BaseModel, Field
import requests

# æ”¯æŒä» .env æ–‡ä»¶è¯»å–ç¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    # å¦‚æœæ²¡æœ‰ python-dotenvï¼Œæ‰‹åŠ¨è¯»å– .env æ–‡ä»¶
    def load_dotenv():
        env_file = os.path.join(os.path.dirname(__file__), '.env')
        if os.path.exists(env_file):
            with open(env_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#') and '=' in line:
                        key, value = line.split('=', 1)
                        os.environ[key.strip()] = value.strip().strip('"').strip("'")
    load_dotenv()


# ============================================================================
# æ•°æ®æ¨¡å‹å®šä¹‰ (Pydantic)
# ============================================================================

class SearchResult(BaseModel):
    """å•ä¸ªæœç´¢ç»“æœ"""
    title: str = Field(description="æœç´¢ç»“æœæ ‡é¢˜")
    url: str = Field(description="ç»“æœURL")
    snippet: str = Field(description="ç»“æœæ‘˜è¦", default="")


class EvaluationResult(BaseModel):
    """LLMè¯„ä¼°ç»“æœ"""
    is_good_batch: bool = Field(description="è¿™ä¸€æ‰¹ç»“æœé‡Œæ˜¯å¦æœ‰é«˜è´¨é‡çš„åˆ—è¡¨")
    best_urls: List[str] = Field(description="æå–å‡ºçš„åˆé›†URLåˆ—è¡¨", default_factory=list)
    feedback: str = Field(description="è¯„ä¼°åé¦ˆå’Œå»ºè®®", default="")


class ChapterInfo(BaseModel):
    """ç« èŠ‚ä¿¡æ¯"""
    grade_level: str = Field(description="å¹´çº§")
    subject: str = Field(description="å­¦ç§‘")
    chapter_title: str = Field(description="ç« èŠ‚æ ‡é¢˜")
    topics_count: int = Field(description="è¯¥ç« èŠ‚ä¸‹çš„çŸ¥è¯†ç‚¹æ•°é‡", default=0)


class PlaylistRecord(BaseModel):
    """æœ€ç»ˆè¾“å‡ºçš„æ’­æ”¾åˆ—è¡¨è®°å½•"""
    grade_level: str = Field(description="å¹´çº§")
    subject: str = Field(description="å­¦ç§‘")
    chapter_title: str = Field(description="ç« èŠ‚æ ‡é¢˜")
    playlist_url: str = Field(description="æ’­æ”¾åˆ—è¡¨URL")
    search_query: str = Field(description="ä½¿ç”¨çš„æœç´¢è¯")
    attempt_number: int = Field(description="ç¬¬å‡ æ¬¡å°è¯•æˆåŠŸ", default=1)
    reason: str = Field(description="é€‰æ‹©ç†ç”±", default="")


# ============================================================================
# AI Builders å®¢æˆ·ç«¯ (ä½¿ç”¨ç»Ÿä¸€LLMå®¢æˆ·ç«¯ï¼Œæ”¯æŒåŒAPIç³»ç»Ÿ)
# ============================================================================

# å¯¼å…¥ç»Ÿä¸€LLMå®¢æˆ·ç«¯
try:
    from llm_client import UnifiedLLMClient, AIBuildersAPIClient
    HAS_UNIFIED_CLIENT = True
except ImportError:
    HAS_UNIFIED_CLIENT = False
    print("[âš ï¸] è­¦å‘Š: æ— æ³•å¯¼å…¥ç»Ÿä¸€LLMå®¢æˆ·ç«¯ï¼Œå°†ä½¿ç”¨åŸæœ‰å®ç°")

# å¯¼å…¥æç¤ºè¯ç®¡ç†å™¨
try:
    from utils.prompt_manager import get_prompt_manager
    HAS_PROMPT_MANAGER = True
except ImportError:
    HAS_PROMPT_MANAGER = False
    print("[âš ï¸] è­¦å‘Š: æ— æ³•å¯¼å…¥æç¤ºè¯ç®¡ç†å™¨ï¼Œå°†ä½¿ç”¨åŸæœ‰å®ç°")

class AIBuildersClient:
    """
    AI Builders API å®¢æˆ·ç«¯ï¼ˆå…¼å®¹æ€§åŒ…è£…å™¨ï¼‰
    å†…éƒ¨ä½¿ç”¨ç»Ÿä¸€LLMå®¢æˆ·ç«¯ï¼Œæ”¯æŒå…¬å¸å†…éƒ¨APIå’ŒAI Builders APIçš„fallbackæœºåˆ¶
    """
    
    def __init__(self, api_token: Optional[str] = None):
        """
        åˆå§‹åŒ–å®¢æˆ·ç«¯
        
        Args:
            api_token: AI Builders API ä»¤ç‰Œï¼Œå¦‚æœä¸æä¾›åˆ™ä»ç¯å¢ƒå˜é‡è¯»å–
        """
        self.api_token = api_token or os.getenv("AI_BUILDER_TOKEN")
        
        # å°è¯•ä½¿ç”¨ç»Ÿä¸€LLMå®¢æˆ·ç«¯
        if HAS_UNIFIED_CLIENT:
            try:
                # è·å–å…¬å¸å†…éƒ¨APIå¯†é’¥ï¼ˆå¯é€‰ï¼‰
                internal_api_key = os.getenv("INTERNAL_API_KEY")
                self.unified_client = UnifiedLLMClient(
                    internal_api_key=internal_api_key,
                    ai_builder_token=self.api_token
                )
                self.use_unified_client = True
                print("[âœ…] ä½¿ç”¨ç»Ÿä¸€LLMå®¢æˆ·ç«¯ï¼ˆæ”¯æŒåŒAPIç³»ç»Ÿï¼‰")
            except Exception as e:
                print(f"[âš ï¸] ç»Ÿä¸€LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}ï¼Œå›é€€åˆ°åŸæœ‰å®ç°")
                self.use_unified_client = False
                # å›é€€åˆ°åŸæœ‰å®ç°
                if not self.api_token:
                    raise ValueError("è¯·è®¾ç½® AI_BUILDER_TOKEN ç¯å¢ƒå˜é‡æˆ–ä¼ å…¥ api_token å‚æ•°")
        else:
            self.use_unified_client = False
            if not self.api_token:
                raise ValueError("è¯·è®¾ç½® AI_BUILDER_TOKEN ç¯å¢ƒå˜é‡æˆ–ä¼ å…¥ api_token å‚æ•°")
        
        # ä¿ç•™åŸæœ‰å±æ€§ä»¥ä¿æŒå…¼å®¹æ€§
        self.base_url = "https://space.ai-builders.com/backend"
        self.headers = {
            "Authorization": f"Bearer {self.api_token or ''}",
            "Content-Type": "application/json"
        }
    
    def call_gemini(self, prompt: str, system_prompt: Optional[str] = None, 
                    max_tokens: int = 8000, temperature: float = 0.3,
                    model: str = "gemini-2.5-pro") -> str:
        """
        è°ƒç”¨ gemini-2.5-pro æ¨¡å‹
        
        Args:
            prompt: ç”¨æˆ·æç¤ºè¯
            system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰
            max_tokens: æœ€å¤§ç”Ÿæˆ token æ•°
            temperature: æ¸©åº¦å‚æ•°
        
        Returns:
            æ¨¡å‹è¿”å›çš„æ–‡æœ¬å†…å®¹
        """
        # å¦‚æœä½¿ç”¨ç»Ÿä¸€å®¢æˆ·ç«¯ï¼Œç›´æ¥è°ƒç”¨
        if self.use_unified_client:
            return self.unified_client.call_gemini(
                prompt=prompt,
                system_prompt=system_prompt,
                max_tokens=max_tokens,
                temperature=temperature
            )
        
        # å¦åˆ™ä½¿ç”¨åŸæœ‰å®ç°
        endpoint = f"{self.base_url}/v1/chat/completions"
        
        messages = []
        if system_prompt:
            messages.append({
                "role": "system",
                "content": system_prompt
            })
        messages.append({
            "role": "user",
            "content": prompt
        })
        
        payload = {
            "model": model,  # ä½¿ç”¨ä¼ å…¥çš„æ¨¡å‹å‚æ•°
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": temperature
            # ä¸è®¾ç½® tool_choice å’Œ toolsï¼Œè®© API ä½¿ç”¨é»˜è®¤è¡Œä¸º
        }
        
        # å°è¯•æ·»åŠ å®‰å…¨è®¾ç½®ï¼Œå…è®¸æ‰€æœ‰å†…å®¹ï¼ˆå¦‚æœ API æ”¯æŒï¼‰
        # æ³¨æ„ï¼šè¿™å–å†³äº API æä¾›è€…çš„å®ç°
        # å¦‚æœ API ä¸æ”¯æŒæ­¤å‚æ•°ï¼Œä¼šè¢«å¿½ç•¥
        try:
            # æŸäº› Gemini API å®ç°å¯èƒ½æ”¯æŒ safety_settings
            # ä½† AI Builders API å¯èƒ½ä¸æ”¯æŒï¼Œæ‰€ä»¥å…ˆæ³¨é‡Šæ‰
            # payload["safety_settings"] = [
            #     {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            #     {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            #     {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            #     {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"}
            # ]
            pass
        except:
            pass
        
        try:
            proxies = {
                "http": None,
                "https": None
            }
            # æ ¹æ® OpenAPI æ–‡æ¡£ï¼Œæ·»åŠ  debug=true å‚æ•°ä»¥è·å– orchestrator æ‰§è¡Œè·Ÿè¸ª
            # è¿™å¯ä»¥å¸®åŠ©æˆ‘ä»¬è¯Šæ–­ä¸ºä»€ä¹ˆè¿”å›ç©ºå†…å®¹
            params = {"debug": True}
            response = requests.post(
                endpoint,
                headers=self.headers,
                json=payload,
                params=params,  # æ·»åŠ  debug å‚æ•°
                timeout=300,
                proxies=proxies
            )
            
            if response.status_code == 200:
                result = response.json()
                if "choices" in result and len(result["choices"]) > 0:
                    message = result["choices"][0].get("message", {})
                    content = message.get("content")
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰ tool_callsï¼ˆå·¥å…·è°ƒç”¨ï¼‰
                    if message.get("tool_calls"):
                        # å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œè¯´æ˜æ¨¡å‹æƒ³è¦è°ƒç”¨å·¥å…·è€Œä¸æ˜¯ç›´æ¥è¿”å›å†…å®¹
                        tool_calls = message.get("tool_calls", [])
                        print(f"    [âš ï¸ è­¦å‘Š] LLM è¿”å›äº†å·¥å…·è°ƒç”¨è€Œä¸æ˜¯å†…å®¹ï¼Œå·¥å…·è°ƒç”¨æ•°é‡: {len(tool_calls)}")
                        # å¯¹äºè¯„ä¼°ä»»åŠ¡ï¼Œæˆ‘ä»¬ä¸å¸Œæœ›ä½¿ç”¨å·¥å…·è°ƒç”¨ï¼Œåº”è¯¥è¿”å›é”™è¯¯
                        raise ValueError("LLM è¿”å›äº†å·¥å…·è°ƒç”¨è€Œä¸æ˜¯è¯„ä¼°ç»“æœï¼Œè¯·æ£€æŸ¥æç¤ºè¯")
                    
                    if content is None:
                        raise ValueError("API å“åº”ä¸­ content å­—æ®µä¸º None")
                    
                    if not content.strip():
                        # è°ƒè¯•ï¼šæ‰“å°å®Œæ•´å“åº”ï¼ˆä»…ç”¨äºè°ƒè¯•ï¼‰
                        print(f"    [ğŸ” è°ƒè¯•] content ä¸ºç©ºå­—ç¬¦ä¸²")
                        print(f"    [ğŸ” è°ƒè¯•] finish_reason: {result['choices'][0].get('finish_reason', 'N/A')}")
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰ safety_ratings æˆ–å…¶ä»–é˜»æ­¢ä¿¡æ¯
                        choice = result['choices'][0]
                        message = choice.get('message', {})
                        
                        # æ£€æŸ¥å„ç§å¯èƒ½çš„å­—æ®µ
                        if 'safety_ratings' in choice:
                            print(f"    [ğŸ” è°ƒè¯•] safety_ratings: {choice.get('safety_ratings')}")
                        if 'finish_details' in choice:
                            print(f"    [ğŸ” è°ƒè¯•] finish_details: {choice.get('finish_details')}")
                        if 'safety_ratings' in message:
                            print(f"    [ğŸ” è°ƒè¯•] message.safety_ratings: {message.get('safety_ratings')}")
                        
                        # æ£€æŸ¥å“åº”ä¸­çš„å…¶ä»–å­—æ®µ
                        if 'prompt_feedback' in result:
                            print(f"    [ğŸ” è°ƒè¯•] prompt_feedback: {result.get('prompt_feedback')}")
                        
                        # æ£€æŸ¥ orchestrator_traceï¼ˆæ ¹æ® OpenAPI æ–‡æ¡£ï¼Œdebug=true æ—¶ä¼šåŒ…å«æ­¤å­—æ®µï¼‰
                        if 'orchestrator_trace' in result and result.get('orchestrator_trace'):
                            trace = result.get('orchestrator_trace')
                            print(f"    [ğŸ” è°ƒè¯•] orchestrator_trace å­˜åœ¨ï¼Œé•¿åº¦: {len(str(trace))}")
                            
                            # æ£€æŸ¥æ˜¯å¦æœ‰ forced_tool é…ç½®
                            rounds = trace.get('rounds', [])
                            for round_info in rounds:
                                if round_info.get('forced_tool'):
                                    forced_tool = round_info.get('forced_tool')
                                    print(f"    [âš ï¸ è­¦å‘Š] æ£€æµ‹åˆ° forced_tool: {forced_tool}")
                                    print(f"    [ğŸ’¡ å»ºè®®] æ¨¡å‹ {model} è¢«é…ç½®ä¸ºå¼ºåˆ¶ä½¿ç”¨å·¥å…· '{forced_tool}'")
                                    print(f"    [ğŸ’¡ å»ºè®®] è¯·æ”¹ç”¨ 'deepseek' æ¨¡å‹è¿›è¡Œçº¯æ–‡æœ¬ç”Ÿæˆä»»åŠ¡")
                            
                            print(f"    [ğŸ” è°ƒè¯•] orchestrator_trace å†…å®¹: {json.dumps(trace, ensure_ascii=False, indent=2)[:1000]}...")
                        else:
                            print(f"    [ğŸ” è°ƒè¯•] orchestrator_trace: ä¸å­˜åœ¨æˆ–ä¸ºç©º")
                        
                        # æ‰“å° token ä½¿ç”¨æƒ…å†µ
                        usage = result.get('usage', {})
                        print(f"    [ğŸ” è°ƒè¯•] prompt_tokens: {usage.get('prompt_tokens', 0)}")
                        print(f"    [ğŸ” è°ƒè¯•] completion_tokens: {usage.get('completion_tokens', 0)}")
                        print(f"    [ğŸ” è°ƒè¯•] total_tokens: {usage.get('total_tokens', 0)}")
                        
                        # æ‰“å°å®Œæ•´çš„åŸå§‹ JSON å“åº”ä»¥ä¾¿è°ƒè¯•ï¼ˆä»…åœ¨è¯¦ç»†æ¨¡å¼ä¸‹ï¼‰
                        print(f"    [ğŸ” è°ƒè¯•] åŸå§‹ API å“åº” JSON: {json.dumps(result, ensure_ascii=False, indent=2)}")
                        
                        # æä¾›è¯Šæ–­å»ºè®®
                        print(f"    [ğŸ’¡ å»ºè®®] LLM è¿”å›ç©ºå†…å®¹å¯èƒ½çš„åŸå› ï¼š")
                        print(f"        1. API æä¾›è€…çš„ Safety Settings é…ç½®è¿‡äºä¸¥æ ¼")
                        print(f"        2. API ç«¯ç‚¹é…ç½®é—®é¢˜")
                        print(f"        3. æ¨¡å‹ç‰ˆæœ¬æˆ–é…ç½®é—®é¢˜")
                        print(f"        å»ºè®®ï¼šè”ç³» API æä¾›è€…ï¼ˆAI Buildersï¼‰æ£€æŸ¥é…ç½®")
                        
                        raise ValueError("API å“åº”ä¸­ content ä¸ºç©ºå­—ç¬¦ä¸²")
                    
                    return content
                else:
                    raise ValueError(f"API å“åº”æ ¼å¼å¼‚å¸¸: {json.dumps(result, ensure_ascii=False)}")
            else:
                raise ValueError(f"API è°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}, å“åº”: {response.text[:500]}")
        except requests.exceptions.RequestException as e:
            raise ValueError(f"API è¯·æ±‚å¼‚å¸¸: {str(e)}")
    
    def call_llm(self, prompt: str, system_prompt: Optional[str] = None,
                 max_tokens: int = 8000, temperature: float = 0.3,  # [ä¿®å¤] 2026-01-20: ä»2000å¢åŠ åˆ°8000
                 model: str = "deepseek") -> str:
        """
        è°ƒç”¨ LLMï¼ˆæ”¯æŒ DeepSeek å’Œ Geminiï¼‰
        
        Args:
            prompt: ç”¨æˆ·æç¤ºè¯
            system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰
            max_tokens: æœ€å¤§ç”Ÿæˆ token æ•°
            temperature: æ¸©åº¦å‚æ•°
            model: æ¨¡å‹åç§°ï¼ˆdeepseek æˆ– gemini-2.5-proï¼‰
        
        Returns:
            æ¨¡å‹è¿”å›çš„æ–‡æœ¬å†…å®¹
        """
        # å¦‚æœä½¿ç”¨ç»Ÿä¸€å®¢æˆ·ç«¯ï¼Œç›´æ¥è°ƒç”¨
        if self.use_unified_client:
            return self.unified_client.call_llm(
                prompt=prompt,
                system_prompt=system_prompt,
                max_tokens=max_tokens,
                temperature=temperature,
                model=model
            )
        
        # å¦åˆ™ä½¿ç”¨åŸæœ‰å®ç°
        # å¯¹äº deepseekï¼Œä½¿ç”¨ call_gemini æ–¹æ³•ï¼ˆå› ä¸º API æ¥å£ç›¸åŒï¼‰
        # ä½†è®¾ç½® model="deepseek" å’Œ tool_choice="none"
        if model == "deepseek":
            endpoint = f"{self.base_url}/v1/chat/completions"
            
            messages = []
            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})
            messages.append({"role": "user", "content": prompt})
            
            payload = {
                "model": model,
                "messages": messages,
                "max_tokens": max_tokens,
                "temperature": temperature
                # ä¸è®¾ç½® tool_choice å’Œ toolsï¼Œè®© API ä½¿ç”¨é»˜è®¤è¡Œä¸º
            }
            
            try:
                from llm_client import get_proxy_config
                response = requests.post(
                    endpoint,
                    headers=self.headers,
                    json=payload,
                    params={"debug": "true"},
                    timeout=300,
                    proxies=None  # [ä¿®å¤] 2026-01-20: AI Builders æ˜¯å†…ç½‘ APIï¼Œä¸éœ€è¦ä»£ç†
                )
                
                if response.status_code == 200:
                    result = response.json()
                    if "choices" in result and len(result["choices"]) > 0:
                        content = result["choices"][0].get("message", {}).get("content", "")
                        if content and content.strip():
                            return content.strip()
                        else:
                            # å¦‚æœ deepseek å¤±è´¥ï¼Œå°è¯• gemini
                            if model == "deepseek":
                                print(f"    [âš ï¸ è­¦å‘Š] DeepSeek è¿”å›ç©ºå†…å®¹ï¼Œå°è¯• Gemini...")
                                return self.call_gemini(prompt, system_prompt, max_tokens, temperature, "gemini-2.5-pro")
                            raise ValueError("API å“åº”ä¸­ content ä¸ºç©ºå­—ç¬¦ä¸²")
                    else:
                        raise ValueError(f"API å“åº”æ ¼å¼å¼‚å¸¸")
                else:
                    raise ValueError(f"API è°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            except requests.exceptions.RequestException as e:
                raise ValueError(f"API è¯·æ±‚å¼‚å¸¸: {str(e)}")
        else:
            # å¯¹äºå…¶ä»–æ¨¡å‹ï¼Œä½¿ç”¨ call_gemini
            return self.call_gemini(prompt, system_prompt, max_tokens, temperature, model)
    
    def search(self, query: str, max_results: int = 10, region: str = "id",
               search_depth: str = "advanced",
               include_domains: Optional[List[str]] = None,
               country_code: Optional[str] = None) -> List[SearchResult]:
        """
        ä½¿ç”¨ AI Builders Tavily æœç´¢ API æ‰§è¡Œæœç´¢
        [ä¿®å¤] 2026-01-20: æ·»åŠ  country_code å‚æ•°æ”¯æŒ

        Args:
            query: æœç´¢æŸ¥è¯¢è¯
            max_results: æœ€å¤§è¿”å›ç»“æœæ•°ï¼ˆ1-20ï¼Œé»˜è®¤10ï¼‰
            region: æœç´¢åŒºåŸŸï¼ˆé»˜è®¤ï¼šidï¼Œå°å°¼ï¼‰- æ³¨æ„ï¼šTavily API å¯èƒ½ä¸æ”¯æŒæ­¤å‚æ•°
            search_depth: æœç´¢æ·±åº¦ï¼ˆ"basic" æˆ– "advanced"ï¼Œé»˜è®¤ "advanced"ï¼‰
            include_domains: é™å®šæœç´¢çš„åŸŸååˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
            country_code: å›½å®¶ä»£ç ï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™ä½¿ç”¨ country_codeï¼‰

        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        # å¦‚æœä½¿ç”¨ç»Ÿä¸€å®¢æˆ·ç«¯ï¼Œå°è¯•ä½¿ç”¨å…¶searchæ–¹æ³•
        if self.use_unified_client:
            try:
                # [ä¿®å¤] 2026-01-20: ä¼ é€’ country_code å‚æ•°
                search_results = self.unified_client.search(
                    query=query,
                    max_results=max_results,
                    include_domains=include_domains,
                    country_code=country_code or region  # å¦‚æœæä¾›äº† country_codeï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ä½¿ç”¨ region
                )
                # è½¬æ¢ä¸ºSearchResultå¯¹è±¡
                results = []
                for item in search_results:
                    results.append(SearchResult(
                        title=item.get('title', ''),
                        url=item.get('url', ''),
                        snippet=item.get('content', item.get('snippet', item.get('description', '')))
                    ))
                return results
            except Exception as e:
                print(f"[âš ï¸] ç»Ÿä¸€å®¢æˆ·ç«¯æœç´¢å¤±è´¥: {str(e)}ï¼Œå›é€€åˆ°åŸæœ‰å®ç°")
                # å›é€€åˆ°åŸæœ‰å®ç°
        
        # åŸæœ‰å®ç°
        # Tavily æœç´¢ç«¯ç‚¹
        endpoint = f"{self.base_url}/v1/search/"
        
        # æ„å»ºè¯·æ±‚ä½“ï¼ˆæ ¹æ® OpenAPI è§„èŒƒï¼‰
        payload = {
            "keywords": [query],  # Tavily API æ¥å—å…³é”®è¯æ•°ç»„
            "max_results": min(max_results, 20)  # é™åˆ¶åœ¨ 1-20 ä¹‹é—´
        }
        
        # æ³¨æ„ï¼šæ ¹æ® OpenAPI æ–‡æ¡£ï¼Œinclude_domains å’Œ search_depth å¯èƒ½ä¸åœ¨æ ‡å‡†è¯·æ±‚ä½“ä¸­
        # è¿™äº›å‚æ•°å¯èƒ½éœ€è¦é€šè¿‡ Tavily API çš„åŸå§‹å‚æ•°ä¼ é€’
        # å¦‚æœåç«¯æ”¯æŒï¼Œå¯ä»¥å°è¯•æ·»åŠ è¿™äº›å‚æ•°
        # ä½†æ ¹æ® OpenAPI è§„èŒƒï¼ŒSearchRequest åªåŒ…å« keywords å’Œ max_results
        
        try:
            proxies = {
                "http": None,
                "https": None
            }
            response = requests.post(
                endpoint,
                headers=self.headers,
                json=payload,
                timeout=30,
                proxies=proxies
            )
            
            if response.status_code == 200:
                result = response.json()
                results = []
                
                # è§£æ Tavily å“åº”æ ¼å¼
                # å“åº”æ ¼å¼ï¼š{"queries": [{"keyword": "...", "response": {...}}], ...}
                if isinstance(result, dict) and "queries" in result:
                    queries = result.get("queries", [])
                    if queries:
                        # è·å–ç¬¬ä¸€ä¸ªæŸ¥è¯¢çš„ç»“æœï¼ˆå› ä¸ºæˆ‘ä»¬åªä¼ äº†ä¸€ä¸ªå…³é”®è¯ï¼‰
                        query_result = queries[0]
                        tavily_response = query_result.get("response", {})
                        
                        # Tavily å“åº”é€šå¸¸åŒ…å« "results" æ•°ç»„
                        tavily_results = tavily_response.get("results", [])
                        
                        for item in tavily_results[:max_results]:
                            # Tavily ç»“æœæ ¼å¼ï¼štitle, url, content, score ç­‰
                            results.append(SearchResult(
                                title=item.get('title', ''),
                                url=item.get('url', ''),
                                snippet=item.get('content', item.get('snippet', item.get('description', '')))
                            ))
                
                if results:
                    return results
                else:
                    raise ValueError(f"Tavily æœç´¢è¿”å›ç©ºç»“æœ")
            else:
                error_text = response.text[:500] if hasattr(response, 'text') else str(response.status_code)
                raise ValueError(f"Tavily æœç´¢ API è°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}, å“åº”: {error_text}")
                
        except requests.exceptions.RequestException as e:
            raise ValueError(f"Tavily æœç´¢ API è¯·æ±‚å¼‚å¸¸: {str(e)}")
    
    def _search_via_llm_tools(self, query: str, max_results: int, region: str) -> List[SearchResult]:
        """
        é€šè¿‡ LLM å·¥å…·è°ƒç”¨æ–¹å¼æ‰§è¡Œæœç´¢ï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰

        Args:
            query: æœç´¢æŸ¥è¯¢è¯
            max_results: æœ€å¤§è¿”å›ç»“æœæ•°
            region: æœç´¢åŒºåŸŸ

        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        # âœ¨ ä½¿ç”¨æç¤ºè¯ç®¡ç†å™¨æ„å»ºæœç´¢åŠ©æ‰‹æç¤ºè¯ï¼ˆæ›¿ä»£ç¡¬ç¼–ç ï¼‰
        if HAS_PROMPT_MANAGER:
            prompt_mgr = get_prompt_manager()
            system_prompt, user_prompt = prompt_mgr.get_llm_search_assistant_prompts(
                query=query,
                max_results=max_results,
                region=region
            )
        else:
            # é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨åŸæœ‰å®ç°
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªæœç´¢åŠ©æ‰‹ã€‚å½“ç”¨æˆ·è¯·æ±‚æœç´¢æ—¶ï¼Œè¯·ä½¿ç”¨å¯ç”¨çš„æœç´¢å·¥å…·æ¥è·å–ç»“æœã€‚
å¦‚æœæœç´¢å·¥å…·è¿”å›äº†ç»“æœï¼Œè¯·ä»¥ JSON æ ¼å¼è¿”å›æœç´¢ç»“æœæ•°ç»„ã€‚"""

            user_prompt = f"""è¯·æœç´¢ä»¥ä¸‹æŸ¥è¯¢è¯ï¼Œè¿”å›å‰ {max_results} ä¸ªç»“æœï¼š
æŸ¥è¯¢è¯: {query}
åœ°åŒº: {region}

è¯·ä»¥ JSON æ•°ç»„æ ¼å¼è¿”å›ç»“æœï¼Œæ¯ä¸ªç»“æœåŒ…å« title, url, snippet å­—æ®µã€‚"""
        
        # å°è¯•è°ƒç”¨ LLMï¼Œçœ‹æ˜¯å¦æ”¯æŒå·¥å…·è°ƒç”¨
        try:
            response_text = self.call_gemini(
                prompt=user_prompt,
                system_prompt=system_prompt,
                max_tokens=8000,  # [ä¿®å¤] 2026-01-20: ä»4000å¢åŠ åˆ°8000
                temperature=0.1
            )
            
            # å°è¯•ä»å“åº”ä¸­æå– JSON
            json_text = self._extract_json_from_response(response_text)
            results_data = json.loads(json_text)
            
            results = []
            if isinstance(results_data, list):
                for item in results_data[:max_results]:
                    results.append(SearchResult(
                        title=item.get('title', ''),
                        url=item.get('url', ''),
                        snippet=item.get('snippet', '')
                    ))
            
            return results
            
        except Exception as e:
            raise ValueError(f"é€šè¿‡ LLM å·¥å…·è°ƒç”¨æœç´¢å¤±è´¥: {str(e)}")
    
    def _extract_json_from_response(self, response_text: str) -> str:
        """ä»å“åº”æ–‡æœ¬ä¸­æå– JSON éƒ¨åˆ†"""
        # å°è¯•æŸ¥æ‰¾ä»£ç å—ä¸­çš„ JSON
        json_pattern = r'```(?:json)?\s*(\[.*?\])\s*```'
        match = re.search(json_pattern, response_text, re.DOTALL)
        if match:
            return match.group(1)
        
        # å°è¯•æ‰¾åˆ° JSON æ•°ç»„çš„å¼€å§‹å’Œç»“æŸ
        start_idx = response_text.find('[')
        end_idx = response_text.rfind(']')
        
        if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
            return response_text[start_idx:end_idx+1]
        
        raise ValueError("æ— æ³•ä»å“åº”ä¸­æå– JSON")


# ============================================================================
# æœç´¢å·¥å…· (Hunter)
# ============================================================================

class SearchHunter:
    """æœç´¢æ‰§è¡Œå™¨ - è´Ÿè´£æ‰§è¡Œå®é™…æœç´¢"""
    
    def __init__(self, search_engine: str = "ai-builders", llm_client: Optional[AIBuildersClient] = None):
        """
        åˆå§‹åŒ–æœç´¢å™¨
        
        Args:
            search_engine: æœç´¢å¼•æ“ç±»å‹ ("ai-builders", "duckduckgo", "serpapi", "google" æˆ– "baidu")
            llm_client: AI Builders å®¢æˆ·ç«¯ï¼ˆå½“ä½¿ç”¨ ai-builders æ—¶å¿…éœ€ï¼‰
        """
        self.search_engine = search_engine
        self.llm_client = llm_client
        
        # æ£€æŸ¥Googleæœç´¢é…ç½®
        if search_engine == "google":
            self.google_api_key = os.getenv("GOOGLE_API_KEY")
            self.google_cx = os.getenv("GOOGLE_CX")
            if not self.google_api_key:
                print(f"    [âš ï¸ è­¦å‘Š] GOOGLE_API_KEY æœªè®¾ç½®ï¼ŒGoogleæœç´¢å°†ä¸å¯ç”¨")
            if not self.google_cx:
                print(f"    [âš ï¸ è­¦å‘Š] GOOGLE_CX æœªè®¾ç½®ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®")
        
        # æ£€æŸ¥ç™¾åº¦æœç´¢é…ç½®
        if search_engine == "baidu":
            self.baidu_api_key = os.getenv("BAIDU_API_KEY")
            self.baidu_secret_key = os.getenv("BAIDU_SECRET_KEY")
            if not self.baidu_api_key:
                print(f"    [âš ï¸ è­¦å‘Š] BAIDU_API_KEY æœªè®¾ç½®ï¼Œç™¾åº¦æœç´¢å°†ä¸å¯ç”¨")
            if not self.baidu_secret_key:
                print(f"    [âš ï¸ è­¦å‘Š] BAIDU_SECRET_KEY æœªè®¾ç½®ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®")
    
    def search(self, query: str, max_results: int = 10, country_code: str = None) -> List[SearchResult]:
        """
        æ‰§è¡Œæœç´¢

        Args:
            query: æœç´¢æŸ¥è¯¢è¯
            max_results: æœ€å¤§è¿”å›ç»“æœæ•°
            country_code: å›½å®¶ä»£ç ï¼ˆISO 3166-1 alpha-2ï¼‰ï¼Œç”¨äºæœ¬åœ°åŒ–æœç´¢ç»“æœ

        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        print(f"    [ğŸ” æœç´¢] æ‰§è¡Œæœç´¢: \"{query}\"" + (f" [å›½å®¶: {country_code}]" if country_code else ""))

        try:
            if self.search_engine == "ai-builders":
                return self._search_ai_builders(query, max_results, country_code)
            elif self.search_engine == "duckduckgo":
                return self._search_duckduckgo(query, max_results)
            elif self.search_engine == "serpapi":
                return self._search_serpapi(query, max_results)
            elif self.search_engine == "google":
                return self._search_google(query, max_results, country_code)
            elif self.search_engine == "baidu":
                return self._search_baidu(query, max_results)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æœç´¢å¼•æ“: {self.search_engine}")
        except Exception as e:
            print(f"    [âŒ é”™è¯¯] æœç´¢å¤±è´¥: {str(e)}")
            # å¦‚æœ ai-builders å¤±è´¥ï¼Œå°è¯•é™çº§åˆ° duckduckgo
            if self.search_engine == "ai-builders":
                print(f"    [ğŸ”„ é™çº§] AI Builders æœç´¢å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ DuckDuckGo...")
                try:
                    return self._search_duckduckgo(query, max_results)
                except Exception as e2:
                    print(f"    [âŒ é”™è¯¯] DuckDuckGo æœç´¢ä¹Ÿå¤±è´¥: {str(e2)}")
                    return []
            return []
    
    def _search_duckduckgo(self, query: str, max_results: int) -> List[SearchResult]:
        """
        ä½¿ç”¨ DuckDuckGo æœç´¢ï¼ˆä½¿ç”¨ duckduckgo-search åº“ï¼‰
        
        Args:
            query: æœç´¢æŸ¥è¯¢è¯
            max_results: æœ€å¤§è¿”å›ç»“æœæ•°
        
        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        try:
            from duckduckgo_search import DDGS
            
            results = []
            with DDGS() as ddgs:
                # æœç´¢ï¼Œè·å–å‰ max_results ä¸ªç»“æœ
                search_results = ddgs.text(
                    query,
                    max_results=max_results,
                    region='id',  # å°å°¼åœ°åŒº
                    safesearch='moderate'
                )
                
                for result in search_results:
                    results.append(SearchResult(
                        title=result.get('title', ''),
                        url=result.get('href', ''),
                        snippet=result.get('body', '')
                    ))
            
            print(f"    [âœ… æœç´¢] æ‰¾åˆ° {len(results)} ä¸ªç»“æœ")
            return results
            
        except ImportError:
            print(f"    [âš ï¸ è­¦å‘Š] duckduckgo-search åº“æœªå®‰è£…ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæœç´¢")
            return self._mock_search(query, max_results)
        except Exception as e:
            print(f"    [âŒ é”™è¯¯] DuckDuckGo æœç´¢å¼‚å¸¸: {str(e)}")
            return self._mock_search(query, max_results)
    
    def _search_ai_builders(self, query: str, max_results: int, country_code: str = None) -> List[SearchResult]:
        """
        ä½¿ç”¨ AI Builders Tavily æœç´¢ APIï¼ˆå¢å¼ºæ—¥å¿—ç‰ˆæœ¬ï¼‰

        Args:
            query: æœç´¢æŸ¥è¯¢è¯
            max_results: æœ€å¤§è¿”å›ç»“æœæ•°
            country_code: å›½å®¶ä»£ç ï¼ˆISO 3166-1 alpha-2ï¼‰

        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        if not self.llm_client:
            raise ValueError("ä½¿ç”¨ ai-builders æœç´¢éœ€è¦æä¾› llm_client")

        try:
            print(f"    [ğŸ” Tavily] å‡†å¤‡è°ƒç”¨ APIï¼ŒæŸ¥è¯¢: \"{query}\"")
            print(f"    [ğŸ” Tavily] è¯·æ±‚å‚æ•°: max_results={max_results}, country_code={country_code or 'ID'}")

            results = self.llm_client.search(
                query=query,
                max_results=max_results,
                country_code=country_code or "ID"
                # æ³¨æ„ï¼šsearch_depth å’Œ include_domains å‚æ•°å·²ç§»é™¤ï¼Œå› ä¸º API ä¸æ”¯æŒ
            )
            
            print(f"    [âœ… Tavily] API è°ƒç”¨æˆåŠŸï¼Œè¿”å› {len(results)} ä¸ªç»“æœ")
            if results:
                print(f"    [ğŸ“Š Tavily] ç»“æœé¢„è§ˆ:")
                for i, result in enumerate(results[:3], 1):
                    print(f"      [{i}] {result.title[:50]}... -> {result.url[:50]}...")
            
            return results
        except Exception as e:
            print(f"    [âŒ é”™è¯¯] Tavily æœç´¢å¼‚å¸¸: {str(e)}")
            import traceback
            print(f"    [ğŸ” è°ƒè¯•] å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()[:300]}")
            raise
    
    def _search_serpapi(self, query: str, max_results: int) -> List[SearchResult]:
        """
        ä½¿ç”¨ SerpAPI æœç´¢
        
        Args:
            query: æœç´¢æŸ¥è¯¢è¯
            max_results: æœ€å¤§è¿”å›ç»“æœæ•°
        
        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        api_key = os.getenv("SERPAPI_KEY")
        if not api_key:
            print(f"    [âš ï¸ è­¦å‘Š] SERPAPI_KEY æœªè®¾ç½®ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæœç´¢")
            return self._mock_search(query, max_results)
        
        try:
            params = {
                "q": query,
                "api_key": api_key,
                "engine": "google",
                "gl": "id",  # å°å°¼åœ°åŒº
                "num": max_results
            }
            
            response = requests.get("https://serpapi.com/search", params=params, timeout=30)
            response.raise_for_status()
            data = response.json()
            
            results = []
            if "organic_results" in data:
                for item in data["organic_results"][:max_results]:
                    results.append(SearchResult(
                        title=item.get('title', ''),
                        url=item.get('link', ''),
                        snippet=item.get('snippet', '')
                    ))
            
            print(f"    [âœ… æœç´¢] æ‰¾åˆ° {len(results)} ä¸ªç»“æœ")
            return results
            
        except Exception as e:
            print(f"    [âŒ é”™è¯¯] SerpAPI æœç´¢å¼‚å¸¸: {str(e)}")
            return self._mock_search(query, max_results)
    
    def _search_google(self, query: str, max_results: int, country_code: str = None) -> List[SearchResult]:
        """
        ä½¿ç”¨ Google Custom Search API æœç´¢

        Args:
            query: æœç´¢æŸ¥è¯¢è¯
            max_results: æœ€å¤§è¿”å›ç»“æœæ•°ï¼ˆGoogle APIé™åˆ¶æ¯æ¬¡æœ€å¤š10ä¸ªç»“æœï¼‰
            country_code: å›½å®¶ä»£ç ï¼ˆISO 3166-1 alpha-2ï¼‰ï¼Œç”¨äºæœ¬åœ°åŒ–æœç´¢ç»“æœ

        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        # âœ¨ ä¿®å¤ï¼šå›½å®¶ä»£ç åˆ° Google å‚æ•°çš„æ˜ å°„ï¼ˆæ”¯æŒå¤šè¯­è¨€/å¤šåœ°åŒºæœç´¢ï¼‰
        # å‚è€ƒ: https://developers.google.com/custom-search/v1/parameter_guide
        country_google_params = {
            # äºšæ´²
            "ID": {"gl": "ID", "hl": "id", "lr": "lang_id"},  # å°åº¦å°¼è¥¿äºš
            "PH": {"gl": "PH", "hl": "fil", "lr": "lang_tl"},  # è²å¾‹å®¾
            "JP": {"gl": "JP", "hl": "ja", "lr": "lang_ja"},  # æ—¥æœ¬
            "CN": {"gl": "CN", "hl": "zh-CN", "lr": "lang_zh-CN"},  # ä¸­å›½
            "MY": {"gl": "MY", "hl": "ms", "lr": "lang_ms"},  # é©¬æ¥è¥¿äºš
            "SG": {"gl": "SG", "hl": "en", "lr": "lang_en"},  # æ–°åŠ å¡
            "IN": {"gl": "IN", "hl": "hi", "lr": "lang_hi"},  # å°åº¦
            "TH": {"gl": "TH", "hl": "th", "lr": "lang_th"},  # æ³°å›½
            "VN": {"gl": "VN", "hl": "vi", "lr": "lang_vi"},  # è¶Šå—
            "KR": {"gl": "KR", "hl": "ko", "lr": "lang_ko"},  # éŸ©å›½
            "TW": {"gl": "TW", "hl": "zh-TW", "lr": "lang_zh-TW"},  # å°æ¹¾
            # ä¸­ä¸œ
            "IQ": {"gl": "IQ", "hl": "ar", "lr": "lang_ar"},  # ä¼Šæ‹‰å…‹
            "SA": {"gl": "SA", "hl": "ar", "lr": "lang_ar"},  # æ²™ç‰¹é˜¿æ‹‰ä¼¯
            "AE": {"gl": "AE", "hl": "ar", "lr": "lang_ar"},  # é˜¿è”é…‹
            "EG": {"gl": "EG", "hl": "ar", "lr": "lang_ar"},  # åŸƒåŠ
            "IR": {"gl": "IR", "hl": "fa", "lr": "lang_fa"},  # ä¼Šæœ—
            "SY": {"gl": "SY", "hl": "ar", "lr": "lang_ar"},  # å™åˆ©äºš
            "JO": {"gl": "JO", "hl": "ar", "lr": "lang_ar"},  # çº¦æ—¦
            "LB": {"gl": "LB", "hl": "ar", "lr": "lang_ar"},  # é»å·´å«©
            "IL": {"gl": "IL", "hl": "he", "lr": "lang_he"},  # ä»¥è‰²åˆ—
            "KW": {"gl": "KW", "hl": "ar", "lr": "lang_ar"},  # ç§‘å¨ç‰¹
            "QA": {"gl": "QA", "hl": "ar", "lr": "lang_ar"},  # å¡å¡”å°”
            "BH": {"gl": "BH", "hl": "ar", "lr": "lang_ar"},  # å·´æ—
            "OM": {"gl": "OM", "hl": "ar", "lr": "lang_ar"},  # é˜¿æ›¼
            "YE": {"gl": "YE", "hl": "ar", "lr": "lang_ar"},  # ä¹Ÿé—¨
            # æ¬§ç¾
            "US": {"gl": "US", "hl": "en", "lr": "lang_en"},  # ç¾å›½
            "GB": {"gl": "GB", "hl": "en", "lr": "lang_en"},  # è‹±å›½
            "CA": {"gl": "CA", "hl": "en", "lr": "lang_en"},  # åŠ æ‹¿å¤§
            "AU": {"gl": "AU", "hl": "en", "lr": "lang_en"},  # æ¾³å¤§åˆ©äºš
            "NZ": {"gl": "NZ", "hl": "en", "lr": "lang_en"},  # æ–°è¥¿å…°
            "DE": {"gl": "DE", "hl": "de", "lr": "lang_de"},  # å¾·å›½
            "FR": {"gl": "FR", "hl": "fr", "lr": "lang_fr"},  # æ³•å›½
            "IT": {"gl": "IT", "hl": "it", "lr": "lang_it"},  # æ„å¤§åˆ©
            "ES": {"gl": "ES", "hl": "es", "lr": "lang_es"},  # è¥¿ç­ç‰™
            "RU": {"gl": "RU", "hl": "ru", "lr": "lang_ru"},  # ä¿„ç½—æ–¯
            "TR": {"gl": "TR", "hl": "tr", "lr": "lang_tr"},  # åœŸè€³å…¶
            # æ‹‰ç¾
            "BR": {"gl": "BR", "hl": "pt-BR", "lr": "lang_pt-BR"},  # å·´è¥¿
            "MX": {"gl": "MX", "hl": "es", "lr": "lang_es"},  # å¢¨è¥¿å“¥
            "AR": {"gl": "AR", "hl": "es", "lr": "lang_es"},  # é˜¿æ ¹å»·
            "CL": {"gl": "CL", "hl": "es", "lr": "lang_es"},  # æ™ºåˆ©
            "CO": {"gl": "CO", "hl": "es", "lr": "lang_es"},  # å“¥ä¼¦æ¯”äºš
            "PE": {"gl": "PE", "hl": "es", "lr": "lang_es"},  # ç§˜é²
            # éæ´²
            "ZA": {"gl": "ZA", "hl": "en", "lr": "lang_en"},  # å—é
            "NG": {"gl": "NG", "hl": "en", "lr": "lang_en"},  # å°¼æ—¥åˆ©äºš
            "KE": {"gl": "KE", "hl": "en", "lr": "lang_en"},  # è‚¯å°¼äºš
            "GH": {"gl": "GH", "hl": "en", "lr": "lang_en"},  # åŠ çº³
            "ET": {"gl": "ET", "hl": "am", "lr": "lang_am"},  # åŸƒå¡ä¿„æ¯”äºš
            "MA": {"gl": "MA", "hl": "ar", "lr": "lang_ar"},  # æ‘©æ´›å“¥
            "DZ": {"gl": "DZ", "hl": "ar", "lr": "lang_ar"},  # é˜¿å°”åŠåˆ©äºš
            "TN": {"gl": "TN", "hl": "ar", "lr": "lang_ar"},  # çªå°¼æ–¯
            "LY": {"gl": "LY", "hl": "ar", "lr": "lang_ar"},  # åˆ©æ¯”äºš
            "SD": {"gl": "SD", "hl": "ar", "lr": "lang_ar"},  # è‹ä¸¹
        }

        # æ ¹æ®å›½å®¶ä»£ç è·å– Google å‚æ•°ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™ä½¿ç”¨é»˜è®¤å€¼ï¼ˆè‹±è¯­ï¼‰
        # âœ¨ å¢å¼ºï¼šæ”¯æŒå›½å®¶åç§°ï¼ˆå¦‚ "Iraq"ï¼‰å’Œ ISO ä»£ç ï¼ˆå¦‚ "IQ"ï¼‰
        country_key = country_code.upper() if country_code else None
        if country_key and country_key in country_google_params:
            google_params = country_google_params[country_key]
            print(f"    [âœ… æœ¬åœ°åŒ–] ä½¿ç”¨å›½å®¶ä»£ç  {country_key}: gl={google_params['gl']}, hl={google_params['hl']}, lr={google_params['lr']}")
        elif country_key:
            # å°è¯•ä»å›½å®¶åç§°æŸ¥æ‰¾ ISO ä»£ç 
            # åˆ›å»ºå›½å®¶åç§°åˆ° ISO ä»£ç çš„åå‘æ˜ å°„
            name_to_code = {
                "IRAQ": "IQ", "IRAQ": "IQ",
                "INDONESIA": "ID", "INDONESIA": "ID",
                "SAUDI ARABIA": "SA", "SAUDI ARABIA": "SA",
                "UNITED ARAB EMIRATES": "AE", "UAE": "AE",
                "EGYPT": "EG",
                "IRAN": "IR",
                "SYRIA": "SY",
                "JORDAN": "JO",
                "LEBANON": "LB",
                "ISRAEL": "IL",
                "KUWAIT": "KW",
                "QATAR": "QA",
                "BAHRAIN": "BH",
                "OMAN": "OM",
                "YEMEN": "YE",
                "PHILIPPINES": "PH",
                "JAPAN": "JP",
                "CHINA": "CN",
                "MALAYSIA": "MY",
                "SINGAPORE": "SG",
                "INDIA": "IN",
                "THAILAND": "TH",
                "VIETNAM": "VN",
                "SOUTH KOREA": "KR", "KOREA": "KR",
                "TAIWAN": "TW",
                "UNITED STATES": "US", "USA": "US",
                "UNITED KINGDOM": "GB", "UK": "GB",
                "CANADA": "CA",
                "AUSTRALIA": "AU",
                "NEW ZEALAND": "NZ",
                "GERMANY": "DE",
                "FRANCE": "FR",
                "ITALY": "IT",
                "SPAIN": "ES",
                "RUSSIA": "RU",
                "TURKEY": "TR",
                "BRAZIL": "BR",
                "MEXICO": "MX",
                "ARGENTINA": "AR",
                "CHILE": "CL",
                "COLOMBIA": "CO",
                "PERU": "PE",
                "SOUTH AFRICA": "ZA",
                "NIGERIA": "NG",
                "KENYA": "KE",
                "GHANA": "GH",
                "ETHIOPIA": "ET",
                "MOROCCO": "MA",
                "ALGERIA": "DZ",
                "TUNISIA": "TN",
                "LIBYA": "LY",
                "SUDAN": "SD",
            }
            iso_code = name_to_code.get(country_key)
            if iso_code and iso_code in country_google_params:
                google_params = country_google_params[iso_code]
                print(f"    [âœ… æœ¬åœ°åŒ–] ä»å›½å®¶åç§° {country_key} æ˜ å°„åˆ° ISO ä»£ç  {iso_code}: gl={google_params['gl']}, hl={google_params['hl']}, lr={google_params['lr']}")
            else:
                # é»˜è®¤ä½¿ç”¨è‹±è¯­
                google_params = {"gl": "US", "hl": "en", "lr": "lang_en"}
                print(f"    [âš ï¸ è­¦å‘Š] æœªæ‰¾åˆ°å›½å®¶ {country_key} çš„æ˜ å°„ï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼ˆç¾å›½/è‹±è¯­ï¼‰")
        else:
            # é»˜è®¤ä½¿ç”¨è‹±è¯­
            google_params = {"gl": "US", "hl": "en", "lr": "lang_en"}
            print(f"    [â„¹ï¸ ä¿¡æ¯] æœªæä¾›å›½å®¶ä»£ç ï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼ˆç¾å›½/è‹±è¯­ï¼‰")

        api_key = getattr(self, 'google_api_key', None) or os.getenv("GOOGLE_API_KEY")
        cx = getattr(self, 'google_cx', None) or os.getenv("GOOGLE_CX")
        
        if not api_key:
            print(f"    [âš ï¸ è­¦å‘Š] GOOGLE_API_KEY æœªè®¾ç½®ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæœç´¢")
            return self._mock_search(query, max_results)
        
        if not cx:
            print(f"    [âŒ é”™è¯¯] GOOGLE_CX æœªè®¾ç½®ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®GOOGLE_CX")
            raise ValueError("GOOGLE_CXç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼Œè¯·é…ç½®æœç´¢å¼•æ“ID")
        
        try:
            # Google Custom Search APIç«¯ç‚¹
            endpoint = "https://customsearch.googleapis.com/customsearch/v1"
            
            # Google APIé™åˆ¶æ¯æ¬¡æœ€å¤šè¿”å›10ä¸ªç»“æœ
            # å¦‚æœéœ€è¦æ›´å¤šç»“æœï¼Œéœ€è¦åˆ†é¡µè¯·æ±‚
            num_results = min(max_results, 10)
            
            params = {
                "key": api_key,
                "cx": cx,
                "q": query,
                "num": num_results,
                # âœ¨ ä¿®å¤ï¼šä½¿ç”¨åŠ¨æ€å›½å®¶å‚æ•°ï¼ˆæ”¯æŒå¤šè¯­è¨€/å¤šåœ°åŒºæœç´¢ï¼‰
                "gl": google_params["gl"],  # åœ°ç†ä½ç½®ï¼ˆå½±å“æ’åºå’Œæœ¬åœ°åŒ–ï¼‰
                "hl": google_params["hl"],  # ç•Œé¢è¯­è¨€
                "lr": google_params["lr"]   # ç»“æœè¯­è¨€é™åˆ¶
            }

            print(f"    [ğŸ” Google] å‡†å¤‡è°ƒç”¨ APIï¼ŒæŸ¥è¯¢: \"{query}\"")
            print(f"    [ğŸ” Google] è¯·æ±‚å‚æ•°: num={num_results}, cx={cx}, gl={google_params['gl']}, hl={google_params['hl']}, lr={google_params['lr']}")
            
            response = requests.get(endpoint, params=params, timeout=30)
            response.raise_for_status()
            data = response.json()
            
            results = []
            if "items" in data:
                for item in data["items"][:max_results]:
                    results.append(SearchResult(
                        title=item.get('title', ''),
                        url=item.get('link', ''),
                        snippet=item.get('snippet', item.get('htmlSnippet', ''))
                    ))
            
            print(f"    [âœ… Google] API è°ƒç”¨æˆåŠŸï¼Œè¿”å› {len(results)} ä¸ªç»“æœ")
            if results:
                print(f"    [ğŸ“Š Google] ç»“æœé¢„è§ˆ:")
                for i, result in enumerate(results[:3], 1):
                    print(f"      [{i}] {result.title[:50]}... -> {result.url[:50]}...")
            
            return results
            
        except requests.exceptions.RequestException as e:
            print(f"    [âŒ é”™è¯¯] Google æœç´¢ API è¯·æ±‚å¼‚å¸¸: {str(e)}")
            if hasattr(e, 'response') and e.response is not None:
                try:
                    error_data = e.response.json()
                    print(f"    [âŒ é”™è¯¯] API é”™è¯¯è¯¦æƒ…: {error_data}")
                except:
                    print(f"    [âŒ é”™è¯¯] API å“åº”: {e.response.text[:200]}")
            return self._mock_search(query, max_results)
        except Exception as e:
            print(f"    [âŒ é”™è¯¯] Google æœç´¢å¼‚å¸¸: {str(e)}")
            import traceback
            print(f"    [ğŸ” è°ƒè¯•] å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()[:300]}")
            return self._mock_search(query, max_results)
    
    def _search_baidu(self, query: str, max_results: int) -> List[SearchResult]:
        """
        ä½¿ç”¨ç™¾åº¦æœç´¢APIæœç´¢
        
        Args:
            query: æœç´¢æŸ¥è¯¢è¯
            max_results: æœ€å¤§è¿”å›ç»“æœæ•°
        
        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        api_key = getattr(self, 'baidu_api_key', None) or os.getenv("BAIDU_API_KEY")
        secret_key = getattr(self, 'baidu_secret_key', None) or os.getenv("BAIDU_SECRET_KEY")
        
        if not api_key or not secret_key:
            print(f"    [âš ï¸ è­¦å‘Š] ç™¾åº¦æœç´¢APIå¯†é’¥æœªè®¾ç½®ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæœç´¢")
            return self._mock_search(query, max_results)
        
        try:
            # å¯¼å…¥ç™¾åº¦æœç´¢å®¢æˆ·ç«¯
            from baidu_search_client import BaiduSearchAPIClient
            
            client = BaiduSearchAPIClient(api_key=api_key, secret_key=secret_key)
            search_results = client.search(query, max_results=max_results)
            
            # è½¬æ¢ä¸ºSearchResultå¯¹è±¡
            results = []
            for item in search_results:
                results.append(SearchResult(
                    title=item.get('title', ''),
                    url=item.get('url', ''),
                    snippet=item.get('snippet', '')
                ))
            
            print(f"    [âœ… æœç´¢] æ‰¾åˆ° {len(results)} ä¸ªç»“æœ")
            return results
        
        except ImportError:
            print(f"    [âš ï¸ è­¦å‘Š] baidu_search_client æ¨¡å—æœªæ‰¾åˆ°ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæœç´¢")
            return self._mock_search(query, max_results)
        except Exception as e:
            print(f"    [âŒ é”™è¯¯] ç™¾åº¦æœç´¢å¼‚å¸¸: {str(e)}")
            import traceback
            print(f"    [ğŸ” è°ƒè¯•] å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()[:300]}")
            return self._mock_search(query, max_results)
    
    def _mock_search(self, query: str, max_results: int) -> List[SearchResult]:
        """
        æ¨¡æ‹Ÿæœç´¢ï¼ˆç”¨äºæµ‹è¯•æˆ–å½“çœŸå®æœç´¢ä¸å¯ç”¨æ—¶ï¼‰
        
        Args:
            query: æœç´¢æŸ¥è¯¢è¯
            max_results: æœ€å¤§è¿”å›ç»“æœæ•°
        
        Returns:
            æ¨¡æ‹Ÿæœç´¢ç»“æœåˆ—è¡¨
        """
        print(f"    [ğŸ§ª æ¨¡æ‹Ÿ] ç”Ÿæˆ {max_results} ä¸ªæ¨¡æ‹Ÿæœç´¢ç»“æœ")
        # è¿”å›ç©ºåˆ—è¡¨ï¼Œå®é™…ä½¿ç”¨æ—¶åº”è¯¥è¿”å›æ¨¡æ‹Ÿæ•°æ®
        return []


# ============================================================================
# ç»“æœè¯„ä¼°å™¨ (Inspector - LLM)
# ============================================================================

class ResultInspector:
    """ç»“æœè¯„ä¼°å™¨ - ä½¿ç”¨ LLM è¯„ä¼°æœç´¢ç»“æœè´¨é‡ï¼Œå¸¦è§„åˆ™å…œåº•æœºåˆ¶"""
    
    def __init__(self, llm_client: AIBuildersClient):
        """
        åˆå§‹åŒ–è¯„ä¼°å™¨

        Args:
            llm_client: LLM å®¢æˆ·ç«¯å®ä¾‹
        """
        self.llm_client = llm_client
        # âœ¨ åˆå§‹åŒ–æç¤ºè¯ç®¡ç†å™¨
        self.prompt_mgr = get_prompt_manager() if HAS_PROMPT_MANAGER else None
    
    def evaluate_results(self, search_results: List[SearchResult], 
                        chapter_info: ChapterInfo) -> EvaluationResult:
        """
        è¯„ä¼°æœç´¢ç»“æœï¼Œåˆ¤æ–­æ˜¯å¦æœ‰é«˜è´¨é‡çš„æ’­æ”¾åˆ—è¡¨
        é‡‡ç”¨ä¸‰æ­¥ç­–ç•¥ï¼šè§„åˆ™ç­›é€‰ -> LLM ç­›é€‰ï¼ˆå¯é€‰ï¼‰-> åˆå¹¶ç»“æœ
        
        Args:
            search_results: æœç´¢ç»“æœåˆ—è¡¨
            chapter_info: ç« èŠ‚ä¿¡æ¯
        
        Returns:
            è¯„ä¼°ç»“æœ
        """
        print(f"    [ğŸ•µï¸ è¯„ä¼°] æ­£åœ¨è¯„ä¼° {len(search_results)} ä¸ªæœç´¢ç»“æœ...")
        
        # ========================================================================
        # Step 1: è§„åˆ™ç­›é€‰ï¼ˆç¡¬è§„åˆ™æ£€æŸ¥ï¼‰- æ ¸å¿ƒå…œåº•æœºåˆ¶
        # ========================================================================
        print(f"    [ğŸ“‹ Step 1] æ‰§è¡Œè§„åˆ™åŒ¹é…ï¼ˆç¡¬è§„åˆ™æ£€æŸ¥ï¼‰...")
        rule_matched_urls = self._heuristic_match(search_results, chapter_info)
        
        if rule_matched_urls:
            print(f"    [âœ… è§„åˆ™åŒ¹é…] é€šè¿‡ç¡¬è§„åˆ™æ‰¾åˆ° {len(rule_matched_urls)} ä¸ªé«˜è´¨é‡èµ„æº")
            for i, url in enumerate(rule_matched_urls, 1):
                url_type = self._classify_url_type(url)
                print(f"    [âœ… è§„åˆ™èµ„æº {i}] {url_type}: {url[:70]}...")
        
        # ========================================================================
        # Step 2: LLM ç­›é€‰ï¼ˆå¯é€‰ï¼‰- å¯¹å‰©ä½™æ¨¡ç³Šç»“æœè¿›è¡Œåˆ¤æ–­
        # ========================================================================
        llm_matched_urls = []
        llm_feedback = ""
        
        # å¦‚æœè§„åˆ™åŒ¹é…å·²ç»æ‰¾åˆ°è¶³å¤Ÿå¥½çš„ç»“æœï¼Œå¯ä»¥è·³è¿‡ LLMï¼ˆä½†ä¸ºäº†æ›´å…¨é¢ï¼Œæˆ‘ä»¬è¿˜æ˜¯å°è¯• LLMï¼‰
        # å¦‚æœè§„åˆ™åŒ¹é…ä¸ºç©ºï¼Œåˆ™å¿…é¡»ä½¿ç”¨ LLM
        try:
            print(f"    [ğŸ¤– Step 2] å°è¯•ä½¿ç”¨ LLM è¯„ä¼°å‰©ä½™ç»“æœ...")
            
            # ç®€åŒ–æç¤ºè¯ï¼Œå‡å°‘é•¿åº¦ï¼Œé¿å…è§¦å‘å®‰å…¨é™åˆ¶
            # åªè¯„ä¼°å‰5ä¸ªç»“æœï¼Œå‡å°‘ token æ•°é‡
            limited_results = search_results[:5]
            results_text = self._format_results_for_llm(limited_results)

            # âœ¨ ä½¿ç”¨æç¤ºè¯ç®¡ç†å™¨æ„å»ºè¯„ä¼°æç¤ºè¯ï¼ˆæ›¿ä»£ç¡¬ç¼–ç ï¼‰
            if self.prompt_mgr:
                user_prompt = self.prompt_mgr.get_search_evaluation_user_prompt(
                    grade=chapter_info.grade_level,
                    subject=chapter_info.subject,
                    chapter=chapter_info.chapter_title,
                    results_text=results_text
                )
            else:
                # é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨åŸæœ‰å®ç°
                user_prompt = f"""è¯·ç›´æ¥è¿”å›JSONæ ¼å¼ï¼Œä¸è¦ä½¿ç”¨ä»»ä½•å·¥å…·æˆ–æœç´¢åŠŸèƒ½ã€‚

ä»ä»¥ä¸‹æœç´¢ç»“æœä¸­é€‰æ‹©é€‚åˆå°å­¦1-2å¹´çº§æ•°å­¦æ•™å­¦çš„è§†é¢‘èµ„æºã€‚

å¹´çº§ï¼š{chapter_info.grade_level}
å­¦ç§‘ï¼š{chapter_info.subject}
ç« èŠ‚ï¼š{chapter_info.chapter_title}

æœç´¢ç»“æœï¼š
{results_text}

è¯·ç›´æ¥è¿”å›ä»¥ä¸‹JSONæ ¼å¼ï¼Œä¸è¦è°ƒç”¨ä»»ä½•å·¥å…·ï¼š
{{
    "is_good_batch": true,
    "best_indices": [1, 2],
    "feedback": "æ‰¾åˆ°èµ„æº"
}}"""
            
            # å°è¯•å¤šä¸ªæ¨¡å‹ï¼Œå¦‚æœ Gemini å¤±è´¥åˆ™é™çº§åˆ° deepseek
            models_to_try = ["gemini-2.5-pro", "deepseek"]
            max_retries = 2
            response_text = None
            
            for model_name in models_to_try:
                if response_text:
                    break  # å¦‚æœå·²ç»æˆåŠŸè·å–å“åº”ï¼Œè·³å‡ºå¾ªç¯
                    
                for retry in range(max_retries):
                    try:
                        print(f"    [ğŸ” å°è¯•] ä½¿ç”¨æ¨¡å‹: {model_name} (å°è¯• {retry + 1}/{max_retries})")
                        # å°è¯•ä¸ä½¿ç”¨ system_promptï¼Œç›´æ¥åˆå¹¶åˆ° user_promptï¼Œé¿å…å¯èƒ½çš„æ ¼å¼é—®é¢˜
                        response_text = self.llm_client.call_gemini(
                            prompt=user_prompt,
                            system_prompt=None,  # ä¸ä½¿ç”¨ system_promptï¼Œé¿å…å¯èƒ½çš„æ ¼å¼é—®é¢˜
                            max_tokens=8000,  # [ä¿®å¤] 2026-01-20: ä»500å¢åŠ åˆ°8000
                            temperature=0.0,  # ä½¿ç”¨æœ€ä½æ¸©åº¦ï¼Œä½¿è¾“å‡ºæ›´ç¡®å®š
                            model=model_name  # ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹
                        )
                        
                        # æ£€æŸ¥å“åº”æ˜¯å¦ä¸ºç©º
                        if response_text and response_text.strip():
                            print(f"    [âœ… æˆåŠŸ] æ¨¡å‹ {model_name} è¿”å›äº†å†…å®¹")
                            break  # æˆåŠŸè·å–å“åº”ï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                        else:
                            if retry < max_retries - 1:
                                print(f"    [âš ï¸ è­¦å‘Š] æ¨¡å‹ {model_name} è¿”å›ç©ºå“åº”ï¼Œé‡è¯• {retry + 1}/{max_retries}...")
                                time.sleep(1)
                                continue
                            else:
                                print(f"    [âš ï¸ è­¦å‘Š] æ¨¡å‹ {model_name} è¿”å›ç©ºå“åº”ï¼ˆå·²é‡è¯• {max_retries} æ¬¡ï¼‰ï¼Œå°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹...")
                                response_text = None
                                break  # å°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹
                    except Exception as e:
                        if retry < max_retries - 1:
                            print(f"    [âš ï¸ è­¦å‘Š] æ¨¡å‹ {model_name} è°ƒç”¨å¤±è´¥: {str(e)}ï¼Œé‡è¯• {retry + 1}/{max_retries}...")
                            time.sleep(1)
                            continue
                        else:
                            print(f"    [âš ï¸ è­¦å‘Š] æ¨¡å‹ {model_name} è°ƒç”¨å¤±è´¥ï¼ˆå·²é‡è¯• {max_retries} æ¬¡ï¼‰: {str(e)}ï¼Œå°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹...")
                            response_text = None
                            break  # å°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹
            
            # å¦‚æœæ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥ï¼Œè®¾ç½® response_text ä¸º None
            if not response_text or not response_text.strip():
                response_text = None
                print(f"    [âš ï¸ è­¦å‘Š] æ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥ï¼Œè½¬ä¸ºä½¿ç”¨è§„åˆ™è¿‡æ»¤")
            
            # å¦‚æœ LLM è°ƒç”¨æˆåŠŸï¼Œè§£æç»“æœ
            if response_text:
                try:
                    # æå– JSON
                    try:
                        json_text = self._extract_json_from_response(response_text)
                        # è§£æ JSON
                        eval_data = json.loads(json_text)
                    except (ValueError, json.JSONDecodeError) as e:
                        print(f"    [âš ï¸ è­¦å‘Š] JSON è§£æå¤±è´¥ï¼Œå°è¯•ä¿®å¤: {str(e)}")
                        print(f"    [ğŸ” è°ƒè¯•] å“åº”å†…å®¹é¢„è§ˆ: {response_text[:300]}")
                        # å°è¯•ä¿®å¤å¸¸è§çš„ JSON é—®é¢˜
                        json_text = response_text.strip()
                        # ç§»é™¤å¯èƒ½çš„ markdown ä»£ç å—æ ‡è®°
                        json_text = re.sub(r'```(?:json)?\s*', '', json_text)
                        json_text = re.sub(r'```\s*$', '', json_text)
                        # å°è¯•æ‰¾åˆ° JSON å¯¹è±¡
                        start_idx = json_text.find('{')
                        end_idx = json_text.rfind('}')
                        if start_idx != -1 and end_idx != -1:
                            json_text = json_text[start_idx:end_idx+1]
                            try:
                                eval_data = json.loads(json_text)
                            except Exception as parse_error:
                                print(f"    [âš ï¸ è­¦å‘Š] JSON è§£ææœ€ç»ˆå¤±è´¥ï¼Œè½¬ä¸ºä½¿ç”¨è§„åˆ™è¿‡æ»¤: {str(parse_error)}")
                                eval_data = None
                        else:
                            print(f"    [âš ï¸ è­¦å‘Š] æ— æ³•æ‰¾åˆ° JSON å¯¹è±¡ï¼Œè½¬ä¸ºä½¿ç”¨è§„åˆ™è¿‡æ»¤")
                            eval_data = None
                    
                    if eval_data:
                        # ä»ç´¢å¼•ä¸­æå–çœŸå®çš„ URL
                        best_indices = eval_data.get("best_indices", [])
                        
                        # å¦‚æœ LLM è¿”å›äº† best_urlsï¼ˆå‘åå…¼å®¹ï¼‰ï¼Œä¹Ÿå°è¯•ä½¿ç”¨
                        if not best_indices and "best_urls" in eval_data:
                            llm_matched_urls = eval_data.get("best_urls", [])
                        else:
                            # ä»ç´¢å¼•ä¸­æå– URLï¼ˆç´¢å¼•ä»1å¼€å§‹ï¼Œç›¸å¯¹äº limited_resultsï¼‰
                            # éœ€è¦æ˜ å°„å›åŸå§‹çš„ search_results
                            for idx in best_indices:
                                if isinstance(idx, int) and 1 <= idx <= len(limited_results):
                                    # limited_results ä¸­çš„ç´¢å¼•ï¼ˆ1-basedï¼‰
                                    limited_result = limited_results[idx - 1]  # è½¬æ¢ä¸º0-basedç´¢å¼•
                                    # æ‰¾åˆ°åœ¨åŸå§‹ search_results ä¸­çš„ä½ç½®
                                    for orig_idx, orig_result in enumerate(search_results):
                                        if orig_result.url == limited_result.url:
                                            if orig_result.url and orig_result.url.strip():
                                                llm_matched_urls.append(orig_result.url.strip())
                                            break
                        
                        llm_feedback = eval_data.get("feedback", "")
                        print(f"    [âœ… LLM è¯„ä¼°] æ‰¾åˆ° {len(llm_matched_urls)} ä¸ªé«˜è´¨é‡èµ„æº")
                        print(f"    [âœ… LLM åé¦ˆ] {llm_feedback[:200]}...")
                    else:
                        print(f"    [âš ï¸ è­¦å‘Š] LLM è¿”å›çš„æ•°æ®æ— æ³•è§£æï¼Œè½¬ä¸ºä½¿ç”¨è§„åˆ™è¿‡æ»¤")
                except Exception as e:
                    print(f"    [âš ï¸ è­¦å‘Š] LLM è¯„ä¼°è¿‡ç¨‹å¼‚å¸¸ï¼Œè½¬ä¸ºä½¿ç”¨è§„åˆ™è¿‡æ»¤: {str(e)}")
            else:
                print(f"    [âš ï¸ è­¦å‘Š] LLM è°ƒç”¨å¤±è´¥ï¼Œè½¬ä¸ºä½¿ç”¨è§„åˆ™è¿‡æ»¤")
        
        except Exception as e:
            # LLM è°ƒç”¨å®Œå…¨å¤±è´¥ï¼Œè®°å½•é”™è¯¯ä½†ä¸å´©æºƒ
            print(f"    [âš ï¸ è­¦å‘Š] LLM è¯„ä¼°å¤±è´¥ï¼Œè½¬ä¸ºä½¿ç”¨è§„åˆ™è¿‡æ»¤: {str(e)}")
        
        # ========================================================================
        # Step 3: åˆå¹¶ç»“æœ
        # ========================================================================
        print(f"    [ğŸ”„ Step 3] åˆå¹¶è§„åˆ™åŒ¹é…å’Œ LLM è¯„ä¼°ç»“æœ...")
        
        # åˆå¹¶ URLï¼ˆå»é‡ï¼‰
        all_matched_urls = list(set(rule_matched_urls + llm_matched_urls))
        
        # åˆ†ç±» URL
        valid_urls = []
        video_urls = []
        
        for url in all_matched_urls:
            if "youtube.com/watch" in url and "list=" not in url:
                video_urls.append(url)
            else:
                valid_urls.append(url)
        
        # å°†å•é›†è§†é¢‘ä¹Ÿæ·»åŠ åˆ°æœ‰æ•ˆ URL åˆ—è¡¨ä¸­ï¼ˆæ”¾å®½æ ‡å‡†ï¼‰
        valid_urls.extend(video_urls)
        
        # æ„å»ºæœ€ç»ˆè¯„ä¼°ç»“æœ
        is_good_batch = len(valid_urls) > 0
        
        # ç”Ÿæˆåé¦ˆä¿¡æ¯
        feedback_parts = []
        if rule_matched_urls:
            feedback_parts.append(f"è§„åˆ™åŒ¹é…æ‰¾åˆ° {len(rule_matched_urls)} ä¸ªèµ„æº")
        if llm_matched_urls:
            feedback_parts.append(f"LLM è¯„ä¼°æ‰¾åˆ° {len(llm_matched_urls)} ä¸ªèµ„æº")
        if llm_feedback:
            feedback_parts.append(llm_feedback)
        
        feedback = " | ".join(feedback_parts) if feedback_parts else "ä½¿ç”¨è§„åˆ™åŒ¹é…å’Œ LLM è¯„ä¼°"
        
        evaluation = EvaluationResult(
            is_good_batch=is_good_batch,
            best_urls=valid_urls,
            feedback=feedback
        )
        
        # è¯¦ç»†æ—¥å¿—è¾“å‡º
        if evaluation.is_good_batch:
            print(f"    [âœ… æœ€ç»ˆè¯„ä¼°] å‘ç° {len(evaluation.best_urls)} ä¸ªé«˜è´¨é‡èµ„æº")
            print(f"    [âœ… è¯„ä¼°è¯¦æƒ…] è§„åˆ™åŒ¹é…: {len(rule_matched_urls)} ä¸ª")
            print(f"    [âœ… è¯„ä¼°è¯¦æƒ…] LLM è¯„ä¼°: {len(llm_matched_urls)} ä¸ª")
            print(f"    [âœ… è¯„ä¼°è¯¦æƒ…] æ’­æ”¾åˆ—è¡¨/é¢‘é“: {len(valid_urls) - len(video_urls)} ä¸ª")
            print(f"    [âœ… è¯„ä¼°è¯¦æƒ…] å•é›†è§†é¢‘ï¼ˆç³»åˆ—ï¼‰: {len(video_urls)} ä¸ª")
            for i, url in enumerate(evaluation.best_urls, 1):
                url_type = "è§†é¢‘ï¼ˆç³»åˆ—ï¼‰" if url in video_urls else "æ’­æ”¾åˆ—è¡¨/é¢‘é“"
                source = "è§„åˆ™" if url in rule_matched_urls else "LLM"
                print(f"    [âœ… èµ„æº {i}] [{source}] {url_type}: {url[:70]}...")
        else:
            print(f"    [âš ï¸ æœ€ç»ˆè¯„ä¼°] æœªå‘ç°é«˜è´¨é‡åˆ—è¡¨")
        
        return evaluation
    
    def _heuristic_match(self, search_results: List[SearchResult], 
                        chapter_info: ChapterInfo) -> List[str]:
        """
        è§„åˆ™åŒ¹é…ï¼ˆç¡¬è§„åˆ™æ£€æŸ¥ï¼‰- æ ¸å¿ƒå…œåº•æœºåˆ¶
        åœ¨è°ƒç”¨ LLM ä¹‹å‰æˆ– LLM å¤±è´¥åï¼Œä½¿ç”¨ç¡¬è§„åˆ™ç­›é€‰é«˜è´¨é‡èµ„æº
        
        Args:
            search_results: æœç´¢ç»“æœåˆ—è¡¨
            chapter_info: ç« èŠ‚ä¿¡æ¯
        
        Returns:
            åŒ¹é…çš„ URL åˆ—è¡¨
        """
        matched_urls = []
        
        for result in search_results:
            url = result.url.lower() if result.url else ""
            title = result.title.lower() if result.title else ""
            snippet = result.snippet.lower() if result.snippet else ""
            
            # è§„åˆ™ 1: YouTube æ’­æ”¾åˆ—è¡¨ï¼ˆ100% ç¡®å®šï¼‰
            if ("youtube.com/playlist" in url or 
                ("youtube.com/watch" in url and "list=" in url)):
                matched_urls.append(result.url)
                continue
            
            # è§„åˆ™ 2: YouTube é¢‘é“é¡µé¢
            if any(pattern in url for pattern in ["youtube.com/c/", "youtube.com/channel/", "youtube.com/@"]):
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ•™è‚²ç›¸å…³å†…å®¹
                if any(keyword in title or keyword in snippet for keyword in 
                       ["matematika", "belajar", "pembelajaran", "kelas", "education", "tutorial"]):
                    matched_urls.append(result.url)
                    continue
            
            # è§„åˆ™ 3: EdTech ç½‘ç«™ï¼ˆå°å°¼ä¸»è¦æ•™è‚²å¹³å°ï¼‰
            edtech_domains = ["ruangguru.com", "zenius.net", "quipper.com", 
                             "pahamify.com", "kelaspintar.id"]
            if any(domain in url for domain in edtech_domains):
                # æ£€æŸ¥è·¯å¾„æ˜¯å¦çœ‹èµ·æ¥åƒè¯¾ç¨‹é¡µï¼ˆåŒ…å«è¯¾ç¨‹ç›¸å…³å…³é”®è¯ï¼‰
                course_keywords = ["course", "kelas", "materi", "pembelajaran", 
                                  "video", "tutorial", "belajar"]
                if any(keyword in url or keyword in title or keyword in snippet 
                       for keyword in course_keywords):
                    matched_urls.append(result.url)
                    continue
            
            # è§„åˆ™ 4: YouTube å•é›†è§†é¢‘ï¼ˆä½†æ ‡é¢˜æ˜¾ç¤ºæ˜¯ç³»åˆ—çš„ä¸€éƒ¨åˆ†ï¼‰
            if "youtube.com/watch" in url:
                series_keywords = ["part 1", "part 2", "bagian 1", "bagian 2",
                                  "episode", "seri", "series", "full", "lengkap",
                                  "complete", "playlist", "kumpulan"]
                if any(keyword in title or keyword in snippet for keyword in series_keywords):
                    matched_urls.append(result.url)
                    continue
            
            # è§„åˆ™ 5: æ ‡é¢˜åŒ…å«ç« èŠ‚å…³é”®è¯çš„å•é›†è§†é¢‘
            if "youtube.com/watch" in url:
                chapter_keywords = chapter_info.chapter_title.lower().split()
                # æ£€æŸ¥æ ‡é¢˜æˆ–æ‘˜è¦ä¸­æ˜¯å¦åŒ…å«ç« èŠ‚å…³é”®è¯
                if any(keyword in title or keyword in snippet for keyword in chapter_keywords if len(keyword) > 3):
                    # åŒæ—¶æ£€æŸ¥æ˜¯å¦ä¸æ•°å­¦ç›¸å…³
                    if "matematika" in title or "matematika" in snippet:
                        matched_urls.append(result.url)
                        continue
        
        return matched_urls
    
    def _classify_url_type(self, url: str) -> str:
        """
        åˆ†ç±» URL ç±»å‹
        
        Args:
            url: URL å­—ç¬¦ä¸²
        
        Returns:
            URL ç±»å‹æè¿°
        """
        url_lower = url.lower()
        if "youtube.com/playlist" in url_lower or ("youtube.com/watch" in url_lower and "list=" in url_lower):
            return "æ’­æ”¾åˆ—è¡¨"
        elif any(pattern in url_lower for pattern in ["youtube.com/c/", "youtube.com/channel/", "youtube.com/@"]):
            return "é¢‘é“é¡µé¢"
        elif "youtube.com/watch" in url_lower:
            return "å•é›†è§†é¢‘ï¼ˆç³»åˆ—ï¼‰"
        elif any(domain in url_lower for domain in ["ruangguru.com", "zenius.net", "quipper.com", 
                                                    "pahamify.com", "kelaspintar.id"]):
            return "EdTech å¹³å°"
        else:
            return "å…¶ä»–èµ„æº"
    
    def _format_results_for_llm(self, results: List[SearchResult]) -> str:
        """
        æ ¼å¼åŒ–æœç´¢ç»“æœä¾› LLM è¯„ä¼°
        
        Args:
            results: æœç´¢ç»“æœåˆ—è¡¨
        
        Returns:
            æ ¼å¼åŒ–åçš„æ–‡æœ¬
        """
        formatted = []
        for i, result in enumerate(results, 1):
            # Tavily è¿”å›çš„ content å­—æ®µé€šå¸¸åŒ…å«æ›´è¯¦ç»†çš„å†…å®¹ï¼Œä¼˜å…ˆä½¿ç”¨
            snippet = result.snippet
            # å¦‚æœ snippet ä¸ºç©ºæˆ–å¾ˆçŸ­ï¼Œå°è¯•ä½¿ç”¨æ›´é•¿çš„å†…å®¹ï¼ˆTavily çš„ content å­—æ®µå¯èƒ½æ›´é•¿ï¼‰
            if not snippet or len(snippet) < 50:
                snippet = result.snippet  # ä¿æŒåŸæ ·ï¼Œå› ä¸º SearchResult å·²ç»å¤„ç†äº†
            
            # æ˜¾ç¤ºæ›´å¤šå†…å®¹ï¼ˆTavily çš„ content å­—æ®µé€šå¸¸åŒ…å«æ›´è¯¦ç»†çš„ä¿¡æ¯ï¼‰
            snippet_preview = snippet[:300] if snippet else "ï¼ˆæ— æ‘˜è¦ï¼‰"
            formatted.append(f"""
ç»“æœ {i}:
æ ‡é¢˜: {result.title}
URL: {result.url}
å†…å®¹: {snippet_preview}...
""")
        return "\n".join(formatted)
    
    def _extract_json_from_response(self, response_text: str) -> str:
        """ä»å“åº”æ–‡æœ¬ä¸­æå– JSON éƒ¨åˆ†"""
        # å°è¯•æŸ¥æ‰¾ä»£ç å—ä¸­çš„ JSON
        json_pattern = r'```(?:json)?\s*(\{.*?\})\s*```'
        match = re.search(json_pattern, response_text, re.DOTALL)
        if match:
            return match.group(1)
        
        # å°è¯•æ‰¾åˆ° JSON å¯¹è±¡çš„å¼€å§‹å’Œç»“æŸ
        start_idx = response_text.find('{')
        end_idx = response_text.rfind('}')
        
        if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
            return response_text[start_idx:end_idx+1]
        
        return response_text


# ============================================================================
# ğŸ”¥ QueryGenerator å·²è¢«ç§»é™¤ï¼ˆ2025-01-10ï¼‰
# åŸå› ï¼šåŠŸèƒ½ä¸ IntelligentQueryGenerator é‡å¤
# - IntelligentQueryGenerator ä½¿ç”¨æ›´æ–°çš„æ¨¡å‹ï¼ˆgemini-2.5-flashï¼‰
# - IntelligentQueryGenerator æ”¯æŒæ›´å¥½çš„å¤šè¯­è¨€è¯†åˆ«
# - æœç´¢æµç¨‹å·²æœ‰ 3 å±‚é™çº§ï¼šIntelligentQueryGenerator â†’ æœç´¢ç­–ç•¥ â†’ è§„åˆ™ç”Ÿæˆ
# - QueryGenerator ä½œä¸ºç¬¬ 4 å±‚é™çº§æ²¡æœ‰å¿…è¦ï¼Œå¢åŠ ç³»ç»Ÿå¤æ‚åº¦
#
# æ›¿ä»£æ–¹æ¡ˆï¼š
# 1. IntelligentQueryGenerator (core/intelligent_query_generator.py)
#    - ä½¿ç”¨ LLM æ™ºèƒ½ç”Ÿæˆå¤šè¯­è¨€æœç´¢è¯
#    - æ”¯æŒå¤šå›½è¯­è¨€å’Œæœ¯è¯­è¯†åˆ«
# 2. SearchStrategist._generate_fallback_query() (æœ¬æ–‡ä»¶)
#    - ä½¿ç”¨è§„åˆ™ç”Ÿæˆé™çº§æœç´¢è¯
# 3. SearchEngineV2._generate_fallback_query() (search_engine_v2.py)
#    - æœ€ç»ˆé™çº§ï¼šç®€å•æ‹¼æ¥æœç´¢è¯
# ============================================================================

# ============================================================================
# ä¸»æœç´¢ç­–ç•¥å™¨ (Search Strategist)
# ============================================================================

class SearchStrategist:
    """æœç´¢ç­–ç•¥å™¨ - æ ¸å¿ƒ Agent é€»è¾‘"""
    
    def __init__(self, llm_client: AIBuildersClient, search_engine: str = "ai-builders"):
        """
        åˆå§‹åŒ–æœç´¢ç­–ç•¥å™¨

        Args:
            llm_client: LLM å®¢æˆ·ç«¯
            search_engine: æœç´¢å¼•æ“ç±»å‹ ("ai-builders", "duckduckgo" æˆ– "serpapi")
        """
        self.hunter = SearchHunter(search_engine, llm_client=llm_client)
        self.inspector = ResultInspector(llm_client)
        self.unique_playlists: Set[str] = set()  # å…¨å±€å»é‡é›†åˆ
        self.all_records: List[PlaylistRecord] = []  # æ‰€æœ‰æ‰¾åˆ°çš„è®°å½•

    def _generate_fallback_query(self, chapter_info: 'ChapterInfo', attempt: int) -> str:
        """
        ç”Ÿæˆé™çº§æœç´¢è¯ï¼ˆè§„åˆ™ç”Ÿæˆï¼Œæ›¿ä»£ QueryGeneratorï¼‰

        Args:
            chapter_info: ç« èŠ‚ä¿¡æ¯
            attempt: å°è¯•æ¬¡æ•°ï¼ˆ1-5ï¼‰

        Returns:
            æœç´¢æŸ¥è¯¢è¯
        """
        import re

        # æå–å¹´çº§å…³é”®è¯
        grade_text = chapter_info.grade_level
        if "Kelas 1-2" in grade_text or "Fase A" in grade_text:
            grade_keyword = "kelas 1"
        elif "Kelas" in grade_text:
            match = re.search(r'Kelas\s+(\d+)', grade_text)
            if match:
                grade_keyword = f"kelas {match.group(1)}"
            else:
                grade_keyword = "kelas 1"
        else:
            grade_keyword = "kelas 1"

        # ç®€åŒ–ç« èŠ‚åç§°
        chapter = chapter_info.chapter_title.lower()

        # åˆ¤æ–­å­¦æœŸï¼ˆç®€å•å¯å‘å¼ï¼‰
        semester2_keywords = ["geometri", "statistik", "peluang", "data", "pengukuran", "bangun"]
        semester = "semester 2" if any(kw in chapter for kw in semester2_keywords) else "semester 1"

        # æ ¹æ®å°è¯•æ¬¡æ•°ç”Ÿæˆä¸åŒçš„æœç´¢è¯
        if attempt == 1:
            # å°è¯• 1: ç²¾å‡†åˆ—è¡¨ - é™å®š YouTubeï¼ŒåŒ…å«ç« èŠ‚å
            query = f"site:youtube.com playlist matematika {grade_keyword} {chapter}"
        elif attempt == 2:
            # å°è¯• 2: å­¦æœŸ/å…¨å¥—åˆé›†
            query = f"site:youtube.com playlist matematika {grade_keyword} full course {semester}"
        elif attempt == 3:
            # å°è¯• 3: å¯»æ‰¾é¢‘é“
            query = f"rekomendasi channel youtube belajar matematika {grade_keyword} terbaik"
        elif attempt == 4:
            # å°è¯• 4: æ›´å®½æ³›çš„ YouTube æœç´¢
            query = f"playlist lengkap matematika {grade_keyword} {semester}"
        else:
            # å°è¯• 5: æ•™è‚²å¹³å°æœç´¢
            query = f"ruangguru zenius pahamify matematika {grade_keyword} {chapter}"

        return query

    def search_for_playlists(self, syllabus_data: Dict[str, Any]) -> List[PlaylistRecord]:
        """
        ä¸»å‡½æ•°ï¼šä¸ºæ•™å­¦å¤§çº²æ•°æ®æœç´¢æ’­æ”¾åˆ—è¡¨
        
        Args:
            syllabus_data: çŸ¥è¯†ç‚¹ JSON æ•°æ®
        
        Returns:
            æ‰¾åˆ°çš„æ’­æ”¾åˆ—è¡¨è®°å½•åˆ—è¡¨
        """
        print("\n" + "="*80)
        print("ğŸš€ å¼€å§‹æœç´¢æ’­æ”¾åˆ—è¡¨")
        print("="*80 + "\n")
        
        # æå–çŸ¥è¯†ç‚¹æ•°æ®
        knowledge_points = syllabus_data.get("knowledge_points", [])
        
        if not knowledge_points:
            print("âŒ é”™è¯¯: æœªæ‰¾åˆ°çŸ¥è¯†ç‚¹æ•°æ®")
            return []
        
        # æŒ‰ç« èŠ‚åˆ†ç»„
        chapters = self._group_by_chapter(knowledge_points)
        
        print(f"ğŸ“š å‘ç° {len(chapters)} ä¸ªç« èŠ‚éœ€è¦æœç´¢\n")
        
        # éå†æ¯ä¸ªç« èŠ‚
        for idx, (chapter_key, chapter_info) in enumerate(chapters.items(), 1):
            print(f"\n{'â”€'*80}")
            print(f"ğŸ“– [{idx}/{len(chapters)}] å¤„ç†ç« èŠ‚: {chapter_info.chapter_title}")
            print(f"{'â”€'*80}")
            
            # ä¸ºæ¯ä¸ªç« èŠ‚æ‰§è¡Œæ™ºèƒ½æœç´¢å¾ªç¯
            self._search_chapter(chapter_info)
            
            # æ·»åŠ å»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡å¿«
            time.sleep(1)
        
        print(f"\n{'='*80}")
        print(f"âœ… æœç´¢å®Œæˆï¼å…±æ‰¾åˆ° {len(self.all_records)} ä¸ªæ’­æ”¾åˆ—è¡¨")
        print(f"{'='*80}\n")
        
        return self.all_records
    
    def _group_by_chapter(self, knowledge_points: List[Dict[str, Any]]) -> Dict[str, ChapterInfo]:
        """
        æŒ‰ç« èŠ‚åˆ†ç»„çŸ¥è¯†ç‚¹
        
        Args:
            knowledge_points: çŸ¥è¯†ç‚¹åˆ—è¡¨
        
        Returns:
            ç« èŠ‚å­—å…¸ï¼Œkey ä¸ºç« èŠ‚å”¯ä¸€æ ‡è¯†ï¼Œvalue ä¸ºç« èŠ‚ä¿¡æ¯
        """
        chapters = {}
        
        for point in knowledge_points:
            # æ„å»ºç« èŠ‚å”¯ä¸€æ ‡è¯†
            chapter_key = f"{point.get('grade_level', '')}_{point.get('subject', '')}_{point.get('chapter_title', '')}"
            
            if chapter_key not in chapters:
                chapters[chapter_key] = ChapterInfo(
                    grade_level=point.get('grade_level', ''),
                    subject=point.get('subject', ''),
                    chapter_title=point.get('chapter_title', ''),
                    topics_count=0
                )
            
            chapters[chapter_key].topics_count += 1
        
        return chapters
    
    def _search_chapter(self, chapter_info: ChapterInfo, max_attempts: int = 5):
        """
        ä¸ºå•ä¸ªç« èŠ‚æ‰§è¡Œæ™ºèƒ½æœç´¢å¾ªç¯ï¼ˆå¢å¼ºæ—¥å¿—ç‰ˆæœ¬ï¼‰
        
        Args:
            chapter_info: ç« èŠ‚ä¿¡æ¯
            max_attempts: æœ€å¤§å°è¯•æ¬¡æ•°
        """
        print(f"\n[ğŸ” ç­–ç•¥] æ­£ä¸ºç« èŠ‚ \"{chapter_info.chapter_title}\" ç”Ÿæˆæœç´¢è¯...")
        print(f"[ğŸ” ç­–ç•¥è¯¦æƒ…] å¹´çº§: {chapter_info.grade_level}, å­¦ç§‘: {chapter_info.subject}")
        
        # è·å–æ‰€æœ‰ç« èŠ‚åˆ—è¡¨ï¼ˆç”¨äºåˆ¤æ–­å­¦æœŸï¼‰
        all_chapter_titles = list(set([r.chapter_title for r in self.all_records] + [chapter_info.chapter_title]))
        
        # æ™ºèƒ½æœç´¢å¾ªç¯
        for attempt in range(1, max_attempts + 1):
            print(f"\n{'='*60}")
            print(f"[ğŸ”„ å¾ªç¯ {attempt}/{max_attempts}] å¼€å§‹æ–°çš„æœç´¢å°è¯•")
            print(f"{'='*60}")
            
            # ç”ŸæˆæŸ¥è¯¢ï¼ˆæ ¹æ®å°è¯•æ¬¡æ•°è°ƒæ•´ç­–ç•¥ï¼‰
            query = self._generate_fallback_query(chapter_info, attempt)
            print(f"[ğŸ“ æœ€ç»ˆæŸ¥è¯¢] \"{query}\"")
            
            # æ­¥éª¤ A: æ‰§è¡Œæœç´¢
            print(f"\n[ğŸ” æœç´¢æ‰§è¡Œ] è°ƒç”¨ Tavily æœç´¢ API...")
            search_results = self.hunter.search(query, max_results=10)
            
            if not search_results:
                print(f"[âš ï¸ è­¦å‘Š] Tavily æœªè¿”å›æœç´¢ç»“æœ")
                print(f"[ğŸ”„ å¾ªç¯] å°è¯•æ¬¡æ•° {attempt}/{max_attempts} å¤±è´¥ï¼Œç»§ç»­ä¸‹ä¸€æ¬¡å°è¯•...")
                continue
            
            # æ‰“å° Tavily è¿”å›çš„åŸå§‹ç»“æœ
            print(f"\n[ğŸ“Š Tavily è¿”å›ç»“æœ] å…± {len(search_results)} ä¸ªç»“æœ:")
            for i, result in enumerate(search_results[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ª
                print(f"  [{i}] {result.title[:60]}...")
                print(f"      URL: {result.url[:70]}...")
                print(f"      æ‘˜è¦: {result.snippet[:80]}..." if result.snippet else "      æ‘˜è¦: ï¼ˆæ— ï¼‰")
            
            # æ­¥éª¤ B: è¯„ä¼°ç»“æœ
            print(f"\n[ğŸ•µï¸ LLM è¯„ä¼°] å¼€å§‹è¯„ä¼°æœç´¢ç»“æœ...")
            evaluation = self.inspector.evaluate_results(search_results, chapter_info)
            
            # æ­¥éª¤ C: å†³ç­–ä¸ä¿®æ­£
            if evaluation.is_good_batch and evaluation.best_urls:
                # æ‰¾åˆ°é«˜è´¨é‡åˆ—è¡¨ï¼Œä¿å­˜å¹¶è·³å‡ºå¾ªç¯
                print(f"\n[âœ… è¯„ä¼°æˆåŠŸ] æ‰¾åˆ° {len(evaluation.best_urls)} ä¸ªé«˜è´¨é‡èµ„æº")
                for url in evaluation.best_urls:
                    if url not in self.unique_playlists:
                        self.unique_playlists.add(url)
                        # ç”Ÿæˆç†ç”±
                        reason = f"åŒ¹é…ç« èŠ‚: {chapter_info.chapter_title}"
                        if evaluation.feedback:
                            reason += f" | {evaluation.feedback[:100]}"
                        
                        # æ£€æŸ¥æ˜¯å¦æ˜¯å•é›†è§†é¢‘
                        url_type = "Video Source" if "youtube.com/watch" in url and "list=" not in url else "Playlist/Channel"
                        reason += f" | ç±»å‹: {url_type}"
                        
                        record = PlaylistRecord(
                            grade_level=chapter_info.grade_level,
                            subject=chapter_info.subject,
                            chapter_title=chapter_info.chapter_title,
                            playlist_url=url,
                            search_query=query,
                            attempt_number=attempt,
                            reason=reason
                        )
                        self.all_records.append(record)
                        print(f"[âœ… æˆåŠŸ] é”å®šèµ„æº ({url_type}): {url}")
                
                print(f"[âœ… å¾ªç¯å®Œæˆ] åœ¨ç¬¬ {attempt} æ¬¡å°è¯•ä¸­æˆåŠŸæ‰¾åˆ°èµ„æºï¼Œé€€å‡ºå¾ªç¯")
                return
            
            else:
                # æœªæ‰¾åˆ°é«˜è´¨é‡åˆ—è¡¨
                print(f"\n[âš ï¸ è¯„ä¼°ç»“æœ] æœªæ‰¾åˆ°é«˜è´¨é‡èµ„æº")
                print(f"[âš ï¸ åé¦ˆ] {evaluation.feedback[:200]}...")
                if attempt < max_attempts:
                    print(f"[ğŸ”„ å¾ªç¯] å°è¯•æ¬¡æ•° {attempt}/{max_attempts} æœªæˆåŠŸï¼Œç»§ç»­ä¸‹ä¸€æ¬¡å°è¯•...")
                else:
                    print(f"[âŒ å¾ªç¯] å·²è¾¾åˆ°æœ€å¤§å°è¯•æ¬¡æ•° {max_attempts}ï¼Œé€€å‡ºå¾ªç¯")
        
        # å¦‚æœæ‰€æœ‰å°è¯•éƒ½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ LLM ç”Ÿæˆå·²çŸ¥æ•™è‚²å¹³å°çš„ç›´æ¥é“¾æ¥
        # æ£€æŸ¥å½“å‰ç« èŠ‚æ˜¯å¦å·²ç»æ‰¾åˆ°èµ„æº
        current_chapter_found = any(
            record.chapter_title == chapter_info.chapter_title 
            for record in self.all_records
        )
        
        if not current_chapter_found:
            print(f"[ğŸ”„ è¡¥å……ç­–ç•¥] å°è¯•ä½¿ç”¨ LLM ç”Ÿæˆå·²çŸ¥æ•™è‚²å¹³å°çš„ç›´æ¥é“¾æ¥...")
            self._try_llm_generated_links(chapter_info)
        
        # å†æ¬¡æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°èµ„æº
        final_check = any(
            record.chapter_title == chapter_info.chapter_title 
            for record in self.all_records
        )
        
        if not final_check:
            print(f"[âš ï¸ å®Œæˆ] ç« èŠ‚ \"{chapter_info.chapter_title}\" æœªæ‰¾åˆ°åˆé€‚çš„æ’­æ”¾åˆ—è¡¨")
    
    def _try_llm_generated_links(self, chapter_info: ChapterInfo):
        """ä½¿ç”¨ LLM ç”Ÿæˆå·²çŸ¥å°å°¼æ•™è‚²å¹³å°çš„ç›´æ¥é“¾æ¥"""
        try:
            # âœ¨ ä½¿ç”¨æç¤ºè¯ç®¡ç†å™¨æ„å»ºå¹³å°é“¾æ¥ç”Ÿæˆæç¤ºè¯ï¼ˆæ›¿ä»£ç¡¬ç¼–ç ï¼‰
            if self.prompt_mgr:
                prompt = self.prompt_mgr.get_platform_links_user_prompt(
                    grade=chapter_info.grade_level,
                    subject=chapter_info.subject,
                    chapter=chapter_info.chapter_title
                )
            else:
                # é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨åŸæœ‰å®ç°
                prompt = f"""è¯·ä¸ºä»¥ä¸‹ç« èŠ‚æä¾›å°å°¼ä¸»è¦æ•™è‚²å¹³å°ï¼ˆRuangguru, Quipper, Zenius, Pahamify, Kelas Pintarï¼‰çš„ç›´æ¥é“¾æ¥ã€‚

å¹´çº§ï¼š{chapter_info.grade_level}ï¼ˆå°å­¦1-2å¹´çº§ï¼‰
å­¦ç§‘ï¼š{chapter_info.subject}
ç« èŠ‚ï¼š{chapter_info.chapter_title}

è¯·æä¾›è¿™äº›å¹³å°çš„è¯¾ç¨‹é¡µé¢æˆ–æ’­æ”¾åˆ—è¡¨é“¾æ¥ã€‚å¦‚æœä¸çŸ¥é“ç¡®åˆ‡é“¾æ¥ï¼Œè¯·æä¾›å¹³å°ä¸»é¡µå’Œæœç´¢å»ºè®®ã€‚

è¯·ä»¥ JSON æ ¼å¼è¿”å›ï¼š
{{
    "links": [
        {{"platform": "å¹³å°åç§°", "url": "é“¾æ¥", "description": "æè¿°"}},
        ...
    ]
}}

åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚"""
            
            response = self.inspector.llm_client.call_gemini(
                prompt,
                max_tokens=8000,  # [ä¿®å¤] 2026-01-20: ä»1000å¢åŠ åˆ°8000
                temperature=0.3
            )
            
            # æå– JSON
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group(0))
                links = data.get("links", [])
                
                for link_info in links[:3]:  # æœ€å¤š3ä¸ª
                    url = link_info.get("url", "")
                    if url and url.startswith("http"):
                        if url not in self.unique_playlists:
                            self.unique_playlists.add(url)
                            reason = f"LLMç”Ÿæˆ | {link_info.get('platform', '')}: {link_info.get('description', '')}"
                            record = PlaylistRecord(
                                grade_level=chapter_info.grade_level,
                                subject=chapter_info.subject,
                                chapter_title=chapter_info.chapter_title,
                                playlist_url=url,
                                search_query=f"LLMç”Ÿæˆ-{link_info.get('platform', '')}",
                                attempt_number=999,
                                reason=reason
                            )
                            self.all_records.append(record)
                            print(f"[âœ… è¡¥å……] LLMç”Ÿæˆé“¾æ¥: {url}")
        except Exception as e:
            print(f"[âš ï¸ è­¦å‘Š] LLMç”Ÿæˆé“¾æ¥å¤±è´¥: {str(e)}")


# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================

def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    # ç¡®å®šè¾“å…¥æ–‡ä»¶
    if len(sys.argv) > 1:
        input_file = sys.argv[1]
    else:
        # é»˜è®¤ä½¿ç”¨ 1-2 å¹´çº§çš„æ–‡ä»¶
        input_file = "/Users/shmiwanghao8/Desktop/education/Indonesia/Knowledge Point/5. Final Panduan Mata Pelajaran Matematika_12_09_2025_Revisi 3_30-58_knowledge_points.json"
    
    if not os.path.exists(input_file):
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        return
    
    # è¯»å–çŸ¥è¯†ç‚¹æ•°æ®
    print(f"ğŸ“– è¯»å–çŸ¥è¯†ç‚¹æ–‡ä»¶: {input_file}")
    with open(input_file, 'r', encoding='utf-8') as f:
        syllabus_data = json.load(f)
    
    # åˆå§‹åŒ–å®¢æˆ·ç«¯å’Œç­–ç•¥å™¨
    try:
        llm_client = AIBuildersClient()
        # ä½¿ç”¨ ai-builders æœç´¢ APIï¼ˆå…è´¹ä¸”æ›´æ™ºèƒ½ï¼‰
        strategist = SearchStrategist(llm_client, search_engine="ai-builders")
        
        # æ‰§è¡Œæœç´¢
        playlist_records = strategist.search_for_playlists(syllabus_data)
        
        # ä¿å­˜ç»“æœåˆ° CSV
        output_file = input_file.replace("_knowledge_points.json", "_playlists.csv")
        print(f"\nğŸ’¾ ä¿å­˜ç»“æœåˆ°: {output_file}")
        
        if playlist_records:
            with open(output_file, 'w', encoding='utf-8', newline='') as f:
                writer = csv.DictWriter(f, fieldnames=[
                    'grade_level', 'subject', 'chapter_title', 
                    'playlist_url', 'search_query', 'attempt_number', 'reason'
                ])
                writer.writeheader()
                for record in playlist_records:
                    writer.writerow(record.model_dump())
            
            print(f"âœ… æˆåŠŸä¿å­˜ {len(playlist_records)} æ¡è®°å½•")
        else:
            print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•æ’­æ”¾åˆ—è¡¨")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

