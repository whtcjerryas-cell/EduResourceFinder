# Search Engine V2 ä¼˜åŒ–æ–¹æ¡ˆ

**åˆ›å»ºæ—¶é—´**: 2026-01-20
**ç›®æ ‡**: ç®€åŒ–æœç´¢æµç¨‹ï¼Œæé«˜æœç´¢è´¨é‡ï¼Œå‡å°‘APIè°ƒç”¨æˆæœ¬
**å½“å‰é—®é¢˜**: 7ä¸ªæŸ¥è¯¢ â†’ 124ä¸ªç»“æœ â†’ ä»…ä¿ç•™20ä¸ªï¼ˆæµªè´¹èµ„æºï¼‰

---

## ğŸ“Š å½“å‰å®ç°åˆ†æ

### æœç´¢æµç¨‹æ¦‚è§ˆ

```
[ç”¨æˆ·è¯·æ±‚]
    â†“
[Step 0] ç”Ÿæˆæœç´¢ç­–ç•¥ (2-5ç§’ï¼ŒLLMè°ƒç”¨)
    - ç”Ÿæˆ5-7ä¸ªé«˜åº¦å·®å¼‚åŒ–çš„æœç´¢è¯
    - ç¡®å®šæœç´¢è¯­è¨€ã€å¹³å°ã€ä¼˜å…ˆåŸŸå
    â†“
[Step 1] é€‰æ‹©ç¬¬ä¸€ä¸ªæœç´¢è¯
    â†“
[Step 2] å¹¶è¡Œæœç´¢ (60-120ç§’)
    - 5x Tavily/Metasoæœç´¢ (æ¯ä¸ªæŸ¥è¯¢30ç»“æœ) = 150ç»“æœ
    - 1x Googleæœç´¢ (ç¬¬ä¸€ä¸ªæŸ¥è¯¢20ç»“æœ) = 20ç»“æœ
    - 1x Baiduæœç´¢ (å¦‚æœä¸­æ–‡ï¼Œ30ç»“æœ) = 30ç»“æœ
    - 1x æœ¬åœ°å®šå‘æœç´¢ (20ç»“æœ) = 20ç»“æœ
    - åˆè®¡: ~220ä¸ªåŸå§‹ç»“æœ
    â†“
[Step 3] URLå»é‡
    - ~124ä¸ªå»é‡åç»“æœ
    â†“
[Step 4] è¯„åˆ†æ’åº
    - è§„åˆ™è¯„åˆ† (1-2ç§’)
    - LLMè¯„åˆ† (10-20ç§’)
    â†“
[Step 5] è¿”å›å‰20ä¸ªé«˜è´¨é‡ç»“æœ
```

### æ ¸å¿ƒé—®é¢˜

| é—®é¢˜ | å½±å“ | ä¸¥é‡ç¨‹åº¦ |
|------|------|----------|
| **è¿‡åº¦æœç´¢** | 7æ¬¡APIè°ƒç”¨è·å–220ç»“æœï¼Œä»…ä¿ç•™20ä¸ª | ğŸ”´ é«˜ |
| **è¯­ä¹‰é‡å¤** | 5ä¸ªæŸ¥è¯¢å°½ç®¡"å·®å¼‚åŒ–"ä½†ä»é«˜åº¦é‡å  | ğŸŸ¡ ä¸­ |
| **èµ„æºæµªè´¹** | APIæˆæœ¬æµªè´¹83% (220â†’20) | ğŸ”´ é«˜ |
| **å“åº”æ…¢** | 60-120ç§’ç”¨æˆ·ä½“éªŒå·® | ğŸŸ¡ ä¸­ |
| **é€»è¾‘å¤æ‚** | 7è·¯å¹¶è¡Œæœç´¢éš¾ä»¥è°ƒè¯•ç»´æŠ¤ | ğŸŸ¡ ä¸­ |
| **è´¨é‡æ³¢åŠ¨** | å½“æ‰€æœ‰ç»“æœè´¨é‡ä½æ—¶æ— é™çº§ç­–ç•¥ | ğŸ”´ é«˜ |

### æ€§èƒ½æ•°æ®

**å½“å‰å®ç°**:
- æœç´¢æ¬¡æ•°: 7æ¬¡å¹¶è¡Œ
- åŸå§‹ç»“æœ: 220ä¸ª
- å»é‡å: 124ä¸ª
- æœ€ç»ˆè¿”å›: 20ä¸ª
- ä¿ç•™ç‡: 16% (20/124)
- æµªè´¹ç‡: 84%
- å“åº”æ—¶é—´: 60-120ç§’
- APIæˆæœ¬: 7x

---

## ğŸ¯ ä¼˜åŒ–ç›®æ ‡

1. **ç®€åŒ–æµç¨‹**: å‡å°‘7æ¬¡æœç´¢åˆ°1-3æ¬¡
2. **æé«˜è´¨é‡**: ä¿æŒæˆ–æå‡ç»“æœç›¸å…³æ€§
3. **é™ä½æˆæœ¬**: å‡å°‘83%çš„APIè°ƒç”¨
4. **åŠ å¿«é€Ÿåº¦**: ç›®æ ‡å“åº”æ—¶é—´ < 30ç§’
5. **è´¨é‡ä¿éšœ**: ä½è´¨é‡ç»“æœçš„é™çº§ç­–ç•¥

---

## ğŸ“‹ ä¼˜åŒ–æ–¹æ¡ˆå¯¹æ¯”

### æ–¹æ¡ˆä¸€ï¼šæ¸è¿›å¼æœç´¢ï¼ˆæ¨è â­â­â­â­â­ï¼‰

**æ ¸å¿ƒç†å¿µ**: ä»å°‘åˆ°å¤šï¼ŒæŒ‰éœ€æ‰©å±•

#### å®ç°é€»è¾‘

```
[ç”¨æˆ·è¯·æ±‚]
    â†“
[Step 1] é«˜è´¨é‡æŸ¥è¯¢ç”Ÿæˆ (2-3ç§’)
    - ä½¿ç”¨LLMç”Ÿæˆ1ä¸ªæœ€ä¼˜æŸ¥è¯¢ï¼ˆè€Œé5-7ä¸ªï¼‰
    - åŒ…å«: "playlist" + "subject" + "grade" + "country"
    â†“
[Step 2] åˆå§‹æœç´¢ (15-20ç§’) âš¡
    - 1x Tavily/Metaso (30ç»“æœ)
    - ä½¿ç”¨æœ€ä¼˜æŸ¥è¯¢
    â†“
[Step 3] å¿«é€Ÿè´¨é‡è¯„ä¼° (3-5ç§’)
    - ä½¿ç”¨è§„åˆ™è¯„åˆ†ï¼ˆä¸å«LLMï¼‰
    - è®¡ç®—å‰10ä¸ªç»“æœçš„å¹³å‡åˆ†
    â†“
[è´¨é‡åˆ¤æ–­]
    â”œâ”€ é«˜è´¨é‡ (å¹³å‡åˆ† > 7.0)
    â”‚   â””â”€ ç›´æ¥è¿”å›å‰20ä¸ª âœ… (æ€»è€—æ—¶: ~25ç§’)
    â”‚
    â”œâ”€ ä¸­ç­‰è´¨é‡ (5.0 - 7.0)
    â”‚   â””â”€ [Step 4] è¡¥å……æœç´¢ (+15ç§’)
    â”‚       - 1x Google (20ç»“æœ)
    â”‚       - ä½¿ç”¨ç›¸åŒæŸ¥è¯¢
    â”‚       - åˆå¹¶åé‡æ–°è¯„åˆ†
    â”‚       - è¿”å›å‰20ä¸ª âœ… (æ€»è€—æ—¶: ~43ç§’)
    â”‚
    â””â”€ ä½è´¨é‡ (< 5.0)
        â””â”€ [Step 5] æŸ¥è¯¢é‡è¯• (+20ç§’)
            - ä½¿ç”¨ä¸åŒå…³é”®è¯é‡æ–°ç”ŸæˆæŸ¥è¯¢
            - é‡æ–°æœç´¢1æ¬¡ (Tavily/Metaso)
            - é‡æ–°è¯„åˆ†
            - è¿”å›å‰20ä¸ª âœ… (æ€»è€—æ—¶: ~48ç§’)
```

#### ä¼ªä»£ç 

```python
def incremental_search(request):
    # Step 1: ç”Ÿæˆæœ€ä¼˜æŸ¥è¯¢
    query = strategy_agent.generate_best_query(
        country=request.country,
        grade=request.grade,
        subject=request.subject
    )  # 2-3ç§’

    # Step 2: åˆå§‹æœç´¢
    results = llm_client.search(
        query=query,
        max_results=30,
        engine="tavily"  # æˆ– metaso
    )  # 15-20ç§’

    # Step 3: å¿«é€Ÿè´¨é‡è¯„ä¼°
    scored = rule_scorer.score_results(results, query)[:10]
    avg_score = sum(r['score'] for r in scored) / len(scored)

    # Step 4-5: æ ¹æ®è´¨é‡å†³å®šæ˜¯å¦è¡¥å……æœç´¢
    if avg_score > 7.0:
        # é«˜è´¨é‡ï¼Œç›´æ¥è¿”å›
        return scored[:20]
    elif avg_score > 5.0:
        # ä¸­ç­‰è´¨é‡ï¼Œè¡¥å……æœç´¢
        google_results = google_hunter.search(query, max_results=20)
        all_results = deduplicate(results + google_results)
        return rule_scorer.score_results(all_results, query)[:20]
    else:
        # ä½è´¨é‡ï¼ŒæŸ¥è¯¢é‡è¯•
        retry_query = strategy_agent.generate_alternative_query(request)
        retry_results = llm_client.search(retry_query, max_results=30)
        return rule_scorer.score_results(retry_results, retry_query)[:20]
```

#### ä¼˜ç‚¹
âœ… **APIæˆæœ¬é™ä½**: 1-2æ¬¡è°ƒç”¨ï¼ˆå½“å‰7æ¬¡ï¼‰
âœ… **å¹³å‡å“åº”å¿«**: 25ç§’ï¼ˆå½“å‰60-120ç§’ï¼‰
âœ… **è´¨é‡è‡ªé€‚åº”**: æ ¹æ®è´¨é‡åŠ¨æ€è°ƒæ•´
âœ… **å®ç°ç®€å•**: æœ€å°ä»£ç æ”¹åŠ¨
âœ… **æ˜“äºè°ƒè¯•**: å•çº¿ç¨‹æµç¨‹æ¸…æ™°

#### ç¼ºç‚¹
âš ï¸ æœ€åæƒ…å†µç•¥æ…¢: 48ç§’ï¼ˆä½†æ¯”å½“å‰60-120ç§’ä»å¿«ï¼‰
âš ï¸ éœ€è¦å‡†ç¡®çš„è´¨é‡é˜ˆå€¼

#### é€‚ç”¨åœºæ™¯
- 90%çš„æ­£å¸¸æœç´¢è¯·æ±‚
- å¯¹å“åº”æ—¶é—´æ•æ„Ÿçš„åœºæ™¯
- APIé¢„ç®—æœ‰é™çš„æƒ…å†µ

---

### æ–¹æ¡ˆäºŒï¼šæ™ºèƒ½æŸ¥è¯¢èåˆï¼ˆæ¨è â­â­â­â­ï¼‰

**æ ¸å¿ƒç†å¿µ**: ä¿ç•™æŸ¥è¯¢å¤šæ ·æ€§ï¼Œä½†å‡å°‘æœç´¢æ¬¡æ•°

#### å®ç°é€»è¾‘

```
[ç”¨æˆ·è¯·æ±‚]
    â†“
[Step 1] ç”Ÿæˆ3ä¸ªæŸ¥è¯¢å˜ä½“ (2-3ç§’)
    - Query 1: æ’­æ”¾åˆ—è¡¨æŸ¥è¯¢ (playlist + subject + grade)
    - Query 2: å¸¸è§„æŸ¥è¯¢ (subject + grade + video lesson)
    - Query 3: æœ¬åœ°åŒ–æŸ¥è¯¢ (subject + grade + æœ¬åœ°è¯­è¨€å…³é”®è¯)
    â†“
[Step 2] æ™ºèƒ½æœç´¢é€‰æ‹© (5-30ç§’)
    - æ ¹æ®å›½å®¶/è¯­è¨€è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜å¼•æ“
    - ä¸­æ–‡ â†’ Google + Baidu
    - è‹±è¯­ â†’ Google + Metaso
    - å…¶ä»– â†’ Tavily + Google
    â†“
[Step 3] èåˆå»é‡ (2-3ç§’)
    - ä½¿ç”¨RRF (Reciprocal Rank Fusion)èåˆç»“æœ
    - URLå»é‡
    â†“
[Step 4] è¯„åˆ†æ’åº (1-2ç§’)
    - è§„åˆ™è¯„åˆ†
    - è¿”å›å‰20ä¸ª
```

#### ä¼ªä»£ç 

```python
def smart_fusion_search(request):
    # Step 1: ç”Ÿæˆ3ä¸ªæŸ¥è¯¢
    queries = strategy_agent.generate_3_queries(request)  # 2-3ç§’

    # Step 2: æ™ºèƒ½å¼•æ“é€‰æ‹©
    country_config = config_manager.get_country_config(request.country)
    language = country_config.language_code

    if language == 'zh':
        # ä¸­æ–‡ï¼šGoogle + Baidu
        results_q1 = google_hunter.search(queries[0], max_results=20)
        results_q2 = baidu_hunter.search(queries[1], max_results=20)
        results_q3 = google_hunter.search(queries[2], max_results=10)
    elif language == 'en':
        # è‹±è¯­ï¼šGoogle + Metaso
        results_q1 = google_hunter.search(queries[0], max_results=20)
        results_q2 = metaso_client.search(queries[1], max_results=20)
        results_q3 = google_hunter.search(queries[2], max_results=10)
    else:
        # å…¶ä»–ï¼šTavily + Google
        results_q1 = tavily_client.search(queries[0], max_results=30)
        results_q2 = google_hunter.search(queries[1], max_results=20)
        results_q3 = tavily_client.search(queries[2], max_results=10)

    # Step 3: RRFèåˆ
    all_results = rrf_fuse([
        results_q1, results_q2, results_q3
    ])

    # Step 4: è¯„åˆ†è¿”å›
    return rule_scorer.score_results(all_results, query)[:20]
```

#### RRFèåˆç®—æ³•

```python
def rrf_fuse(result_lists, k=60):
    """
    Reciprocal Rank Fusion èåˆå¤šä¸ªæœç´¢ç»“æœåˆ—è¡¨

    Args:
        result_lists: å¤šä¸ªæœç´¢å¼•æ“çš„ç»“æœåˆ—è¡¨
        k: å¸¸æ•°ï¼ˆé€šå¸¸60ï¼‰

    Returns:
        èåˆåçš„æ’åºç»“æœ
    """
    scores = {}

    for results in result_lists:
        for rank, result in enumerate(results, 1):
            url = result['url']
            if url not in scores:
                scores[url] = {
                    'result': result,
                    'rrf_score': 0.0
                }
            # RRFå…¬å¼: 1/(k + rank)
            scores[url]['rrf_score'] += 1.0 / (k + rank)

    # æŒ‰RRFåˆ†æ•°æ’åº
    sorted_results = sorted(
        scores.values(),
        key=lambda x: x['rrf_score'],
        reverse=True
    )

    return [item['result'] for item in sorted_results]
```

#### ä¼˜ç‚¹
âœ… **å¹³è¡¡å¤šæ ·æ€§ä¸æ•ˆç‡**: 3ä¸ªæŸ¥è¯¢è¦†ç›–ä¸åŒåœºæ™¯
âœ… **æ™ºèƒ½å¼•æ“é€‰æ‹©**: æ ¹æ®è¯­è¨€è‡ªåŠ¨ä¼˜åŒ–
âœ… **RRFèåˆ**: æ›´ç§‘å­¦çš„æ’åèåˆ
âœ… **APIæˆæœ¬é™ä½**: 2-3æ¬¡è°ƒç”¨ï¼ˆå½“å‰7æ¬¡ï¼‰
âœ… **è´¨é‡ç¨³å®š**: å¤šæŸ¥è¯¢ä¿è¯è¦†ç›–ç‡

#### ç¼ºç‚¹
âš ï¸ RRFéœ€è¦è°ƒä¼˜kå‚æ•°
âš ï¸ å¼•æ“é€‰æ‹©é€»è¾‘éœ€è¦ç»´æŠ¤
âš ï¸ ä»£ç å¤æ‚åº¦ä¸­ç­‰

#### é€‚ç”¨åœºæ™¯
- éœ€è¦è¦†ç›–å¤šè¯­è¨€å¸‚åœº
- å¯¹ç»“æœè´¨é‡è¦æ±‚é«˜
- æœ‰ä¸€å®šAPIé¢„ç®—

---

### æ–¹æ¡ˆä¸‰ï¼šæ··åˆè¯„åˆ†ä¼˜åŒ–ï¼ˆæ¨è â­â­â­ï¼‰

**æ ¸å¿ƒç†å¿µ**: ä¿ç•™7æ¬¡æœç´¢ï¼Œä½†ä¼˜åŒ–è¯„åˆ†è´¨é‡

#### å®ç°é€»è¾‘

```
[ç”¨æˆ·è¯·æ±‚]
    â†“
[Step 1-2] ä¿æŒå½“å‰æœç´¢æµç¨‹
    - ç”Ÿæˆ5-7ä¸ªæŸ¥è¯¢
    - 7æ¬¡å¹¶è¡Œæœç´¢
    - è·å–~124ä¸ªç»“æœ
    â†“
[Step 3] å¤šçº§è¯„åˆ†æ¼æ–— (15-25ç§’)
    Level 1: å¿«é€Ÿè¿‡æ»¤ (1ç§’)
        - ç§»é™¤æ˜æ˜¾æ— å…³ç»“æœ
        - URLé»‘åå•è¿‡æ»¤
        - æ ‡é¢˜å…³é”®è¯åŒ¹é…
        â†’ 124 â†’ ~80ä¸ªç»“æœ
    â†“
    Level 2: è§„åˆ™è¯„åˆ† (2ç§’)
        - URLè´¨é‡ã€æ ‡é¢˜ç›¸å…³æ€§ã€æ¥æºå¯ä¿¡åº¦
        â†’ ~80 â†’ ~40ä¸ªç»“æœ
    â†“
    Level 3: LLMç²¾é€‰è¯„åˆ† (15-20ç§’)
        - ä»…å¯¹å‰40ä¸ªç»“æœä½¿ç”¨LLMæ·±åº¦è¯„åˆ†
        - æ‰¹é‡è¯„åˆ†ï¼ˆä¸€æ¬¡APIè°ƒç”¨ï¼‰
        â†’ ~40 â†’ 20ä¸ªæœ€ä½³ç»“æœ
    â†“
[Step 4] è¿”å›å‰20ä¸ª
```

#### ä¼ªä»£ç 

```python
def hybrid_scoring_search(request):
    # Step 1-2: ä¿æŒåŸæœ‰æœç´¢é€»è¾‘
    queries = strategy_agent.generate_strategy(request).search_queries
    results = parallel_search(queries[:5])  # 7æ¬¡å¹¶è¡Œæœç´¢
    results = deduplicate(results)  # ~124ä¸ª

    # Step 3: å¤šçº§è¯„åˆ†æ¼æ–—

    # Level 1: å¿«é€Ÿè¿‡æ»¤
    filtered = []
    for r in results:
        # URLé»‘åå•
        if is_blacklisted(r['url']):
            continue
        # æ ‡é¢˜å…³é”®è¯åŒ¹é…ï¼ˆå¿…é¡»åŒ…å«subjectæˆ–ç›¸å…³è¯ï¼‰
        if not has_relevant_keywords(r['title'], request.subject):
            continue
        filtered.append(r)
    # ~124 â†’ ~80ä¸ª

    # Level 2: è§„åˆ™è¯„åˆ†
    scored = rule_scorer.score_results(filtered, query)
    scored.sort(key=lambda x: x['score'], reverse=True)
    top_40 = scored[:40]
    # ~80 â†’ ~40ä¸ª

    # Level 3: LLMç²¾é€‰è¯„åˆ†ï¼ˆä»…å‰40ä¸ªï¼‰
    if should_use_llm_scoring(request):
        batch_prompt = build_batch_prompt(top_40, request)
        llm_scores = llm_client.call_llm(
            prompt=batch_prompt,
            max_tokens=8000,
            model="gemini-2.5-flash"
        )
        # è§£æLLMè¯„åˆ†å¹¶åˆå¹¶
        final_results = merge_scores(top_40, llm_scores)
    else:
        final_results = top_40

    return final_results[:20]
```

#### ä¼˜ç‚¹
âœ… **æœ€å¤§åŒ–åˆ©ç”¨ç°æœ‰ç»“æœ**: ä¸æµªè´¹å·²è·å–çš„124ä¸ªç»“æœ
âœ… **è´¨é‡æœ€é«˜**: å¤šçº§æ¼æ–—ä¿è¯ç»“æœè´¨é‡
âœ… **æ¸è¿›å¼æˆæœ¬**: Level 3 LLMè¯„åˆ†å¯é€‰
âœ… **çµæ´»æ§åˆ¶**: å¯æ ¹æ®é…ç½®è°ƒæ•´å„çº§é˜ˆå€¼

#### ç¼ºç‚¹
âš ï¸ APIæˆæœ¬ä»ç„¶é«˜: 7æ¬¡æœç´¢è°ƒç”¨
âš ï¸ å“åº”æ—¶é—´ä»æ…¢: 75-145ç§’
âš ï¸ å¤æ‚åº¦é«˜: å¤šçº§è¿‡æ»¤é€»è¾‘

#### é€‚ç”¨åœºæ™¯
- å¯¹ç»“æœè´¨é‡è¦æ±‚æé«˜
- APIé¢„ç®—å……è¶³
- ä¸åœ¨æ„å“åº”æ—¶é—´

---

### æ–¹æ¡ˆå››ï¼šAsyncIOå¼‚æ­¥æœç´¢ï¼ˆæ¨è â­â­â­â­ï¼‰

**æ ¸å¿ƒç†å¿µ**: ä½¿ç”¨å¼‚æ­¥I/OåŠ é€Ÿæœç´¢

#### å®ç°é€»è¾‘

```python
import asyncio
import aiohttp

class AsyncSearchEngine:
    async def search_async(self, query: str, engine: str):
        """å¼‚æ­¥æœç´¢å•ä¸ªå¼•æ“"""
        if engine == "tavily":
            return await self._search_tavily_async(query)
        elif engine == "google":
            return await self._search_google_async(query)
        # ...

    async def parallel_search_async(self, queries: List[str]):
        """å¹¶è¡Œæœç´¢å¤šä¸ªæŸ¥è¯¢"""
        tasks = []
        for query in queries[:3]:  # åªç”¨å‰3ä¸ªæŸ¥è¯¢
            # åŒæ—¶å‘èµ·Tavilyå’ŒGoogle
            tasks.append(self.search_async(query, "tavily"))
            tasks.append(self.search_async(query, "google"))

        # å¹¶è¡Œæ‰§è¡Œï¼Œç­‰å¾…æ‰€æœ‰å®Œæˆ
        results = await asyncio.gather(*tasks)
        return merge_results(results)

    def search(self, request):
        """åŒæ­¥å…¥å£"""
        queries = strategy_agent.generate_queries(request)[:3]
        loop = asyncio.get_event_loop()
        results = loop.run_until_complete(
            self.parallel_search_async(queries)
        )
        return score_and_filter(results)[:20]
```

#### æ€§èƒ½æå‡

| æœç´¢æ–¹å¼ | å¹¶è¡Œåº¦ | è€—æ—¶ |
|----------|--------|------|
| **å½“å‰ (ThreadPool)** | 7ä¸ªä»»åŠ¡ | 60-120ç§’ |
| **AsyncIO (3æŸ¥è¯¢x2å¼•æ“)** | 6ä¸ªä»»åŠ¡ | 20-30ç§’ |
| **æå‡** | - | **60-75%** |

#### ä¼˜ç‚¹
âœ… **æ€§èƒ½æœ€ä½³**: å¼‚æ­¥I/Oæ€§èƒ½æœ€ä¼˜
âœ… **ä»£ç ç®€æ´**: PythonåŸç”Ÿasync/await
âœ… **èµ„æºåˆ©ç”¨ç‡é«˜**: éé˜»å¡I/O
âœ… **APIæˆæœ¬é€‚ä¸­**: 3-6æ¬¡è°ƒç”¨

#### ç¼ºç‚¹
âš ï¸ éœ€è¦é‡å†™æœç´¢å®¢æˆ·ç«¯ä¸ºå¼‚æ­¥
âš ï¸ éœ€è¦å¤„ç†å¼‚æ­¥é”™è¯¯
âš ï¸ å­¦ä¹ æ›²çº¿

#### é€‚ç”¨åœºæ™¯
- è¿½æ±‚æè‡´æ€§èƒ½
- æœ‰Pythonå¼‚æ­¥ç¼–ç¨‹ç»éªŒ
- é•¿æœŸç»´æŠ¤çš„é¡¹ç›®

---

### æ–¹æ¡ˆäº”ï¼šç¼“å­˜ä¼˜å…ˆç­–ç•¥ï¼ˆæ¨è â­â­â­â­â­ï¼‰

**æ ¸å¿ƒç†å¿µ**: ä¼˜å…ˆè¿”å›ç¼“å­˜ç»“æœï¼ŒæŒ‰éœ€æœç´¢

#### å®ç°é€»è¾‘

```
[ç”¨æˆ·è¯·æ±‚]
    â†“
[Step 1] æ£€æŸ¥L1å†…å­˜ç¼“å­˜ (5ms)
    - ç¼“å­˜é”®: country+grade+subject
    - TTL: 5åˆ†é’Ÿ
    - å¦‚æœå‘½ä¸­ â†’ ç›´æ¥è¿”å› âœ…
    â†“
[Step 2] æ£€æŸ¥L2 Redisç¼“å­˜ (50ms)
    - TTL: 1å°æ—¶
    - å¦‚æœå‘½ä¸­ â†’ æ›´æ–°L1ï¼Œè¿”å› âœ…
    â†“
[Step 3] æ£€æŸ¥L3ç£ç›˜ç¼“å­˜ (100ms)
    - TTL: 24å°æ—¶
    - å¦‚æœå‘½ä¸­ â†’ æ›´æ–°L1/L2ï¼Œè¿”å› âœ…
    â†“
[Step 4] æ‰§è¡Œå®é™…æœç´¢ (25-48ç§’)
    - ä½¿ç”¨[æ–¹æ¡ˆä¸€]æ¸è¿›å¼æœç´¢
    - æ›´æ–°æ‰€æœ‰ç¼“å­˜å±‚çº§
    - è¿”å›ç»“æœ âœ…
```

#### ä¼ªä»£ç 

```python
class CachedSearchEngine:
    def __init__(self):
        self.l1_cache = {}  # å†…å­˜ç¼“å­˜
        self.l2_cache = Redis()  # Redisç¼“å­˜
        self.l3_cache = DiskCache()  # ç£ç›˜ç¼“å­˜

    def search(self, request):
        cache_key = f"{request.country}:{request.grade}:{request.subject}"

        # L1: å†…å­˜ç¼“å­˜
        if cache_key in self.l1_cache:
            logger.info("[ç¼“å­˜L1] å‘½ä¸­")
            return self.l1_cache[cache_key]

        # L2: Redisç¼“å­˜
        l2_result = self.l2_cache.get(cache_key)
        if l2_result:
            logger.info("[ç¼“å­˜L2] å‘½ä¸­")
            self.l1_cache[cache_key] = l2_result
            return l2_result

        # L3: ç£ç›˜ç¼“å­˜
        l3_result = self.l3_cache.get(cache_key)
        if l3_result:
            logger.info("[ç¼“å­˜L3] å‘½ä¸­")
            self.l1_cache[cache_key] = l3_result
            self.l2_cache.set(cache_key, l3_result, ttl=3600)
            return l3_result

        # æœªå‘½ä¸­ï¼Œæ‰§è¡Œå®é™…æœç´¢
        logger.info("[ç¼“å­˜æœªå‘½ä¸­] æ‰§è¡Œæœç´¢")
        results = self.incremental_search(request)

        # æ›´æ–°æ‰€æœ‰ç¼“å­˜å±‚çº§
        self.l1_cache[cache_key] = results
        self.l2_cache.set(cache_key, results, ttl=300)  # 5åˆ†é’Ÿ
        self.l3_cache.set(cache_key, results, ttl=86400)  # 24å°æ—¶

        return results
```

#### ç¼“å­˜å‘½ä¸­ç‡é¢„ä¼°

| åœºæ™¯ | å‘½ä¸­ç‡ | è¯´æ˜ |
|------|--------|------|
| **çƒ­é—¨æŸ¥è¯¢** | 80-90% | å¦‚: Indonesia/Kelas 1/Matematika |
| **å¸¸è§„æŸ¥è¯¢** | 40-60% | ç›¸åŒå¹´çº§/å­¦ç§‘çš„ä¸åŒå­¦æœŸ |
| **é•¿å°¾æŸ¥è¯¢** | 10-20% | æ–°å›½å®¶/å†·é—¨å­¦ç§‘ |

#### ä¼˜ç‚¹
âœ… **å“åº”æå¿«**: ç¼“å­˜å‘½ä¸­ < 100ms
âœ… **APIæˆæœ¬æœ€ä½**: 80%+è¯·æ±‚æ— éœ€APIè°ƒç”¨
âœ… **ç”¨æˆ·ä½“éªŒæœ€ä½³**: çƒ­é—¨å†…å®¹ç§’å¼€
âœ… **é™çº§å‹å¥½**: ç¼“å­˜å¤±è´¥ä¸å½±å“æœç´¢

#### ç¼ºç‚¹
âš ï¸ éœ€è¦RedisæœåŠ¡å™¨
âš ï¸ ç¼“å­˜æ›´æ–°ç­–ç•¥å¤æ‚
âš ï¸ å¯èƒ½è¿”å›è¿‡æ—¶å†…å®¹

#### é€‚ç”¨åœºæ™¯
- æœ‰å¤§é‡é‡å¤æŸ¥è¯¢
- å¯¹å“åº”æ—¶é—´è¦æ±‚æé«˜
- æœ‰RedisåŸºç¡€è®¾æ–½

---

## ğŸ¯ ä½è´¨é‡ç»“æœå¤„ç†ç­–ç•¥

### æ£€æµ‹æ–¹æ³•

```python
def detect_low_quality_results(results: List[Dict], request) -> bool:
    """
    æ£€æµ‹æœç´¢ç»“æœæ˜¯å¦æ•´ä½“è´¨é‡ä½

    Args:
        results: è¯„åˆ†åçš„ç»“æœåˆ—è¡¨
        request: åŸå§‹è¯·æ±‚

    Returns:
        True if low quality, False otherwise
    """
    if not results:
        return True

    # æ–¹æ³•1: å¹³å‡åˆ†æ£€æµ‹
    scores = [r.get('score', 0) for r in results[:20]]
    avg_score = sum(scores) / len(scores)
    if avg_score < 5.0:
        logger.warning(f"[ä½è´¨é‡] å¹³å‡åˆ† {avg_score:.2f} < 5.0")
        return True

    # æ–¹æ³•2: é«˜åˆ†ç»“æœæ•°é‡æ£€æµ‹
    high_score_count = sum(1 for s in scores if s >= 7.0)
    if high_score_count < 3:
        logger.warning(f"[ä½è´¨é‡] é«˜åˆ†ç»“æœä»… {high_score_count} ä¸ª")
        return True

    # æ–¹æ³•3: æ ‡é¢˜ç›¸å…³æ€§æ£€æµ‹
    relevant_count = 0
    for r in results[:10]:
        title_lower = r.get('title', '').lower()
        if any(keyword in title_lower for keyword in
               [request.subject.lower(), request.grade.lower()]):
            relevant_count += 1

    if relevant_count < 5:
        logger.warning(f"[ä½è´¨é‡] ç›¸å…³æ ‡é¢˜ä»… {relevant_count}/10")
        return True

    return False
```

### é™çº§ç­–ç•¥

#### ç­–ç•¥1: æŸ¥è¯¢é‡å†™

```python
def fallback_query_rewriting(request):
    """é™çº§ç­–ç•¥1: æŸ¥è¯¢é‡å†™"""
    logger.warning("[é™çº§] å°è¯•æŸ¥è¯¢é‡å†™...")

    # åŸæŸ¥è¯¢
    original_query = f"{request.subject} {request.grade}"

    # é‡å†™é€‰é¡¹
    rewrite_options = [
        # é€‰é¡¹1: ä½¿ç”¨è‹±æ–‡
        f"{translate_to_english(request.subject)} {translate_to_english(request.grade)}",

        # é€‰é¡¹2: æ·»åŠ "video"å…³é”®è¯
        f"{original_query} video",

        # é€‰é¡¹3: ä½¿ç”¨"course"
        f"{original_query} course",

        # é€‰é¡¹4: ç§»é™¤å¹´çº§ï¼Œåªç”¨å­¦ç§‘
        f"{request.subject}",

        # é€‰é¡¹5: ä½¿ç”¨YouTubeç‰¹å®šè¯­æ³•
        f"site:youtube.com {original_query}"
    ]

    # å°è¯•æ¯ä¸ªé‡å†™é€‰é¡¹ï¼Œç›´åˆ°è·å¾—é«˜è´¨é‡ç»“æœ
    for rewrite_query in rewrite_options:
        logger.info(f"[é‡è¯•] ä½¿ç”¨é‡å†™æŸ¥è¯¢: {rewrite_query}")
        results = llm_client.search(rewrite_query, max_results=30)
        scored = rule_scorer.score_results(results, rewrite_query)

        if not detect_low_quality_results(scored, request):
            logger.info(f"[âœ… é™çº§æˆåŠŸ] æŸ¥è¯¢: {rewrite_query}")
            return scored[:20]

    # æ‰€æœ‰é‡å†™éƒ½å¤±è´¥ï¼Œè¿”å›æ··åˆç»“æœ
    logger.error("[âŒ é™çº§å¤±è´¥] æ‰€æœ‰é‡å†™æŸ¥è¯¢éƒ½å¤±è´¥")
    return merge_all_attempts[:20]
```

#### ç­–ç•¥2: å¼•æ“åˆ‡æ¢

```python
def fallback_engine_switching(request):
    """é™çº§ç­–ç•¥2: å¼•æ“åˆ‡æ¢"""
    logger.warning("[é™çº§] å°è¯•å¼•æ“åˆ‡æ¢...")

    query = f"{request.subject} {request.grade}"

    # å°è¯•ä¸åŒå¼•æ“
    engines = [
        ("Tavily", lambda q: tavily_client.search(q, max_results=30)),
        ("Google", lambda q: google_hunter.search(q, max_results=20)),
        ("Metaso", lambda q: metaso_client.search(q, max_results=20)),
        ("Baidu", lambda q: baidu_hunter.search(q, max_results=30))
    ]

    for engine_name, search_func in engines:
        logger.info(f"[é‡è¯•] å°è¯• {engine_name}...")
        try:
            results = search_func(query)
            scored = rule_scorer.score_results(results, query)

            if not detect_low_quality_results(scored, request):
                logger.info(f"[âœ… é™çº§æˆåŠŸ] å¼•æ“: {engine_name}")
                return scored[:20]
        except Exception as e:
            logger.warning(f"[âš ï¸ {engine_name}] å¤±è´¥: {e}")

    logger.error("[âŒ é™çº§å¤±è´¥] æ‰€æœ‰å¼•æ“éƒ½å¤±è´¥")
    return []
```

#### ç­–ç•¥3: æ”¾å®½ç­›é€‰æ¡ä»¶

```python
def fallback_relax_filters(request):
    """é™çº§ç­–ç•¥3: æ”¾å®½ç­›é€‰æ¡ä»¶"""
    logger.warning("[é™çº§] æ”¾å®½ç­›é€‰æ¡ä»¶...")

    query = f"{request.subject} {request.grade}"

    # æ­£å¸¸æœç´¢
    all_results = llm_client.search(query, max_results=50)  # å¢åŠ åˆ°50

    # ç¬¬ä¸€è½®: ä¸¥æ ¼è¯„åˆ†ï¼ˆæ­£å¸¸é˜ˆå€¼ï¼‰
    scored_strict = rule_scorer.score_results(
        all_results,
        query,
        metadata={'strict_mode': True}
    )

    if not detect_low_quality_results(scored_strict, request):
        return scored_strict[:20]

    # ç¬¬äºŒè½®: å®½æ¾è¯„åˆ†ï¼ˆé™ä½é˜ˆå€¼ï¼‰
    logger.warning("[é™çº§] ä½¿ç”¨å®½æ¾è¯„åˆ†...")
    scored_relaxed = rule_scorer.score_results(
        all_results,
        query,
        metadata={
            'strict_mode': False,
            'min_score_threshold': 3.0,  # é™ä½åˆ°3.0
            'allow_partial_matches': True
        }
    )

    return scored_relaxed[:20]
```

#### ç­–ç•¥4: è¿”å›ç¼“å­˜å†å²ç»“æœ

```python
def fallback_historical_cache(request):
    """é™çº§ç­–ç•¥4: è¿”å›å†å²ç¼“å­˜"""
    logger.warning("[é™çº§] ä½¿ç”¨å†å²ç¼“å­˜...")

    cache_key = f"{request.country}:{request.grade}:{request.subject}"

    # æŸ¥æ‰¾å†å²ç¼“å­˜ï¼ˆå³ä½¿æ˜¯è¿‡æœŸçš„ï¼‰
    historical_results = []

    # L3: ç£ç›˜ç¼“å­˜ï¼ˆåŒ…æ‹¬å·²è¿‡æœŸçš„ï¼‰
    l3_data = l3_cache.get(cache_key, include_expired=True)
    if l3_data:
        historical_results.append({
            'source': 'L3_disk_cache',
            'age_hours': l3_data['age_hours'],
            'results': l3_data['results']
        })

    # æŸ¥æ‰¾ç›¸ä¼¼æŸ¥è¯¢çš„ç¼“å­˜
    similar_keys = l3_cache.find_similar(cache_key, max_results=5)
    for key in similar_keys:
        data = l3_cache.get(key, include_expired=True)
        if data:
            historical_results.append({
                'source': f'similar_cache:{key}',
                'age_hours': data['age_hours'],
                'results': data['results']
            })

    if historical_results:
        # è¿”å›æœ€æ–°çš„å†å²ç»“æœï¼Œå¹¶æ ‡è®°ä¸ºé™çº§
        best = historical_results[0]
        logger.info(f"[âœ… é™çº§] è¿”å›å†å²ç¼“å­˜ (æ¥æº: {best['source']}, "
                   f"æ—¶æ•ˆ: {best['age_hours']:.1f}å°æ—¶)")

        # æ·»åŠ é™çº§æ ‡è®°
        for r in best['results']:
            r['_fallback'] = True
            r['_fallback_source'] = best['source']
            r['_fallback_age'] = best['age_hours']

        return best['results'][:20]

    logger.error("[âŒ é™çº§å¤±è´¥] æ— å¯ç”¨å†å²ç¼“å­˜")
    return []
```

### ç»¼åˆé™çº§æµç¨‹

```python
def comprehensive_fallback(request):
    """ç»¼åˆé™çº§æµç¨‹"""

    # å°è¯•1: æŸ¥è¯¢é‡å†™
    results = fallback_query_rewriting(request)
    if results:
        return results

    # å°è¯•2: å¼•æ“åˆ‡æ¢
    results = fallback_engine_switching(request)
    if results:
        return results

    # å°è¯•3: æ”¾å®½ç­›é€‰æ¡ä»¶
    results = fallback_relax_filters(request)
    if results:
        return results

    # å°è¯•4: å†å²ç¼“å­˜
    results = fallback_historical_cache(request)
    if results:
        return results

    # æœ€ç»ˆé™çº§: è¿”å›ç©ºç»“æœ + å»ºè®®åé¦ˆ
    logger.error("[âŒ æ‰€æœ‰é™çº§å¤±è´¥] è¿”å›ç©ºç»“æœ")
    return {
        'results': [],
        'message': 'æœªæ‰¾åˆ°ç›¸å…³èµ„æºï¼Œè¯·å°è¯•è°ƒæ•´æœç´¢å…³é”®è¯æˆ–è”ç³»ç®¡ç†å‘˜',
        'suggestions': [
            'å°è¯•ä½¿ç”¨æ›´é€šç”¨çš„å­¦ç§‘åç§°',
            'å‡å°‘å¹´çº§é™åˆ¶',
            'ä½¿ç”¨è‹±æ–‡æœç´¢'
        ]
    }
```

---

## ğŸ“Š æ–¹æ¡ˆå¯¹æ¯”æ€»ç»“

| æ–¹æ¡ˆ | APIè°ƒç”¨ | å“åº”æ—¶é—´ | è´¨é‡ | å¤æ‚åº¦ | æ¨èåº¦ |
|------|---------|----------|------|--------|--------|
| **æ–¹æ¡ˆä¸€: æ¸è¿›å¼æœç´¢** | 1-2æ¬¡ | 25-48ç§’ | â­â­â­â­ | ä½ | â­â­â­â­â­ |
| **æ–¹æ¡ˆäºŒ: æ™ºèƒ½èåˆ** | 2-3æ¬¡ | 25-35ç§’ | â­â­â­â­â­ | ä¸­ | â­â­â­â­ |
| **æ–¹æ¡ˆä¸‰: æ··åˆè¯„åˆ†** | 7æ¬¡ | 75-145ç§’ | â­â­â­â­â­ | é«˜ | â­â­â­ |
| **æ–¹æ¡ˆå››: AsyncIO** | 3-6æ¬¡ | 20-30ç§’ | â­â­â­â­ | ä¸­ | â­â­â­â­ |
| **æ–¹æ¡ˆäº”: ç¼“å­˜ä¼˜å…ˆ** | 0.2-1æ¬¡ | <100ms-48ç§’ | â­â­â­â­ | ä¸­ | â­â­â­â­â­ |

---

## ğŸš€ æ¨èå®æ–½è·¯çº¿

### é˜¶æ®µ1: å¿«é€Ÿä¼˜åŒ–ï¼ˆ1-2å¤©ï¼‰

**å®æ–½æ–¹æ¡ˆä¸€ï¼ˆæ¸è¿›å¼æœç´¢ï¼‰**:

1. ä¿®æ”¹ `search_strategy_agent.py`:
   - ä¿®æ”¹ `generate_strategy()` è¿”å›1ä¸ªæœ€ä¼˜æŸ¥è¯¢
   - æ·»åŠ  `generate_alternative_query()` å¤‡ç”¨æ–¹æ³•

2. ä¿®æ”¹ `search_engine_v2.py`:
   - ç®€åŒ–å¹¶è¡Œæœç´¢é€»è¾‘ä¸ºå•æ¬¡æœç´¢
   - æ·»åŠ è´¨é‡è¯„ä¼°é€»è¾‘
   - å®ç°è¡¥å……æœç´¢å’Œé‡è¯•æœºåˆ¶

3. æ·»åŠ é™çº§ç­–ç•¥:
   - å®ç° `detect_low_quality_results()`
   - å®ç° `fallback_query_rewriting()`

**é¢„æœŸæ”¶ç›Š**:
- APIæˆæœ¬é™ä½ 83% (7â†’1-2æ¬¡)
- å¹³å‡å“åº”æ—¶é—´æå‡ 58% (60â†’25ç§’)
- ä»£ç å¯ç»´æŠ¤æ€§æ˜¾è‘—æå‡

### é˜¶æ®µ2: æ€§èƒ½ä¼˜åŒ–ï¼ˆ3-5å¤©ï¼‰

**å®æ–½æ–¹æ¡ˆå››ï¼ˆAsyncIOï¼‰+ æ–¹æ¡ˆäº”ï¼ˆç¼“å­˜ï¼‰**:

1. é‡æ„æœç´¢å®¢æˆ·ç«¯ä¸ºå¼‚æ­¥:
   - `async_tavily_client.py`
   - `async_google_client.py`

2. å®ç°ä¸‰çº§ç¼“å­˜:
   - L1: å†…å­˜ç¼“å­˜ (5åˆ†é’ŸTTL)
   - L2: Redisç¼“å­˜ (1å°æ—¶TTL)
   - L3: ç£ç›˜ç¼“å­˜ (24å°æ—¶TTL)

3. ä¼˜åŒ–é™çº§ç­–ç•¥:
   - æ·»åŠ å¼•æ“åˆ‡æ¢é€»è¾‘
   - æ·»åŠ å†å²ç¼“å­˜é™çº§

**é¢„æœŸæ”¶ç›Š**:
- ç¼“å­˜å‘½ä¸­æ—¶å“åº” < 100ms
- æœªå‘½ä¸­æ—¶å“åº” 20-30ç§’
- 80%+ è¯·æ±‚æ— éœ€APIè°ƒç”¨

### é˜¶æ®µ3: è´¨é‡æå‡ï¼ˆ5-7å¤©ï¼‰

**å®æ–½æ–¹æ¡ˆäºŒï¼ˆæ™ºèƒ½èåˆï¼‰**:

1. å®ç°RRFèåˆç®—æ³•
2. ä¼˜åŒ–æŸ¥è¯¢ç”Ÿæˆé€»è¾‘ï¼ˆ3ä¸ªæŸ¥è¯¢ï¼‰
3. æ ¹æ®è¯­è¨€æ™ºèƒ½é€‰æ‹©å¼•æ“
4. A/Bæµ‹è¯•éªŒè¯æ•ˆæœ

**é¢„æœŸæ”¶ç›Š**:
- ç»“æœè´¨é‡æå‡ 20-30%
- å¤šè¯­è¨€æ”¯æŒä¼˜åŒ–
- APIæˆæœ¬ä¿æŒä½ä½

---

## âœ… éªŒæ”¶æ ‡å‡†

### åŠŸèƒ½éªŒæ”¶

- [ ] æœç´¢ç»“æœæ•°é‡ >= 20ä¸ªï¼ˆé™¤éæ— ç»“æœï¼‰
- [ ] ä½è´¨é‡ç»“æœè‡ªåŠ¨è§¦å‘é™çº§
- [ ] é™çº§ç­–ç•¥è‡³å°‘å®ç°3ç§ï¼ˆæŸ¥è¯¢é‡å†™ã€å¼•æ“åˆ‡æ¢ã€æ”¾å®½æ¡ä»¶ï¼‰
- [ ] ç¼“å­˜å‘½ä¸­ç‡ >= 50%ï¼ˆæ¨¡æ‹Ÿæµ‹è¯•ï¼‰
- [ ] æ‰€æœ‰é™çº§åœºæ™¯éƒ½æœ‰æ˜ç¡®æ—¥å¿—

### æ€§èƒ½éªŒæ”¶

- [ ] å¹³å‡å“åº”æ—¶é—´ < 30ç§’ï¼ˆæ–¹æ¡ˆä¸€ï¼‰
- [ ] 90%å“åº”æ—¶é—´ < 45ç§’
- [ ] APIè°ƒç”¨æ¬¡æ•° <= 2æ¬¡/è¯·æ±‚ï¼ˆæ–¹æ¡ˆä¸€ï¼‰
- [ ] ç¼“å­˜å‘½ä¸­å“åº” < 100msï¼ˆæ–¹æ¡ˆäº”ï¼‰

### è´¨é‡éªŒæ”¶

- [ ] ç»“æœç›¸å…³æ€§è¯„åˆ† >= 7.0ï¼ˆå¹³å‡å€¼ï¼‰
- [ ] æ’­æ”¾åˆ—è¡¨å æ¯” >= 30%
- [ ] åŸŸååŒ¹é…ç‡ >= 60%

### ä»£ç è´¨é‡

- [ ] å•å…ƒæµ‹è¯•è¦†ç›–ç‡ >= 70%
- [ ] æ‰€æœ‰é™çº§è·¯å¾„éƒ½æœ‰æ—¥å¿—
- [ ] ä»£ç æ³¨é‡Šå®Œæ•´ï¼ˆä¸­æ–‡ï¼‰
- [ ] é”™è¯¯å¤„ç†å®Œå–„

---

## ğŸ“ å®æ–½å»ºè®®

### ä¼˜å…ˆçº§æ’åº

1. **ç«‹å³å®æ–½**: æ–¹æ¡ˆä¸€ï¼ˆæ¸è¿›å¼æœç´¢ï¼‰
   - ç«‹ç«¿è§å½±çš„æ•ˆæœ
   - å®æ–½é£é™©ä½
   - æˆæœ¬èŠ‚çœæ˜æ˜¾

2. **çŸ­æœŸå®æ–½**: æ–¹æ¡ˆäº”ï¼ˆç¼“å­˜ä¼˜å…ˆï¼‰
   - ç”¨æˆ·ä½“æ„Ÿæå‡æœ€æ˜æ˜¾
   - éœ€è¦RedisåŸºç¡€è®¾æ–½

3. **ä¸­æœŸå®æ–½**: æ–¹æ¡ˆå››ï¼ˆAsyncIOï¼‰
   - éœ€è¦é‡æ„ç°æœ‰ä»£ç 
   - æ€§èƒ½æå‡æ˜æ˜¾

4. **é•¿æœŸä¼˜åŒ–**: æ–¹æ¡ˆäºŒï¼ˆæ™ºèƒ½èåˆï¼‰+ æ–¹æ¡ˆä¸‰ï¼ˆæ··åˆè¯„åˆ†ï¼‰
   - æ ¹æ®å®é™…æ•ˆæœå†³å®š
   - éœ€è¦å¤§é‡A/Bæµ‹è¯•

### é£é™©ç®¡ç†

| é£é™© | åº”å¯¹ç­–ç•¥ |
|------|----------|
| **è´¨é‡ä¸‹é™** | ä¿ç•™æ—§ç‰ˆæœ¬ï¼Œç°åº¦å‘å¸ƒï¼ŒA/Bæµ‹è¯•å¯¹æ¯” |
| **ç¼“å­˜ä¸€è‡´æ€§é—®é¢˜** | è®¾ç½®åˆç†TTLï¼Œæä¾›æ‰‹åŠ¨åˆ·æ–°æ¥å£ |
| **é™çº§å¤±è´¥** | å®ç°å¤šå±‚é™çº§ï¼Œé¿å…å•ç‚¹æ•…éšœ |
| **APIé¢åº¦ç”¨å°½** | ç›‘æ§APIä½¿ç”¨ï¼Œå®ç°è‡ªåŠ¨é™çº§åˆ°å…è´¹å¼•æ“ |

---

## ğŸ”§ é…ç½®å»ºè®®

### ç¯å¢ƒå˜é‡

```bash
# æœç´¢å¼•æ“é…ç½®
ENABLE_PARALLEL_SEARCH=false  # ç¦ç”¨å¹¶è¡Œæœç´¢ï¼ˆæ–¹æ¡ˆä¸€ï¼‰
ENABLE_MULTI_CACHE=true       # å¯ç”¨å¤šçº§ç¼“å­˜ï¼ˆæ–¹æ¡ˆäº”ï¼‰
ENABLE_ASYNC_SEARCH=true      # å¯ç”¨å¼‚æ­¥æœç´¢ï¼ˆæ–¹æ¡ˆå››ï¼‰

# è´¨é‡é˜ˆå€¼
QUALITY_THRESHOLD_HIGH=7.0    # é«˜è´¨é‡é˜ˆå€¼
QUALITY_THRESHOLD_LOW=5.0     # ä½è´¨é‡é˜ˆå€¼
MIN_RESULTS_COUNT=15          # æœ€å°‘ç»“æœæ•°é‡

# é™çº§ç­–ç•¥
ENABLE_FALLBACK_QUERY_REWRITE=true   # æŸ¥è¯¢é‡å†™
ENABLE_FALLBACK_ENGINE_SWITCH=true   # å¼•æ“åˆ‡æ¢
ENABLE_FALLBACK_RELAX_FILTERS=true   # æ”¾å®½ç­›é€‰
ENABLE_FALLBACK_HISTORICAL_CACHE=true # å†å²ç¼“å­˜

# ç¼“å­˜é…ç½®
REDIS_URL=redis://localhost:6379/0
L1_CACHE_TTL=300          # 5åˆ†é’Ÿ
L2_CACHE_TTL=3600         # 1å°æ—¶
L3_CACHE_TTL=86400        # 24å°æ—¶
```

### é…ç½®æ–‡ä»¶ (config/search.yaml)

```yaml
search_engine:
  # ä¼˜åŒ–æ–¹æ¡ˆé€‰æ‹©: incremental/fusion/async/cached
  strategy: incremental

  # æŸ¥è¯¢ç”Ÿæˆ
  query_generation:
    max_queries: 1  # æ–¹æ¡ˆä¸€åªç”¨1ä¸ªæŸ¥è¯¢
    use_llm: true
    include_playlist: true
    include_localized: true

  # æœç´¢å¼•æ“é…ç½®
  engines:
    primary: tavily    # ä¸»å¼•æ“
    secondary: google  # è¾…åŠ©å¼•æ“
    fallback: metaso   # é™çº§å¼•æ“

  # è´¨é‡æ§åˆ¶
  quality:
    high_threshold: 7.0
    low_threshold: 5.0
    min_results: 15
    enable_llm_scoring: false  # æ–¹æ¡ˆä¸€ä¸ä½¿ç”¨LLMè¯„åˆ†

  # é™çº§ç­–ç•¥
  fallback:
    enabled: true
    max_attempts: 3
    strategies:
      - query_rewrite
      - engine_switch
      - relax_filters
      - historical_cache

  # ç¼“å­˜é…ç½®
  cache:
    enabled: true
    l1_enabled: true   # å†…å­˜ç¼“å­˜
    l2_enabled: true   # Redisç¼“å­˜
    l3_enabled: true   # ç£ç›˜ç¼“å­˜
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

### å¤–éƒ¨èµ„æº

- **RRFè®ºæ–‡**: [Reciprocal Rank Fusion outperforms Condorcet and individual Rank Learning Methods](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf)
- **AsyncIOæ–‡æ¡£**: [Python asyncioå®˜æ–¹æ–‡æ¡£](https://docs.python.org/3/library/asyncio.html)
- **Tavily API**: [Tavily Search API Documentation](https://docs.tavily.com/docs/tavily-api/rest-api)
- **Google Custom Search**: [Google Programmable Search](https://developers.google.com/custom-search)

### å†…éƒ¨æ–‡æ¡£

- å½“å‰å®ç°: `search_engine_v2.py:1100-1300`
- æœç´¢ç­–ç•¥: `search_strategy_agent.py:1-300`
- LLMå®¢æˆ·ç«¯: `llm_client.py:915-1020`
- è¯„åˆ†ç³»ç»Ÿ: `scoring/scorer.py`, `core/result_scorer.py`

### æœ€ä½³å®è·µ

- **æ¸è¿›å¼ä¼˜åŒ–**: ä»ç®€å•æ–¹æ¡ˆå¼€å§‹ï¼Œé€æ­¥ä¼˜åŒ–
- **A/Bæµ‹è¯•**: å¯¹æ¯”æ–°æ—§æ–¹æ¡ˆæ•ˆæœ
- **ç›‘æ§æŒ‡æ ‡**: APIè°ƒç”¨æ¬¡æ•°ã€å“åº”æ—¶é—´ã€ç¼“å­˜å‘½ä¸­ç‡
- **é™çº§ä¼˜å…ˆ**: ä¼˜å…ˆä¿è¯æœåŠ¡å¯ç”¨æ€§

---

**æœ€åæ›´æ–°**: 2026-01-20
**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**è´Ÿè´£äºº**: Claude Code
**å®¡æ ¸çŠ¶æ€**: å¾…å®¡æ ¸
