#!/usr/bin/env python3
"""
æµ‹è¯• AI Builders API ä¸­çš„æ¨¡åž‹æ˜¯å¦æ”¯æŒè§†è§‰è¾“å…¥
æµ‹è¯•æ¨¡åž‹ï¼šGemini 2.5 Pro, Grok-4-Fast, GPT-5
"""

import os
import json
import base64
import requests
from typing import Dict, Any, Optional
from pathlib import Path
from PIL import Image, ImageDraw, ImageFont
import io

# æ”¯æŒä»Ž .env æ–‡ä»¶è¯»å–çŽ¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    def load_dotenv():
        env_file = os.path.join(os.path.dirname(__file__), '..', '.env')
        if os.path.exists(env_file):
            with open(env_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#') and '=' in line:
                        key, value = line.split('=', 1)
                        os.environ[key.strip()] = value.strip().strip('"').strip("'")
    load_dotenv()


def create_test_image() -> bytes:
    """
    åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•å›¾ç‰‡ï¼ˆåŒ…å«æ–‡å­—å’Œå›¾å½¢ï¼‰
    ç”¨äºŽæµ‹è¯•è§†è§‰æ¨¡åž‹æ˜¯å¦èƒ½è¯†åˆ«å›¾ç‰‡å†…å®¹
    """
    # åˆ›å»ºä¸€ä¸ª400x300çš„ç™½è‰²èƒŒæ™¯å›¾ç‰‡
    img = Image.new('RGB', (400, 300), color='white')
    draw = ImageDraw.Draw(img)
    
    # ç»˜åˆ¶ä¸€äº›å›¾å½¢
    # çŸ©å½¢
    draw.rectangle([50, 50, 150, 100], fill='blue', outline='black', width=2)
    
    # åœ†å½¢
    draw.ellipse([200, 50, 300, 150], fill='red', outline='black', width=2)
    
    # æ–‡å­—
    try:
        # å°è¯•ä½¿ç”¨ç³»ç»Ÿå­—ä½“
        font = ImageFont.truetype("/System/Library/Fonts/Helvetica.ttc", 24)
    except:
        font = ImageFont.load_default()
    
    draw.text((50, 150), "Test Image", fill='black', font=font)
    draw.text((50, 200), "Blue Rectangle", fill='blue', font=font)
    draw.text((200, 200), "Red Circle", fill='red', font=font)
    draw.text((50, 250), "AI Vision Test", fill='green', font=font)
    
    # è½¬æ¢ä¸ºbytes
    img_bytes = io.BytesIO()
    img.save(img_bytes, format='PNG')
    img_bytes.seek(0)
    return img_bytes.getvalue()


def image_to_base64(image_bytes: bytes) -> str:
    """å°†å›¾ç‰‡bytesè½¬æ¢ä¸ºbase64å­—ç¬¦ä¸²"""
    return base64.b64encode(image_bytes).decode('utf-8')


def test_model_vision(
    model_name: str,
    api_token: str,
    test_image_bytes: bytes,
    test_method: str = "array_format"
) -> Dict[str, Any]:
    """
    æµ‹è¯•æŒ‡å®šæ¨¡åž‹æ˜¯å¦æ”¯æŒè§†è§‰è¾“å…¥
    
    Args:
        model_name: æ¨¡åž‹åç§°
        api_token: APIä»¤ç‰Œ
        test_image_bytes: æµ‹è¯•å›¾ç‰‡çš„bytes
        test_method: æµ‹è¯•æ–¹æ³• ("array_format", "base64_string", "url")
    
    Returns:
        æµ‹è¯•ç»“æžœå­—å…¸
    """
    base_url = "https://space.ai-builders.com/backend"
    endpoint = f"{base_url}/v1/chat/completions"
    
    headers = {
        "Authorization": f"Bearer {api_token}",
        "Content-Type": "application/json"
    }
    
    # å‡†å¤‡æµ‹è¯•å›¾ç‰‡çš„base64ç¼–ç 
    image_base64 = image_to_base64(test_image_bytes)
    
    # æž„å»ºä¸åŒçš„è¯·æ±‚æ ¼å¼
    if test_method == "array_format":
        # æ–¹æ³•1: OpenAIæ ¼å¼çš„å¤šæ¨¡æ€æ•°ç»„
        user_content = [
            {
                "type": "text",
                "text": "è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼ŒåŒ…æ‹¬é¢œè‰²ã€å½¢çŠ¶ã€æ–‡å­—ç­‰æ‰€æœ‰ç»†èŠ‚ã€‚"
            },
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/png;base64,{image_base64}"
                }
            }
        ]
    elif test_method == "base64_string":
        # æ–¹æ³•2: ç›´æŽ¥åœ¨æ–‡æœ¬ä¸­åŒ…å«base64ï¼ˆå®Œæ•´ç¼–ç ï¼‰
        user_content = f"""è¯·åˆ†æžä»¥ä¸‹å›¾ç‰‡ï¼ˆbase64ç¼–ç ï¼‰ï¼š
data:image/png;base64,{image_base64}

è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼ŒåŒ…æ‹¬ï¼š
1. å›¾ç‰‡ä¸­æœ‰å“ªäº›é¢œè‰²ï¼Ÿ
2. æœ‰å“ªäº›å½¢çŠ¶ï¼ˆçŸ©å½¢ã€åœ†å½¢ç­‰ï¼‰ï¼Ÿ
3. å›¾ç‰‡ä¸­æœ‰å“ªäº›æ–‡å­—ï¼Ÿ
4. æ•´ä½“å¸ƒå±€å¦‚ä½•ï¼Ÿ

è¯·å°½å¯èƒ½è¯¦ç»†åœ°æè¿°ã€‚"""
    elif test_method == "url":
        # æ–¹æ³•3: ä½¿ç”¨å›¾ç‰‡URLï¼ˆéœ€è¦å…ˆä¸Šä¼ å›¾ç‰‡ï¼‰
        user_content = "è¯·åˆ†æžè¿™å¼ å›¾ç‰‡ï¼šhttps://example.com/test.png"
    else:
        user_content = "è¯·æè¿°ä¸€å¼ æµ‹è¯•å›¾ç‰‡çš„å†…å®¹ã€‚"
    
    # æž„å»ºæ¶ˆæ¯
    messages = [
        {
            "role": "system",
            "content": "ä½ æ˜¯ä¸€ä¸ªè§†è§‰åˆ†æžä¸“å®¶ï¼Œæ“…é•¿è¯¦ç»†æè¿°å›¾ç‰‡å†…å®¹ã€‚"
        },
        {
            "role": "user",
            "content": user_content
        }
    ]
    
    # GPT-5æœ‰ç‰¹æ®Šè¦æ±‚ï¼štemperatureå¿…é¡»ä¸º1.0ï¼Œä¸”ä½¿ç”¨max_completion_tokens
    if model_name == "gpt-5":
        payload = {
            "model": model_name,
            "messages": messages,
            "max_completion_tokens": 1000,  # GPT-5ä½¿ç”¨max_completion_tokens
            "temperature": 1.0,  # GPT-5å¿…é¡»ä¸º1.0
            # GPT-5ä¸æ”¯æŒtool_choiceå’Œtoolså‚æ•°
        }
    else:
        payload = {
            "model": model_name,
            "messages": messages,
            "max_tokens": 1000,
            "temperature": 0.3,
            "tool_choice": "none",
            "tools": None
        }
    
    print(f"\n{'='*80}")
    print(f"ðŸ§ª æµ‹è¯•æ¨¡åž‹: {model_name}")
    print(f"ðŸ“‹ æµ‹è¯•æ–¹æ³•: {test_method}")
    print(f"{'='*80}")
    print(f"ðŸ“¤ è¯·æ±‚Payload:")
    print(f"   Model: {model_name}")
    print(f"   Messagesæ•°é‡: {len(messages)}")
    print(f"   User Contentç±»åž‹: {type(user_content).__name__}")
    if isinstance(user_content, list):
        print(f"   User Contenté¡¹ç›®æ•°: {len(user_content)}")
        for i, item in enumerate(user_content):
            print(f"     é¡¹ç›®{i+1}: type={item.get('type', 'N/A')}")
    else:
        print(f"   User Contenté•¿åº¦: {len(str(user_content))} å­—ç¬¦")
    
    result = {
        "model": model_name,
        "test_method": test_method,
        "success": False,
        "supports_vision": False,
        "response_text": "",
        "error": None,
        "token_usage": {},
        "http_status": None,
        "raw_response": None
    }
    
    try:
        import sys
        from pathlib import Path
        project_root = Path(__file__).parent.parent
        if str(project_root) not in sys.path:
            sys.path.insert(0, str(project_root))
        from llm_client import get_proxy_config
        
        response = requests.post(
            endpoint,
            headers=headers,
            json=payload,
            params={"debug": "true"},
            timeout=60,
            proxies=get_proxy_config()
        )
        
        result["http_status"] = response.status_code
        
        print(f"\nðŸ“¥ HTTPå“åº”çŠ¶æ€: {response.status_code}")
        
        if response.status_code == 200:
            response_data = response.json()
            result["raw_response"] = response_data
            
            # æå–å“åº”å†…å®¹
            if "choices" in response_data and len(response_data["choices"]) > 0:
                choice = response_data["choices"][0]
                message = choice.get("message", {})
                content = message.get("content", "")
                
                result["response_text"] = content
                result["success"] = True
                
                # åˆ¤æ–­æ˜¯å¦æ”¯æŒè§†è§‰ï¼ˆé€šè¿‡å“åº”å†…å®¹åˆ¤æ–­ï¼‰
                # å¦‚æžœæ¨¡åž‹èƒ½æè¿°å›¾ç‰‡çš„å…·ä½“å†…å®¹ï¼ˆé¢œè‰²ã€å½¢çŠ¶ã€æ–‡å­—ï¼‰ï¼Œè¯´æ˜Žæ”¯æŒè§†è§‰
                vision_keywords = ["è“è‰²", "çº¢è‰²", "çŸ©å½¢", "åœ†å½¢", "Test Image", "blue", "red", 
                                 "rectangle", "circle", "æ–‡å­—", "text", "å›¾ç‰‡", "image"]
                content_lower = content.lower()
                matched_keywords = [kw for kw in vision_keywords if kw.lower() in content_lower]
                
                if len(matched_keywords) >= 3:
                    result["supports_vision"] = True
                    print(f"âœ… æ¨¡åž‹å“åº”æˆåŠŸï¼Œæ£€æµ‹åˆ°è§†è§‰å…³é”®è¯: {matched_keywords[:5]}")
                else:
                    result["supports_vision"] = False
                    print(f"âš ï¸  æ¨¡åž‹å“åº”æˆåŠŸï¼Œä½†æœªæ£€æµ‹åˆ°è¶³å¤Ÿçš„è§†è§‰å…³é”®è¯")
                
                # æå–tokenä½¿ç”¨æƒ…å†µ
                if "usage" in response_data:
                    result["token_usage"] = response_data["usage"]
                    usage = response_data["usage"]
                    print(f"\nðŸ“Š Tokenä½¿ç”¨æƒ…å†µ:")
                    print(f"   è¾“å…¥Token: {usage.get('prompt_tokens', 'N/A')}")
                    print(f"   è¾“å‡ºToken: {usage.get('completion_tokens', 'N/A')}")
                    print(f"   æ€»è®¡Token: {usage.get('total_tokens', 'N/A')}")
                
                print(f"\nðŸ“ æ¨¡åž‹å“åº”å†…å®¹:")
                print(f"{'-'*80}")
                print(content[:500])
                if len(content) > 500:
                    print(f"... (å…±{len(content)}å­—ç¬¦)")
                print(f"{'-'*80}")
                
            else:
                result["error"] = "å“åº”ä¸­ç¼ºå°‘choiceså­—æ®µ"
                print(f"âŒ å“åº”æ ¼å¼å¼‚å¸¸: ç¼ºå°‘choiceså­—æ®µ")
                print(f"å“åº”å†…å®¹: {json.dumps(response_data, indent=2, ensure_ascii=False)[:500]}")
        
        elif response.status_code == 422:
            # éªŒè¯é”™è¯¯ï¼Œå¯èƒ½æ˜¯æ ¼å¼ä¸æ”¯æŒ
            error_data = response.json()
            result["error"] = f"éªŒè¯é”™è¯¯: {error_data}"
            print(f"âŒ HTTP 422: éªŒè¯é”™è¯¯")
            print(f"é”™è¯¯è¯¦æƒ…: {json.dumps(error_data, indent=2, ensure_ascii=False)[:500]}")
            result["supports_vision"] = False
        
        else:
            error_text = response.text[:500] if hasattr(response, 'text') else 'N/A'
            result["error"] = f"HTTP {response.status_code}: {error_text}"
            print(f"âŒ HTTP {response.status_code}: {error_text}")
            result["supports_vision"] = False
    
    except requests.exceptions.RequestException as e:
        result["error"] = str(e)
        print(f"âŒ è¯·æ±‚å¼‚å¸¸: {str(e)}")
        result["supports_vision"] = False
    
    except Exception as e:
        result["error"] = str(e)
        print(f"âŒ æœªçŸ¥é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        result["supports_vision"] = False
    
    return result


def evaluate_model_results(results: list) -> Dict[str, Any]:
    """
    å¯¹æµ‹è¯•ç»“æžœè¿›è¡Œå…¨æ–¹ä½è¯„ä»·
    
    Args:
        results: æµ‹è¯•ç»“æžœåˆ—è¡¨
    
    Returns:
        è¯„ä»·ç»“æžœå­—å…¸
    """
    evaluation = {
        "summary": {},
        "detailed_comparison": [],
        "recommendations": []
    }
    
    for result in results:
        model_name = result["model"]
        model_eval = {
            "model": model_name,
            "supports_vision": result.get("supports_vision", False),
            "success": result.get("success", False),
            "response_quality": "unknown",
            "token_efficiency": "unknown",
            "error_type": result.get("error"),
            "response_length": len(result.get("response_text", "")),
            "token_usage": result.get("token_usage", {})
        }
        
        # è¯„ä»·å“åº”è´¨é‡
        response_text = result.get("response_text", "")
        if response_text:
            # æ£€æŸ¥å“åº”æ˜¯å¦è¯¦ç»†
            if len(response_text) > 200:
                model_eval["response_quality"] = "detailed"
            elif len(response_text) > 50:
                model_eval["response_quality"] = "moderate"
            else:
                model_eval["response_quality"] = "brief"
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«è§†è§‰æè¿°
            vision_indicators = ["é¢œè‰²", "å½¢çŠ¶", "æ–‡å­—", "å›¾ç‰‡", "çŸ©å½¢", "åœ†å½¢", 
                               "color", "shape", "text", "image", "rectangle", "circle"]
            vision_count = sum(1 for indicator in vision_indicators if indicator.lower() in response_text.lower())
            model_eval["vision_indicators_count"] = vision_count
        
        # è¯„ä»·Tokenæ•ˆçŽ‡
        token_usage = result.get("token_usage", {})
        if token_usage:
            total_tokens = token_usage.get("total_tokens", 0)
            if total_tokens > 0:
                if total_tokens < 500:
                    model_eval["token_efficiency"] = "excellent"
                elif total_tokens < 1000:
                    model_eval["token_efficiency"] = "good"
                else:
                    model_eval["token_efficiency"] = "moderate"
        
        evaluation["detailed_comparison"].append(model_eval)
    
    # ç”Ÿæˆæ€»ç»“
    vision_support_count = sum(1 for r in results if r.get("supports_vision", False))
    success_count = sum(1 for r in results if r.get("success", False))
    
    evaluation["summary"] = {
        "total_models_tested": len(results),
        "models_supporting_vision": vision_support_count,
        "successful_requests": success_count,
        "best_model_for_vision": None,
        "most_cost_effective": None
    }
    
    # æ‰¾å‡ºæœ€ä½³æ¨¡åž‹
    vision_models = [r for r in results if r.get("supports_vision", False)]
    if vision_models:
        # æŒ‰tokenä½¿ç”¨é‡æŽ’åº
        vision_models_sorted = sorted(
            vision_models,
            key=lambda x: x.get("token_usage", {}).get("total_tokens", float('inf'))
        )
        evaluation["summary"]["best_model_for_vision"] = vision_models_sorted[0]["model"]
    
    # æ‰¾å‡ºæœ€ç»æµŽçš„æ¨¡åž‹
    all_successful = [r for r in results if r.get("success", False)]
    if all_successful:
        cost_sorted = sorted(
            all_successful,
            key=lambda x: x.get("token_usage", {}).get("total_tokens", float('inf'))
        )
        evaluation["summary"]["most_cost_effective"] = cost_sorted[0]["model"]
    
    # ç”Ÿæˆå»ºè®®
    if vision_support_count == 0:
        evaluation["recommendations"].append(
            "âš ï¸  æ‰€æœ‰æµ‹è¯•çš„æ¨¡åž‹éƒ½ä¸æ”¯æŒè§†è§‰è¾“å…¥ï¼Œå»ºè®®ä½¿ç”¨å¤–éƒ¨Vision APIï¼ˆå¦‚Google Cloud Vision APIï¼‰"
        )
    elif vision_support_count == len(results):
        evaluation["recommendations"].append(
            "âœ… æ‰€æœ‰æ¨¡åž‹éƒ½æ”¯æŒè§†è§‰è¾“å…¥ï¼Œå¯ä»¥é€‰æ‹©æˆæœ¬æœ€ä½Žçš„æ¨¡åž‹"
        )
    else:
        vision_model_names = [r["model"] for r in results if r.get("supports_vision", False)]
        evaluation["recommendations"].append(
            f"âœ… ä»¥ä¸‹æ¨¡åž‹æ”¯æŒè§†è§‰è¾“å…¥: {', '.join(vision_model_names)}"
        )
    
    return evaluation


def main():
    """ä¸»å‡½æ•°"""
    print("="*80)
    print("ðŸ§ª AI Builders è§†è§‰æ¨¡åž‹æ”¯æŒæµ‹è¯•")
    print("="*80)
    
    # èŽ·å–API Token
    api_token = os.getenv("AI_BUILDER_TOKEN")
    if not api_token:
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ° AI_BUILDER_TOKEN çŽ¯å¢ƒå˜é‡")
        print("ðŸ’¡ æç¤º: è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® AI_BUILDER_TOKEN")
        return
    
    # åˆ›å»ºæµ‹è¯•å›¾ç‰‡
    print("\nðŸ“¸ åˆ›å»ºæµ‹è¯•å›¾ç‰‡...")
    test_image_bytes = create_test_image()
    print(f"âœ… æµ‹è¯•å›¾ç‰‡å·²åˆ›å»ºï¼Œå¤§å°: {len(test_image_bytes)} bytes")
    
    # ä¿å­˜æµ‹è¯•å›¾ç‰‡ï¼ˆç”¨äºŽå‚è€ƒï¼‰
    test_image_path = Path(__file__).parent / "test_vision_image.png"
    with open(test_image_path, 'wb') as f:
        f.write(test_image_bytes)
    print(f"ðŸ’¾ æµ‹è¯•å›¾ç‰‡å·²ä¿å­˜åˆ°: {test_image_path}")
    
    # è¦æµ‹è¯•çš„æ¨¡åž‹åˆ—è¡¨
    models_to_test = [
        "gemini-2.5-pro",
        "grok-4-fast",
        "gpt-5"
    ]
    
    # æµ‹è¯•æ–¹æ³•ï¼ˆä¼˜å…ˆä½¿ç”¨æ•°ç»„æ ¼å¼ï¼Œè¿™æ˜¯OpenAIæ ‡å‡†æ ¼å¼ï¼‰
    test_methods = ["array_format"]  # å…ˆæµ‹è¯•æ•°ç»„æ ¼å¼
    
    all_results = []
    
    # å¯¹æ¯ä¸ªæ¨¡åž‹è¿›è¡Œæµ‹è¯•
    for model_name in models_to_test:
        for test_method in test_methods:
            print(f"\n{'#'*80}")
            print(f"æµ‹è¯•: {model_name} ({test_method})")
            print(f"{'#'*80}")
            
            result = test_model_vision(
                model_name=model_name,
                api_token=api_token,
                test_image_bytes=test_image_bytes,
                test_method=test_method
            )
            
            all_results.append(result)
            
            # å¦‚æžœæ•°ç»„æ ¼å¼å¤±è´¥ï¼Œå°è¯•å…¶ä»–æ ¼å¼
            if not result.get("success") and test_method == "array_format":
                print(f"\nâš ï¸  æ•°ç»„æ ¼å¼å¤±è´¥ï¼Œå°è¯•base64å­—ç¬¦ä¸²æ ¼å¼...")
                result2 = test_model_vision(
                    model_name=model_name,
                    api_token=api_token,
                    test_image_bytes=test_image_bytes,
                    test_method="base64_string"
                )
                all_results.append(result2)
    
    # è¯„ä»·ç»“æžœ
    print("\n" + "="*80)
    print("ðŸ“Š æµ‹è¯•ç»“æžœè¯„ä»·")
    print("="*80)
    
    evaluation = evaluate_model_results(all_results)
    
    # æ‰“å°æ€»ç»“
    print("\nðŸ“‹ æµ‹è¯•æ€»ç»“:")
    print(f"   æµ‹è¯•æ¨¡åž‹æ•°é‡: {evaluation['summary']['total_models_tested']}")
    print(f"   æ”¯æŒè§†è§‰çš„æ¨¡åž‹æ•°: {evaluation['summary']['models_supporting_vision']}")
    print(f"   æˆåŠŸè¯·æ±‚æ•°: {evaluation['summary']['successful_requests']}")
    if evaluation['summary']['best_model_for_vision']:
        print(f"   æœ€ä½³è§†è§‰æ¨¡åž‹: {evaluation['summary']['best_model_for_vision']}")
    if evaluation['summary']['most_cost_effective']:
        print(f"   æœ€ç»æµŽæ¨¡åž‹: {evaluation['summary']['most_cost_effective']}")
    
    # æ‰“å°è¯¦ç»†æ¯”è¾ƒ
    print("\nðŸ“Š è¯¦ç»†æ¯”è¾ƒ:")
    for model_eval in evaluation["detailed_comparison"]:
        print(f"\n   {model_eval['model']}:")
        print(f"      æ”¯æŒè§†è§‰: {'âœ… æ˜¯' if model_eval['supports_vision'] else 'âŒ å¦'}")
        print(f"      è¯·æ±‚æˆåŠŸ: {'âœ… æ˜¯' if model_eval['success'] else 'âŒ å¦'}")
        print(f"      å“åº”è´¨é‡: {model_eval['response_quality']}")
        print(f"      Tokenæ•ˆçŽ‡: {model_eval['token_efficiency']}")
        if model_eval.get('token_usage'):
            usage = model_eval['token_usage']
            print(f"      Tokenä½¿ç”¨: {usage.get('prompt_tokens', 'N/A')} è¾“å…¥ + {usage.get('completion_tokens', 'N/A')} è¾“å‡º = {usage.get('total_tokens', 'N/A')} æ€»è®¡")
        if model_eval.get('error_type'):
            print(f"      é”™è¯¯: {model_eval['error_type'][:100]}")
    
    # æ‰“å°å»ºè®®
    print("\nðŸ’¡ å»ºè®®:")
    for rec in evaluation["recommendations"]:
        print(f"   {rec}")
    
    # ä¿å­˜ç»“æžœåˆ°JSONæ–‡ä»¶
    output_file = Path(__file__).parent / "vision_test_results.json"
    output_data = {
        "test_image_path": str(test_image_path),
        "test_image_size_bytes": len(test_image_bytes),
        "results": all_results,
        "evaluation": evaluation
    }
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)
    
    print(f"\nðŸ’¾ å®Œæ•´ç»“æžœå·²ä¿å­˜åˆ°: {output_file}")
    print("="*80)
    
    return all_results, evaluation


if __name__ == "__main__":
    try:
        results, evaluation = main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        import traceback
        print(f"\n\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        traceback.print_exc()

