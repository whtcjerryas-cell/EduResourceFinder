#!/usr/bin/env python3
"""
ä»å°åº¦å°¼è¥¿äºšæ•°å­¦å­¦ç§‘ K12 æ•™å­¦å¤§çº² PDF ä¸­æå–ç»“æ„åŒ–çŸ¥è¯†ç‚¹
ä½¿ç”¨ AI Builders çš„ gemini-2.5-pro æ¨¡å‹è¿›è¡Œæå–å’Œæ£€æŸ¥
æŒ‰ç…§ç”¨æˆ·è¦æ±‚çš„æ–°æ ¼å¼æå–ï¼šç«  -> èŠ‚ -> çŸ¥è¯†ç‚¹çš„å±‚çº§å…³ç³»
"""

import os
import json
import re
import requests
from typing import Dict, List, Optional, Any
from pypdf import PdfReader


class AIBuildersClient:
    """AI Builders API å®¢æˆ·ç«¯"""
    
    def __init__(self, api_token: Optional[str] = None):
        """
        åˆå§‹åŒ–å®¢æˆ·ç«¯
        
        Args:
            api_token: AI Builders API ä»¤ç‰Œï¼Œå¦‚æœä¸æä¾›åˆ™ä»ç¯å¢ƒå˜é‡è¯»å–
        """
        self.api_token = api_token or os.getenv("AI_BUILDER_TOKEN")
        if not self.api_token:
            raise ValueError("è¯·è®¾ç½® AI_BUILDER_TOKEN ç¯å¢ƒå˜é‡æˆ–ä¼ å…¥ api_token å‚æ•°")
        
        # æ ¹æ®æ–‡æ¡£ï¼Œæ­£ç¡®çš„ API ç«¯ç‚¹
        self.base_url = "https://space.ai-builders.com/backend"
        self.headers = {
            "Authorization": f"Bearer {self.api_token}",
            "Content-Type": "application/json"
        }
    
    def call_gemini(self, prompt: str, system_prompt: Optional[str] = None, 
                    max_tokens: int = 8000, temperature: float = 0.3) -> str:
        """
        è°ƒç”¨ gemini-2.5-pro æ¨¡å‹
        
        Args:
            prompt: ç”¨æˆ·æç¤ºè¯
            system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰
            max_tokens: æœ€å¤§ç”Ÿæˆ token æ•°
            temperature: æ¸©åº¦å‚æ•°
        
        Returns:
            æ¨¡å‹è¿”å›çš„æ–‡æœ¬å†…å®¹
        """
        endpoint = f"{self.base_url}/v1/chat/completions"
        
        messages = []
        if system_prompt:
            messages.append({
                "role": "system",
                "content": system_prompt
            })
        messages.append({
            "role": "user",
            "content": prompt
        })
        
        payload = {
            "model": "gemini-2.5-pro",
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": temperature
        }
        
        try:
            # ç¦ç”¨ä»£ç†ä»¥é¿å…è¿æ¥é—®é¢˜
            proxies = {
                "http": None,
                "https": None
            }
            response = requests.post(
                endpoint,
                headers=self.headers,
                json=payload,
                timeout=600,  # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°10åˆ†é’Ÿ
                proxies=proxies
            )
            
            if response.status_code == 200:
                result = response.json()
                if "choices" in result and len(result["choices"]) > 0:
                    return result["choices"][0]["message"]["content"]
                else:
                    raise ValueError(f"API å“åº”æ ¼å¼å¼‚å¸¸: {json.dumps(result, ensure_ascii=False)}")
            else:
                raise ValueError(f"API è°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}, å“åº”: {response.text[:500]}")
        except requests.exceptions.RequestException as e:
            raise ValueError(f"API è¯·æ±‚å¼‚å¸¸: {str(e)}")


class SyllabusExtractor:
    """æ•™å­¦å¤§çº²çŸ¥è¯†ç‚¹æå–å™¨"""
    
    def __init__(self, pdf_path: str, api_token: Optional[str] = None):
        """
        åˆå§‹åŒ–æå–å™¨
        
        Args:
            pdf_path: PDF æ–‡ä»¶è·¯å¾„
            api_token: AI Builders API ä»¤ç‰Œ
        """
        self.pdf_path = pdf_path
        self.client = AIBuildersClient(api_token)
        self.pdf_text = None
        self.pdf_pages = 0
    
    def read_pdf(self) -> str:
        """è¯»å– PDF æ–‡ä»¶å†…å®¹"""
        print(f"ğŸ“– æ­£åœ¨è¯»å– PDF æ–‡ä»¶: {self.pdf_path}")
        try:
            reader = PdfReader(self.pdf_path)
            text_parts = []
            
            for i, page in enumerate(reader.pages):
                text = page.extract_text()
                if text.strip():
                    text_parts.append(f"=== ç¬¬ {i+1} é¡µ ===\n{text}\n")
                if (i + 1) % 10 == 0:
                    print(f"   å·²è¯»å– {i+1} é¡µ...")
            
            self.pdf_pages = len(reader.pages)
            self.pdf_text = "\n".join(text_parts)
            print(f"âœ… PDF è¯»å–å®Œæˆï¼Œå…± {self.pdf_pages} é¡µ")
            return self.pdf_text
        except Exception as e:
            raise ValueError(f"è¯»å– PDF æ–‡ä»¶å¤±è´¥: {str(e)}")
    
    def split_text_if_needed(self, text: str, max_chars: int = 200000) -> List[str]:
        """
        å¦‚æœæ–‡æœ¬è¿‡é•¿ï¼ŒæŒ‰é€»è¾‘åˆ†å‰²æˆå¤šä¸ªéƒ¨åˆ†
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            max_chars: æ¯ä¸ªéƒ¨åˆ†çš„æœ€å¤§å­—ç¬¦æ•°
        
        Returns:
            åˆ†å‰²åçš„æ–‡æœ¬åˆ—è¡¨
        """
        if len(text) <= max_chars:
            return [text]
        
        # å°è¯•æŒ‰ç« èŠ‚åˆ†å‰²
        parts = []
        current_part = ""
        
        # æŒ‰é¡µé¢åˆ†å‰²ï¼Œå°½é‡ä¿æŒå®Œæ•´æ€§
        pages = text.split("=== ç¬¬ ")
        for i, page in enumerate(pages):
            if not page.strip():
                continue
            
            page_with_header = f"=== ç¬¬ {page}" if i > 0 else page
            
            if len(current_part) + len(page_with_header) > max_chars and current_part:
                parts.append(current_part)
                current_part = page_with_header
            else:
                current_part += page_with_header
        
        if current_part:
            parts.append(current_part)
        
        return parts if parts else [text]
    
    def extract_knowledge_points(self, pdf_text: str = None) -> List[Dict[str, Any]]:
        """
        æå–çŸ¥è¯†ç‚¹ï¼ˆä½¿ç”¨å¤§æ¨¡å‹1 - Generatorï¼‰
        
        Args:
            pdf_text: PDF æ–‡æœ¬å†…å®¹ï¼Œå¦‚æœä¸º None åˆ™ä»æ–‡ä»¶è¯»å–
        
        Returns:
            æå–çš„çŸ¥è¯†ç‚¹ JSON æ•°æ®åˆ—è¡¨
        """
        if pdf_text is None:
            if not self.pdf_text:
                self.read_pdf()
            pdf_text = self.pdf_text
        
        print("\nğŸ¤– æ­£åœ¨ä½¿ç”¨ gemini-2.5-pro æå–çŸ¥è¯†ç‚¹...")
        
        # ç”¨æˆ·æä¾›çš„ç³»ç»Ÿæç¤ºè¯
        system_prompt = """ä½ æ˜¯å°åº¦å°¼è¥¿äºš K12 æ•™è‚²ä½“ç³»æ„å»ºä¸“å®¶ï¼Œç²¾é€š Kurikulum Merdeka å’Œ K13 è¯¾ç¨‹æ ‡å‡†ã€‚"""
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ†å‰²æ–‡æœ¬
        text_parts = self.split_text_if_needed(pdf_text, max_chars=200000)
        
        all_knowledge_points = []
        
        for part_idx, text_part in enumerate(text_parts):
            print(f"\nğŸ“„ å¤„ç†ç¬¬ {part_idx + 1}/{len(text_parts)} éƒ¨åˆ†...")
            
            user_prompt = f"""**è§’è‰²å®šä¹‰ï¼š** 
ä½ æ˜¯å°åº¦å°¼è¥¿äºš K12 æ•™è‚²ä½“ç³»æ„å»ºä¸“å®¶ï¼Œç²¾é€š Kurikulum Merdeka å’Œ K13 è¯¾ç¨‹æ ‡å‡†ã€‚

**ä»»åŠ¡ç›®æ ‡ï¼š**
è¯»å–ä»¥ä¸‹PDFæ–‡ä»¶å†…å®¹ï¼ˆå°å°¼æ•°å­¦æ•™å­¦å¤§çº²ï¼‰ï¼Œå°†å…¶è§£æä¸ºæ ‡å‡†åŒ–çš„"çŸ¥è¯†å›¾è°±"JSON æ•°æ®ã€‚
è¯¥æ•°æ®å°†ä½œä¸º"éª¨æ¶"ï¼Œç”¨äºåç»­å°†è§†é¢‘èµ„æºç²¾å‡†æŒ‚è½½åˆ°å¯¹åº”çš„çŸ¥è¯†ç‚¹ä¸Šã€‚å› æ­¤ï¼Œå±‚çº§å…³ç³»å’Œæ¦‚å¿µå®šä¹‰çš„å‡†ç¡®æ€§è‡³å…³é‡è¦ã€‚

**æ‰§è¡Œæ­¥éª¤ï¼š**

**Step 1: æ·±åº¦ç»“æ„åŒ–æå– (Generator)**
è¯·åˆ†ææ–‡æ¡£ï¼Œè¯†åˆ«"ç«  (Chapter) -> èŠ‚ (Section) -> çŸ¥è¯†ç‚¹ (Topic)"çš„å±‚çº§å…³ç³»ã€‚æå–ä»¥ä¸‹å­—æ®µï¼š

*   `id`: (å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œå¦‚ "MAT-7-01-02"ï¼Œæ ¼å¼ï¼šMAT-{{å¹´çº§æ•°å­—}}-{{ç« èŠ‚å·}}-{{çŸ¥è¯†ç‚¹å·}})
*   `curriculum_standard`: (ä¾‹å¦‚ Kurikulum Merdeka)
*   `grade_level`: (ä¾‹å¦‚ Kelas 7)
*   `subject`: (Matematika)
*   `chapter_title`: (ç« èŠ‚å°å°¼è¯­åŸå)
*   `topic_title_id`: (çŸ¥è¯†ç‚¹å°å°¼è¯­åŸåï¼Œéœ€æ¸…æ´—æ‰åºå·ï¼Œå¦‚ "1.2 Bilangan Bulat" -> "Bilangan Bulat")
*   `topic_title_cn`: (çŸ¥è¯†ç‚¹ä¸­æ–‡ç¿»è¯‘ï¼Œéœ€ä½¿ç”¨æ ‡å‡†æ•°å­¦æœ¯è¯­ï¼Œå¦‚ "Teorema Pythagoras" -> "å‹¾è‚¡å®šç†")
*   `learning_objective`: (æ ¸å¿ƒæ•™å­¦ç›®æ ‡ã€‚è¿™æ˜¯åˆ¤æ–­è§†é¢‘å†…å®¹æ˜¯å¦åˆæ ¼çš„"é‡‘æ ‡å‡†")
*   `mapping_tags`: (æ•°ç»„æ ¼å¼ã€‚åˆ—å‡º 3-5 ä¸ªè¯¥çŸ¥è¯†ç‚¹çš„æ ¸å¿ƒå°å°¼è¯­è¯æ±‡æˆ–åŒä¹‰è¯ã€‚**æ³¨æ„ï¼šè¿™ä¸æ˜¯ä¸ºäº†æœç´¢ï¼Œè€Œæ˜¯ä¸ºäº†è®©åç»­ AI åˆ¤æ–­ä¸€ä¸ªè§†é¢‘æ ‡é¢˜æ˜¯å¦å±äºè¯¥çŸ¥è¯†ç‚¹ã€‚** ä¾‹å¦‚ï¼šå¯¹äº"æ··åˆè¿ç®—"ï¼ŒTag åº”åŒ…å« "Campuran", "Kabataku", "Urutan Operasi")

**Step 2: é€»è¾‘ä¸å®Œæ•´æ€§æ ¡éªŒ (Critic)**
åœ¨ç”Ÿæˆæœ€ç»ˆ JSON å‰ï¼Œè¯·æ‰§è¡Œä»¥ä¸‹è‡ªæˆ‘æ£€æŸ¥ï¼ˆSelf-Reflectionï¼‰ï¼š
1.  **è¦†ç›–ç‡æ£€æŸ¥**ï¼šæ˜¯å¦é—æ¼äº†ä»»ä½•å°èŠ‚ï¼Ÿå¤§çº²ä¸­çš„æ‰€æœ‰çŸ¥è¯†ç‚¹æ˜¯å¦éƒ½å·²è½¬åŒ–ä¸º JSON èŠ‚ç‚¹ï¼Ÿ
2.  **æœ¯è¯­å‡†ç¡®æ€§**ï¼šä¸­æ–‡ç¿»è¯‘æ˜¯å¦ç¬¦åˆæ•°å­¦æ•™å­¦è§„èŒƒï¼Ÿï¼ˆä¾‹å¦‚ä¸è¦æŠŠ "Akar Kuadrat" ç¿»è¯‘æˆ "æ–¹æ ¹" è€Œåº”æ˜¯ "å¹³æ–¹æ ¹"ï¼‰ã€‚
3.  **å»å™ª**ï¼š`topic_title_id` ä¸­æ˜¯å¦è¿˜æœ‰ "1.2", "A." ç­‰å¹²æ‰°å­—ç¬¦ï¼Ÿè¯·å»é™¤ã€‚

**Step 3: è¾“å‡º**
è¾“å‡ºä¸¥æ ¼çš„ JSON åˆ—è¡¨æ ¼å¼ï¼Œå¿…é¡»æ˜¯æœ‰æ•ˆçš„ JSON æ•°ç»„ã€‚

**æ¨¡å‹æŒ‡ä»¤ï¼š**
è¯·ä½¿ç”¨ ai-builders ä¸­çš„ gemini 2.5 proã€‚å¦‚æœ PDF åŒ…å«å¤æ‚çš„è·¨é¡µè¡¨æ ¼ï¼Œè¯·ä¼˜å…ˆä¿æŒé€»è¾‘å±‚çº§çš„è¿è´¯æ€§ã€‚

**PDF å†…å®¹ï¼š**
{text_part}

è¯·ç›´æ¥è¾“å‡º JSON æ•°ç»„ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—è¯´æ˜ã€markdown ä»£ç å—æ ‡è®°æˆ–è§£é‡Šã€‚æ ¼å¼ç¤ºä¾‹ï¼š
[
  {{
    "id": "MAT-7-01-01",
    "curriculum_standard": "Kurikulum Merdeka",
    "grade_level": "Kelas 7",
    "subject": "Matematika",
    "chapter_title": "Bilangan Bulat",
    "topic_title_id": "Bilangan Bulat",
    "topic_title_cn": "æ•´æ•°",
    "learning_objective": "å­¦ç”Ÿèƒ½å¤Ÿç†è§£æ•´æ•°çš„æ¦‚å¿µï¼Œè¿›è¡Œæ•´æ•°çš„åŠ å‡è¿ç®—",
    "mapping_tags": ["Bilangan Bulat", "Integer", "Angka Bulat", "Operasi Bilangan Bulat"]
  }}
]"""
            
            try:
                response_text = self.client.call_gemini(
                    prompt=user_prompt,
                    system_prompt=system_prompt,
                    max_tokens=32000,  # å¢åŠ  token é™åˆ¶
                    temperature=0.3
                )
                
                # å°è¯•ä»å“åº”ä¸­æå– JSON
                json_text = self._extract_json_from_response(response_text)
                
                # è§£æ JSON
                try:
                    knowledge_points = json.loads(json_text)
                    if isinstance(knowledge_points, list):
                        all_knowledge_points.extend(knowledge_points)
                        print(f"âœ… æˆåŠŸæå– {len(knowledge_points)} ä¸ªçŸ¥è¯†ç‚¹")
                    else:
                        print(f"âš ï¸ è¿”å›çš„ä¸æ˜¯æ•°ç»„æ ¼å¼ï¼Œè·³è¿‡æ­¤éƒ¨åˆ†")
                except json.JSONDecodeError as e:
                    print(f"âš ï¸ JSON è§£æå¤±è´¥: {str(e)}")
                    print(f"å“åº”å†…å®¹å‰1000å­—ç¬¦: {response_text[:1000]}")
                    # ä¿å­˜å¤±è´¥çš„å“åº”ä»¥ä¾¿è°ƒè¯•
                    with open(f"failed_response_part_{part_idx}.txt", "w", encoding="utf-8") as f:
                        f.write(response_text)
                    raise ValueError(f"JSON è§£æå¤±è´¥: {str(e)}")
                    
            except Exception as e:
                print(f"âš ï¸ æå–ç¬¬ {part_idx + 1} éƒ¨åˆ†æ—¶å‡ºé”™: {str(e)}")
                raise
        
        print(f"\nâœ… æ€»å…±æå– {len(all_knowledge_points)} ä¸ªçŸ¥è¯†ç‚¹")
        return all_knowledge_points
    
    def _extract_json_from_response(self, response_text: str) -> str:
        """ä»å“åº”æ–‡æœ¬ä¸­æå– JSON éƒ¨åˆ†"""
        # é¦–å…ˆå°è¯•æŸ¥æ‰¾ä»£ç å—ä¸­çš„ JSONï¼ˆæ•°ç»„æˆ–å¯¹è±¡ï¼‰
        json_pattern_array = r'```(?:json)?\s*(\[.*?\])\s*```'
        json_pattern_object = r'```(?:json)?\s*(\{.*?\})\s*```'
        
        match = re.search(json_pattern_array, response_text, re.DOTALL)
        if match:
            return match.group(1)
        
        match = re.search(json_pattern_object, response_text, re.DOTALL)
        if match:
            return match.group(1)
        
        # å°è¯•æ‰¾åˆ° JSON æ•°ç»„çš„å¼€å§‹å’Œç»“æŸ
        start_idx = response_text.find('[')
        end_idx = response_text.rfind(']')
        
        if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
            json_text = response_text[start_idx:end_idx+1]
            # éªŒè¯æ˜¯å¦æ˜¯æœ‰æ•ˆçš„ JSON
            try:
                json.loads(json_text)
                return json_text
            except:
                pass
        
        # å°è¯•æ‰¾åˆ° JSON å¯¹è±¡çš„å¼€å§‹å’Œç»“æŸ
        start_idx = response_text.find('{')
        end_idx = response_text.rfind('}')
        
        if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
            json_text = response_text[start_idx:end_idx+1]
            # éªŒè¯æ˜¯å¦æ˜¯æœ‰æ•ˆçš„ JSON
            try:
                json.loads(json_text)
                return json_text
            except:
                pass
        
        # å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œè¿”å›åŸæ–‡æœ¬
        return response_text
    
    def check_json_quality(self, knowledge_points: List[Dict[str, Any]], 
                          iteration: int = 1) -> Dict[str, Any]:
        """
        æ£€æŸ¥ JSON è´¨é‡ï¼ˆä½¿ç”¨å¤§æ¨¡å‹2 - Criticï¼‰
        
        Args:
            knowledge_points: å¾…æ£€æŸ¥çš„çŸ¥è¯†ç‚¹åˆ—è¡¨
            iteration: å½“å‰è¿­ä»£æ¬¡æ•°
        
        Returns:
            åŒ…å«æ£€æŸ¥ç»“æœå’Œä¿®æ­£åæ•°æ®çš„å­—å…¸
        """
        print(f"\nğŸ” ç¬¬ {iteration} æ¬¡æ£€æŸ¥ JSON è´¨é‡...")
        
        system_prompt = """ä½ æ˜¯å°åº¦å°¼è¥¿äºš K12 æ•™è‚²ä½“ç³»æ„å»ºä¸“å®¶ï¼Œç²¾é€š Kurikulum Merdeka å’Œ K13 è¯¾ç¨‹æ ‡å‡†ã€‚
ä½ çš„ä»»åŠ¡æ˜¯ä»”ç»†æ£€æŸ¥çŸ¥è¯†ç‚¹ JSON æ•°æ®ï¼Œæ‰¾å‡ºé—®é¢˜å¹¶æä¾›ä¿®æ­£å»ºè®®ã€‚"""
        
        knowledge_points_json = json.dumps(knowledge_points, ensure_ascii=False, indent=2)
        
        # å¦‚æœæ•°æ®å¤ªé•¿ï¼Œéœ€è¦åˆ†å‰²æ£€æŸ¥
        max_check_length = 150000
        if len(knowledge_points_json) > max_check_length:
            print(f"âš ï¸ æ•°æ®è¿‡é•¿ ({len(knowledge_points_json)} å­—ç¬¦)ï¼Œå°†åˆ†æ‰¹æ£€æŸ¥...")
            # åˆ†æ‰¹æ£€æŸ¥ï¼Œä½†è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œåªæ£€æŸ¥å‰ä¸€éƒ¨åˆ†
            knowledge_points_json = knowledge_points_json[:max_check_length] + "\n... (æ•°æ®å·²æˆªæ–­)"
        
        user_prompt = f"""è¯·ä»”ç»†æ£€æŸ¥ä»¥ä¸‹çŸ¥è¯†ç‚¹ JSON æ•°æ®ï¼Œæ‰¾å‡ºä»¥ä¸‹é—®é¢˜ï¼š

1. **è¦†ç›–ç‡æ£€æŸ¥**ï¼šæ˜¯å¦é—æ¼äº†ä»»ä½•å°èŠ‚ï¼Ÿå¤§çº²ä¸­çš„æ‰€æœ‰çŸ¥è¯†ç‚¹æ˜¯å¦éƒ½å·²è½¬åŒ–ä¸º JSON èŠ‚ç‚¹ï¼Ÿ
2. **æœ¯è¯­å‡†ç¡®æ€§**ï¼šä¸­æ–‡ç¿»è¯‘æ˜¯å¦ç¬¦åˆæ•°å­¦æ•™å­¦è§„èŒƒï¼Ÿï¼ˆä¾‹å¦‚ä¸è¦æŠŠ "Akar Kuadrat" ç¿»è¯‘æˆ "æ–¹æ ¹" è€Œåº”æ˜¯ "å¹³æ–¹æ ¹"ï¼‰
3. **å»å™ª**ï¼š`topic_title_id` ä¸­æ˜¯å¦è¿˜æœ‰ "1.2", "A." ç­‰å¹²æ‰°å­—ç¬¦ï¼Ÿè¯·å»é™¤
4. **å­—æ®µå®Œæ•´æ€§**ï¼šæ¯ä¸ªçŸ¥è¯†ç‚¹æ˜¯å¦éƒ½åŒ…å«æ‰€æœ‰å¿…å¡«å­—æ®µï¼ˆid, curriculum_standard, grade_level, subject, chapter_title, topic_title_id, topic_title_cn, learning_objective, mapping_tagsï¼‰ï¼Ÿ
5. **ID å”¯ä¸€æ€§**ï¼šæ‰€æœ‰ id æ˜¯å¦å”¯ä¸€ï¼Ÿ
6. **mapping_tags è´¨é‡**ï¼šmapping_tags æ˜¯å¦åŒ…å« 3-5 ä¸ªæ ¸å¿ƒå°å°¼è¯­è¯æ±‡æˆ–åŒä¹‰è¯ï¼Ÿ

çŸ¥è¯†ç‚¹æ•°æ®ï¼š
{knowledge_points_json}

**é‡è¦**ï¼šè¯·åªè¾“å‡º JSON æ ¼å¼çš„æ£€æŸ¥ç»“æœï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—è¯´æ˜ã€‚æ ¼å¼å¦‚ä¸‹ï¼š
{{
  "has_issues": true/false,
  "issues": [
    "é—®é¢˜1æè¿°",
    "é—®é¢˜2æè¿°"
  ],
  "suggestions": [
    "å»ºè®®1",
    "å»ºè®®2"
  ],
  "corrected_data": [ä¿®æ­£åçš„çŸ¥è¯†ç‚¹æ•°ç»„ï¼Œå¦‚æœæ²¡æœ‰é—®é¢˜åˆ™ä¿æŒåŸæ ·]
}}

å¦‚æœå‘ç°é—®é¢˜ï¼Œè¯·åœ¨ corrected_data ä¸­æä¾›ä¿®æ­£åçš„æ•°æ®ã€‚å¦‚æœæ•°æ®è´¨é‡è‰¯å¥½ï¼Œhas_issues è®¾ä¸º falseï¼Œcorrected_data ä¿æŒåŸæ ·ã€‚è¯·ç›´æ¥è¾“å‡º JSONï¼Œä¸è¦æœ‰ä»»ä½•å‰ç¼€æˆ–åç¼€æ–‡å­—ï¼Œä¸è¦ä½¿ç”¨ markdown ä»£ç å—ã€‚"""
        
        try:
            response_text = self.client.call_gemini(
                prompt=user_prompt,
                system_prompt=system_prompt,
                max_tokens=32000,
                temperature=0.2
            )
            
            # æå– JSON
            json_text = self._extract_json_from_response(response_text)
            
            try:
                check_result = json.loads(json_text)
                
                if check_result.get("has_issues", False):
                    issues = check_result.get("issues", [])
                    print(f"âš ï¸ å‘ç° {len(issues)} ä¸ªé—®é¢˜ï¼š")
                    for issue in issues[:10]:  # æ˜¾ç¤ºå‰10ä¸ª
                        print(f"   - {issue}")
                    
                    # å¦‚æœæœ‰ä¿®æ­£åçš„æ•°æ®ï¼Œä½¿ç”¨å®ƒ
                    if "corrected_data" in check_result and check_result["corrected_data"]:
                        print("âœ… å·²åº”ç”¨ä¿®æ­£")
                        return {
                            "has_issues": True,
                            "issues": issues,
                            "data": check_result["corrected_data"]
                        }
                    else:
                        return {
                            "has_issues": True,
                            "issues": issues,
                            "data": knowledge_points
                        }
                else:
                    print("âœ… æ£€æŸ¥é€šè¿‡ï¼Œæ•°æ®è´¨é‡è‰¯å¥½")
                    return {
                        "has_issues": False,
                        "issues": [],
                        "data": check_result.get("corrected_data", knowledge_points)
                    }
                    
            except json.JSONDecodeError as e:
                print(f"âš ï¸ æ£€æŸ¥ç»“æœ JSON è§£æå¤±è´¥: {str(e)}")
                print(f"å“åº”å†…å®¹å‰1000å­—ç¬¦: {response_text[:1000]}")
                # ä¿å­˜å¤±è´¥çš„å“åº”ä»¥ä¾¿è°ƒè¯•
                with open(f"failed_check_response_iter_{iteration}.txt", "w", encoding="utf-8") as f:
                    f.write(response_text)
                # å¦‚æœè§£æå¤±è´¥ï¼Œè®¤ä¸ºæ£€æŸ¥é€šè¿‡
                return {
                    "has_issues": False,
                    "issues": ["æ£€æŸ¥ç»“æœè§£æå¤±è´¥"],
                    "data": knowledge_points
                }
                
        except Exception as e:
            print(f"âš ï¸ æ£€æŸ¥è¿‡ç¨‹å‡ºé”™: {str(e)}")
            return {
                "has_issues": False,
                "issues": [f"æ£€æŸ¥è¿‡ç¨‹å‡ºé”™: {str(e)}"],
                "data": knowledge_points
            }
    
    def extract_with_validation(self, max_iterations: int = 2) -> Dict[str, Any]:
        """
        æå–çŸ¥è¯†ç‚¹å¹¶è¿›è¡ŒéªŒè¯ï¼ˆæœ€å¤šå¾ªç¯ max_iterations æ¬¡ï¼‰
        
        Args:
            max_iterations: æœ€å¤§æ£€æŸ¥è¿­ä»£æ¬¡æ•°
        
        Returns:
            æœ€ç»ˆçš„çŸ¥è¯†ç‚¹æ•°æ®å’Œè´¨é‡æŠ¥å‘Š
        """
        # ç¬¬ä¸€æ¬¡æå–
        knowledge_points = self.extract_knowledge_points()
        
        all_issues = []
        current_data = knowledge_points
        
        # æ£€æŸ¥å¾ªç¯ï¼ˆæœ€å¤š max_iterations æ¬¡ï¼‰
        for iteration in range(1, max_iterations + 1):
            check_result = self.check_json_quality(current_data, iteration)
            
            all_issues.extend(check_result.get("issues", []))
            current_data = check_result.get("data", current_data)
            
            # å¦‚æœæ²¡æœ‰é—®é¢˜ï¼Œæå‰ç»“æŸ
            if not check_result.get("has_issues", False):
                break
        
        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        result = {
            "metadata": {
                "source_file": self.pdf_path,
                "total_pages": self.pdf_pages,
                "total_knowledge_points": len(current_data),
                "check_iterations": min(iteration, max_iterations),
                "has_remaining_issues": len(all_issues) > 0
            },
            "knowledge_points": current_data,
            "issues": all_issues
        }
        
        return result


def main():
    """ä¸»å‡½æ•°"""
    import sys
    import glob
    
    # ç¡®å®šè¾“å‡ºç›®å½•
    output_dir = "/Users/shmiwanghao8/Desktop/education/Indonesia/Knowledge Point"
    os.makedirs(output_dir, exist_ok=True)
    
    # å¦‚æœæä¾›äº†å‘½ä»¤è¡Œå‚æ•°ï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™å¤„ç†æ‰€æœ‰PDFæ–‡ä»¶
    if len(sys.argv) > 1:
        pdf_files = [sys.argv[1]]
    else:
        # å¤„ç†æ‰€æœ‰PDFæ–‡ä»¶
        syllabus_dir = "/Users/shmiwanghao8/Desktop/education/Indonesia/syllabus"
        pdf_files = sorted(glob.glob(os.path.join(syllabus_dir, "*.pdf")))
    
    if not pdf_files:
        print("âŒ é”™è¯¯: æ²¡æœ‰æ‰¾åˆ° PDF æ–‡ä»¶")
        return
    
    print(f"ğŸ“š æ‰¾åˆ° {len(pdf_files)} ä¸ª PDF æ–‡ä»¶éœ€è¦å¤„ç†\n")
    
    all_results = []
    
    for idx, pdf_file in enumerate(pdf_files, 1):
        print(f"\n{'='*80}")
        print(f"ğŸ“„ å¤„ç†æ–‡ä»¶ {idx}/{len(pdf_files)}: {os.path.basename(pdf_file)}")
        print(f"{'='*80}\n")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(pdf_file):
            print(f"âŒ é”™è¯¯: PDF æ–‡ä»¶ä¸å­˜åœ¨: {pdf_file}")
            continue
        
        try:
            # åˆ›å»ºæå–å™¨
            extractor = SyllabusExtractor(pdf_file)
            
            # æå–å¹¶éªŒè¯çŸ¥è¯†ç‚¹
            result = extractor.extract_with_validation(max_iterations=2)
            
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            base_name = os.path.splitext(os.path.basename(pdf_file))[0]
            output_file = os.path.join(output_dir, f"{base_name}_knowledge_points.json")
            
            # ä¿å­˜ç»“æœ
            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            print(f"\nâœ… æå–å®Œæˆï¼")
            print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
            print(f"   - PDF é¡µæ•°: {result['metadata']['total_pages']}")
            print(f"   - çŸ¥è¯†ç‚¹æ€»æ•°: {result['metadata']['total_knowledge_points']}")
            print(f"   - æ£€æŸ¥è¿­ä»£æ¬¡æ•°: {result['metadata']['check_iterations']}")
            print(f"   - å‘ç°é—®é¢˜æ•°: {len(result['issues'])}")
            print(f"   - è¾“å‡ºæ–‡ä»¶: {output_file}")
            
            if result['issues']:
                print(f"\nâš ï¸ å‘ç°çš„é—®é¢˜ï¼ˆéœ€è¦äººå·¥ç¡®è®¤ï¼‰ï¼š")
                for i, issue in enumerate(result['issues'], 1):
                    print(f"   {i}. {issue}")
            
            all_results.append({
                "file": os.path.basename(pdf_file),
                "knowledge_points": result['metadata']['total_knowledge_points'],
                "issues": len(result['issues']),
                "output_file": output_file
            })
        
        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            all_results.append({
                "file": os.path.basename(pdf_file),
                "error": str(e)
            })
    
    # æ‰“å°æ€»ç»“
    print(f"\n\n{'='*80}")
    print(f"ğŸ“Š å¤„ç†æ€»ç»“")
    print(f"{'='*80}")
    total_knowledge_points = sum(r.get('knowledge_points', 0) for r in all_results)
    successful_files = sum(1 for r in all_results if 'error' not in r)
    
    print(f"âœ… æˆåŠŸå¤„ç†: {successful_files}/{len(pdf_files)} ä¸ªæ–‡ä»¶")
    print(f"ğŸ“š çŸ¥è¯†ç‚¹æ€»æ•°: {total_knowledge_points}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    
    print(f"\nè¯¦ç»†ç»“æœï¼š")
    for r in all_results:
        if 'error' in r:
            print(f"   âŒ {r['file']}: {r['error']}")
        else:
            print(f"   âœ… {r['file']}: {r['knowledge_points']} ä¸ªçŸ¥è¯†ç‚¹, {r['issues']} ä¸ªé—®é¢˜")


if __name__ == "__main__":
    main()

