#!/usr/bin/env python3
"""
æ–°ç‰ˆæœç´¢å¼•æ“ - åŸºäºå›½å®¶/å¹´çº§/å­¦æœŸæœç´¢
ä½¿ç”¨ AI ç”Ÿæˆæœ¬åœ°è¯­è¨€çš„æœç´¢è¯

TODO é‡æ„ä»»åŠ¡ï¼ˆP1 - ä»£ç è´¨é‡æ”¹è¿›ï¼‰:
- [008] è¶…é•¿å‡½æ•°ï¼šsearch()æ–¹æ³•éœ€è¦æ‹†åˆ†ä¸ºå¤šä¸ªå°å‡½æ•°ï¼ˆå½“å‰çº¦1000+è¡Œï¼‰
- [009] å…¨å±€å˜é‡ï¼šå‡å°‘globalå…³é”®å­—ä½¿ç”¨ï¼Œæ”¹ç”¨ä¾èµ–æ³¨å…¥æ¨¡å¼
- [010] ç¡¬ç¼–ç è·¯å¾„ï¼šåˆ›å»ºPathManagerç»Ÿä¸€ç®¡ç†è·¯å¾„é…ç½®
"""

import os
import json
import time
import re
from typing import Dict, List, Optional, Any, Callable
from pydantic import BaseModel, Field
from datetime import datetime, timezone
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed, TimeoutError as FuturesTimeoutError
import concurrent.futures
from config_manager import ConfigManager
from logger_utils import get_logger
from json_utils import extract_json_array
from search_strategy_agent import SearchStrategyAgent
from core.search_cache import get_search_cache
from core.multi_level_cache import get_cache as get_multi_level_cache
from core.config_loader import get_config
from core.performance_monitor import get_performance_monitor
from core.result_scorer import get_result_scorer
from core.recommendation_generator import get_recommendation_generator
from core.grade_subject_validator import GradeSubjectValidator
from core.text_utils import clean_title, clean_snippet, extract_video_info
from core.quality_evaluator import QualityEvaluator
from core.intelligent_search_optimizer import IntelligentSearchOptimizer
# from core.optimization_approval import get_approval_manager  # å·²ç¦ç”¨ - SISåŠŸèƒ½
# æ—¥å¿—è„±æ•å·¥å…·ï¼ˆå®‰å…¨ä¿®å¤ï¼šP1 - é˜²æ­¢æ•æ„Ÿä¿¡æ¯æ³„éœ²ï¼‰
from utils.log_sanitizer import safe_log, safe_log_json

# åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨
logger = get_logger('search_engine')

# åˆå§‹åŒ–æ€§èƒ½ç›‘æ§å™¨
perf_monitor = get_performance_monitor()

# æ”¯æŒä» .env æ–‡ä»¶è¯»å–ç¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    def load_dotenv():
        env_file = os.path.join(os.path.dirname(__file__), '.env')
        if os.path.exists(env_file):
            with open(env_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#') and '=' in line:
                        key, value = line.split('=', 1)
                        os.environ[key.strip()] = value.strip().strip('"').strip("'")
    load_dotenv()


# ============================================================================
# æ•°æ®æ¨¡å‹å®šä¹‰
# ============================================================================

class SearchRequest(BaseModel):
    """æœç´¢è¯·æ±‚"""
    country: str = Field(description="å›½å®¶ä»£ç ï¼ˆå¦‚ï¼šID, CN, USï¼‰")
    grade: str = Field(description="å¹´çº§ï¼ˆå¦‚ï¼š1, 2, 3 æˆ– Kelas 1, Grade 1ï¼‰")
    semester: Optional[str] = Field(description="å­¦æœŸï¼ˆå¦‚ï¼š1, 2 æˆ– Semester 1ï¼‰", default=None)
    subject: str = Field(description="å­¦ç§‘ï¼ˆå¦‚ï¼šMatematika, Mathematics, æ•°å­¦ï¼‰")
    language: Optional[str] = Field(description="æœç´¢è¯­è¨€ï¼ˆå¦‚ï¼šid, en, zhï¼‰", default=None)


class SearchResult(BaseModel):
    """å•ä¸ªæœç´¢ç»“æœ"""
    title: str = Field(description="æœç´¢ç»“æœæ ‡é¢˜")
    url: str = Field(description="ç»“æœURL")
    snippet: str = Field(description="ç»“æœæ‘˜è¦", default="")
    source: str = Field(description="æ¥æºï¼ˆè§„åˆ™/LLMï¼‰", default="è§„åˆ™")
    search_engine: str = Field(description="æœç´¢å¼•æ“æ¥æºï¼ˆTavily/Google/Baiduï¼‰", default="Unknown")
    score: float = Field(description="è¯„ä¼°åˆ†æ•°ï¼ˆ0-10åˆ†ï¼‰", default=0.0)
    recommendation_reason: str = Field(description="æ¨èç†ç”±", default="")
    evaluation_method: Optional[str] = Field(description="è¯„ä¼°æ–¹æ³•ï¼ˆMCP Tools/Rule-based/LLMï¼‰", default=None)
    resource_type: Optional[str] = Field(description="èµ„æºç±»å‹ï¼ˆè§†é¢‘ã€æ•™æã€æ•™è¾…ã€å­¦ä¹ èµ„æ–™ã€ç»ƒä¹ é¢˜ç­‰ï¼‰", default=None)
    is_selected: bool = Field(description="æ˜¯å¦è¢«äººå·¥é€‰ä¸­", default=False)
    evaluation_status: Optional[str] = Field(description="è¯„ä¼°çŠ¶æ€ï¼ˆpending/evaluating/completed/failedï¼‰", default=None)
    evaluation_result: Optional[Dict[str, Any]] = Field(description="è§†é¢‘è¯„ä¼°ç»“æœï¼ˆå¦‚æœå·²è¯„ä¼°ï¼‰", default=None)


class SearchResponse(BaseModel):
    """æœç´¢å“åº”"""
    success: bool = Field(description="æ˜¯å¦æˆåŠŸ")
    query: str = Field(description="ä½¿ç”¨çš„æœç´¢è¯")
    results: List[SearchResult] = Field(description="æœç´¢ç»“æœåˆ—è¡¨", default_factory=list)
    total_count: int = Field(description="ç»“æœæ€»æ•°", default=0)
    playlist_count: int = Field(description="æ’­æ”¾åˆ—è¡¨æ•°é‡", default=0)
    video_count: int = Field(description="è§†é¢‘æ•°é‡", default=0)
    message: str = Field(description="æ¶ˆæ¯", default="")
    timestamp: str = Field(description="æ—¶é—´æˆ³", default_factory=lambda: datetime.now(timezone.utc).isoformat())
    quality_report: Optional[Dict[str, Any]] = Field(description="è´¨é‡è¯„ä¼°æŠ¥å‘Š", default=None)
    optimization_request: Optional[Dict[str, Any]] = Field(description="ä¼˜åŒ–è¯·æ±‚ï¼ˆå¦‚æœæ£€æµ‹åˆ°è´¨é‡é—®é¢˜ï¼‰", default=None)


# ============================================================================
# AI Builders å®¢æˆ·ç«¯ (ä½¿ç”¨ç»Ÿä¸€LLMå®¢æˆ·ç«¯ï¼Œæ”¯æŒåŒAPIç³»ç»Ÿ)
# ============================================================================

# å¯¼å…¥ç»Ÿä¸€LLMå®¢æˆ·ç«¯
try:
    from llm_client import UnifiedLLMClient, AIBuildersAPIClient
    HAS_UNIFIED_CLIENT = True
except ImportError:
    HAS_UNIFIED_CLIENT = False
    print("[âš ï¸] è­¦å‘Š: æ— æ³•å¯¼å…¥ç»Ÿä¸€LLMå®¢æˆ·ç«¯ï¼Œå°†ä½¿ç”¨åŸæœ‰å®ç°")

class AIBuildersClient:
    """
    AI Builders API å®¢æˆ·ç«¯ï¼ˆå…¼å®¹æ€§åŒ…è£…å™¨ï¼‰
    å†…éƒ¨ä½¿ç”¨ç»Ÿä¸€LLMå®¢æˆ·ç«¯ï¼Œæ”¯æŒå…¬å¸å†…éƒ¨APIå’ŒAI Builders APIçš„fallbackæœºåˆ¶
    """
    
    def __init__(self, api_token: Optional[str] = None):
        self.api_token = api_token or os.getenv("AI_BUILDER_TOKEN")
        
        # å°è¯•ä½¿ç”¨ç»Ÿä¸€LLMå®¢æˆ·ç«¯
        if HAS_UNIFIED_CLIENT:
            try:
                # è·å–å…¬å¸å†…éƒ¨APIå¯†é’¥ï¼ˆå¯é€‰ï¼‰
                internal_api_key = os.getenv("INTERNAL_API_KEY")
                self.unified_client = UnifiedLLMClient(
                    internal_api_key=internal_api_key,
                    ai_builder_token=self.api_token
                )
                self.use_unified_client = True
                print("[âœ…] ä½¿ç”¨ç»Ÿä¸€LLMå®¢æˆ·ç«¯ï¼ˆæ”¯æŒåŒAPIç³»ç»Ÿï¼‰")
            except Exception as e:
                print(f"[âš ï¸] ç»Ÿä¸€LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}ï¼Œå›é€€åˆ°åŸæœ‰å®ç°")
                self.use_unified_client = False
                # å›é€€åˆ°åŸæœ‰å®ç°
                if not self.api_token:
                    raise ValueError("è¯·è®¾ç½® AI_BUILDER_TOKEN ç¯å¢ƒå˜é‡")
        else:
            self.use_unified_client = False
            if not self.api_token:
                raise ValueError("è¯·è®¾ç½® AI_BUILDER_TOKEN ç¯å¢ƒå˜é‡")
        
        # ä¿ç•™åŸæœ‰å±æ€§ä»¥ä¿æŒå…¼å®¹æ€§
        self.base_url = "https://space.ai-builders.com/backend"
        self.headers = {
            "Authorization": f"Bearer {self.api_token or ''}",
            "Content-Type": "application/json"
        }
    
    def call_llm(self, prompt: str, system_prompt: Optional[str] = None,
                 max_tokens: int = 8000, temperature: float = 0.3,  # [ä¿®å¤] 2026-01-20: ä»2000å¢åŠ åˆ°8000
                 model: str = "deepseek") -> str:
        """è°ƒç”¨ LLM"""
        # å¦‚æœä½¿ç”¨ç»Ÿä¸€å®¢æˆ·ç«¯ï¼Œç›´æ¥è°ƒç”¨
        if self.use_unified_client:
            return self.unified_client.call_llm(
                prompt=prompt,
                system_prompt=system_prompt,
                max_tokens=max_tokens,
                temperature=temperature,
                model=model
            )
        
        # å¦åˆ™ä½¿ç”¨åŸæœ‰å®ç°
        endpoint = f"{self.base_url}/v1/chat/completions"
        
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})
        
        payload = {
            "model": model,
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": temperature
            # ä¸è®¾ç½® tool_choice å’Œ toolsï¼Œè®© API ä½¿ç”¨é»˜è®¤è¡Œä¸º
        }
        
        # è¯¦ç»†æ—¥å¿—ï¼šLLMè°ƒç”¨è¾“å…¥ï¼ˆä½¿ç”¨è„±æ•é˜²æ­¢æ•æ„Ÿä¿¡æ¯æ³„éœ²ï¼‰
        print(f"\n{'='*80}")
        print(f"[ğŸ¤– LLMè°ƒç”¨] å¼€å§‹è°ƒç”¨ {model}")
        print(f"{'='*80}")
        print(f"[ğŸ“¤ è¾“å…¥] Endpoint: {endpoint}")
        print(f"[ğŸ“¤ è¾“å…¥] Model: {model}")
        print(f"[ğŸ“¤ è¾“å…¥] Max Tokens: {max_tokens}")
        print(f"[ğŸ“¤ è¾“å…¥] Temperature: {temperature}")
        print(f"[ğŸ“¤ è¾“å…¥] System Prompt é•¿åº¦: {len(system_prompt) if system_prompt else 0} å­—ç¬¦")
        print(f"[ğŸ“¤ è¾“å…¥] User Prompt é•¿åº¦: {len(prompt)} å­—ç¬¦")
        if system_prompt:
            print(f"[ğŸ“¤ è¾“å…¥] System Prompt (å‰500å­—ç¬¦):\n{safe_log(system_prompt[:500])}...")
        print(f"[ğŸ“¤ è¾“å…¥] User Prompt (å‰500å­—ç¬¦):\n{safe_log(prompt[:500])}...")
        print(f"[ğŸ“¤ è¾“å…¥] å®Œæ•´ User Prompt:\n{safe_log(prompt)}")
        print(f"[ğŸ“¤ è¾“å…¥] Payload (å·²è„±æ•):\n{safe_log_json(payload)}")
        
        try:
            import time
            from llm_client import get_proxy_config
            start_time = time.time()
            response = requests.post(
                endpoint,
                headers=self.headers,
                json=payload,
                params={"debug": "true"},
                timeout=300,
                proxies=None  # [ä¿®å¤] 2026-01-20: AI Builders æ˜¯å†…ç½‘ APIï¼Œä¸éœ€è¦ä»£ç†
            )
            elapsed_time = time.time() - start_time
            
            # è¯¦ç»†æ—¥å¿—ï¼šAPIå“åº”ï¼ˆä½¿ç”¨è„±æ•é˜²æ­¢æ•æ„Ÿä¿¡æ¯æ³„éœ²ï¼‰
            print(f"\n[ğŸ“¥ å“åº”] HTTP çŠ¶æ€ç : {response.status_code}")
            print(f"[ğŸ“¥ å“åº”] å“åº”æ—¶é—´: {elapsed_time:.2f} ç§’")

            if response.status_code == 200:
                result = response.json()
                print(f"[ğŸ“¥ å“åº”] å“åº”ç±»å‹: {type(result).__name__}")
                print(f"[ğŸ“¥ å“åº”] å“åº”é”®: {list(result.keys()) if isinstance(result, dict) else 'N/A'}")

                # æ‰“å°å®Œæ•´çš„APIå“åº”ï¼ˆç”¨äºè°ƒè¯•ï¼Œå·²è„±æ•ï¼‰
                print(f"[ğŸ“¥ å“åº”] å®Œæ•´ API å“åº” (å·²è„±æ•):\n{safe_log_json(result)}")
                
                if "choices" in result and len(result["choices"]) > 0:
                    choice = result["choices"][0]
                    message = choice.get("message", {})
                    content = message.get("content", "")
                    finish_reason = choice.get("finish_reason", "unknown")
                    
                    print(f"[ğŸ“¥ å“åº”] Finish Reason: {finish_reason}")
                    print(f"[ğŸ“¥ å“åº”] Content é•¿åº¦: {len(content) if content else 0} å­—ç¬¦")
                    
                    # æ‰“å° usage ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                    if "usage" in result:
                        usage = result["usage"]
                        print(f"[ğŸ“¥ å“åº”] Token ä½¿ç”¨:")
                        print(f"    - Prompt Tokens: {usage.get('prompt_tokens', 'N/A')}")
                        print(f"    - Completion Tokens: {usage.get('completion_tokens', 'N/A')}")
                        print(f"    - Total Tokens: {usage.get('total_tokens', 'N/A')}")
                    
                    # æ‰“å° orchestrator_traceï¼ˆå¦‚æœå­˜åœ¨ï¼Œç”¨äºè°ƒè¯•ï¼Œå·²è„±æ•ï¼‰
                    if "orchestrator_trace" in result:
                        trace = result["orchestrator_trace"]
                        print(f"[ğŸ“¥ å“åº”] Orchestrator Trace å­˜åœ¨ï¼Œé•¿åº¦: {len(json.dumps(trace))} å­—ç¬¦")
                        print(f"[ğŸ“¥ å“åº”] Orchestrator Trace (å·²è„±æ•):\n{safe_log_json(trace)}")
                    
                    if content and content.strip():
                        print(f"[ğŸ“¥ å“åº”] Content (å‰1000å­—ç¬¦):\n{content[:1000]}...")
                        print(f"[ğŸ“¥ å“åº”] å®Œæ•´ Content:\n{content}")
                        print(f"{'='*80}\n")
                        return content.strip()
                    else:
                        # å¦‚æœ deepseek å¤±è´¥ï¼Œå°è¯• gemini
                        if model == "deepseek":
                            print(f"    [âš ï¸ è­¦å‘Š] DeepSeek è¿”å›ç©ºå†…å®¹ï¼Œå°è¯• Gemini...")
                            return self.call_llm(prompt, system_prompt, max_tokens, temperature, "gemini-2.5-pro")
                        raise ValueError("API å“åº”ä¸­ content ä¸ºç©ºå­—ç¬¦ä¸²")
                else:
                    print(f"[âŒ é”™è¯¯] API å“åº”æ ¼å¼å¼‚å¸¸ï¼Œç¼ºå°‘ choices å­—æ®µ")
                    raise ValueError(f"API å“åº”æ ¼å¼å¼‚å¸¸")
            else:
                error_text = response.text[:500] if hasattr(response, 'text') else 'N/A'
                print(f"[âŒ é”™è¯¯] API è°ƒç”¨å¤±è´¥")
                print(f"[âŒ é”™è¯¯] çŠ¶æ€ç : {response.status_code}")
                print(f"[âŒ é”™è¯¯] é”™è¯¯å“åº”: {error_text}")
                raise ValueError(f"API è°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
        except requests.exceptions.RequestException as e:
            print(f"[âŒ é”™è¯¯] API è¯·æ±‚å¼‚å¸¸: {str(e)}")
            print(f"[âŒ é”™è¯¯] å¼‚å¸¸ç±»å‹: {type(e).__name__}")
            import traceback
            print(f"[âŒ é”™è¯¯] å¼‚å¸¸å †æ ˆ:\n{traceback.format_exc()}")
            raise ValueError(f"API è¯·æ±‚å¼‚å¸¸: {str(e)}")
            
    def search(self, query: str, max_results: int = 10, include_domains: list = None, country_code: str = None) -> list:
        """
        æ‰§è¡Œæœç´¢ (é€‚é… Tavily/Metaso)
        [ä¿®å¤] 2026-01-20: æ·»åŠ  country_code å‚æ•°æ”¯æŒ
        """
        # 1. ä¼˜å…ˆä½¿ç”¨ UnifiedClient çš„ search æ–¹æ³•ï¼ˆæ”¯æŒ Google/Tavily/Metasoï¼‰
        if self.use_unified_client:
            try:
                # ä½¿ç”¨ç»Ÿä¸€å®¢æˆ·ç«¯çš„ search æ–¹æ³•ï¼Œå®ƒä¼šè‡ªåŠ¨é€‰æ‹©æœ€ä½³çš„æœç´¢å¼•æ“
                results_dicts = self.unified_client.search(
                    query=query,
                    max_results=max_results,
                    include_domains=include_domains,
                    country_code=country_code or "CN"  # é»˜è®¤ä½¿ç”¨ä¸­å›½ï¼Œå¯ä»¥ä¼ å…¥å…¶ä»–ä»£ç 
                )
                # Convert dicts to SearchResult objects
                results = []
                for item in results_dicts:
                    results.append(SearchResult(
                        title=item.get('title', ''),
                        url=item.get('url', ''),
                        snippet=item.get('snippet', item.get('content', '')),
                        source=item.get('search_engine', 'Unknown'),
                        search_engine=item.get('search_engine', 'Unknown')
                    ))
                return results
            except Exception as e:
                print(f"[âš ï¸ æœç´¢å¤±è´¥] UnifiedClient æœç´¢å¤±è´¥: {str(e)}")
                import traceback
                traceback.print_exc()
        # 2. Fallbackï¼šè¿”å›ç©ºåˆ—è¡¨
        print(f"[âŒ æœç´¢å¤±è´¥] æ— å¯ç”¨çš„æœç´¢å¼•æ“")
        return []
    
        """
        ä½¿ç”¨ Google ä¼˜å…ˆæœç´¢ (ç”¨æˆ·è¯·æ±‚: è§£å†³æœç´¢ç»“æœä¸ä¸€è‡´é—®é¢˜)
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            max_results: æœ€å¤§ç»“æœæ•°
            include_domains: å¯é€‰çš„åŸŸååˆ—è¡¨ï¼Œç”¨äºé™åˆ¶æœç´¢èŒƒå›´
        """
        # 1. ä¼˜å…ˆå°è¯• Google æœç´¢ (å¦‚æœå¯ç”¨)
        if self.google_search_enabled and self.google_hunter:
            try:
                print(f"    [ğŸ” Googleæœç´¢] ä¼˜å…ˆä½¿ç”¨ Google: {query}")
                google_results = self.google_hunter.search(query)
                
                # è½¬æ¢æ ¼å¼
                results = []
                for item in google_results[:max_results]:
                    # GoogleSearchResults å¯èƒ½è¿”å›å­—å…¸æˆ–å¯¹è±¡ï¼Œéœ€é€‚é…
                    # å‡è®¾è¿”å›çš„æ˜¯å­—å…¸åˆ—è¡¨ï¼ŒåŒ…å« title, link, snippet
                    url = item.get('link', item.get('url', ''))
                    title = item.get('title', '')
                    snippet = item.get('snippet', item.get('body', ''))
                    
                    cleaned_title = clean_title(title, url)
                    cleaned_snippet = clean_snippet(snippet)
                    
                    results.append(SearchResult(
                        title=cleaned_title,
                        url=url,
                        snippet=cleaned_snippet,
                        source="Google",
                        search_engine="Google"
                    ))
                
                if results:
                    print(f"    [âœ… Googleæœç´¢] æˆåŠŸè·å– {len(results)} ä¸ªç»“æœ")
                    return results
                else:
                    print(f"    [âš ï¸ Googleæœç´¢] è¿”å›ç»“æœä¸ºç©ºï¼Œå›é€€åˆ° Tavily")
            
            except Exception as e:
                print(f"    [âŒ Googleæœç´¢] å¤±è´¥: {str(e)}ï¼Œå›é€€åˆ° Tavily")
        
        # 2. å¦‚æœä½¿ç”¨ç»Ÿä¸€å®¢æˆ·ç«¯ï¼Œå°è¯•ä½¿ç”¨å…¶searchæ–¹æ³• (Tavily/Fallback)
        # å¦‚æœä½¿ç”¨ç»Ÿä¸€å®¢æˆ·ç«¯ï¼Œå°è¯•ä½¿ç”¨å…¶searchæ–¹æ³•
        if self.use_unified_client:
            try:
                search_results = self.unified_client.search(
                    query=query,
                    max_results=max_results,
                    include_domains=include_domains
                )
                # è½¬æ¢ä¸ºSearchResultå¯¹è±¡ï¼Œå¹¶æ¸…ç†æ ‡é¢˜
                results = []
                for item in search_results:
                    original_title = item.get('title', '')
                    url = item.get('url', '')
                    # æ¸…ç†æ ‡é¢˜
                    cleaned_title = clean_title(original_title, url)
                    # æ¸…ç†æ‘˜è¦
                    raw_snippet = item.get('content', item.get('snippet', item.get('description', '')))
                    cleaned_snippet = clean_snippet(raw_snippet)

                    # ğŸ”¥ æå–search_engineå­—æ®µ
                    search_engine = item.get('search_engine', 'Tavily')

                    results.append(SearchResult(
                        title=cleaned_title,
                        url=url,
                        snippet=cleaned_snippet,
                        source="Tavily",
                        search_engine=search_engine  # ğŸ”¥ ä¼ é€’æœç´¢å¼•æ“å­—æ®µ
                    ))
                return results
            except Exception as e:
                print(f"[âš ï¸] ç»Ÿä¸€å®¢æˆ·ç«¯æœç´¢å¤±è´¥: {str(e)}ï¼Œå›é€€åˆ°åŸæœ‰å®ç°")
                # å›é€€åˆ°åŸæœ‰å®ç°
        
        # åŸæœ‰å®ç°
        endpoint = f"{self.base_url}/v1/search/"
        
        print(f"        [ğŸ” Tavilyæœç´¢] åŸå§‹æŸ¥è¯¢: \"{query}\"")
        print(f"        [âš™ï¸ å‚æ•°] max_results={max_results}, include_domains={include_domains}")
        
        payload = {
            "keywords": [query],
            "max_results": min(max_results, 20)
        }
        
        # å¦‚æœæä¾›äº†åŸŸååˆ—è¡¨ï¼Œå¼ºåˆ¶ç¡®ä¿æŸ¥è¯¢ä¸­åŒ…å«site:è¯­æ³•
        # é‡è¦ï¼šå³ä½¿æŸ¥è¯¢ä¸­å·²æœ‰site:è¯­æ³•ï¼Œæˆ‘ä»¬ä¹Ÿå¼ºåˆ¶é‡æ–°æ„å»ºä»¥ç¡®ä¿æ­£ç¡®æ€§
        if include_domains and len(include_domains) > 0:
            # æ£€æŸ¥æŸ¥è¯¢ä¸­æ˜¯å¦å·²åŒ…å«site:è¯­æ³•
            query_lower = query.lower()
            has_site_syntax = any(f"site:{domain.lower()}" in query_lower for domain in include_domains)
            
            print(f"        [ğŸ” æ£€æŸ¥] æŸ¥è¯¢è¯åŒ…å«site:è¯­æ³•: {has_site_syntax}")
            print(f"        [ğŸ” æ£€æŸ¥] æŸ¥è¯¢è¯: \"{query}\"")
            print(f"        [ğŸ” æ£€æŸ¥] ç›®æ ‡åŸŸå: {include_domains[:5]}")
            
            # å¼ºåˆ¶æ·»åŠ site:è¯­æ³•ï¼ˆå³ä½¿æŸ¥è¯¢ä¸­å·²æœ‰ï¼Œä¹Ÿé‡æ–°æ„å»ºä»¥ç¡®ä¿æ­£ç¡®æ€§ï¼‰
            # é€‰æ‹©å‰5ä¸ªæœ€é‡è¦çš„åŸŸåï¼ˆé¿å…æŸ¥è¯¢è¿‡é•¿ï¼‰
            selected_domains = include_domains[:5]
            domain_site_clause = " OR ".join([f"site:{domain}" for domain in selected_domains])
            
            # å¦‚æœæŸ¥è¯¢ä¸­å·²æœ‰site:è¯­æ³•ï¼Œå…ˆç§»é™¤æ—§çš„site:éƒ¨åˆ†
            if has_site_syntax:
                # å°è¯•ç§»é™¤æ—§çš„site:éƒ¨åˆ†ï¼ˆä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ï¼‰
                # ç§»é™¤ (site:xxx OR site:yyy) è¿™æ ·çš„æ¨¡å¼
                query_cleaned = re.sub(r'\s*\(site:[^)]+\)', '', query, flags=re.IGNORECASE)
                query_cleaned = query_cleaned.strip()
                # å¦‚æœæ¸…ç†åä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹æŸ¥è¯¢
                if not query_cleaned:
                    query_cleaned = query
                enhanced_query = f"{query_cleaned} ({domain_site_clause})"
                print(f"        [ğŸ”§ å¤„ç†] æŸ¥è¯¢ä¸­å·²æœ‰site:è¯­æ³•ï¼Œæ¸…ç†åé‡æ–°æ·»åŠ ")
                print(f"        [ğŸ”§ å¤„ç†] æ¸…ç†åçš„æŸ¥è¯¢: \"{query_cleaned}\"")
            else:
                # å¦‚æœæŸ¥è¯¢ä¸­æ²¡æœ‰site:è¯­æ³•ï¼Œç›´æ¥æ·»åŠ 
                enhanced_query = f"{query} ({domain_site_clause})"
                print(f"        [ğŸ”§ å¤„ç†] æŸ¥è¯¢ä¸­ç¼ºå°‘site:è¯­æ³•ï¼Œæ·»åŠ åŸŸåé™åˆ¶")
            
            payload["keywords"] = [enhanced_query]
            print(f"        [âœ… ç¡®è®¤] æœ€ç»ˆæŸ¥è¯¢ï¼ˆå¼ºåˆ¶åŒ…å«site:è¯­æ³•ï¼‰: \"{enhanced_query}\"")
            print(f"        [âœ… ç¡®è®¤] ä½¿ç”¨çš„åŸŸå: {selected_domains}")
            
            # åŒæ—¶å°è¯•åœ¨payloadä¸­æ·»åŠ include_domainså‚æ•°ï¼ˆå¦‚æœAPIæ”¯æŒï¼‰
            # æ³¨æ„ï¼šè¿™å–å†³äºTavily APIçš„å®é™…å®ç°
            # payload["include_domains"] = include_domains[:5]
        
        print(f"        [ğŸ“¤ è¯·æ±‚] Endpoint: {endpoint}")
        print(f"        [ğŸ“¤ è¯·æ±‚] Payload: {json.dumps(payload, ensure_ascii=False, indent=2)}")
        
        try:
            from llm_client import get_proxy_config
            response = requests.post(
                endpoint,
                headers=self.headers,
                json=payload,
                timeout=30,
                proxies=None  # [ä¿®å¤] 2026-01-20: AI Builders æ˜¯å†…ç½‘ APIï¼Œä¸éœ€è¦ä»£ç†
            )
            
            print(f"        [ğŸ“¥ å“åº”] çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                print(f"[ğŸ“¥ å“åº”] å“åº”ç±»å‹: {type(result).__name__}")
                print(f"[ğŸ“¥ å“åº”] å“åº”é”®: {list(result.keys()) if isinstance(result, dict) else 'N/A'}")
                print(f"[ğŸ“¥ å“åº”] å®Œæ•´ API å“åº”:\n{json.dumps(result, ensure_ascii=False, indent=2)}")
                
                results = []
                
                if isinstance(result, dict) and "queries" in result:
                    queries = result.get("queries", [])
                    print(f"[ğŸ“¥ å“åº”] queries æ•°é‡: {len(queries)}")
                    
                    if queries:
                        query_result = queries[0]
                        tavily_response = query_result.get("response", {})
                        tavily_results = tavily_response.get("results", [])
                        print(f"[ğŸ“¥ å“åº”] Tavily ç»“æœæ•°é‡: {len(tavily_results)}")
                        
                        for idx, item in enumerate(tavily_results[:max_results], 1):
                            # æ¸…ç†æ ‡é¢˜å’Œæ‘˜è¦
                            url = item.get('url', '')
                            original_title = item.get('title', '')
                            cleaned_title = clean_title(original_title, url)
                            raw_snippet = item.get('content', item.get('snippet', item.get('description', '')))
                            cleaned_snippet = clean_snippet(raw_snippet)

                            result_obj = SearchResult(
                                title=cleaned_title,
                                url=url,
                                snippet=cleaned_snippet,
                                source="Tavily",
                                search_engine="Tavily"
                            )
                            results.append(result_obj)
                            print(f"[ğŸ“‹ ç»“æœ{idx}] {result_obj.title[:60]}...")
                            print(f"    URL: {result_obj.url}")
                            print(f"    Snippet é•¿åº¦: {len(result_obj.snippet)} å­—ç¬¦")
                            print(f"    Snippet (å‰200å­—ç¬¦): {result_obj.snippet[:200]}...")
                            # æ£€æŸ¥æ˜¯å¦åŒ¹é…ç›®æ ‡åŸŸå
                            if include_domains:
                                url_lower = result_obj.url.lower()
                                matched = any(domain.lower() in url_lower for domain in include_domains)
                                if matched:
                                    matched_domain = next((d for d in include_domains if d.lower() in url_lower), None)
                                    print(f"    âœ… åŒ¹é…ç›®æ ‡åŸŸå: {matched_domain}")
                                else:
                                    print(f"    âš ï¸ æœªåŒ¹é…ç›®æ ‡åŸŸå")
                    else:
                        print(f"[âš ï¸ å“åº”] queries ä¸ºç©º")
                else:
                    print(f"[âš ï¸ å“åº”] å“åº”æ ¼å¼å¼‚å¸¸ï¼Œç¼ºå°‘ queries å­—æ®µ")
                    print(f"[ğŸ“¥ å“åº”] å“åº”é”®: {list(result.keys()) if isinstance(result, dict) else 'N/A'}")
                
                print(f"[âœ… å®Œæˆ] è¿”å› {len(results)} ä¸ªç»“æœ")
                print(f"{'='*80}\n")
                return results
            else:
                error_text = response.text[:500] if hasattr(response, 'text') else 'N/A'
                print(f"[âŒ é”™è¯¯] æœç´¢ API è°ƒç”¨å¤±è´¥")
                print(f"[âŒ é”™è¯¯] çŠ¶æ€ç : {response.status_code}")
                print(f"[âŒ é”™è¯¯] é”™è¯¯å“åº”: {error_text}")
                raise ValueError(f"æœç´¢ API è°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
        except requests.exceptions.RequestException as e:
            print(f"[âŒ é”™è¯¯] æœç´¢ API è¯·æ±‚å¼‚å¸¸: {str(e)}")
            print(f"[âŒ é”™è¯¯] å¼‚å¸¸ç±»å‹: {type(e).__name__}")
            import traceback
            print(f"[âŒ é”™è¯¯] å¼‚å¸¸å †æ ˆ:\n{traceback.format_exc()}")
            raise ValueError(f"æœç´¢ API è¯·æ±‚å¼‚å¸¸: {str(e)}")


# ============================================================================
# æœç´¢è¯ç”Ÿæˆå™¨
# ============================================================================

# ============================================================================
# ç»“æœè¯„ä¼°å™¨ï¼ˆå¤ç”¨è§„åˆ™åŒ¹é…ï¼‰
# ============================================================================

class ResultEvaluator:
    """ç»“æœè¯„ä¼°å™¨ - ğŸ”’ å½“å‰å·²ç¦ç”¨ï¼ˆå¯é‡æ–°å¯ç”¨ï¼‰"""
    
    def __init__(self, llm_client: Optional[AIBuildersClient] = None):
        self.llm_client = llm_client or AIBuildersClient()
        print(f"    [âœ… ResultEvaluator] åˆå§‹åŒ–ï¼ˆè¯„ä¼°é€»è¾‘å·²ç¦ç”¨ï¼‰")
    
    def _classify_resource_type(self, title: str, url: str, snippet: str) -> str:
        """
        åŸºäºè§„åˆ™å’ŒLLMåˆ†ç±»èµ„æºç±»å‹
        è¿”å›ï¼šæ’­æ”¾åˆ—è¡¨ã€è§†é¢‘ã€æ•™æã€æ•™è¾…ã€ç»ƒä¹ é¢˜ã€å…¶ä»–
        """
        title_lower = title.lower()
        url_lower = url.lower()
        snippet_lower = snippet.lower() if snippet else ""
        combined_text = f"{title_lower} {url_lower} {snippet_lower}"

        # 0. æ’­æ”¾åˆ—è¡¨æ£€æŸ¥ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
        # âš ï¸ æ’é™¤åšä¸»çš„å…¨éƒ¨æ’­æ”¾åˆ—è¡¨é¡µé¢ï¼ˆä¸æ˜¯å•ä¸ªè§†é¢‘åˆé›†ï¼‰
        if any(exclude in url_lower for exclude in ['/playlists$', '/channel/', '/c/', '/user/']):
            # è¿™äº›æ˜¯åšä¸»çš„å…¨éƒ¨æ’­æ”¾åˆ—è¡¨é¡µé¢ï¼Œä¸æ˜¯å•ä¸ªè§†é¢‘åˆé›†
            # ä»ç„¶æ ‡è®°ä¸ºæ’­æ”¾åˆ—è¡¨ç±»å‹ï¼Œä½†ä¼šåœ¨åç»­è¿‡æ»¤ä¸­å¤„ç†
            return "å…¶ä»–"

        # æ£€æŸ¥URLä¸­çš„æ’­æ”¾åˆ—è¡¨ç‰¹å¾ï¼ˆå•ä¸ªå…·ä½“çš„æ’­æ”¾åˆ—è¡¨ï¼‰
        if any(indicator in url_lower for indicator in ['playlist?', 'list=', '/videos']):
            return "æ’­æ”¾åˆ—è¡¨"

        # æ£€æŸ¥æ ‡é¢˜ä¸­çš„æ’­æ”¾åˆ—è¡¨å…³é”®è¯
        playlist_keywords = [
            'playlist', 'play list',
            'complete course', 'full course', 'all lessons',
            'series', 'collection',
            'Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªØ´ØºÙŠÙ„', 'Ø³Ù„Ø³Ù„Ø©',  # é˜¿æ‹‰ä¼¯è¯­
            'æ’­æ”¾åˆ—è¡¨', 'ç³»åˆ—', 'å…¨å¥—', 'å®Œæ•´è¯¾ç¨‹'
        ]
        if any(kw in combined_text for kw in playlist_keywords):
            # å¦‚æœæ ‡é¢˜åŒ…å«æ’­æ”¾åˆ—è¡¨å…³é”®è¯ï¼Œä½†URLæ˜¯/playlistsé¡µé¢ï¼Œåˆ™æ’é™¤
            if '/playlists' in url_lower and not any(ind in url_lower for ind in ['list=', 'playlist?']):
                return "å…¶ä»–"
            return "æ’­æ”¾åˆ—è¡¨"

        # 1. è§†é¢‘ç›¸å…³å…³é”®è¯
        video_keywords = [
            'video', 'youtube.com', 'youtu.be', 'watch',
            'æ’­æ”¾', 'è§†é¢‘', 'video pembelajaran',
            'video lesson', 'tutorial', 'è¯¾ç¨‹è§†é¢‘', 'lecture', 'lesson',
            'vimeo.com', 'bilibili.com/video', 'dailymotion.com'
        ]
        if any(keyword in combined_text for keyword in video_keywords):
            return "è§†é¢‘"

        # 2. ç»ƒä¹ é¢˜ç›¸å…³å…³é”®è¯
        exercise_keywords = [
            'exercise', 'practice', 'quiz', 'test', 'exam', 'worksheet',
            'ç»ƒä¹ é¢˜', 'ç»ƒä¹ ', 'latihan', 'soal', 'ujian', 'kuis',
            'lembar kerja', 'lkpd', 'assess', 'assessment'
        ]
        if any(keyword in combined_text for keyword in exercise_keywords):
            return "ç»ƒä¹ é¢˜"

        # 3. æ•™æç›¸å…³å…³é”®è¯ï¼ˆä¼˜å…ˆçº§é«˜äºæ•™è¾…ï¼‰
        textbook_keywords = [
            'textbook', 'book', 'æ•™æ', 'æ•™ç§‘ä¹¦', 'buku', 'buku pelajaran',
            'modul', 'module', 'coursebook', 'student book',
            'buku siswa', 'buku guru', 'kurikulum'
        ]
        if any(keyword in combined_text for keyword in textbook_keywords):
            return "æ•™æ"

        # 4. æ•™è¾…ç›¸å…³å…³é”®è¯
        supplement_keywords = [
            'guide', 'handbook', 'manual', 'æ•™è¾…', 'å‚è€ƒä¹¦', 'panduan',
            'å‚è€ƒ', 'supplement', 'è¾…åŠ©ææ–™', 'supplementary material',
            'bahan ajar', 'teaching material'
        ]
        if any(keyword in combined_text for keyword in supplement_keywords):
            return "æ•™è¾…"

        # 5. PDFæ–‡ä»¶é€šå¸¸å±äºæ•™ææˆ–æ•™è¾…
        if '.pdf' in url_lower:
            # è¿›ä¸€æ­¥åˆ¤æ–­
            if any(kw in title_lower for kw in ['modul', 'buku', 'textbook', 'kurikulum']):
                return "æ•™æ"
            elif any(kw in title_lower for kw in ['panduan', 'guide', 'handbook']):
                return "æ•™è¾…"
            else:
                return "æ•™æ"

        # 6. å­¦ä¹ èµ„æ–™ç›¸å…³
        learning_keywords = [
            'material', 'resource', 'content', 'å­¦ä¹ èµ„æ–™', 'å­¦ä¹ èµ„æº',
            'materi', 'bahan ajar', 'learning material', 'study material'
        ]
        if any(keyword in combined_text for keyword in learning_keywords):
            return "å…¶ä»–"

        # 7. æ ¹æ®URLæ¨æ–­
        if 'slideshare.net' in url_lower or 'scribd.com' in url_lower:
            return "æ•™è¾…"
        if 'kemdikbud.go.id' in url_lower:
            return "æ•™æ"

        # é»˜è®¤è¿”å›"å…¶ä»–"
        return "å…¶ä»–"
    
    def evaluate_results(self, search_results: List[SearchResult],
                         country: str = "", grade: str = "", subject: str = "") -> List[SearchResult]:
        """
        è¯„ä¼°æœç´¢ç»“æœå¹¶åˆ†ç±»èµ„æºç±»å‹

        åŠŸèƒ½ï¼š
        - ä¸ºæ¯ä¸ªç»“æœåˆ†ç±»èµ„æºç±»å‹ï¼ˆè§†é¢‘ã€æ•™æã€æ•™è¾…ã€ç»ƒä¹ é¢˜ï¼‰
        - è®¾ç½®é»˜è®¤è¯„åˆ†
        """
        if not search_results:
            return search_results

        print(f"    [â„¹ï¸ è¯„ä¼°] å¼€å§‹è¯„ä¼°å’Œåˆ†ç±» {len(search_results)} ä¸ªç»“æœ...")

        for result in search_results:
            # åˆ†ç±»èµ„æºç±»å‹
            resource_type = self._classify_resource_type(result.title, result.url, result.snippet)
            result.resource_type = resource_type

            # è®¾ç½®é»˜è®¤è¯„åˆ† (ä¿®å¤: ç§»é™¤è™šå‡çš„é»˜è®¤è¯„åˆ†)
            # if not result.score or result.score == 0:
            #     result.score = 7.5
            # if not result.recommendation_reason:
            #     result.recommendation_reason = "é»˜è®¤æ¨è"
            if not result.source:
                result.source = "è§„åˆ™"

        # ç»Ÿè®¡åˆ†ç±»ç»“æœ
        type_counts = {}
        for result in search_results:
            rtype = result.resource_type or "æœªåˆ†ç±»"
            type_counts[rtype] = type_counts.get(rtype, 0) + 1

        print(f"    [ğŸ“Š åˆ†ç±»ç»Ÿè®¡] {', '.join([f'{k}:{v}' for k,v in type_counts.items()])}")

        return search_results
    


# ============================================================================
# ä¸»æœç´¢å¼•æ“
# ============================================================================

class SearchEngineV2:
    """æ–°ç‰ˆæœç´¢å¼•æ“"""

    def __init__(self, llm_client: Optional[AIBuildersClient] = None, log_collector=None):
        self.llm_client = llm_client or AIBuildersClient()
        self.log_collector = log_collector  # ä¿å­˜æ—¥å¿—æ”¶é›†å™¨å¼•ç”¨
        self.config_manager = ConfigManager()  # ç”¨äºè¯»å–å›½å®¶é…ç½®

        # åˆå§‹åŒ–æœç´¢ç­–ç•¥ä»£ç†
        self.strategy_agent = SearchStrategyAgent(
            llm_client=self.llm_client,
            config_manager=self.config_manager
        )

        # åˆå§‹åŒ–ç»“æœè¯„ä¼°å™¨
        self.evaluator = ResultEvaluator(llm_client=self.llm_client)

        # ğŸ”¥ ç§»é™¤ QueryGeneratorï¼ˆå·²è¢« IntelligentQueryGenerator æ›¿ä»£ï¼ŒåŠŸèƒ½é‡å¤ï¼‰
        # IntelligentQueryGenerator ä½¿ç”¨æ›´æ–°çš„æ¨¡å‹ï¼ˆgemini-2.5-flash vs deepseekï¼‰ï¼Œæ•ˆæœæ›´å¥½
        # self.query_generator = QueryGenerator(
        #     llm_client=self.llm_client,
        #     config_manager=self.config_manager
        # )

        # ç®€å•çš„é…ç½®ç®¡ç†å™¨å ä½ç¬¦ï¼ˆç”¨äºå¹¶è¡Œæœç´¢é…ç½®ï¼‰
        class SimpleConfigManager:
            def get_search_config(self):
                return {
                    'edtech_domains': [
                        'khanacademy.org', 'coursera.org', 'edx.org',
                        'youtube.com', 'vimeo.com', 'dailymotion.com'
                    ],
                    'localization': {
                        'ar': 'ÙÙŠØ¯ÙŠÙˆ ØªØ¹Ù„ÙŠÙ…ÙŠ',
                        'en': 'Video lesson',
                        'id': 'Video pelajaran',
                        'zh': 'æ•™å­¦è§†é¢‘'
                    }
                }

        self.app_config = SimpleConfigManager()

        self.search_cache = get_search_cache()  # æ—§ç‰ˆå•çº§ç¼“å­˜ï¼ˆå…¼å®¹ä¿ç•™ï¼‰
        self.multi_cache = get_multi_level_cache()  # æ–°ç‰ˆä¸‰çº§ç¼“å­˜ï¼ˆL1å†…å­˜+L2Redis+L3ç£ç›˜ï¼‰
        # è¯„åˆ†å™¨å°†åœ¨searchæ–¹æ³•ä¸­æ ¹æ®country_codeåŠ¨æ€åˆå§‹åŒ–ï¼ˆå¸¦çŸ¥è¯†åº“ï¼‰
        self.result_scorer = None  # å°†åœ¨searchæ—¶åˆå§‹åŒ–ä¸ºå¸¦çŸ¥è¯†åº“çš„è¯„åˆ†å™¨
        self.result_scorer_without_kb = get_result_scorer()  # æ— çŸ¥è¯†åº“çš„å¤‡ç”¨è¯„åˆ†å™¨
        self._scorer_cache = {}  # ç¼“å­˜å„å›½çš„è¯„åˆ†å™¨ {country_code: scorer}
        self.recommendation_generator = get_recommendation_generator()  # LLMæ¨èç†ç”±ç”Ÿæˆå™¨
        print(f"    [âœ…] æ™ºèƒ½è¯„åˆ†å™¨å·²åˆå§‹åŒ–ï¼ˆå°†åœ¨æœç´¢æ—¶åŠ è½½çŸ¥è¯†åº“ï¼‰")
        print(f"    [âœ…] LLMæ¨èç†ç”±ç”Ÿæˆå™¨å·²åˆå§‹åŒ–")
        print(f"    [âœ…] ä¸‰çº§ç¼“å­˜ç³»ç»Ÿå·²å¯ç”¨ (L1:å†…å­˜100æ¡/5åˆ†é’Ÿ + L2:Redis/1å°æ—¶ + L3:ç£ç›˜/24å°æ—¶)")

        # åˆå§‹åŒ–ç™¾åº¦æœç´¢å®¢æˆ·ç«¯ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
        self.baidu_search_enabled = False
        try:
            baidu_api_key = os.getenv("BAIDU_API_KEY")
            if baidu_api_key:
                from search_strategist import SearchHunter
                self.baidu_hunter = SearchHunter(search_engine="baidu", llm_client=None)
                self.baidu_search_enabled = True
                print(f"    [âœ…] ç™¾åº¦æœç´¢å·²å¯ç”¨")
            else:
                print(f"    [â„¹ï¸] ç™¾åº¦æœç´¢æœªé…ç½®ï¼ˆBAIDU_API_KEYæœªè®¾ç½®ï¼‰")
        except Exception as e:
            print(f"    [âš ï¸] ç™¾åº¦æœç´¢åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.baidu_search_enabled = False

        # åˆå§‹åŒ– Google æœç´¢å®¢æˆ·ç«¯ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
        self.google_search_enabled = False
        try:
            google_api_key = os.getenv("GOOGLE_API_KEY")
            google_cx = os.getenv("GOOGLE_CX")
            if google_api_key and google_cx:
                from search_strategist import SearchHunter
                self.google_hunter = SearchHunter(search_engine="google", llm_client=None)
                self.google_search_enabled = True
                print(f"    [âœ…] Google æœç´¢å·²å¯ç”¨")
            else:
                print(f"    [â„¹ï¸] Google æœç´¢æœªé…ç½®ï¼ˆéœ€è¦ GOOGLE_API_KEY å’Œ GOOGLE_CXï¼‰")
        except Exception as e:
            print(f"    [âš ï¸] Google æœç´¢åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.google_search_enabled = False

    def _get_memory_usage(self) -> str:
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        try:
            import resource
            import sys
            rss_kb = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
            if sys.platform == 'darwin':
                rss_mb = rss_kb / 1024 / 1024
            else:
                rss_mb = rss_kb / 1024
            return f"{rss_mb:.1f} MB"
        except:
            return "Unknown"

    def _cached_search(self, query: str, search_func, engine_name: str, max_results: int = 15,
                       include_domains: Optional[List[str]] = None) -> List[SearchResult]:
        """
        å¸¦å¤šçº§ç¼“å­˜çš„æœç´¢åŒ…è£…å™¨

        ä½¿ç”¨ä¸‰çº§ç¼“å­˜ç³»ç»Ÿï¼ˆL1å†…å­˜+L2Redis+L3ç£ç›˜ï¼‰æå‡æ€§èƒ½
        [ä¿®å¤] 2026-01-20: æ·»åŠ ç¯å¢ƒå˜é‡ ENABLE_MULTI_CACHE æ§åˆ¶ç¼“å­˜å¼€å…³

        Args:
            query: æœç´¢æŸ¥è¯¢
            search_func: å®é™…çš„æœç´¢å‡½æ•°
            engine_name: æœç´¢å¼•æ“åç§°ï¼ˆç”¨äºç¼“å­˜é”®ï¼‰
            max_results: æœ€å¤§ç»“æœæ•°
            include_domains: åŒ…å«çš„åŸŸååˆ—è¡¨

        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨å¤šçº§ç¼“å­˜
        enable_multi_cache = os.getenv("ENABLE_MULTI_CACHE", "false").lower() == "true"

        if enable_multi_cache:
            # ä½¿ç”¨å¤šçº§ç¼“å­˜ç³»ç»Ÿï¼ˆå¸¦æŸ¥è¯¢è§„èŒƒåŒ–ï¼‰
            cached_result = self.multi_cache.get(
                query=query,
                engine=engine_name,
                max_results=max_results,
                include_domains=include_domains
            )
        else:
            # ç¦ç”¨ç¼“å­˜ï¼Œç›´æ¥æ‰§è¡Œæœç´¢
            cached_result = None

        if cached_result is not None:
            cache_stats = self.multi_cache.get_stats()
            logger.info(
                f"âœ… å¤šçº§ç¼“å­˜å‘½ä¸­ [{engine_name}]: {query[:50]}... "
                f"(å‘½ä¸­ç‡: {cache_stats['hit_rate']:.1f}%, "
                f"L1:{cache_stats['l1_hit_rate']:.1f}% "
                f"L2:{cache_stats['l2_hit_rate']:.1f}% "
                f"L3:{cache_stats['l3_hit_rate']:.1f}%)"
            )
            # ä»ç¼“å­˜æ•°æ®é‡å»ºSearchResultå¯¹è±¡
            return [SearchResult(**item) for item in cached_result]

        # ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œå®é™…æœç´¢
        if not enable_multi_cache:
            logger.info(f"âš ï¸ å¤šçº§ç¼“å­˜å·²ç¦ç”¨ [{engine_name}]: {query[:50]}...")
        else:
            logger.info(f"âŒ å¤šçº§ç¼“å­˜æœªå‘½ä¸­ [{engine_name}]: {query[:50]}...")
        results = search_func(query, max_results, include_domains)

        # å°†ç»“æœå­˜å…¥å¤šçº§ç¼“å­˜ï¼ˆä»…åœ¨å¯ç”¨æ—¶ï¼‰
        if enable_multi_cache:
            results_dict = [result.model_dump() for result in results]
            self.multi_cache.set(
                query=query,
                engine=engine_name,
                data=results_dict,
                ttl=3600,  # 1å°æ—¶TTL
                max_results=max_results,
                include_domains=include_domains
            )
        return results

    def _parallel_search(self, query: str, search_tasks: List[Dict[str, Any]],
                        timeout: int = 30, country_code: str = "CN") -> Dict[str, List[SearchResult]]:
        """
        å¹¶è¡Œæ‰§è¡Œå¤šä¸ªæœç´¢ä»»åŠ¡

        Args:
            query: é»˜è®¤æœç´¢æŸ¥è¯¢ï¼ˆå¦‚æœä»»åŠ¡æ²¡æœ‰æŒ‡å®šæŸ¥è¯¢ï¼Œåˆ™ä½¿ç”¨æ­¤æŸ¥è¯¢ï¼‰
            search_tasks: æœç´¢ä»»åŠ¡åˆ—è¡¨ï¼Œæ¯ä¸ªä»»åŠ¡åŒ…å«:
                - name: ä»»åŠ¡åç§°
                - query: ä»»åŠ¡ç‰¹å®šçš„æœç´¢æŸ¥è¯¢ï¼ˆå¯é€‰ï¼Œä¼˜å…ˆçº§é«˜äºé»˜è®¤queryï¼‰
                - func: æœç´¢å‡½æ•°
                - engine_name: æœç´¢å¼•æ“åç§°ï¼ˆç”¨äºç¼“å­˜ï¼‰
                - max_results: æœ€å¤§ç»“æœæ•°
                - include_domains: åŒ…å«çš„åŸŸåï¼ˆå¯é€‰ï¼‰
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            country_code: å›½å®¶ä»£ç ï¼ˆç”¨äºå…è´¹é¢åº¦ä¼˜å…ˆç­–ç•¥ï¼‰

        Returns:
            å­—å…¸ï¼Œé”®ä¸ºä»»åŠ¡åç§°ï¼Œå€¼ä¸ºæœç´¢ç»“æœåˆ—è¡¨
        """
        results = {}
        start_time = time.time()

        print(f"    [âš¡ å¹¶è¡Œæœç´¢] å¯åŠ¨ {len(search_tasks)} ä¸ªå¹¶è¡Œæœç´¢ä»»åŠ¡")
        print(f"    [âš™ï¸ å‚æ•°] è¶…æ—¶æ—¶é—´: {timeout}ç§’, å›½å®¶ä»£ç : {country_code}")

        def execute_search_task(task: Dict[str, Any]) -> tuple:
            """æ‰§è¡Œå•ä¸ªæœç´¢ä»»åŠ¡"""
            task_name = task['name']
            search_func = task['func']
            engine_name = task['engine_name']
            max_results = task.get('max_results', 15)
            include_domains = task.get('include_domains', None)
            # ä½¿ç”¨ä»»åŠ¡ç‰¹å®šçš„æŸ¥è¯¢ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤æŸ¥è¯¢
            task_query = task.get('query', query)

            try:
                task_start = time.time()

                # åˆ¤æ–­æ˜¯å¦æ˜¯ llm_client.searchï¼ˆæ”¯æŒ country_code å‚æ•°ï¼‰
                # æ£€æŸ¥æ˜¯å¦æ˜¯ UnifiedLLMClient çš„æ–¹æ³•
                is_llm_client_search = (
                    hasattr(search_func, '__self__') and
                    isinstance(search_func.__self__, UnifiedLLMClient) and
                    search_func.__name__ == 'search'
                )

                if is_llm_client_search:
                    # llm_client.search æ”¯æŒ country_code å‚æ•°ï¼ˆå…è´¹é¢åº¦ä¼˜å…ˆç­–ç•¥ï¼‰
                    task_results = self._cached_search(
                        query=task_query,
                        search_func=lambda q, mr, id: search_func(q, max_results=mr, include_domains=include_domains, country_code=country_code),
                        engine_name=engine_name,
                        max_results=max_results,
                        include_domains=include_domains
                    )
                else:
                    # âœ¨ ä¿®å¤ï¼šæ£€æŸ¥æœç´¢å‡½æ•°æ˜¯å¦æ”¯æŒ country_code å‚æ•°
                    # åªç»™ Google Hunter ä¼ é€’ country_codeï¼ˆç”¨äºæœ¬åœ°åŒ–æœç´¢ï¼‰
                    # Tavily/Metaso/Baidu ä¸æ”¯æŒæ­¤å‚æ•°
                    import inspect
                    func_name = search_func.__name__ if hasattr(search_func, '__name__') else str(search_func)
                    if hasattr(search_func, '__self__') and 'google_hunter' in str(type(search_func.__self__)):
                        # Google Hunter æ”¯æŒ country_code å‚æ•°
                        task_results = self._cached_search(
                            query=task_query,
                            search_func=lambda q, mr, id: search_func(q, max_results=mr, country_code=country_code),
                            engine_name=engine_name,
                            max_results=max_results,
                            include_domains=include_domains
                        )
                    else:
                        # å…¶ä»–æœç´¢å¼•æ“ä¸æ”¯æŒ country_code å‚æ•°
                        task_results = self._cached_search(
                            query=task_query,
                            search_func=lambda q, mr, id: search_func(q, max_results=mr),
                            engine_name=engine_name,
                            max_results=max_results,
                            include_domains=include_domains
                        )

                task_elapsed = time.time() - task_start
                print(f"    [âœ… {task_name}] å®Œæˆ ({task_elapsed:.2f}ç§’, {len(task_results)}ä¸ªç»“æœ)")
                return (task_name, task_results)
            except Exception as e:
                print(f"    [âŒ {task_name}] å¤±è´¥: {str(e)}")
                logger.error(f"å¹¶è¡Œæœç´¢ä»»åŠ¡å¤±è´¥ [{task_name}]: {str(e)}")
                return (task_name, [])

        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œæ‰§è¡Œæœç´¢ï¼ˆTODOï¼šæœªæ¥è¿ç§»åˆ°aiohttpä»¥å®ç°çœŸæ­£çš„å¼‚æ­¥I/Oï¼‰
        # å½“å‰ä½¿ç”¨ThreadPoolExecutoråŒ…è£…åŒæ­¥requestsè°ƒç”¨ï¼Œå·²å¯å¹¶å‘æ‰§è¡Œä½†ä»æœ‰æ”¹è¿›ç©ºé—´
        # ä¼˜åŒ–å»ºè®®ï¼šä½¿ç”¨aiohttp + asyncioå®ç°å¼‚æ­¥HTTPè¯·æ±‚ï¼Œæ€§èƒ½å¯æå‡30%+
        with ThreadPoolExecutor(max_workers=min(len(search_tasks), 10)) as executor:  # å¢åŠ å¹¶å‘åº¦ï¼ˆP1ä¿®å¤ï¼‰
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_task = {
                executor.submit(execute_search_task, task): task
                for task in search_tasks
            }

            # æ”¶é›†å®Œæˆçš„ä»»åŠ¡ç»“æœï¼ˆæ·»åŠ è¶…æ—¶ä¿æŠ¤ï¼‰
            try:
                for future in as_completed(future_to_task, timeout=timeout):
                    try:
                        task_name, task_results = future.result(timeout=1.0)  # å•ä¸ªfutureç»“æœè·å–è¶…æ—¶
                        results[task_name] = task_results
                    except concurrent.futures.TimeoutError:
                        logger.warning(f"ä»»åŠ¡ {future_to_task[future].get('name', 'unknown')} ç»“æœè·å–è¶…æ—¶")
                        results[future_to_task[future].get('name', 'unknown')] = []
                    except Exception as e:
                        logger.error(f"ä»»åŠ¡ç»“æœå¤„ç†å¤±è´¥: {str(e)}")
                        results[future_to_task[future].get('name', 'unknown')] = []
            except concurrent.futures.TimeoutError:
                logger.warning(f"å¹¶è¡Œæœç´¢æ•´ä½“è¶…æ—¶ ({timeout}ç§’)ï¼Œå·²æ”¶é›†éƒ¨åˆ†ç»“æœ")
                # å°è¯•è·å–å·²å®Œæˆçš„ä»»åŠ¡ç»“æœ
                for future in future_to_task:
                    if future.done():
                        try:
                            task_name, task_results = future.result(timeout=0.5)
                            if task_name not in results:
                                results[task_name] = task_results
                        except:
                            pass

        elapsed_time = time.time() - start_time
        total_results = sum(len(r) for r in results.values())
        print(f"    [âš¡ å¹¶è¡Œæœç´¢] å®Œæˆï¼Œè€—æ—¶ {elapsed_time:.2f}ç§’ï¼Œå…± {total_results} ä¸ªç»“æœ")

        return results

    def _is_edtech_domain(self, url: str) -> bool:
        """
        æ£€æŸ¥URLæ˜¯å¦æ¥è‡ªEdTechå¹³å°ï¼ˆçŸ¥åæ•™è‚²å¹³å°ï¼‰

        Args:
            url: è¦æ£€æŸ¥çš„URL

        Returns:
            æ˜¯å¦æ¥è‡ªEdTechå¹³å°
        """
        try:
            search_config = self.app_config.get_search_config()
            edtech_domains = search_config.get('edtech_domains', [])

            url_lower = url.lower()
            for domain in edtech_domains:
                if domain.lower() in url_lower:
                    logger.debug(f"æ£€æµ‹åˆ°EdTechå¹³å°: {domain}")
                    return True

            return False
        except Exception as e:
            logger.warning(f"æ£€æŸ¥EdTechåŸŸåå¤±è´¥: {str(e)}")
            return False

    def _generate_fallback_query(self, request: SearchRequest) -> str:
        """
        ç”Ÿæˆé™çº§æœç´¢è¯ï¼ˆè§„åˆ™ç”Ÿæˆï¼Œä¸ä½¿ç”¨LLMï¼‰

        Args:
            request: æœç´¢è¯·æ±‚

        Returns:
            æœç´¢è¯
        """
        # è§„åˆ™ç”Ÿæˆé»˜è®¤æœç´¢è¯
        default_query = f"{request.subject} {request.grade} playlist"
        if request.semester:
            default_query += f" semester {request.semester}"

        logger.info(f"[ğŸ”„ è§„åˆ™ç”Ÿæˆ] ç”Ÿæˆé»˜è®¤æœç´¢è¯: \"{default_query}\"")
        return default_query

    def incremental_search(self, request: SearchRequest) -> SearchResponse:
        """
        æ¸è¿›å¼æœç´¢ï¼ˆä¼˜åŒ–æ–¹æ¡ˆä¸€ï¼‰

        ç‰¹ç‚¹ï¼š
        - ç”Ÿæˆ1ä¸ªæœ€ä¼˜æŸ¥è¯¢ï¼ˆè€Œé5-7ä¸ªï¼‰
        - æ ¹æ®è´¨é‡åŠ¨æ€å†³å®šæ˜¯å¦è¡¥å……æœç´¢
        - é«˜è´¨é‡ç›´æ¥è¿”å›ï¼Œä¸­ä½è´¨é‡è¿›è¡Œè¡¥å……æœç´¢æˆ–é‡è¯•
        - æ˜¾è‘—é™ä½APIè°ƒç”¨æ¬¡æ•°å’Œå“åº”æ—¶é—´

        Args:
            request: æœç´¢è¯·æ±‚

        Returns:
            æœç´¢å“åº”
        """
        search_start_time = time.time()

        logger.info("="*80)
        logger.info(f"ğŸ¯ [æ¸è¿›å¼æœç´¢] {request.country} - {request.grade} - {request.subject}")
        logger.info("="*80)

        print(f"\n{'='*80}")
        print(f"ğŸ¯ æ¸è¿›å¼æœç´¢ï¼ˆä¼˜åŒ–æ–¹æ¡ˆä¸€ï¼‰")
        print(f"{'='*80}\n")

        # ========== Step 1: ç”Ÿæˆæœ€ä¼˜æŸ¥è¯¢ ==========
        print(f"[Step 1] ç”Ÿæˆæœ€ä¼˜æŸ¥è¯¢...")
        logger.info(f"[Step 1] ç”Ÿæˆæœ€ä¼˜æŸ¥è¯¢...")

        try:
            best_query = self.strategy_agent.generate_best_query(
                country=request.country,
                grade=request.grade,
                subject=request.subject,
                semester=request.semester
            )
            print(f"    [âœ… æœ€ä¼˜æŸ¥è¯¢] \"{best_query}\"")
            logger.info(f"[âœ… æœ€ä¼˜æŸ¥è¯¢] \"{best_query}\"")
        except Exception as e:
            logger.warning(f"[âš ï¸ LLMæŸ¥è¯¢ç”Ÿæˆå¤±è´¥] {str(e)}ï¼Œä½¿ç”¨è§„åˆ™ç”Ÿæˆ")
            best_query = self._generate_fallback_query(request)
            print(f"    [âœ… è§„åˆ™æŸ¥è¯¢] \"{best_query}\"")

        # ========== Step 2: åˆå§‹æœç´¢ ==========
        print(f"\n[Step 2] æ‰§è¡Œåˆå§‹æœç´¢...")
        logger.info(f"[Step 2] æ‰§è¡Œåˆå§‹æœç´¢...")

        initial_results = self._perform_initial_search(best_query, request.country)

        if not initial_results:
            logger.warning("[âš ï¸ åˆå§‹æœç´¢æ— ç»“æœ]ï¼Œå°è¯•é™çº§ç­–ç•¥")
            return self._handle_empty_results(request, best_query)

        print(f"    [âœ… åˆå§‹ç»“æœ] {len(initial_results)} ä¸ª")
        logger.info(f"[âœ… åˆå§‹ç»“æœ] {len(initial_results)} ä¸ª")

        # ========== Step 3: å¿«é€Ÿè´¨é‡è¯„ä¼° ==========
        print(f"\n[Step 3] å¿«é€Ÿè´¨é‡è¯„ä¼°...")
        logger.info(f"[Step 3] å¿«é€Ÿè´¨é‡è¯„ä¼°...")

        # ä½¿ç”¨è§„åˆ™è¯„åˆ†è¿›è¡Œå¿«é€Ÿè´¨é‡è¯„ä¼°
        self._ensure_result_scorer(request.country)
        scored_results = self.result_scorer.score_results(
            initial_results,
            best_query,
            metadata={'country': request.country, 'grade': request.grade, 'subject': request.subject}
        )

        # è®¡ç®—å‰10ä¸ªç»“æœçš„å¹³å‡åˆ†
        top_10 = scored_results[:10]
        avg_score = sum(r.get('score', 0) for r in top_10) / len(top_10) if top_10 else 0.0

        print(f"    [ğŸ“Š è´¨é‡è¯„ä¼°] å¹³å‡åˆ†: {avg_score:.2f}")
        logger.info(f"[ğŸ“Š è´¨é‡è¯„ä¼°] å¹³å‡åˆ†: {avg_score:.2f}")

        # ========== Step 4-5: æ ¹æ®è´¨é‡å†³å®šåç»­ç­–ç•¥ ==========
        if avg_score >= 7.0:
            # é«˜è´¨é‡ï¼šç›´æ¥è¿”å›
            print(f"    [âœ… é«˜è´¨é‡] ç›´æ¥è¿”å›å‰20ä¸ªç»“æœ")
            logger.info(f"[âœ… é«˜è´¨é‡] ç›´æ¥è¿”å›å‰20ä¸ªç»“æœ")
            return self._build_response(best_query, scored_results[:20], search_start_time, request)

        elif avg_score >= 5.0:
            # ä¸­ç­‰è´¨é‡ï¼šè¡¥å……æœç´¢
            print(f"    [âš ï¸ ä¸­ç­‰è´¨é‡] æ‰§è¡Œè¡¥å……æœç´¢...")
            logger.info(f"[âš ï¸ ä¸­ç­‰è´¨é‡] æ‰§è¡Œè¡¥å……æœç´¢...")

            supplementary_results = self._perform_supplementary_search(
                best_query, request.country
            )

            if supplementary_results:
                print(f"    [âœ… è¡¥å……ç»“æœ] {len(supplementary_results)} ä¸ª")
                logger.info(f"[âœ… è¡¥å……ç»“æœ] {len(supplementary_results)} ä¸ª")

                # åˆå¹¶å¹¶é‡æ–°è¯„åˆ†
                all_results = self._merge_and_deduplicate(
                    scored_results, supplementary_results, best_query, request
                )
                return self._build_response(best_query, all_results[:20], search_start_time, request)
            else:
                print(f"    [âš ï¸ è¡¥å……æœç´¢æ— ç»“æœ]ï¼Œè¿”å›åˆå§‹ç»“æœ")
                return self._build_response(best_query, scored_results[:20], search_start_time, request)

        else:
            # ä½è´¨é‡ï¼šæŸ¥è¯¢é‡è¯•
            print(f"    [âŒ ä½è´¨é‡] å°è¯•æŸ¥è¯¢é‡è¯•...")
            logger.info(f"[âŒ ä½è´¨é‡] å°è¯•æŸ¥è¯¢é‡è¯•...")

            # ç”Ÿæˆå¤‡é€‰æŸ¥è¯¢å¹¶é‡è¯•
            for attempt in range(1, 4):  # æœ€å¤šé‡è¯•3æ¬¡
                try:
                    alt_query = self.strategy_agent.generate_alternative_query(
                        country=request.country,
                        grade=request.grade,
                        subject=request.subject,
                        semester=request.semester,
                        attempt_number=attempt
                    )

                    print(f"    [ğŸ”„ é‡è¯• {attempt}] ä½¿ç”¨å¤‡é€‰æŸ¥è¯¢: \"{alt_query}\"")
                    logger.info(f"[ğŸ”„ é‡è¯• {attempt}] å¤‡é€‰æŸ¥è¯¢: \"{alt_query}\"")

                    retry_results = self._perform_initial_search(alt_query, request.country)

                    if retry_results:
                        retry_scored = self.result_scorer.score_results(
                            retry_results,
                            alt_query,
                            metadata={'country': request.country, 'grade': request.grade, 'subject': request.subject}
                        )

                        retry_top_10 = retry_scored[:10]
                        retry_avg = sum(r.get('score', 0) for r in retry_top_10) / len(retry_top_10)

                        print(f"    [ğŸ“Š é‡è¯•è´¨é‡] å¹³å‡åˆ†: {retry_avg:.2f}")
                        logger.info(f"[ğŸ“Š é‡è¯•è´¨é‡] å¹³å‡åˆ†: {retry_avg:.2f}")

                        if retry_avg >= 5.0:
                            print(f"    [âœ… é‡è¯•æˆåŠŸ] è¿”å›é‡è¯•ç»“æœ")
                            logger.info(f"[âœ… é‡è¯•æˆåŠŸ] è¿”å›é‡è¯•ç»“æœ")
                            return self._build_response(alt_query, retry_scored[:20], search_start_time, request)

                except Exception as e:
                    logger.warning(f"[âš ï¸ é‡è¯• {attempt} å¤±è´¥]: {str(e)}")
                    continue

            # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œè¿”å›åˆå§‹ç»“æœ
            print(f"    [âš ï¸ æ‰€æœ‰é‡è¯•å¤±è´¥]ï¼Œè¿”å›åˆå§‹æœ€ä½³ç»“æœ")
            logger.warning(f"[âš ï¸ æ‰€æœ‰é‡è¯•å¤±è´¥]ï¼Œè¿”å›åˆå§‹æœ€ä½³ç»“æœ")
            return self._build_response(best_query, scored_results[:20], search_start_time, request)

    def _perform_initial_search(self, query: str, country_code: str) -> List[Dict]:
        """æ‰§è¡Œåˆå§‹æœç´¢ï¼ˆä½¿ç”¨Tavily/Metasoï¼‰"""
        try:
            results = self.llm_client.search(
                query=query,
                max_results=30,
                country_code=country_code
            )

            # è½¬æ¢ä¸ºSearchResultæ ¼å¼
            search_results = []
            for r in results:
                search_results.append(SearchResult(
                    title=r.get('title', ''),
                    url=r.get('url', ''),
                    snippet=r.get('content', r.get('snippet', '')),
                    source='è§„åˆ™',
                    search_engine=r.get('engine', 'Tavily/Metaso'),
                    score=0.0
                ))

            return search_results

        except Exception as e:
            logger.error(f"[âŒ åˆå§‹æœç´¢å¤±è´¥]: {str(e)}")
            return []

    def _perform_supplementary_search(self, query: str, country_code: str) -> List[Dict]:
        """æ‰§è¡Œè¡¥å……æœç´¢ï¼ˆä½¿ç”¨Googleï¼‰"""
        if not self.google_search_enabled:
            logger.info("[â„¹ï¸ Googleæœç´¢æœªå¯ç”¨ï¼Œè·³è¿‡è¡¥å……æœç´¢]")
            return []

        try:
            results = self.google_hunter.search(
                query=query,
                max_results=20
            )

            # è½¬æ¢ä¸ºSearchResultæ ¼å¼
            search_results = []
            for r in results:
                search_results.append(SearchResult(
                    title=r.get('title', ''),
                    url=r.get('url', ''),
                    snippet=r.get('snippet', ''),
                    source='è§„åˆ™',
                    search_engine='Google',
                    score=0.0
                ))

            return search_results

        except Exception as e:
            logger.error(f"[âŒ è¡¥å……æœç´¢å¤±è´¥]: {str(e)}")
            return []

    def _merge_and_deduplicate(self, initial_results: List[Dict],
                             supplementary_results: List[Dict],
                             query: str, request: SearchRequest) -> List[Dict]:
        """åˆå¹¶ç»“æœå¹¶å»é‡"""
        seen_urls = {r['url'] for r in initial_results}
        merged = list(initial_results)

        for result in supplementary_results:
            if result['url'] not in seen_urls:
                merged.append(result)
                seen_urls.add(result['url'])

        # é‡æ–°è¯„åˆ†åˆå¹¶åçš„ç»“æœ
        scored = self.result_scorer.score_results(
            merged,
            query,
            metadata={'country': request.country, 'grade': request.grade, 'subject': request.subject}
        )

        # æŒ‰åˆ†æ•°æ’åº
        scored.sort(key=lambda x: x.get('score', 0), reverse=True)
        return scored

    def _handle_empty_results(self, request: SearchRequest, query: str) -> SearchResponse:
        """å¤„ç†ç©ºç»“æœçš„æƒ…å†µ"""
        logger.warning(f"[âš ï¸ ç©ºç»“æœ] å°è¯•ä½¿ç”¨å¤‡é€‰æŸ¥è¯¢...")

        # å°è¯•ä½¿ç”¨å¤‡é€‰æŸ¥è¯¢
        for attempt in range(1, 4):
            try:
                alt_query = self.strategy_agent.generate_alternative_query(
                    country=request.country,
                    grade=request.grade,
                    subject=request.subject,
                    semester=request.semester,
                    attempt_number=attempt
                )

                logger.info(f"[ğŸ”„ ç©ºç»“æœé‡è¯• {attempt}]: \"{alt_query}\"")
                results = self._perform_initial_search(alt_query, request.country)

                if results:
                    scored = self.result_scorer.score_results(
                        results,
                        alt_query,
                        metadata={'country': request.country, 'grade': request.grade, 'subject': request.subject}
                    )
                    return self._build_response(alt_query, scored[:20], time.time(), request)

            except Exception as e:
                logger.warning(f"[âš ï¸ ç©ºç»“æœé‡è¯• {attempt} å¤±è´¥]: {str(e)}")
                continue

        # æ‰€æœ‰å°è¯•éƒ½å¤±è´¥ï¼Œè¿”å›ç©ºå“åº”
        return SearchResponse(
            success=False,
            query=query,
            results=[],
            total_count=0,
            playlist_count=0,
            video_count=0,
            message="æœªæ‰¾åˆ°ç›¸å…³æœç´¢ç»“æœï¼Œè¯·å°è¯•è°ƒæ•´æœç´¢å…³é”®è¯"
        )

    def _build_response(self, query: str, results: List[SearchResult],
                       start_time: float, request: SearchRequest) -> SearchResponse:
        """æ„å»ºæœç´¢å“åº”"""
        elapsed = time.time() - start_time

        # ç»Ÿè®¡æ’­æ”¾åˆ—è¡¨å’Œè§†é¢‘æ•°é‡
        playlist_count = sum(1 for r in results if 'playlist' in r.title.lower())
        video_count = len(results) - playlist_count

        logger.info(f"[âœ… æœç´¢å®Œæˆ] è€—æ—¶: {elapsed:.2f}ç§’, ç»“æœ: {len(results)}ä¸ª")
        print(f"    [âœ… å®Œæˆ] è€—æ—¶: {elapsed:.2f}ç§’, è¿”å›: {len(results)}ä¸ªç»“æœ\n")

        return SearchResponse(
            success=True,
            query=query,
            results=results,
            total_count=len(results),
            playlist_count=playlist_count,
            video_count=video_count,
            message=f"æœç´¢å®Œæˆï¼Œè€—æ—¶ {elapsed:.2f} ç§’"
        )

    def _ensure_result_scorer(self, country_code: str):
        """ç¡®ä¿å·²åˆå§‹åŒ–å¸¦çŸ¥è¯†åº“çš„è¯„åˆ†å™¨"""
        if country_code not in self._scorer_cache:
            try:
                from core.result_scorer import get_result_scorer_with_kb
                scorer = get_result_scorer_with_kb(country_code)
                self._scorer_cache[country_code] = scorer
                logger.info(f"[âœ… è¯„åˆ†å™¨] å·²åŠ è½½ {country_code} çŸ¥è¯†åº“è¯„åˆ†å™¨")
            except Exception as e:
                logger.warning(f"[âš ï¸ è¯„åˆ†å™¨] æ— æ³•åŠ è½½çŸ¥è¯†åº“è¯„åˆ†å™¨: {e}")
                self._scorer_cache[country_code] = self.result_scorer_without_kb

        self.result_scorer = self._scorer_cache.get(country_code, self.result_scorer_without_kb)

    def search(self, request: SearchRequest) -> SearchResponse:
        """
        æ‰§è¡Œæœç´¢

        Args:
            request: æœç´¢è¯·æ±‚

        Returns:
            æœç´¢å“åº”
        """
        # æ€§èƒ½ç›‘æ§ - å¼€å§‹è®¡æ—¶
        search_start_time = time.time()

        # ğŸ” è¯¦ç»†æ—¥å¿—ï¼šæœç´¢å¼€å§‹
        logger.info("="*80)
        logger.info(f"ğŸ” [æœç´¢å¼€å§‹] {request.country} - {request.grade} - {request.subject}")
        logger.info(f"   æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info(f"   å†…å­˜ä½¿ç”¨: {self._get_memory_usage()}")
        logger.info("="*80)

        print(f"\n{'='*80}")
        print(f"ğŸ” å¼€å§‹æœç´¢")
        print(f"{'='*80}")
        print(f"å›½å®¶: {request.country}")
        print(f"å¹´çº§: {request.grade}")
        print(f"å­¦æœŸ: {request.semester or 'ä¸æŒ‡å®š'}")
        print(f"å­¦ç§‘: {request.subject}")
        print(f"{'='*80}\n")

        # ========== å¹´çº§-å­¦ç§‘é…å¯¹éªŒè¯ ==========
        logger.info(f"[æ­¥éª¤ 0] å¹´çº§-å­¦ç§‘é…å¯¹éªŒè¯...")
        print(f"[éªŒè¯] æ£€æŸ¥å¹´çº§-å­¦ç§‘é…å¯¹...")
        try:
            validator = GradeSubjectValidator()
            validation_result = validator.validate(
                request.country,
                request.grade,
                request.subject
            )

            if not validation_result["valid"]:
                # é…å¯¹ä¸åˆæ³•ï¼Œæ˜¾ç¤ºè­¦å‘Šä½†ä»å…è®¸æœç´¢
                warning_msg = f"âš ï¸ {validation_result['reason']}"
                print(f"    {warning_msg}")
                if validation_result.get("suggestions"):
                    print(f"    ğŸ’¡ å»ºè®®: {', '.join(validation_result['suggestions'][:5])}")
                logger.warning(f"å¹´çº§-å­¦ç§‘é…å¯¹éªŒè¯å¤±è´¥: {request.country} {request.grade} {request.subject}")
            else:
                print(f"    âœ… å¹´çº§-å­¦ç§‘é…å¯¹éªŒè¯é€šè¿‡")
                logger.info(f"   âœ… é…å¯¹éªŒè¯é€šè¿‡")
        except Exception as e:
            print(f"    âš ï¸ éªŒè¯å¤±è´¥ï¼Œç»§ç»­æœç´¢: {str(e)}")
            logger.warning(f"é…å¯¹éªŒè¯å¼‚å¸¸: {str(e)}")
        # ========== éªŒè¯ç»“æŸ ==========

        # ========== ğŸ“š åˆå§‹åŒ–å¸¦çŸ¥è¯†åº“çš„è¯„åˆ†å™¨ ==========
        try:
            from core.result_scorer import IntelligentResultScorer

            # æ£€æŸ¥ç¼“å­˜ä¸­æ˜¯å¦å·²æœ‰è¯¥å›½å®¶çš„è¯„åˆ†å™¨
            country_code = request.country.upper()
            if country_code not in self._scorer_cache:
                # åˆ›å»ºå¸¦çŸ¥è¯†åº“çš„è¯„åˆ†å™¨ï¼ˆä¼ é€’ log_collectorï¼‰
                self.result_scorer = IntelligentResultScorer(
                    country_code=country_code,
                    log_collector=self.log_collector
                )
                self._scorer_cache[country_code] = self.result_scorer
                logger.info(f"[ğŸ“š çŸ¥è¯†åº“] å·²åŠ è½½ {country_code} è¯„åˆ†å™¨ï¼ˆå¸¦çŸ¥è¯†åº“å’Œæ—¥å¿—è®°å½•ï¼‰")
                print(f"    [âœ… çŸ¥è¯†åº“] å·²åŠ è½½ {country_code} æœç´¢çŸ¥è¯†åº“")
            else:
                # ä½¿ç”¨ç¼“å­˜çš„è¯„åˆ†å™¨ï¼ˆæ›´æ–°å…¶ log_collectorï¼‰
                self.result_scorer = self._scorer_cache[country_code]
                # æ›´æ–° log_collectorï¼ˆå¯èƒ½æ˜¯æ–°çš„æœç´¢è¯·æ±‚ï¼‰
                if self.log_collector:
                    self.result_scorer.log_collector = self.log_collector
                logger.debug(f"[ğŸ“š çŸ¥è¯†åº“] ä½¿ç”¨ç¼“å­˜çš„ {country_code} è¯„åˆ†å™¨")

        except Exception as e:
            # å¦‚æœçŸ¥è¯†åº“åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨ä¸å¸¦çŸ¥è¯†åº“çš„è¯„åˆ†å™¨
            logger.warning(f"[ğŸ“š çŸ¥è¯†åº“] åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨è¯„åˆ†å™¨: {str(e)}")
            self.result_scorer = self.result_scorer_without_kb
            # ä¹Ÿæ›´æ–°å¤‡ç”¨è¯„åˆ†å™¨çš„ log_collector
            if self.log_collector:
                self.result_scorer.log_collector = self.log_collector
        # ========== è¯„åˆ†å™¨åˆå§‹åŒ–ç»“æŸ ==========

        try:
            # Step 0: è·å–æœç´¢ç­–ç•¥ï¼ˆå·²è·³è¿‡LLMç”Ÿæˆï¼Œç›´æ¥ä½¿ç”¨é»˜è®¤ç­–ç•¥ï¼‰
            # [ä¼˜åŒ–] 2026-01-20: è·³è¿‡LLMç­–ç•¥ç”Ÿæˆï¼Œç›´æ¥ä½¿ç”¨é»˜è®¤è§„åˆ™ç­–ç•¥ï¼Œæå‡å“åº”é€Ÿåº¦
            step0_start = time.time()
            logger.info(f"[æ­¥éª¤ 0] è·å–æœç´¢ç­–ç•¥ï¼ˆä½¿ç”¨é»˜è®¤è§„åˆ™ç­–ç•¥ï¼‰...")
            print(f"[æ­¥éª¤ 0] è·å–æœç´¢ç­–ç•¥ï¼ˆå·²è·³è¿‡LLMç”Ÿæˆï¼Œä½¿ç”¨é»˜è®¤è§„åˆ™ç­–ç•¥ï¼‰...")

            # ç›´æ¥ä½¿ç”¨é»˜è®¤ç­–ç•¥ï¼Œè·³è¿‡LLMç”Ÿæˆ
            from search_strategy_agent import SearchStrategy
            country_config = self.config_manager.get_country_config(request.country.upper())
            language_code = country_config.language_code if country_config else "en"
            domains = country_config.domains[:5] if country_config else []

            # æ„å»ºé»˜è®¤æœç´¢è¯ï¼ˆè§„åˆ™ç”Ÿæˆï¼Œä¸ä½¿ç”¨LLMï¼‰
            default_query = f"{request.subject} {request.grade} playlist"
            if request.semester:
                default_query += f" semester {request.semester}"

            # ç”Ÿæˆå¤šä¸ªæ’­æ”¾åˆ—è¡¨ä¼˜å…ˆçš„æœç´¢æŸ¥è¯¢ï¼ˆ7ä¸ªé«˜åº¦å·®å¼‚åŒ–çš„å˜ä½“ï¼‰
            playlist_keywords_map = {
                "id": ["playlist", "complete course", "full series", "koleksi lengkap", "kursus lengkap"],
                "en": ["playlist", "complete course", "full series", "video collection"],
                "zh": ["æ’­æ”¾åˆ—è¡¨", "å®Œæ•´è¯¾ç¨‹", "ç³»åˆ—æ•™ç¨‹"],
                "ms": ["playlist", "kursus lengkap", "siri lengkap"],
                "ar": ["Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªØ´ØºÙŠÙ„", "Ø¯ÙˆØ±Ø© ÙƒØ§Ù…Ù„Ø©"],
                "ru": ["Ğ¿Ğ»ĞµĞ¹Ğ»Ğ¸ÑÑ‚", "Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ ĞºÑƒÑ€Ñ"],
            }
            playlist_keywords = playlist_keywords_map.get(language_code, ["playlist", "complete course"])

            # ç”Ÿæˆ7ä¸ªå·®å¼‚åŒ–æœç´¢æŸ¥è¯¢
            search_queries = [
                f"site:youtube.com {request.subject} {request.grade} {playlist_keywords[0]}",
                f"{request.subject} {request.grade} {playlist_keywords[1] if len(playlist_keywords) > 1 else 'complete course'}",
                f"site:youtube.com \"{request.subject}\" \"{request.grade}\" playlist",
                f"{request.subject} {request.grade} video lesson chapter",
                f"{request.grade} {request.subject} full course curriculum",
                f"{request.subject} for {request.grade} students tutorial",
                f"{request.grade} {request.subject} learning series complete"
            ]

            # åˆ›å»ºç­–ç•¥å¯¹è±¡ï¼ˆä¸ä½¿ç”¨LLMï¼‰
            strategy = SearchStrategy(
                search_language=language_code,
                use_chinese_search_engine=(request.country.upper() == "CN"),
                platforms=["youtube.com"] + domains[:3],
                search_queries=search_queries,
                priority_domains=domains[:5],
                notes=f"é»˜è®¤æœç´¢ç­–ç•¥ï¼ˆè§„åˆ™ç”Ÿæˆï¼‰ï¼šä½¿ç”¨{language_code}è¯­è¨€ï¼Œä¼˜å…ˆæœç´¢YouTubeæ’­æ”¾åˆ—è¡¨ï¼ˆ7ä¸ªå·®å¼‚åŒ–æŸ¥è¯¢ï¼‰"
            )

            print(f"    [âœ… ç­–ç•¥] æœç´¢è¯­è¨€: {strategy.search_language}")
            print(f"    [âœ… ç­–ç•¥] ä½¿ç”¨ä¸­æ–‡æœç´¢å¼•æ“: {strategy.use_chinese_search_engine}")
            print(f"    [âœ… ç­–ç•¥] å¹³å°åˆ—è¡¨: {', '.join(strategy.platforms[:5])}")
            print(f"    [âœ… ç­–ç•¥] ä¼˜å…ˆåŸŸå: {', '.join(strategy.priority_domains[:5])}")
            print(f"    [âš¡ ä¼˜åŒ–] è·³è¿‡LLMç”Ÿæˆï¼Œä½¿ç”¨é»˜è®¤è§„åˆ™ç­–ç•¥ï¼Œæå‡å“åº”é€Ÿåº¦")
            
            # Step 1: ä½¿ç”¨æœç´¢ç­–ç•¥ä¸­çš„æœç´¢è¯
            print(f"\n[æ­¥éª¤ 1] ä½¿ç”¨æœç´¢ç­–ç•¥ç”Ÿæˆçš„é«˜è´¨é‡æœç´¢è¯...")

            # ç›´æ¥ä½¿ç”¨ç­–ç•¥ç”Ÿæˆçš„æœç´¢è¯ï¼ˆå·²åŒ…å«å¤šä¸ªå˜ä½“ï¼ŒåŒ…æ‹¬playlistç­‰ä¼˜åŒ–ï¼‰
            if strategy.search_queries:
                query = strategy.search_queries[0]
                print(f"    [âœ… ä½¿ç”¨ç­–ç•¥æœç´¢è¯] \"{query}\"")
                print(f"    [âœ… ä¼˜åŠ¿] ç­–ç•¥å·²ç”Ÿæˆ {len(strategy.search_queries)} ä¸ªé«˜è´¨é‡å˜ä½“")
            else:
                # é™çº§ï¼šå¦‚æœç­–ç•¥ä¸­æ²¡æœ‰æœç´¢è¯ï¼Œä½¿ç”¨è§„åˆ™ç”Ÿæˆ
                query = self._generate_fallback_query(request)
                print(f"    [âœ… ä½¿ç”¨è§„åˆ™ç”Ÿæˆæœç´¢è¯] \"{query}\"")
                strategy.search_queries = [query]  # å°†ç”Ÿæˆçš„æŸ¥è¯¢æ·»åŠ åˆ°ç­–ç•¥ä¸­

            # æ˜¾ç¤ºæ‰€æœ‰æœç´¢è¯å˜ä½“
            if len(strategy.search_queries) > 1:
                print(f"    [ğŸ¯ æ’­æ”¾åˆ—è¡¨ä¼˜åŒ–] å…±æœ‰ {len(strategy.search_queries)} ä¸ªæœç´¢è¯å˜ä½“")
                for i, q in enumerate(strategy.search_queries, 1):
                    is_playlist_query = any(kw in q.lower() for kw in ['playlist', 'complete course', 'full series', 'koleksi', 'kursus lengkap', 'æ’­æ”¾åˆ—è¡¨', 'å®Œæ•´è¯¾ç¨‹', 'ç³»åˆ—'])
                    marker = "ğŸ [æ’­æ”¾åˆ—è¡¨]" if is_playlist_query else "ğŸ“¹ [å¸¸è§„]"
                    print(f"      {marker} {i}. \"{q}\"")

            # Step 2: æ‰§è¡Œæ··åˆæœç´¢ï¼ˆé€šç”¨æœç´¢ + æœ¬åœ°å®šå‘æœç´¢ï¼‰
            print(f"\n[æ­¥éª¤ 2] æ‰§è¡Œæ··åˆæœç´¢...")

            # ========== å¹¶è¡Œæœç´¢å®ç° (æ–°ç‰ˆæœ¬) ==========
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨å¹¶è¡Œæœç´¢ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
            use_parallel_search = os.getenv("ENABLE_PARALLEL_SEARCH", "true").lower() == "true"

            if use_parallel_search:
                print(f"    [âš¡ æ¨¡å¼] ä½¿ç”¨å¹¶è¡Œæœç´¢")

                # å‡†å¤‡å›½å®¶é…ç½®
                country_code_upper = request.country.upper()
                country_config = self.config_manager.get_country_config(country_code_upper)

                # ä½¿ç”¨ç­–ç•¥ä¸­çš„ä¼˜å…ˆåŸŸåï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é…ç½®ä¸­çš„åŸŸå
                if strategy.priority_domains:
                    selected_domains = strategy.priority_domains[:5]
                elif country_config and country_config.domains:
                    selected_domains = country_config.domains[:5]
                else:
                    selected_domains = []

                # æ„å»ºå¹¶è¡Œæœç´¢ä»»åŠ¡åˆ—è¡¨
                search_tasks = []

                # ä½¿ç”¨ç­–ç•¥ä¸­çš„å¤šä¸ªæœç´¢è¯è¿›è¡Œæœç´¢ï¼ˆä¼˜å…ˆæ’­æ”¾åˆ—è¡¨ç›¸å…³æŸ¥è¯¢ï¼‰
                # âœ¨ å–å‰5ä¸ªæœç´¢è¯ï¼Œå……åˆ†åˆ©ç”¨æŸ¥è¯¢å¤šæ ·æ€§ï¼ˆåŸæ¥åªå–3ä¸ªï¼‰
                queries_to_use = strategy.search_queries[:5] if len(strategy.search_queries) >= 5 else strategy.search_queries
                print(f"    [ğŸ¯ å¤šæŸ¥è¯¢æœç´¢] å°†ä½¿ç”¨ {len(queries_to_use)} ä¸ªé«˜åº¦å·®å¼‚åŒ–çš„æœç´¢è¯è¿›è¡Œæœç´¢")

                # Tavily/Metasoæœç´¢ - å¯¹æ¯ä¸ªæŸ¥è¯¢éƒ½æ‰§è¡Œï¼ˆ5æ¬¡ï¼‰âœ… ä¸»è¦å¼•æ“ï¼ˆé«˜è´¨é‡ï¼Œavg 4.65ï¼‰
                # âœ¨ å¢åŠ æŸ¥è¯¢æ•°é‡ï¼Œæé«˜ç»“æœå¤šæ ·æ€§
                for query_idx, search_query in enumerate(queries_to_use, 1):
                    is_playlist_focused = any(kw in search_query.lower() for kw in ['playlist', 'complete course', 'full series', 'koleksi', 'kursus lengkap', 'æ’­æ”¾åˆ—è¡¨', 'å®Œæ•´è¯¾ç¨‹', 'ç³»åˆ—'])
                    query_type = "æ’­æ”¾åˆ—è¡¨" if is_playlist_focused else "å¸¸è§„"

                    search_tasks.append({
                        'name': f'Tavily/Metasoæœç´¢ [{query_type}] #{query_idx}',
                        'query': search_query,  # ä½¿ç”¨ç‰¹å®šçš„æœç´¢è¯
                        'func': self.llm_client.search,  # å†…éƒ¨ä¼šæ ¹æ®å…è´¹é¢åº¦ä¼˜å…ˆé€‰æ‹©Tavilyæˆ–Metaso
                        'engine_name': 'Tavily/Metaso',
                        'max_results': 30,  # å¢åŠ åˆ°30ï¼Œè·å–æ›´å¤šç»“æœ
                        'include_domains': None
                    })

                # Googleæœç´¢ - åªä½¿ç”¨ç¬¬ä¸€ä¸ªæŸ¥è¯¢ï¼ˆ1æ¬¡ï¼‰âœ… è¾…åŠ©å¼•æ“ï¼ˆä½è´¨é‡ï¼Œavg 1.50ï¼‰
                if self.google_search_enabled and len(queries_to_use) > 0:
                    search_tasks.append({
                        'name': 'Googleæœç´¢',
                        'query': queries_to_use[0],  # åªç”¨ç¬¬ä¸€ä¸ªæŸ¥è¯¢
                        'func': self.google_hunter.search,
                        'engine_name': 'Google',
                        'max_results': 20,  # å¢åŠ åˆ°20
                        'include_domains': None
                    })

                # ä»»åŠ¡3: ç™¾åº¦æœç´¢ï¼ˆå¦‚æœå¯ç”¨ä¸”éœ€è¦ä¸­æ–‡æœç´¢ï¼‰
                if strategy.use_chinese_search_engine and self.baidu_search_enabled and len(queries_to_use) > 0:
                    search_tasks.append({
                        'name': 'ç™¾åº¦æœç´¢',
                        'query': queries_to_use[0],  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæŸ¥è¯¢
                        'func': self.baidu_hunter.search,
                        'engine_name': 'Baidu',
                        'max_results': 30,  # å¢åŠ åˆ°30
                        'include_domains': None
                    })

                # ä»»åŠ¡4: æœ¬åœ°å®šå‘æœç´¢ï¼ˆå¦‚æœæœ‰åŸŸåé…ç½®ï¼‰
                if selected_domains:
                    # æ„å»ºæœ¬åœ°æœç´¢æŸ¥è¯¢
                    base_query = query.replace("playlist", "").replace("Playlist", "").strip()

                    # ä»é…ç½®è¯»å–æœ¬åœ°åŒ–å…³é”®è¯
                    try:
                        search_config = self.app_config.get_search_config()
                        localization_keywords = search_config.get('localization', {})
                        country_language = country_config.language_code if country_config else "en"
                        local_keyword = localization_keywords.get(country_language, "Video lesson")
                        logger.debug(f"ä»é…ç½®è¯»å–æœ¬åœ°åŒ–å…³é”®è¯: {country_language} -> {local_keyword}")
                    except Exception as e:
                        # é™çº§ä¸ºç¡¬ç¼–ç æ˜ å°„
                        logger.warning(f"ä»é…ç½®è¯»å–æœ¬åœ°åŒ–å…³é”®è¯å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨ç¡¬ç¼–ç æ˜ å°„")
                        language_map = {
                            "id": "Video pembelajaran",
                            "en": "Video lesson",
                            "zh": "æ•™å­¦è§†é¢‘",
                            "ms": "Video pembelajaran",
                            "ar": "ÙÙŠØ¯ÙŠÙˆ ØªØ¹Ù„ÙŠÙ…ÙŠ",
                            "ru": "Ğ’Ğ¸Ğ´ĞµĞ¾ ÑƒÑ€Ğ¾Ğº",
                        }
                        country_language = country_config.language_code if country_config else "en"
                        local_keyword = language_map.get(country_language, "Video lesson")

                    # æ„å»ºçº¯å‡€æŸ¥è¯¢
                    clean_query_parts = []
                    if request.subject:
                        clean_query_parts.append(request.subject)
                    if request.grade:
                        clean_query_parts.append(request.grade)
                    if request.semester:
                        clean_query_parts.append(request.semester)

                    local_base_query = " ".join(clean_query_parts) if clean_query_parts else base_query
                    local_query = f"{local_base_query} {local_keyword}".strip()

                    search_tasks.append({
                        'name': f'æœ¬åœ°å®šå‘æœç´¢({country_code_upper})',
                        'func': self.llm_client.search,
                        'engine_name': f'Local-{country_code_upper}',
                        'max_results': 20,  # å¢åŠ åˆ°20
                        'include_domains': selected_domains
                    })

                # æ‰§è¡Œå¹¶è¡Œæœç´¢ï¼ˆä¼ é€’ country_code ç”¨äºå…è´¹é¢åº¦ä¼˜å…ˆç­–ç•¥ï¼‰
                parallel_results = self._parallel_search(query, search_tasks, timeout=30, country_code=request.country)

                # åˆå¹¶æ‰€æœ‰ç»“æœ
                search_results_a = []
                search_results_b = []

                for task_name, results in parallel_results.items():
                    if 'æœ¬åœ°' in task_name or 'Local' in task_name:
                        search_results_b.extend(results)
                    else:
                        search_results_a.extend(results)

                # æ˜¾ç¤ºç»“æœè¯¦æƒ…
                if search_results_a:
                    print(f"    [ğŸ“‹ é€šç”¨æœç´¢ç»“æœ] å…± {len(search_results_a)} ä¸ª")
                    for idx, result in enumerate(search_results_a[:3], 1):
                        print(f"        {idx}. {result.title[:60]}...")

                if search_results_b:
                    print(f"    [ğŸ“‹ æœ¬åœ°æœç´¢ç»“æœ] å…± {len(search_results_b)} ä¸ª")
                    for idx, result in enumerate(search_results_b[:3], 1):
                        print(f"        {idx}. {result.title[:60]}...")

            else:
                # ========== ä¸²è¡Œæœç´¢å®ç° (åŸç‰ˆæœ¬) ==========
                print(f"    [ğŸ”„ æ¨¡å¼] ä½¿ç”¨ä¸²è¡Œæœç´¢")

                # æœç´¢ A: é€šç”¨æœç´¢ï¼ˆä¸»è¦è¦†ç›– YouTubeï¼‰
            # å¦‚æœç­–ç•¥è¦æ±‚ä½¿ç”¨ä¸­æ–‡æœç´¢å¼•æ“ï¼Œä¸”ç™¾åº¦æœç´¢å·²é…ç½®ï¼Œåˆ™ä½¿ç”¨ç™¾åº¦æœç´¢
            if strategy.use_chinese_search_engine and self.baidu_search_enabled:
                print(f"    [ğŸŒ ç­–ç•¥] æ£€æµ‹åˆ°éœ€è¦ä½¿ç”¨ä¸­æ–‡æœç´¢å¼•æ“ï¼Œä½¿ç”¨ç™¾åº¦æœç´¢")
                print(f"    [ğŸ” æœç´¢A-ç™¾åº¦æœç´¢] æŸ¥è¯¢: \"{query}\"")
                print(f"    [âš™ï¸ å‚æ•°] max_results=30")
                try:
                    baidu_results = self.baidu_hunter.search(query, max_results=30)
                    # è½¬æ¢ä¸ºSearchResultå¯¹è±¡
                    search_results_a = []
                    for item in baidu_results:
                        search_results_a.append(SearchResult(
                            title=item.title,
                            url=item.url,
                            snippet=item.snippet,
                            source="ç™¾åº¦æœç´¢",
                            search_engine="Baidu"
                        ))
                    print(f"    [âœ… æœç´¢A-ç™¾åº¦] æ‰¾åˆ° {len(search_results_a)} ä¸ªç»“æœ")
                except Exception as e:
                    print(f"    [âŒ é”™è¯¯] ç™¾åº¦æœç´¢å¤±è´¥: {str(e)}")
                    # é™çº§åˆ° Google æœç´¢ï¼ˆå¦‚æœå¯ç”¨ï¼‰æˆ– Tavily
                    if self.google_search_enabled:
                        print(f"    [ğŸ”„ é™çº§] åˆ‡æ¢åˆ° Google æœç´¢...")
                        try:
                            google_results = self.google_hunter.search(query, max_results=30, country_code=country_code_upper)
                            search_results_a = []
                            for item in google_results:
                                search_results_a.append(SearchResult(
                                    title=item.title,
                                    url=item.url,
                                    snippet=item.snippet,
                                    source="Googleæœç´¢",
                                    search_engine="Google"
                                ))
                            print(f"    [âœ… æœç´¢A-Google] æ‰¾åˆ° {len(search_results_a)} ä¸ªç»“æœ")
                        except Exception as e2:
                            print(f"    [âŒ é”™è¯¯] Google æœç´¢ä¹Ÿå¤±è´¥: {str(e2)}")
                            print(f"    [ğŸ”„ é™çº§] åˆ‡æ¢åˆ° Tavily æœç´¢...")
                            search_results_a = self.llm_client.search(query, max_results=30, country_code=country_code_upper)
                            print(f"    [âœ… æœç´¢A-Tavily] æ‰¾åˆ° {len(search_results_a)} ä¸ªç»“æœ")
                    else:
                        print(f"    [ğŸ”„ é™çº§] åˆ‡æ¢åˆ°Tavilyæœç´¢...")
                        search_results_a = self.llm_client.search(query, max_results=30, country_code=country_code_upper)
                        print(f"    [âœ… æœç´¢A-Tavily] æ‰¾åˆ° {len(search_results_a)} ä¸ªç»“æœ")
            else:
                if strategy.use_chinese_search_engine:
                    print(f"    [ğŸŒ ç­–ç•¥] æ£€æµ‹åˆ°éœ€è¦ä½¿ç”¨ä¸­æ–‡æœç´¢å¼•æ“ï¼ˆå¦‚ç™¾åº¦ã€æœç‹—ï¼‰")
                    if not self.baidu_search_enabled:
                        print(f"    [âš ï¸ æ³¨æ„] ç™¾åº¦æœç´¢æœªé…ç½®ï¼Œä½¿ç”¨å…¶ä»–æœç´¢å¼•æ“ï¼Œå¯èƒ½æ— æ³•å®Œå…¨è¦†ç›–ä¸­æ–‡å†…å®¹")
                    else:
                        print(f"    [â„¹ï¸] ç™¾åº¦æœç´¢å·²é…ç½®ä½†æœªå¯ç”¨ï¼ˆå¯èƒ½ç­–ç•¥åˆ¤æ–­ä¸éœ€è¦ï¼‰")
                
                # å¯¹äºéä¸­æ–‡æœç´¢ï¼Œä¼˜å…ˆä½¿ç”¨ Tavilyï¼ˆé«˜è´¨é‡ï¼Œavg 4.65ï¼‰ï¼ŒGoogleä½œä¸ºé™çº§é€‰é¡¹ï¼ˆä½è´¨é‡ï¼Œavg 1.50ï¼‰
                print(f"    [ğŸ” æœç´¢A-Tavily] æŸ¥è¯¢: \"{query}\"")
                print(f"    [âš™ï¸ å‚æ•°] max_results=30")
                try:
                    # ğŸ”¥ ä»llm_client.search()è¿”å›çš„Dictæˆ–SearchResultè½¬æ¢ä¸ºSearchResult
                    search_dicts = self.llm_client.search(query, max_results=30, country_code=country_code_upper)
                    search_results_a = []
                    for item in search_dicts:
                        # [ä¿®å¤] 2026-01-20: å¤„ç†å­—å…¸å’ŒSearchResultå¯¹è±¡ä¸¤ç§ç±»å‹
                        if isinstance(item, dict):
                            # å¦‚æœæ˜¯å­—å…¸ï¼Œä½¿ç”¨.get()æ–¹æ³•
                            search_engine = item.get('search_engine', 'Tavily')
                            search_results_a.append(SearchResult(
                                title=item.get('title', ''),
                                url=item.get('url', ''),
                                snippet=item.get('snippet', ''),
                                source=item.get('source', 'Tavily'),
                                search_engine=search_engine
                            ))
                        else:
                            # å¦‚æœæ˜¯SearchResultå¯¹è±¡ï¼Œç›´æ¥ä½¿ç”¨å±æ€§è®¿é—®
                            search_results_a.append(item)
                    print(f"    [âœ… æœç´¢A-Tavily] æ‰¾åˆ° {len(search_results_a)} ä¸ªç»“æœ")
                except Exception as e:
                    print(f"    [âŒ é”™è¯¯] Tavily æœç´¢å¤±è´¥: {str(e)}")
                    # é™çº§åˆ° Google æœç´¢ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                    if self.google_search_enabled:
                        print(f"    [ğŸ”„ é™çº§] åˆ‡æ¢åˆ° Google æœç´¢...")
                        try:
                            google_results = self.google_hunter.search(query, max_results=30, country_code=country_code_upper)
                            search_results_a = []
                            for item in google_results:
                                search_results_a.append(SearchResult(
                                    title=item.title,
                                    url=item.url,
                                    snippet=item.snippet,
                                    source="Googleæœç´¢",
                                    search_engine="Google"
                                ))
                            print(f"    [âœ… æœç´¢A-Google] æ‰¾åˆ° {len(search_results_a)} ä¸ªç»“æœ")
                        except Exception as e2:
                            print(f"    [âŒ é”™è¯¯] Google æœç´¢ä¹Ÿå¤±è´¥: {str(e2)}")
                            search_results_a = []
                    else:
                        print(f"    [âŒ é”™è¯¯] Google æœç´¢æœªé…ç½®ï¼Œæ— æ³•é™çº§")
                        search_results_a = []
            if search_results_a:
                print(f"    [ğŸ“‹ æœç´¢Aç»“æœè¯¦æƒ…]")
                for idx, result in enumerate(search_results_a[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ª
                    print(f"        {idx}. {result.title[:60]}...")
                    print(f"           URL: {result.url}")
                if len(search_results_a) > 5:
                    print(f"        ... è¿˜æœ‰ {len(search_results_a) - 5} ä¸ªç»“æœ")
            
            # æœç´¢ B: æœ¬åœ°å®šå‘æœç´¢ï¼ˆå¦‚æœå›½å®¶é…ç½®ä¸­æœ‰åŸŸååˆ—è¡¨ï¼‰
            print(f"\n    [ğŸ” æœç´¢B-æœ¬åœ°] å¼€å§‹æ£€æŸ¥å›½å®¶é…ç½®...")
            search_results_b = []
            country_code_upper = request.country.upper()
            print(f"    [ğŸ“‹ è¾“å…¥] å›½å®¶ä»£ç : {country_code_upper}")
            country_config = self.config_manager.get_country_config(country_code_upper)
            
            if country_config:
                print(f"    [âœ… é…ç½®] æˆåŠŸè¯»å–å›½å®¶é…ç½®: {country_config.country_name}")
                print(f"    [ğŸ“‹ é…ç½®] åŸŸåæ•°é‡: {len(country_config.domains)}")
                if country_config.domains:
                    print(f"    [ğŸ“‹ é…ç½®] åŸŸååˆ—è¡¨:")
                    for idx, domain in enumerate(country_config.domains, 1):
                        print(f"        {idx}. {domain}")
            else:
                print(f"    [âš ï¸ é…ç½®] å›½å®¶é…ç½®ä¸å­˜åœ¨ï¼Œè·³è¿‡æœ¬åœ°æœç´¢")
            
            # ä½¿ç”¨ç­–ç•¥ä¸­çš„ä¼˜å…ˆåŸŸåï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é…ç½®ä¸­çš„åŸŸå
            if strategy.priority_domains:
                selected_domains = strategy.priority_domains[:5]
                print(f"\n    [âœ… ç­–ç•¥] ä½¿ç”¨ç­–ç•¥ä¸­çš„ä¼˜å…ˆåŸŸå: {', '.join(selected_domains)}")
            elif country_config and country_config.domains:
                selected_domains = country_config.domains[:5]
                print(f"\n    [âœ… é…ç½®] ä½¿ç”¨é…ç½®ä¸­çš„åŸŸå: {', '.join(selected_domains)}")
            else:
                selected_domains = []
            
            if selected_domains:
                # ä½¿ç”¨ç­–ç•¥ä¸­çš„ä¼˜å…ˆåŸŸåæˆ–é…ç½®ä¸­çš„åŸŸå
                print(f"\n    [ğŸ”§ å‡†å¤‡] å‡†å¤‡å¹³å°ç‰¹å®šæœç´¢...")
                print(f"    [ğŸ“‹ åŸŸååˆ—è¡¨] å…± {len(selected_domains)} ä¸ªåŸŸå:")
                for idx, domain in enumerate(selected_domains, 1):
                    print(f"        {idx}. {domain}")
                
                if selected_domains:
                    
                    # æ„å»ºæœ¬åœ°æœç´¢è¯ï¼ˆç§»é™¤playlistå…³é”®è¯ï¼Œä½¿ç”¨æœ¬åœ°åŒ–è¯æ±‡ï¼‰
                    print(f"\n    [ğŸ”§ æ„å»º] æ„å»ºæœ¬åœ°æœç´¢è¯...")
                    print(f"    [ğŸ“‹ åŸå§‹æŸ¥è¯¢] \"{query}\"")
                    
                    # ç§»é™¤playlistå…³é”®è¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                    base_query = query.replace("playlist", "").replace("Playlist", "").strip()
                    
                    # æ ¹æ®è¯­è¨€æ·»åŠ æœ¬åœ°åŒ–å…³é”®è¯
                    language_map = {
                        "id": "Video pembelajaran",  # å°å°¼è¯­
                        "en": "Video lesson",  # è‹±è¯­
                        "zh": "æ•™å­¦è§†é¢‘",  # ä¸­æ–‡
                        "ms": "Video pembelajaran",  # é©¬æ¥è¯­
                        "ar": "ÙÙŠØ¯ÙŠÙˆ ØªØ¹Ù„ÙŠÙ…ÙŠ",  # é˜¿æ‹‰ä¼¯è¯­
                        "ru": "Ğ’Ğ¸Ğ´ĞµĞ¾ ÑƒÑ€Ğ¾Ğº",  # ä¿„è¯­
                    }
                    country_language = country_config.language_code if country_config else "en"
                    local_keyword = language_map.get(country_language, "Video lesson")
                    
                    # æ„å»ºçº¯å‡€çš„æœç´¢è¯ï¼ˆå­¦ç§‘ + å¹´çº§ + å­¦æœŸï¼‰
                    clean_query_parts = []
                    if request.subject:
                        clean_query_parts.append(request.subject)
                    if request.grade:
                        clean_query_parts.append(request.grade)
                    if request.semester:
                        clean_query_parts.append(request.semester)
                    
                    # ä½¿ç”¨çº¯å‡€æŸ¥è¯¢ + æœ¬åœ°åŒ–å…³é”®è¯
                    local_base_query = " ".join(clean_query_parts) if clean_query_parts else base_query
                    local_base_query = f"{local_base_query} {local_keyword}".strip()
                    
                    # æ·»åŠ site:è¯­æ³•åˆ°æŸ¥è¯¢æœ«å°¾
                    domain_site_clause = " OR ".join([f"site:{domain}" for domain in selected_domains])
                    local_query = f"{local_base_query} ({domain_site_clause})"
                    
                    print(f"    [ğŸ”§ å¤„ç†] ç§»é™¤playlistå…³é”®è¯åçš„åŸºç¡€æŸ¥è¯¢: \"{base_query}\"")
                    print(f"    [ğŸ”§ å¤„ç†] æœ¬åœ°åŒ–å…³é”®è¯: \"{local_keyword}\"")
                    print(f"    [ğŸ”§ å¤„ç†] çº¯å‡€æŸ¥è¯¢: \"{local_base_query}\"")
                    print(f"    [ğŸ”§ å¤„ç†] æ·»åŠ site:è¯­æ³•åçš„æœ€ç»ˆæŸ¥è¯¢: \"{local_query}\"")
                    print(f"\n    [ğŸ” æœç´¢B-æœ¬åœ°] æŸ¥è¯¢: \"{local_query}\"")
                    print(f"    [ğŸ“ ç›®æ ‡å¹³å°] {', '.join(selected_domains)}")
                    print(f"    [âš™ï¸ å‚æ•°] max_results=10, include_domains={selected_domains}")
                    search_results_b = self.llm_client.search(local_query, max_results=10, include_domains=selected_domains)
                    print(f"    [âœ… æœç´¢B] æ‰¾åˆ° {len(search_results_b)} ä¸ªç»“æœ")
                    if search_results_b:
                        print(f"    [ğŸ“‹ æœç´¢Bç»“æœè¯¦æƒ…]")
                        for idx, result in enumerate(search_results_b, 1):
                            print(f"        {idx}. {result.title[:60]}...")
                            print(f"           URL: {result.url}")
                            # æ£€æŸ¥ URL æ˜¯å¦æ¥è‡ªç›®æ ‡å¹³å°
                            url_lower = result.url.lower()
                            matched_platform = None
                            for domain in selected_domains:
                                if domain.lower() in url_lower:
                                    matched_platform = domain
                                    break
                            if matched_platform:
                                print(f"           âœ… åŒ¹é…å¹³å°: {matched_platform}")
                            else:
                                print(f"           âš ï¸ æœªåŒ¹é…åˆ°ç›®æ ‡å¹³å°")
                    else:
                        print(f"    [âš ï¸ æœç´¢B] æœªæ‰¾åˆ°ä»»ä½•ç»“æœ")
                else:
                    print(f"    [âš ï¸ é…ç½®] åŸŸååˆ—è¡¨ä¸ºç©ºï¼Œè·³è¿‡æœ¬åœ°æœç´¢")
            
            # åˆå¹¶ç»“æœå¹¶å»é‡ï¼ˆåŸºäº URLï¼‰
            print(f"\n    [ğŸ”§ åˆå¹¶] å¼€å§‹åˆå¹¶å’Œå»é‡...")
            all_results = search_results_a + search_results_b
            print(f"    [ğŸ“Š åˆå¹¶å‰] é€šç”¨: {len(search_results_a)} ä¸ª, æœ¬åœ°: {len(search_results_b)} ä¸ª, æ€»è®¡: {len(all_results)} ä¸ª")
            
            seen_urls = set()
            unique_results = []
            duplicate_count = 0
            
            for result in all_results:
                if result.url not in seen_urls:
                    seen_urls.add(result.url)
                    unique_results.append(result)
                else:
                    duplicate_count += 1
                    print(f"        [-] å»é‡: {result.url[:80]}...")
            
            search_results = unique_results
            print(f"    [ğŸ“Š åˆå¹¶å] å»é‡: {duplicate_count} ä¸ª, ä¿ç•™: {len(search_results)} ä¸ª")
            print(f"    [ğŸ“Š ç»Ÿè®¡] é€šç”¨: {len(search_results_a)}, æœ¬åœ°: {len(search_results_b)}, æœ€ç»ˆ: {len(search_results)}")
            
            # Step 3: è¯„ä¼°ç»“æœ
            step3_start = time.time()
            logger.info(f"[æ­¥éª¤ 3] è¯„ä¼°ç»“æœ... (å†…å­˜: {self._get_memory_usage()})")
            print(f"\n[æ­¥éª¤ 3] è¯„ä¼°ç»“æœ...")
            evaluated_results = self.evaluator.evaluate_results(
                search_results,
                country=request.country,
                grade=request.grade,
                subject=request.subject
            )
            step3_elapsed = time.time() - step3_start
            logger.info(f"   âœ… æ­¥éª¤3å®Œæˆ: {step3_elapsed:.2f}ç§’, {len(evaluated_results)}ä¸ªç»“æœ (å†…å­˜: {self._get_memory_usage()})")

            # Step 3.5: æ™ºèƒ½è¯„åˆ†å’Œç”Ÿæˆæ¨èç†ç”±
            step35_start = time.time()
            logger.info(f"[æ­¥éª¤ 3.5] æ™ºèƒ½è¯„åˆ†å¼€å§‹... (å†…å­˜: {self._get_memory_usage()})")
            print(f"\n[æ­¥éª¤ 3.5] æ™ºèƒ½è¯„åˆ†...")

            # å¿«é€Ÿè·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯ï¼ˆç”¨äºè¯„åˆ†ï¼‰
            def get_playlist_info_fast(url: str) -> Optional[Dict[str, Any]]:
                """å¿«é€Ÿè·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯ï¼ˆè§†é¢‘æ•°é‡å’Œæ€»æ—¶é•¿ï¼‰"""
                if not url or 'list=' not in url:
                    return None

                try:
                    import yt_dlp

                    ydl_opts = {
                        'quiet': True,
                        'no_warnings': True,
                        'extract_flat': True,  # å¿«é€Ÿæå–
                        'http_headers': {
                            'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X)',
                        },
                        'extractor_args': {
                            'youtube': {
                                'player_client': ['ios'],
                            }
                        },
                    }

                    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                        info = ydl.extract_info(url, download=False)

                    if not info:
                        return None

                    entries = info.get('entries', [])
                    if not entries:
                        return None

                    video_count = len(entries)

                    # è®¡ç®—æ€»æ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰
                    total_duration_seconds = 0
                    for entry in entries:
                        duration = entry.get('duration', 0)
                        if duration:
                            total_duration_seconds += duration

                    total_duration_minutes = total_duration_seconds / 60 if total_duration_seconds > 0 else 0

                    return {
                        'video_count': video_count,
                        'total_duration_minutes': total_duration_minutes
                    }

                except Exception as e:
                    logger.warning(f"è·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯å¤±è´¥: {str(e)[:100]}")
                    return None

            # ğŸš€ å¹¶å‘è·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯ï¼ˆä¼˜åŒ–æ€§èƒ½ï¼‰
            print(f"\n[æ­¥éª¤ 3.5.1] å¹¶å‘è·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯...")

            # ç¬¬ä¸€æ­¥ï¼šå°†SearchResultå¯¹è±¡è½¬æ¢ä¸ºå­—å…¸ï¼Œå¹¶è¯†åˆ«æ’­æ”¾åˆ—è¡¨
            results_dicts = []
            playlist_results = []  # å­˜å‚¨éœ€è¦è·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯çš„ç»“æœ

            for result in evaluated_results:
                result_dict = {
                    'title': result.title,
                    'url': result.url,
                    'snippet': result.snippet,
                    'source': result.source,
                    'resource_type': getattr(result, 'resource_type', 'unknown')
                }

                # å¦‚æœæ˜¯æ’­æ”¾åˆ—è¡¨URLï¼Œæ ‡è®°ä¸ºéœ€è¦è·å–ä¿¡æ¯
                if 'list=' in result.url:
                    playlist_results.append(result_dict)
                else:
                    # éæ’­æ”¾åˆ—è¡¨ï¼Œç›´æ¥æ·»åŠ 
                    results_dicts.append(result_dict)

            # ç¬¬äºŒæ­¥ï¼šå¹¶å‘è·å–æ‰€æœ‰æ’­æ”¾åˆ—è¡¨ä¿¡æ¯
            if playlist_results:
                import concurrent.futures

                print(f"    [âš¡ å¹¶å‘] å‘ç° {len(playlist_results)} ä¸ªæ’­æ”¾åˆ—è¡¨ï¼Œå¼€å§‹å¹¶å‘è·å–ä¿¡æ¯...")

                # è®¾ç½®å¹¶å‘å‚æ•°
                MAX_PLAYLIST_WORKERS = 20  # æœ€å¤š20ä¸ªå¹¶å‘ï¼ˆä¿®å¤ï¼šP1 - N+1æŸ¥è¯¢ä¼˜åŒ–ï¼‰
                SINGLE_TIMEOUT = 3  # å•ä¸ªæ’­æ”¾åˆ—è¡¨3ç§’è¶…æ—¶ï¼ˆä¼˜åŒ–ï¼šä»8ç§’é™ä½åˆ°3ç§’ï¼Œ2.6å€æé€Ÿï¼‰

                success_count = 0
                fail_count = 0

                with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_PLAYLIST_WORKERS) as executor:
                    # æäº¤æ‰€æœ‰ä»»åŠ¡
                    future_to_result = {
                        executor.submit(get_playlist_info_fast, r['url']): r
                        for r in playlist_results
                    }

                    # ğŸ”§ ä¿®å¤ï¼šç§»é™¤æ•´ä½“è¶…æ—¶ï¼Œé¿å…éƒ¨åˆ†è¶…æ—¶å¯¼è‡´æ•´ä¸ªæœç´¢å¤±è´¥
                    # æ”¶é›†ç»“æœï¼ˆç­‰å¾…æ‰€æœ‰futureå®Œæˆï¼‰
                    for future in concurrent.futures.as_completed(future_to_result):
                        result_dict = future_to_result[future]

                        try:
                            # å•ä¸ªè¶…æ—¶æ§åˆ¶
                            playlist_info = future.result(timeout=SINGLE_TIMEOUT)

                            if playlist_info:
                                result_dict['playlist_info'] = playlist_info
                                print(f"    [âœ… æˆåŠŸ] {result_dict['title'][:40]}... - {playlist_info['video_count']}ä¸ªè§†é¢‘, {playlist_info['total_duration_minutes']:.0f}åˆ†é’Ÿ")
                                success_count += 1
                            else:
                                print(f"    [âš ï¸ å¤±è´¥] {result_dict['title'][:40]}... - æ— æ³•è·å–ä¿¡æ¯")
                                fail_count += 1

                        except concurrent.futures.TimeoutError:
                            print(f"    [â±ï¸ è¶…æ—¶] {result_dict['title'][:40]}... - è·å–è¶…æ—¶({SINGLE_TIMEOUT}ç§’)")
                            fail_count += 1
                        except Exception as e:
                            print(f"    [âŒ å¼‚å¸¸] {result_dict['title'][:40]}... - {str(e)[:50]}")
                            fail_count += 1

                        # æ— è®ºå¦‚ä½•éƒ½æ·»åŠ åˆ°ç»“æœåˆ—è¡¨
                        results_dicts.append(result_dict)

                print(f"    [ğŸ“Š ç»Ÿè®¡] æˆåŠŸ: {success_count}, å¤±è´¥: {fail_count}, æ€»è®¡: {len(playlist_results)}")
            else:
                print(f"    [â„¹ï¸ è·³è¿‡] æ²¡æœ‰æ’­æ”¾åˆ—è¡¨éœ€è¦è·å–ä¿¡æ¯")

            # ========== Step 3.5: è§†è§‰å¿«é€Ÿè¯„ä¼°ï¼ˆTOP 20ï¼‰ ==========
            # âš ï¸ ä¸´æ—¶ç¦ç”¨ï¼šè§†è§‰è¯„ä¼°ä¼šå¯¼è‡´è¯·æ±‚è¶…æ—¶ï¼ˆé”™è¯¯ä»£ç 5ï¼‰
            # åŸå› ï¼šTOP 20ä¸ªç»“æœä¸²è¡Œå¤„ç†éœ€è¦5-10åˆ†é’Ÿï¼Œè¶…è¿‡HTTPè¯·æ±‚è¶…æ—¶é™åˆ¶
            # TODO: éœ€è¦æ”¹ä¸ºåå°å¼‚æ­¥å¤„ç†æˆ–å¤§å¹…å‡å°‘è¯„ä¼°æ•°é‡ï¼ˆTOP 5ï¼‰
            #
            # [ä¿®å¤] 2026-01-20: å¯ç”¨è§†è§‰è¯„ä¼°ï¼ˆé»˜è®¤trueï¼‰ï¼Œä½†é™åˆ¶è¯„ä¼°æ•°é‡ä¸ºTOP 5é¿å…è¶…æ—¶

            # è¯»å–ç¯å¢ƒå˜é‡æ§åˆ¶æ˜¯å¦å¯ç”¨ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
            ENABLE_VISUAL_EVALUATION = os.getenv('ENABLE_VISUAL_EVALUATION', 'true').lower() == 'true'

            # è¯»å–ç¯å¢ƒå˜é‡æ§åˆ¶LLMè¯„åˆ†æ•°é‡ï¼ˆé»˜è®¤TOP 10ï¼Œé¿å…è¶…æ—¶ï¼‰
            LLM_SCORE_TOP_N = int(os.getenv('LLM_SCORE_TOP_N', '10'))

            if not ENABLE_VISUAL_EVALUATION:
                print(f"\n[æ­¥éª¤ 3.5] è§†è§‰è¯„ä¼°å·²ç¦ç”¨ï¼ˆä½¿ç”¨å¿«é€ŸLLMè¯„åˆ†æ¨¡å¼ï¼‰")
                print(f"    [â„¹ï¸  æç¤º] å¦‚éœ€å¯ç”¨è§†è§‰è¯„ä¼°ï¼Œè®¾ç½®ç¯å¢ƒå˜é‡: ENABLE_VISUAL_EVALUATION=true")
                print(f"    [âš¡ æ€§èƒ½ä¼˜åŒ–] åªå¯¹TOP {LLM_SCORE_TOP_N}ä¸ªç»“æœè¿›è¡ŒLLMè¯„åˆ†")

                # âš¡ ä¼˜åŒ–ï¼šåªå¯¹TOP Nä¸ªç»“æœè¿›è¡ŒLLMè¯„åˆ†ï¼Œé¿å…è¶…æ—¶
                if len(results_dicts) > LLM_SCORE_TOP_N:
                    top_n_results = results_dicts[:LLM_SCORE_TOP_N]
                    remaining_results = results_dicts[LLM_SCORE_TOP_N:]

                    # å¯¹TOP Nè¿›è¡ŒLLMè¯„åˆ†
                    print(f"    [ğŸ“Š] TOP {len(top_n_results)} ä¸ªç»“æœå°†è¿›è¡ŒLLMè¯„åˆ†")
                    quickly_scored_results = top_n_results
                    # å‰©ä½™ç»“æœä½¿ç”¨é»˜è®¤åˆ†æ•°ï¼ˆä¸è¿›è¡ŒLLMè¯„åˆ†ï¼‰
                    quickly_scored_results.extend([{
                        **r,
                        'score': 5.0,  # é»˜è®¤ä¸­ç­‰åˆ†æ•°
                        'recommendation_reason': 'æœªè¯„åˆ†ï¼ˆè¶…å‡ºTOP Né™åˆ¶ï¼‰'
                    } for r in remaining_results])
                else:
                    # ç»“æœæ•°å°‘äºTOP Nï¼Œå…¨éƒ¨è¯„åˆ†
                    quickly_scored_results = results_dicts.copy()

                visually_scored_results = []
            else:
                print(f"\n[æ­¥éª¤ 3.5] è§†è§‰å¿«é€Ÿè¯„ä¼°ï¼ˆTOP 5ï¼‰...")

                # æå–TOP 5ä¸ªç»“æœè¿›è¡Œè§†è§‰è¯„ä¼°ï¼ˆå‡å°‘æ•°é‡é¿å…è¶…æ—¶ï¼‰
                TOP_N = 5
                top_results = results_dicts[:TOP_N]
                remaining_results = results_dicts[TOP_N:]

                print(f"    [ğŸ“Š] TOP {len(top_results)} ä¸ªç»“æœå°†è¿›è¡Œè§†è§‰è¯„ä¼°")
                print(f"    [ğŸ“Š] å‰©ä½™ {len(remaining_results)} ä¸ªç»“æœå°†ä½¿ç”¨å¿«é€Ÿè¯„åˆ†")

                # å¹¶å‘æˆªå›¾TOP 5
                screenshot_results = {}
                successful_screenshots = 0

                if top_results:
                    try:
                        # å¯¼å…¥æˆªå›¾æœåŠ¡
                        import asyncio
                        from core.screenshot_service import get_screenshot_service

                        # å‡†å¤‡URLåˆ—è¡¨
                        urls_to_screenshot = [r['url'] for r in top_results]

                        print(f"    [ğŸ“¸] å¼€å§‹å¹¶å‘æˆªå›¾ {len(urls_to_screenshot)} ä¸ªURL...")

                        # å¼‚æ­¥æ‰¹é‡æˆªå›¾ï¼ˆå¢åŠ è¶…æ—¶ä¿æŠ¤ + è‡ªåŠ¨èµ„æºé‡Šæ”¾ + å¤šå±‚ä¿é™©ï¼‰
                        async def capture_screenshots_async():
                            service = None
                            browser = None
                            try:
                                # åˆ›å»ºæˆªå›¾æœåŠ¡
                                service = await get_screenshot_service()
                                browser = service.browser if hasattr(service, 'browser') else None

                                # æ·»åŠ 60ç§’æ€»è¶…æ—¶ä¿æŠ¤
                                result = await asyncio.wait_for(
                                    service.capture_batch(
                                        urls=urls_to_screenshot,
                                        wait_for='domcontentloaded',  # ä½¿ç”¨æ›´å¿«çš„ç­‰å¾…ç­–ç•¥ï¼Œé¿å…YouTubeè¶…æ—¶
                                        full_page=False
                                    ),
                                    timeout=60.0  # æœ€å¤šç­‰å¾…60ç§’
                                )
                                return result
                            except asyncio.TimeoutError:
                                logger.warning("æˆªå›¾è¶…æ—¶(60ç§’)ï¼Œéƒ¨åˆ†æˆªå›¾å¯èƒ½å¤±è´¥")
                                return {}
                            except Exception as e:
                                logger.warning(f"æˆªå›¾æœåŠ¡å¼‚å¸¸: {str(e)[:100]}")
                                return {}
                            finally:
                                # ğŸ”¥ å…³é”®ï¼šå¤šå±‚ä¿é™©ç¡®ä¿èµ„æºé‡Šæ”¾ï¼ˆä¿®å¤ï¼šP1 - å†…å­˜æ³„æ¼ï¼‰
                                # 1. å…³é—­æµè§ˆå™¨å®ä¾‹
                                if browser is not None:
                                    try:
                                        await browser.close()
                                        logger.debug("ğŸ—‘ï¸ æµè§ˆå™¨å®ä¾‹å·²å…³é—­")
                                    except Exception as e:
                                        logger.debug(f"å…³é—­æµè§ˆå™¨å®ä¾‹å¤±è´¥ï¼ˆå¯å¿½ç•¥ï¼‰: {str(e)[:50]}")

                                # 2. åœæ­¢æˆªå›¾æœåŠ¡
                                if service is not None:
                                    try:
                                        await service.stop()
                                        logger.debug("ğŸ—‘ï¸ æˆªå›¾æœåŠ¡å·²å…³é—­")
                                    except Exception as e:
                                        logger.debug(f"å…³é—­æˆªå›¾æœåŠ¡å¤±è´¥ï¼ˆå¯å¿½ç•¥ï¼‰: {str(e)[:50]}")

                                # 3. å¼ºåˆ¶åƒåœ¾å›æ”¶ï¼Œç¡®ä¿å†…å­˜é‡Šæ”¾
                                try:
                                    import gc
                                    gc.collect()
                                    logger.debug("â™»ï¸ å·²å¼ºåˆ¶åƒåœ¾å›æ”¶")
                                except Exception:
                                    pass

                        # è¿è¡Œå¼‚æ­¥ä»»åŠ¡
                        screenshot_results = asyncio.run(capture_screenshots_async())

                        # ç»Ÿè®¡æˆåŠŸæ•°é‡
                        successful_screenshots = sum(1 for path in screenshot_results.values() if path is not None)
                        print(f"    [âœ… æˆªå›¾å®Œæˆ] {successful_screenshots}/{len(urls_to_screenshot)} æˆåŠŸ")

                    except Exception as e:
                        logger.error(f"æˆªå›¾æµç¨‹å¼‚å¸¸: {str(e)}")
                        print(f"    [âŒ æˆªå›¾å¤±è´¥] {str(e)[:100]}")
                        print(f"    [âš ï¸ å°†é™çº§åˆ°å¿«é€Ÿè¯„åˆ†æ¨¡å¼")
                        # ç¡®ä¿screenshot_resultsæ˜¯å­—å…¸
                        if 'screenshot_results' not in locals() or not isinstance(screenshot_results, dict):
                            screenshot_results = {}

                # å¯¹æœ‰æˆªå›¾çš„ç»“æœä½¿ç”¨è§†è§‰è¯„ä¼°
                visually_scored_results = []
                quickly_scored_results = remaining_results.copy()

                for result_dict in top_results:
                    url = result_dict['url']
                    screenshot_path = screenshot_results.get(url)

                    if screenshot_path:
                        # æœ‰æˆªå›¾ï¼Œä½¿ç”¨è§†è§‰è¯„ä¼°ï¼ˆæ·»åŠ è¶…æ—¶ä¿æŠ¤ï¼‰
                        try:
                            import signal

                            # å‡†å¤‡metadata
                            country_config = self.config_manager.get_country_config(request.country.upper()) if self.config_manager else None
                            metadata = {
                                'country_name': country_config.name if country_config else '',
                                'grade_name': request.grade,
                                'subject_name': request.subject,
                                'language_code': country_config.language_code if country_config else 'en'
                            }

                            # è°ƒç”¨è§†è§‰è¯„ä¼°ï¼ˆè¶…æ—¶ä¿æŠ¤30ç§’ï¼‰
                            def timeout_handler(signum, frame):
                                raise TimeoutError("è§†è§‰è¯„ä¼°è¶…æ—¶")

                            # è®¾ç½®è¶…æ—¶ï¼ˆä»…Unixç³»ç»Ÿï¼‰
                            if hasattr(signal, 'SIGALRM'):
                                signal.signal(signal.SIGALRM, timeout_handler)
                                signal.alarm(30)  # 30ç§’è¶…æ—¶

                            try:
                                visual_evaluation = self.result_scorer.evaluate_with_visual(
                                    result=result_dict,
                                    screenshot_path=screenshot_path,
                                    query=query,
                                    metadata=metadata
                                )
                            finally:
                                if hasattr(signal, 'SIGALRM'):
                                    signal.alarm(0)  # å–æ¶ˆè¶…æ—¶

                            if visual_evaluation:
                                # è§†è§‰è¯„ä¼°æˆåŠŸ
                                result_dict['score'] = visual_evaluation['score']
                                result_dict['recommendation_reason'] = visual_evaluation['recommendation_reason']
                                result_dict['evaluation_method'] = 'Visual'
                                result_dict['evaluation_details'] = visual_evaluation.get('evaluation_details', {})
                                result_dict['screenshot_path'] = screenshot_path
                                visually_scored_results.append(result_dict)
                                print(f"    [âœ… è§†è§‰è¯„ä¼°] {result_dict['title'][:40]}... - {visual_evaluation['score']}/10")
                            else:
                                # è§†è§‰è¯„ä¼°å¤±è´¥ï¼Œé™çº§åˆ°å¿«é€Ÿè¯„åˆ†
                                quickly_scored_results.append(result_dict)
                                print(f"    [âš ï¸ é™çº§] {result_dict['title'][:40]}... - è§†è§‰è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨å¿«é€Ÿè¯„åˆ†")

                        except TimeoutError:
                            logger.warning(f"è§†è§‰è¯„ä¼°è¶…æ—¶: {result_dict['title'][:40]}...")
                            print(f"    [â±ï¸ è¶…æ—¶] {result_dict['title'][:40]}... - è§†è§‰è¯„ä¼°è¶…æ—¶ï¼Œä½¿ç”¨å¿«é€Ÿè¯„åˆ†")
                            quickly_scored_results.append(result_dict)
                        except Exception as e:
                            logger.warning(f"è§†è§‰è¯„ä¼°å¼‚å¸¸: {str(e)[:100]}")
                            quickly_scored_results.append(result_dict)
                    else:
                        # æ²¡æœ‰æˆªå›¾ï¼Œä½¿ç”¨å¿«é€Ÿè¯„åˆ†
                        quickly_scored_results.append(result_dict)

            # å¯¹å¿«é€Ÿè¯„åˆ†ç»“æœä½¿ç”¨åŸæœ‰çš„LLM/è§„åˆ™è¯„åˆ†
            if quickly_scored_results:
                llm_start = time.time()
                logger.info(f"[LLMè¯„åˆ†] å¼€å§‹: {len(quickly_scored_results)}ä¸ªç»“æœ (å†…å­˜: {self._get_memory_usage()})")
                print(f"    [ğŸ“Š] å¯¹ {len(quickly_scored_results)} ä¸ªç»“æœè¿›è¡Œå¿«é€Ÿè¯„åˆ†ï¼ˆLLM/è§„åˆ™ï¼‰...")

                # è·å–å›½å®¶è¯­è¨€ä»£ç 
                language_code = None
                if self.config_manager:
                    country_config = self.config_manager.get_country_config(request.country.upper())
                    if country_config:
                        language_code = country_config.language_code

                quickly_scored = self.result_scorer.score_results(
                    results=quickly_scored_results,
                    query=query,
                    metadata={
                        'country': request.country,
                        'grade': request.grade,
                        'subject': request.subject,
                        'language_code': language_code
                    }
                )

                # åˆå¹¶ç»“æœ
                results_dicts = visually_scored_results + quickly_scored

                llm_elapsed = time.time() - llm_start
                logger.info(f"   âœ… LLMè¯„åˆ†å®Œæˆ: {llm_elapsed:.2f}ç§’, {len(quickly_scored)}ä¸ªç»“æœ (å†…å­˜: {self._get_memory_usage()})")
            else:
                results_dicts = visually_scored_results

            print(f"    [âœ… è¯„ä¼°å®Œæˆ] æ€»è®¡ {len(results_dicts)} ä¸ªç»“æœ (è§†è§‰: {len(visually_scored_results)}, å¿«é€Ÿ: {len(quickly_scored_results)})")

            step35_elapsed = time.time() - step35_start
            logger.info(f"   âœ… æ­¥éª¤3.5å®Œæˆ: {step35_elapsed:.2f}ç§’ (å†…å­˜: {self._get_memory_usage()})")
            logger.info(f"   ğŸ“Š è¯„åˆ†ç»“æœ: è§†è§‰={len(visually_scored_results)}, å¿«é€Ÿ={len(quickly_scored_results)}")

            # æ˜¾ç¤ºè¯„åˆ†ç»Ÿè®¡
            if results_dicts:
                scores = [r.get('score', 0) for r in results_dicts]
                avg_score = sum(scores) / len(scores) if scores else 0
                high_score_count = sum(1 for s in scores if s >= 8.0)
                visual_count = sum(1 for r in results_dicts if r.get('evaluation_method') == 'Visual')
                print(f"    [ğŸ“Š è¯„åˆ†ç»Ÿè®¡] å¹³å‡åˆ†: {avg_score:.2f}, é«˜åˆ†(â‰¥8): {high_score_count} ä¸ª, è§†è§‰è¯„ä¼°: {visual_count} ä¸ª")
                print(f"    [ğŸ“Š å‰3åè¯„åˆ†]:")
                for i, r in enumerate(results_dicts[:3], 1):
                    method = r.get('evaluation_method', 'Unknown')
                    print(f"        {i}. {r.get('score', 0):.1f}/10 [{method}] - {r.get('title', 'N/A')[:50]}...")

            # âœ… æ–°é€»è¾‘ï¼šé€šè¿‡URLåŒ¹é…è¯„åˆ†å’Œç»“æœï¼ˆ2025-01-16ï¼‰
            # é—®é¢˜ï¼šresults_dictså’Œevaluated_resultsçš„é¡ºåºå¯èƒ½ä¸ä¸€è‡´
            # è§£å†³ï¼šé€šè¿‡URLè¿›è¡Œä¸€ä¸€å¯¹åº”åŒ¹é…
            logger.info(f"[ğŸ“Š URLåŒ¹é…] å¼€å§‹é€šè¿‡URLåŒ¹é…è¯„åˆ†ï¼ˆ{len(results_dicts)}ä¸ªè¯„åˆ†ï¼Œ{len(evaluated_results)}ä¸ªç»“æœï¼‰")

            # 1. æ„å»ºURLåˆ°è¯„åˆ†çš„æ˜ å°„
            url_to_score = {}
            for scored_dict in results_dicts:
                if 'url' in scored_dict and 'score' in scored_dict:
                    url = scored_dict['url']
                    url_to_score[url] = {
                        'score': scored_dict['score'],
                        'recommendation_reason': scored_dict.get('recommendation_reason', ''),
                        'evaluation_method': scored_dict.get('evaluation_method', 'LLM')
                    }

            # 2. é€šè¿‡URLåŒ¹é…ï¼Œå°†è¯„åˆ†èµ‹å€¼ç»™å¯¹åº”çš„ç»“æœ
            matched_count = 0
            for result in evaluated_results:
                result_url = result.url
                if result_url in url_to_score:
                    # æ‰¾åˆ°åŒ¹é…çš„è¯„åˆ†
                    score_info = url_to_score[result_url]
                    result.score = score_info['score']
                    result.recommendation_reason = score_info['recommendation_reason']
                    matched_count += 1
                else:
                    # æœªæ‰¾åˆ°è¯„åˆ†ï¼Œè®¾ç½®é»˜è®¤å€¼
                    logger.warning(f"[âš ï¸ æœªæ‰¾åˆ°è¯„åˆ†] URL: {result_url[:60]}...")
                    result.score = 0.0
                    result.recommendation_reason = 'æœªæ‰¾åˆ°è¯„åˆ†'

            logger.info(f"[âœ… URLåŒ¹é…å®Œæˆ] åŒ¹é…æˆåŠŸ: {matched_count}/{len(evaluated_results)}")

            # 3. æŒ‰è¯„åˆ†é™åºæ’åº
            evaluated_results.sort(key=lambda x: x.score, reverse=True)
            logger.info(f"âœ… ç»“æœå·²æŒ‰è¯„åˆ†é™åºæ’åº (æœ€é«˜åˆ†: {evaluated_results[0].score if evaluated_results else 0:.1f})")

            # Step 4: ç»Ÿè®¡
            # æ’­æ”¾åˆ—è¡¨ï¼šYouTubeæ’­æ”¾åˆ—è¡¨æˆ–åŒ…å«list=çš„URL
            playlist_count = sum(1 for r in evaluated_results if 
                               "youtube.com/playlist" in r.url.lower() or 
                               ("youtube.com/watch" in r.url.lower() and "list=" in r.url.lower()))
            
            # è§†é¢‘ï¼šYouTubeè§†é¢‘ã€Bç«™è§†é¢‘æˆ–å…¶ä»–è§†é¢‘å¹³å°
            video_count = sum(1 for r in evaluated_results if 
                            "youtube.com/watch" in r.url.lower() or
                            "bilibili.com/video" in r.url.lower() or
                            "/video/" in r.url.lower())
            
            print(f"\n[æ­¥éª¤ 4] ç»Ÿè®¡ç»“æœ...")
            print(f"    [ğŸ“Š ç»Ÿè®¡] æ’­æ”¾åˆ—è¡¨: {playlist_count} ä¸ª")
            print(f"    [ğŸ“Š ç»Ÿè®¡] è§†é¢‘: {video_count} ä¸ª")
            print(f"    [ğŸ“Š ç»Ÿè®¡] æ€»è®¡: {len(evaluated_results)} ä¸ª")

            # æ˜¾ç¤ºå¤šçº§ç¼“å­˜ç»Ÿè®¡
            cache_stats = self.multi_cache.get_stats()
            print(f"\n[ğŸ’¾ å¤šçº§ç¼“å­˜ç»Ÿè®¡]")
            print(f"    [ğŸ“Š L1å†…å­˜] å‘½ä¸­: {cache_stats['l1_hits']}æ¬¡ ({cache_stats['l1_hit_rate']:.1f}%)")
            print(f"    [ğŸ“Š L2 Redis] å‘½ä¸­: {cache_stats['l2_hits']}æ¬¡ ({cache_stats['l2_hit_rate']:.1f}%)")
            print(f"    [ğŸ“Š L3ç£ç›˜] å‘½ä¸­: {cache_stats['l3_hits']}æ¬¡ ({cache_stats['l3_hit_rate']:.1f}%)")
            print(f"    [ğŸ“Š æ€»è®¡] æŸ¥è¯¢: {cache_stats['total']}æ¬¡ | å‘½ä¸­ç‡: {cache_stats['hit_rate']:.1f}%")

            # æ€§èƒ½ç›‘æ§ - è®°å½•æˆåŠŸçš„æœç´¢
            search_duration = time.time() - search_start_time
            perf_monitor.record_metric(
                operation=f"search_{request.country.lower()}",
                duration=search_duration,
                success=True,
                metadata={
                    "country": request.country,
                    "grade": request.grade,
                    "subject": request.subject,
                    "result_count": len(evaluated_results),
                    "playlist_count": playlist_count,
                    "video_count": video_count,
                    "query": query
                }
            )

            # ğŸ”§ ä¿®å¤ï¼šå°†SearchResultå¯¹è±¡è½¬æ¢ä¸ºå­—å…¸ï¼ˆé¿å…PydanticéªŒè¯é”™è¯¯ï¼‰
            results_as_dicts = [r.model_dump() if hasattr(r, 'model_dump') else r.dict() for r in evaluated_results]

            # ========== ğŸ¤– æ™ºèƒ½ä¼˜åŒ–å¾ªç¯ï¼ˆè´¨é‡è¯„ä¼° + ä¼˜åŒ–å»ºè®®ï¼‰ ==========
            quality_report = None
            optimization_request = None

            try:
                # æ£€æŸ¥æ˜¯å¦å¯ç”¨æ™ºèƒ½ä¼˜åŒ–ï¼ˆç¯å¢ƒå˜é‡æ§åˆ¶ï¼‰
                enable_intelligent_optimization = os.getenv("ENABLE_INTELLIGENT_OPTIMIZATION", "true").lower() == "true"

                if enable_intelligent_optimization:
                    print(f"\n[ğŸ¤– æ™ºèƒ½ä¼˜åŒ–] å¼€å§‹è´¨é‡è¯„ä¼°...")

                    # 1. è´¨é‡è¯„ä¼°
                    evaluator = QualityEvaluator()
                    search_params = {
                        'country': request.country,
                        'grade': request.grade,
                        'subject': request.subject,
                        'semester': request.semester
                    }
                    quality_report = evaluator.evaluate_single_search(results_as_dicts, search_params)

                    print(f"    [ğŸ“Š è´¨é‡åˆ†æ•°] {quality_report['overall_quality_score']:.1f}/100")
                    print(f"    [ğŸ¯ è´¨é‡ç­‰çº§] {quality_report['quality_level']}")
                    print(f"    [ğŸ“ˆ å¹³å‡åˆ†] {quality_report['basic_stats']['avg_score']:.2f}/10")

                    # 2. åˆ¤æ–­æ˜¯å¦éœ€è¦ä¼˜åŒ–
                    optimizer = IntelligentSearchOptimizer(search_engine=self)
                    should_opt, issues = optimizer.should_optimize(results_as_dicts, quality_report)

                    if should_opt:
                        print(f"    [âš ï¸ æ£€æµ‹åˆ°é—®é¢˜] {len(issues)}ä¸ª")
                        for i, issue in enumerate(issues, 1):
                            print(f"      {i}. {issue}")

                        # 3. ç”Ÿæˆä¼˜åŒ–æ–¹æ¡ˆ
                        opt_request = optimizer.create_optimization_request(
                            results_as_dicts, quality_report, search_params, issues
                        )

                        # 4. å­˜å‚¨ä¼˜åŒ–è¯·æ±‚åˆ°å®¡æ‰¹ç®¡ç†å™¨ (å·²ç¦ç”¨ - SISåŠŸèƒ½)
                        # approval_manager = get_approval_manager()
                        # stored_request = approval_manager.create_request(opt_request)
                        # print(f"    [âœ… ä¼˜åŒ–è¯·æ±‚å·²åˆ›å»º] ID: {stored_request['request_id']}")
                        # print(f"    [ğŸ“‹ å¾…å®¡æ‰¹æ–¹æ¡ˆ] {len(stored_request['optimization_plans'])}ä¸ª")
                        # optimization_request = stored_request
                        optimization_request = None
                    else:
                        print(f"    [âœ… è´¨é‡è‰¯å¥½] æ— éœ€ä¼˜åŒ–")

            except Exception as opt_error:
                print(f"    [âš ï¸ æ™ºèƒ½ä¼˜åŒ–å¤±è´¥] {str(opt_error)}")
                logger.warning(f"æ™ºèƒ½ä¼˜åŒ–å¤±è´¥: {str(opt_error)}", exc_info=True)
            # ========== æ™ºèƒ½ä¼˜åŒ–å¾ªç¯ç»“æŸ ==========

            # ğŸ” è¯¦ç»†æ—¥å¿—ï¼šæœç´¢å®Œæˆ
            total_elapsed = time.time() - search_start_time
            logger.info("="*80)
            logger.info(f"âœ… [æœç´¢å®Œæˆ] {request.country} - {request.grade} - {request.subject}")
            logger.info(f"   æ€»è€—æ—¶: {total_elapsed:.2f}ç§’")
            logger.info(f"   ç»“æœæ•°: {len(evaluated_results)}")
            logger.info(f"   å†…å­˜ä½¿ç”¨: {self._get_memory_usage()}")
            logger.info(f"   æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            if quality_report:
                logger.info(f"   è´¨é‡åˆ†æ•°: {quality_report['overall_quality_score']:.1f}/100")
            logger.info("="*80)

            return SearchResponse(
                success=True,
                query=query,
                results=results_as_dicts,
                total_count=len(evaluated_results),
                playlist_count=playlist_count,
                video_count=video_count,
                message="æœç´¢æˆåŠŸ",
                quality_report=quality_report,
                optimization_request=optimization_request
            )
            
        except Exception as e:
            print(f"\n[âŒ é”™è¯¯] æœç´¢å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()

            # æ€§èƒ½ç›‘æ§ - è®°å½•å¤±è´¥çš„æœç´¢
            search_duration = time.time() - search_start_time
            perf_monitor.record_metric(
                operation=f"search_{request.country.lower()}",
                duration=search_duration,
                success=False,
                metadata={
                    "country": request.country,
                    "grade": request.grade,
                    "subject": request.subject,
                    "error": str(e)
                }
            )

            return SearchResponse(
                success=False,
                query="",
                results=[],
                message=f"æœç´¢å¤±è´¥: {str(e)}"
            )

        except Exception as e:
            # ğŸ” è¯¦ç»†æ—¥å¿—ï¼šæœç´¢å¤±è´¥
            total_elapsed = time.time() - search_start_time
            logger.error("="*80)
            logger.error(f"âŒ [æœç´¢å¤±è´¥] {request.country} - {request.grade} - {request.subject}")
            logger.error(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
            logger.error(f"   é”™è¯¯ä¿¡æ¯: {str(e)[:200]}")
            logger.error(f"   è€—æ—¶: {total_elapsed:.2f}ç§’")
            logger.error(f"   å†…å­˜ä½¿ç”¨: {self._get_memory_usage()}")
            logger.error(f"   æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            logger.error("="*80)
            import traceback
            logger.error(f"å †æ ˆä¿¡æ¯:\n{traceback.format_exc()}")