#!/usr/bin/env python3
"""
æ–°ç‰ˆæœç´¢å¼•æ“ - åŸºäºå›½å®¶/å¹´çº§/å­¦æœŸæœç´¢
ä½¿ç”¨ AI ç”Ÿæˆæœ¬åœ°è¯­è¨€çš„æœç´¢è¯

TODO é‡æ„ä»»åŠ¡ï¼ˆP1 - ä»£ç è´¨é‡æ”¹è¿›ï¼‰:
- [008] è¶…é•¿å‡½æ•°ï¼šsearch()æ–¹æ³•éœ€è¦æ‹†åˆ†ä¸ºå¤šä¸ªå°å‡½æ•°ï¼ˆå½“å‰çº¦1000+è¡Œï¼‰
- [009] å…¨å±€å˜é‡ï¼šå‡å°‘globalå…³é”®å­—ä½¿ç”¨ï¼Œæ”¹ç”¨ä¾èµ–æ³¨å…¥æ¨¡å¼
- [010] ç¡¬ç¼–ç è·¯å¾„ï¼šåˆ›å»ºPathManagerç»Ÿä¸€ç®¡ç†è·¯å¾„é…ç½®
"""

import os
import json
import time
import re
from typing import Dict, List, Optional, Any, Callable
from pydantic import BaseModel, Field
from datetime import datetime, timezone
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed, TimeoutError as FuturesTimeoutError
import concurrent.futures
from config_manager import ConfigManager
from logger_utils import get_logger
from json_utils import extract_json_array
from search_strategy_agent import SearchStrategyAgent
from core.search_cache import get_search_cache
from core.config_loader import get_config
from core.performance_monitor import get_performance_monitor
from core.result_scorer import get_result_scorer
from core.recommendation_generator import get_recommendation_generator
from core.grade_subject_validator import GradeSubjectValidator
from core.text_utils import clean_title, clean_snippet, extract_video_info
from core.quality_evaluator import QualityEvaluator
from core.intelligent_search_optimizer import IntelligentSearchOptimizer
# from core.optimization_approval import get_approval_manager  # å·²ç¦ç”¨ - SISåŠŸèƒ½
# æ—¥å¿—è„±æ•å·¥å…·ï¼ˆå®‰å…¨ä¿®å¤ï¼šP1 - é˜²æ­¢æ•æ„Ÿä¿¡æ¯æ³„éœ²ï¼‰
from utils.log_sanitizer import safe_log, safe_log_json

# åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨
logger = get_logger('search_engine')

# åˆå§‹åŒ–æ€§èƒ½ç›‘æ§å™¨
perf_monitor = get_performance_monitor()

# æ”¯æŒä» .env æ–‡ä»¶è¯»å–ç¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    def load_dotenv():
        env_file = os.path.join(os.path.dirname(__file__), '.env')
        if os.path.exists(env_file):
            with open(env_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#') and '=' in line:
                        key, value = line.split('=', 1)
                        os.environ[key.strip()] = value.strip().strip('"').strip("'")
    load_dotenv()


# ============================================================================
# æ•°æ®æ¨¡å‹å®šä¹‰
# ============================================================================

class SearchRequest(BaseModel):
    """æœç´¢è¯·æ±‚"""
    country: str = Field(description="å›½å®¶ä»£ç ï¼ˆå¦‚ï¼šID, CN, USï¼‰")
    grade: str = Field(description="å¹´çº§ï¼ˆå¦‚ï¼š1, 2, 3 æˆ– Kelas 1, Grade 1ï¼‰")
    semester: Optional[str] = Field(description="å­¦æœŸï¼ˆå¦‚ï¼š1, 2 æˆ– Semester 1ï¼‰", default=None)
    subject: str = Field(description="å­¦ç§‘ï¼ˆå¦‚ï¼šMatematika, Mathematics, æ•°å­¦ï¼‰")
    language: Optional[str] = Field(description="æœç´¢è¯­è¨€ï¼ˆå¦‚ï¼šid, en, zhï¼‰", default=None)


class SearchResult(BaseModel):
    """å•ä¸ªæœç´¢ç»“æœ"""
    title: str = Field(description="æœç´¢ç»“æœæ ‡é¢˜")
    url: str = Field(description="ç»“æœURL")
    snippet: str = Field(description="ç»“æœæ‘˜è¦", default="")
    source: str = Field(description="æ¥æºï¼ˆè§„åˆ™/LLMï¼‰", default="è§„åˆ™")
    search_engine: str = Field(description="æœç´¢å¼•æ“æ¥æºï¼ˆTavily/Google/Baiduï¼‰", default="Unknown")
    score: float = Field(description="è¯„ä¼°åˆ†æ•°ï¼ˆ0-10åˆ†ï¼‰", default=0.0)
    recommendation_reason: str = Field(description="æ¨èç†ç”±", default="")
    evaluation_method: Optional[str] = Field(description="è¯„ä¼°æ–¹æ³•ï¼ˆMCP Tools/Rule-based/LLMï¼‰", default=None)
    resource_type: Optional[str] = Field(description="èµ„æºç±»å‹ï¼ˆè§†é¢‘ã€æ•™æã€æ•™è¾…ã€å­¦ä¹ èµ„æ–™ã€ç»ƒä¹ é¢˜ç­‰ï¼‰", default=None)
    is_selected: bool = Field(description="æ˜¯å¦è¢«äººå·¥é€‰ä¸­", default=False)
    evaluation_status: Optional[str] = Field(description="è¯„ä¼°çŠ¶æ€ï¼ˆpending/evaluating/completed/failedï¼‰", default=None)
    evaluation_result: Optional[Dict[str, Any]] = Field(description="è§†é¢‘è¯„ä¼°ç»“æœï¼ˆå¦‚æœå·²è¯„ä¼°ï¼‰", default=None)


class SearchResponse(BaseModel):
    """æœç´¢å“åº”"""
    success: bool = Field(description="æ˜¯å¦æˆåŠŸ")
    query: str = Field(description="ä½¿ç”¨çš„æœç´¢è¯")
    results: List[SearchResult] = Field(description="æœç´¢ç»“æœåˆ—è¡¨", default_factory=list)
    total_count: int = Field(description="ç»“æœæ€»æ•°", default=0)
    playlist_count: int = Field(description="æ’­æ”¾åˆ—è¡¨æ•°é‡", default=0)
    video_count: int = Field(description="è§†é¢‘æ•°é‡", default=0)
    message: str = Field(description="æ¶ˆæ¯", default="")
    timestamp: str = Field(description="æ—¶é—´æˆ³", default_factory=lambda: datetime.now(timezone.utc).isoformat())
    quality_report: Optional[Dict[str, Any]] = Field(description="è´¨é‡è¯„ä¼°æŠ¥å‘Š", default=None)
    optimization_request: Optional[Dict[str, Any]] = Field(description="ä¼˜åŒ–è¯·æ±‚ï¼ˆå¦‚æœæ£€æµ‹åˆ°è´¨é‡é—®é¢˜ï¼‰", default=None)


# ============================================================================
# AI Builders å®¢æˆ·ç«¯ (ä½¿ç”¨ç»Ÿä¸€LLMå®¢æˆ·ç«¯ï¼Œæ”¯æŒåŒAPIç³»ç»Ÿ)
# ============================================================================

# å¯¼å…¥ç»Ÿä¸€LLMå®¢æˆ·ç«¯
try:
    from llm_client import UnifiedLLMClient, AIBuildersAPIClient
    HAS_UNIFIED_CLIENT = True
except ImportError:
    HAS_UNIFIED_CLIENT = False
    print("[âš ï¸] è­¦å‘Š: æ— æ³•å¯¼å…¥ç»Ÿä¸€LLMå®¢æˆ·ç«¯ï¼Œå°†ä½¿ç”¨åŸæœ‰å®ç°")

class AIBuildersClient:
    """
    AI Builders API å®¢æˆ·ç«¯ï¼ˆå…¼å®¹æ€§åŒ…è£…å™¨ï¼‰
    å†…éƒ¨ä½¿ç”¨ç»Ÿä¸€LLMå®¢æˆ·ç«¯ï¼Œæ”¯æŒå…¬å¸å†…éƒ¨APIå’ŒAI Builders APIçš„fallbackæœºåˆ¶
    """
    
    def __init__(self, api_token: Optional[str] = None):
        self.api_token = api_token or os.getenv("AI_BUILDER_TOKEN")
        
        # å°è¯•ä½¿ç”¨ç»Ÿä¸€LLMå®¢æˆ·ç«¯
        if HAS_UNIFIED_CLIENT:
            try:
                # è·å–å…¬å¸å†…éƒ¨APIå¯†é’¥ï¼ˆå¯é€‰ï¼‰
                internal_api_key = os.getenv("INTERNAL_API_KEY")
                self.unified_client = UnifiedLLMClient(
                    internal_api_key=internal_api_key,
                    ai_builder_token=self.api_token
                )
                self.use_unified_client = True
                print("[âœ…] ä½¿ç”¨ç»Ÿä¸€LLMå®¢æˆ·ç«¯ï¼ˆæ”¯æŒåŒAPIç³»ç»Ÿï¼‰")
            except Exception as e:
                print(f"[âš ï¸] ç»Ÿä¸€LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}ï¼Œå›é€€åˆ°åŸæœ‰å®ç°")
                self.use_unified_client = False
                # å›é€€åˆ°åŸæœ‰å®ç°
                if not self.api_token:
                    raise ValueError("è¯·è®¾ç½® AI_BUILDER_TOKEN ç¯å¢ƒå˜é‡")
        else:
            self.use_unified_client = False
            if not self.api_token:
                raise ValueError("è¯·è®¾ç½® AI_BUILDER_TOKEN ç¯å¢ƒå˜é‡")
        
        # ä¿ç•™åŸæœ‰å±æ€§ä»¥ä¿æŒå…¼å®¹æ€§
        self.base_url = "https://space.ai-builders.com/backend"
        self.headers = {
            "Authorization": f"Bearer {self.api_token or ''}",
            "Content-Type": "application/json"
        }
    
    def call_llm(self, prompt: str, system_prompt: Optional[str] = None, 
                 max_tokens: int = 2000, temperature: float = 0.3,
                 model: str = "deepseek") -> str:
        """è°ƒç”¨ LLM"""
        # å¦‚æœä½¿ç”¨ç»Ÿä¸€å®¢æˆ·ç«¯ï¼Œç›´æ¥è°ƒç”¨
        if self.use_unified_client:
            return self.unified_client.call_llm(
                prompt=prompt,
                system_prompt=system_prompt,
                max_tokens=max_tokens,
                temperature=temperature,
                model=model
            )
        
        # å¦åˆ™ä½¿ç”¨åŸæœ‰å®ç°
        endpoint = f"{self.base_url}/v1/chat/completions"
        
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})
        
        payload = {
            "model": model,
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": temperature
            # ä¸è®¾ç½® tool_choice å’Œ toolsï¼Œè®© API ä½¿ç”¨é»˜è®¤è¡Œä¸º
        }
        
        # è¯¦ç»†æ—¥å¿—ï¼šLLMè°ƒç”¨è¾“å…¥ï¼ˆä½¿ç”¨è„±æ•é˜²æ­¢æ•æ„Ÿä¿¡æ¯æ³„éœ²ï¼‰
        print(f"\n{'='*80}")
        print(f"[ğŸ¤– LLMè°ƒç”¨] å¼€å§‹è°ƒç”¨ {model}")
        print(f"{'='*80}")
        print(f"[ğŸ“¤ è¾“å…¥] Endpoint: {endpoint}")
        print(f"[ğŸ“¤ è¾“å…¥] Model: {model}")
        print(f"[ğŸ“¤ è¾“å…¥] Max Tokens: {max_tokens}")
        print(f"[ğŸ“¤ è¾“å…¥] Temperature: {temperature}")
        print(f"[ğŸ“¤ è¾“å…¥] System Prompt é•¿åº¦: {len(system_prompt) if system_prompt else 0} å­—ç¬¦")
        print(f"[ğŸ“¤ è¾“å…¥] User Prompt é•¿åº¦: {len(prompt)} å­—ç¬¦")
        if system_prompt:
            print(f"[ğŸ“¤ è¾“å…¥] System Prompt (å‰500å­—ç¬¦):\n{safe_log(system_prompt[:500])}...")
        print(f"[ğŸ“¤ è¾“å…¥] User Prompt (å‰500å­—ç¬¦):\n{safe_log(prompt[:500])}...")
        print(f"[ğŸ“¤ è¾“å…¥] å®Œæ•´ User Prompt:\n{safe_log(prompt)}")
        print(f"[ğŸ“¤ è¾“å…¥] Payload (å·²è„±æ•):\n{safe_log_json(payload)}")
        
        try:
            import time
            from llm_client import get_proxy_config
            start_time = time.time()
            response = requests.post(
                endpoint,
                headers=self.headers,
                json=payload,
                params={"debug": "true"},
                timeout=300,
                proxies=get_proxy_config()
            )
            elapsed_time = time.time() - start_time
            
            # è¯¦ç»†æ—¥å¿—ï¼šAPIå“åº”ï¼ˆä½¿ç”¨è„±æ•é˜²æ­¢æ•æ„Ÿä¿¡æ¯æ³„éœ²ï¼‰
            print(f"\n[ğŸ“¥ å“åº”] HTTP çŠ¶æ€ç : {response.status_code}")
            print(f"[ğŸ“¥ å“åº”] å“åº”æ—¶é—´: {elapsed_time:.2f} ç§’")

            if response.status_code == 200:
                result = response.json()
                print(f"[ğŸ“¥ å“åº”] å“åº”ç±»å‹: {type(result).__name__}")
                print(f"[ğŸ“¥ å“åº”] å“åº”é”®: {list(result.keys()) if isinstance(result, dict) else 'N/A'}")

                # æ‰“å°å®Œæ•´çš„APIå“åº”ï¼ˆç”¨äºè°ƒè¯•ï¼Œå·²è„±æ•ï¼‰
                print(f"[ğŸ“¥ å“åº”] å®Œæ•´ API å“åº” (å·²è„±æ•):\n{safe_log_json(result)}")
                
                if "choices" in result and len(result["choices"]) > 0:
                    choice = result["choices"][0]
                    message = choice.get("message", {})
                    content = message.get("content", "")
                    finish_reason = choice.get("finish_reason", "unknown")
                    
                    print(f"[ğŸ“¥ å“åº”] Finish Reason: {finish_reason}")
                    print(f"[ğŸ“¥ å“åº”] Content é•¿åº¦: {len(content) if content else 0} å­—ç¬¦")
                    
                    # æ‰“å° usage ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                    if "usage" in result:
                        usage = result["usage"]
                        print(f"[ğŸ“¥ å“åº”] Token ä½¿ç”¨:")
                        print(f"    - Prompt Tokens: {usage.get('prompt_tokens', 'N/A')}")
                        print(f"    - Completion Tokens: {usage.get('completion_tokens', 'N/A')}")
                        print(f"    - Total Tokens: {usage.get('total_tokens', 'N/A')}")
                    
                    # æ‰“å° orchestrator_traceï¼ˆå¦‚æœå­˜åœ¨ï¼Œç”¨äºè°ƒè¯•ï¼Œå·²è„±æ•ï¼‰
                    if "orchestrator_trace" in result:
                        trace = result["orchestrator_trace"]
                        print(f"[ğŸ“¥ å“åº”] Orchestrator Trace å­˜åœ¨ï¼Œé•¿åº¦: {len(json.dumps(trace))} å­—ç¬¦")
                        print(f"[ğŸ“¥ å“åº”] Orchestrator Trace (å·²è„±æ•):\n{safe_log_json(trace)}")
                    
                    if content and content.strip():
                        print(f"[ğŸ“¥ å“åº”] Content (å‰1000å­—ç¬¦):\n{content[:1000]}...")
                        print(f"[ğŸ“¥ å“åº”] å®Œæ•´ Content:\n{content}")
                        print(f"{'='*80}\n")
                        return content.strip()
                    else:
                        # å¦‚æœ deepseek å¤±è´¥ï¼Œå°è¯• gemini
                        if model == "deepseek":
                            print(f"    [âš ï¸ è­¦å‘Š] DeepSeek è¿”å›ç©ºå†…å®¹ï¼Œå°è¯• Gemini...")
                            return self.call_llm(prompt, system_prompt, max_tokens, temperature, "gemini-2.5-pro")
                        raise ValueError("API å“åº”ä¸­ content ä¸ºç©ºå­—ç¬¦ä¸²")
                else:
                    print(f"[âŒ é”™è¯¯] API å“åº”æ ¼å¼å¼‚å¸¸ï¼Œç¼ºå°‘ choices å­—æ®µ")
                    raise ValueError(f"API å“åº”æ ¼å¼å¼‚å¸¸")
            else:
                error_text = response.text[:500] if hasattr(response, 'text') else 'N/A'
                print(f"[âŒ é”™è¯¯] API è°ƒç”¨å¤±è´¥")
                print(f"[âŒ é”™è¯¯] çŠ¶æ€ç : {response.status_code}")
                print(f"[âŒ é”™è¯¯] é”™è¯¯å“åº”: {error_text}")
                raise ValueError(f"API è°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
        except requests.exceptions.RequestException as e:
            print(f"[âŒ é”™è¯¯] API è¯·æ±‚å¼‚å¸¸: {str(e)}")
            print(f"[âŒ é”™è¯¯] å¼‚å¸¸ç±»å‹: {type(e).__name__}")
            import traceback
            print(f"[âŒ é”™è¯¯] å¼‚å¸¸å †æ ˆ:\n{traceback.format_exc()}")
            raise ValueError(f"API è¯·æ±‚å¼‚å¸¸: {str(e)}")
    
    def search(self, query: str, max_results: int = 20, include_domains: Optional[List[str]] = None) -> List[SearchResult]:
        """
        ä½¿ç”¨ Tavily æœç´¢
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            max_results: æœ€å¤§ç»“æœæ•°
            include_domains: å¯é€‰çš„åŸŸååˆ—è¡¨ï¼Œç”¨äºé™åˆ¶æœç´¢èŒƒå›´
        """
        # å¦‚æœä½¿ç”¨ç»Ÿä¸€å®¢æˆ·ç«¯ï¼Œå°è¯•ä½¿ç”¨å…¶searchæ–¹æ³•
        if self.use_unified_client:
            try:
                search_results = self.unified_client.search(
                    query=query,
                    max_results=max_results,
                    include_domains=include_domains
                )
                # è½¬æ¢ä¸ºSearchResultå¯¹è±¡ï¼Œå¹¶æ¸…ç†æ ‡é¢˜
                results = []
                for item in search_results:
                    original_title = item.get('title', '')
                    url = item.get('url', '')
                    # æ¸…ç†æ ‡é¢˜
                    cleaned_title = clean_title(original_title, url)
                    # æ¸…ç†æ‘˜è¦
                    raw_snippet = item.get('content', item.get('snippet', item.get('description', '')))
                    cleaned_snippet = clean_snippet(raw_snippet)

                    # ğŸ”¥ æå–search_engineå­—æ®µ
                    search_engine = item.get('search_engine', 'Tavily')

                    results.append(SearchResult(
                        title=cleaned_title,
                        url=url,
                        snippet=cleaned_snippet,
                        source="Tavily",
                        search_engine=search_engine  # ğŸ”¥ ä¼ é€’æœç´¢å¼•æ“å­—æ®µ
                    ))
                return results
            except Exception as e:
                print(f"[âš ï¸] ç»Ÿä¸€å®¢æˆ·ç«¯æœç´¢å¤±è´¥: {str(e)}ï¼Œå›é€€åˆ°åŸæœ‰å®ç°")
                # å›é€€åˆ°åŸæœ‰å®ç°
        
        # åŸæœ‰å®ç°
        endpoint = f"{self.base_url}/v1/search/"
        
        print(f"        [ğŸ” Tavilyæœç´¢] åŸå§‹æŸ¥è¯¢: \"{query}\"")
        print(f"        [âš™ï¸ å‚æ•°] max_results={max_results}, include_domains={include_domains}")
        
        payload = {
            "keywords": [query],
            "max_results": min(max_results, 20)
        }
        
        # å¦‚æœæä¾›äº†åŸŸååˆ—è¡¨ï¼Œå¼ºåˆ¶ç¡®ä¿æŸ¥è¯¢ä¸­åŒ…å«site:è¯­æ³•
        # é‡è¦ï¼šå³ä½¿æŸ¥è¯¢ä¸­å·²æœ‰site:è¯­æ³•ï¼Œæˆ‘ä»¬ä¹Ÿå¼ºåˆ¶é‡æ–°æ„å»ºä»¥ç¡®ä¿æ­£ç¡®æ€§
        if include_domains and len(include_domains) > 0:
            # æ£€æŸ¥æŸ¥è¯¢ä¸­æ˜¯å¦å·²åŒ…å«site:è¯­æ³•
            query_lower = query.lower()
            has_site_syntax = any(f"site:{domain.lower()}" in query_lower for domain in include_domains)
            
            print(f"        [ğŸ” æ£€æŸ¥] æŸ¥è¯¢è¯åŒ…å«site:è¯­æ³•: {has_site_syntax}")
            print(f"        [ğŸ” æ£€æŸ¥] æŸ¥è¯¢è¯: \"{query}\"")
            print(f"        [ğŸ” æ£€æŸ¥] ç›®æ ‡åŸŸå: {include_domains[:5]}")
            
            # å¼ºåˆ¶æ·»åŠ site:è¯­æ³•ï¼ˆå³ä½¿æŸ¥è¯¢ä¸­å·²æœ‰ï¼Œä¹Ÿé‡æ–°æ„å»ºä»¥ç¡®ä¿æ­£ç¡®æ€§ï¼‰
            # é€‰æ‹©å‰5ä¸ªæœ€é‡è¦çš„åŸŸåï¼ˆé¿å…æŸ¥è¯¢è¿‡é•¿ï¼‰
            selected_domains = include_domains[:5]
            domain_site_clause = " OR ".join([f"site:{domain}" for domain in selected_domains])
            
            # å¦‚æœæŸ¥è¯¢ä¸­å·²æœ‰site:è¯­æ³•ï¼Œå…ˆç§»é™¤æ—§çš„site:éƒ¨åˆ†
            if has_site_syntax:
                # å°è¯•ç§»é™¤æ—§çš„site:éƒ¨åˆ†ï¼ˆä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ï¼‰
                # ç§»é™¤ (site:xxx OR site:yyy) è¿™æ ·çš„æ¨¡å¼
                query_cleaned = re.sub(r'\s*\(site:[^)]+\)', '', query, flags=re.IGNORECASE)
                query_cleaned = query_cleaned.strip()
                # å¦‚æœæ¸…ç†åä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹æŸ¥è¯¢
                if not query_cleaned:
                    query_cleaned = query
                enhanced_query = f"{query_cleaned} ({domain_site_clause})"
                print(f"        [ğŸ”§ å¤„ç†] æŸ¥è¯¢ä¸­å·²æœ‰site:è¯­æ³•ï¼Œæ¸…ç†åé‡æ–°æ·»åŠ ")
                print(f"        [ğŸ”§ å¤„ç†] æ¸…ç†åçš„æŸ¥è¯¢: \"{query_cleaned}\"")
            else:
                # å¦‚æœæŸ¥è¯¢ä¸­æ²¡æœ‰site:è¯­æ³•ï¼Œç›´æ¥æ·»åŠ 
                enhanced_query = f"{query} ({domain_site_clause})"
                print(f"        [ğŸ”§ å¤„ç†] æŸ¥è¯¢ä¸­ç¼ºå°‘site:è¯­æ³•ï¼Œæ·»åŠ åŸŸåé™åˆ¶")
            
            payload["keywords"] = [enhanced_query]
            print(f"        [âœ… ç¡®è®¤] æœ€ç»ˆæŸ¥è¯¢ï¼ˆå¼ºåˆ¶åŒ…å«site:è¯­æ³•ï¼‰: \"{enhanced_query}\"")
            print(f"        [âœ… ç¡®è®¤] ä½¿ç”¨çš„åŸŸå: {selected_domains}")
            
            # åŒæ—¶å°è¯•åœ¨payloadä¸­æ·»åŠ include_domainså‚æ•°ï¼ˆå¦‚æœAPIæ”¯æŒï¼‰
            # æ³¨æ„ï¼šè¿™å–å†³äºTavily APIçš„å®é™…å®ç°
            # payload["include_domains"] = include_domains[:5]
        
        print(f"        [ğŸ“¤ è¯·æ±‚] Endpoint: {endpoint}")
        print(f"        [ğŸ“¤ è¯·æ±‚] Payload: {json.dumps(payload, ensure_ascii=False, indent=2)}")
        
        try:
            from llm_client import get_proxy_config
            response = requests.post(
                endpoint,
                headers=self.headers,
                json=payload,
                timeout=30,
                proxies=get_proxy_config()
            )
            
            print(f"        [ğŸ“¥ å“åº”] çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                print(f"[ğŸ“¥ å“åº”] å“åº”ç±»å‹: {type(result).__name__}")
                print(f"[ğŸ“¥ å“åº”] å“åº”é”®: {list(result.keys()) if isinstance(result, dict) else 'N/A'}")
                print(f"[ğŸ“¥ å“åº”] å®Œæ•´ API å“åº”:\n{json.dumps(result, ensure_ascii=False, indent=2)}")
                
                results = []
                
                if isinstance(result, dict) and "queries" in result:
                    queries = result.get("queries", [])
                    print(f"[ğŸ“¥ å“åº”] queries æ•°é‡: {len(queries)}")
                    
                    if queries:
                        query_result = queries[0]
                        tavily_response = query_result.get("response", {})
                        tavily_results = tavily_response.get("results", [])
                        print(f"[ğŸ“¥ å“åº”] Tavily ç»“æœæ•°é‡: {len(tavily_results)}")
                        
                        for idx, item in enumerate(tavily_results[:max_results], 1):
                            # æ¸…ç†æ ‡é¢˜å’Œæ‘˜è¦
                            url = item.get('url', '')
                            original_title = item.get('title', '')
                            cleaned_title = clean_title(original_title, url)
                            raw_snippet = item.get('content', item.get('snippet', item.get('description', '')))
                            cleaned_snippet = clean_snippet(raw_snippet)

                            result_obj = SearchResult(
                                title=cleaned_title,
                                url=url,
                                snippet=cleaned_snippet,
                                source="Tavily",
                                search_engine="Tavily"
                            )
                            results.append(result_obj)
                            print(f"[ğŸ“‹ ç»“æœ{idx}] {result_obj.title[:60]}...")
                            print(f"    URL: {result_obj.url}")
                            print(f"    Snippet é•¿åº¦: {len(result_obj.snippet)} å­—ç¬¦")
                            print(f"    Snippet (å‰200å­—ç¬¦): {result_obj.snippet[:200]}...")
                            # æ£€æŸ¥æ˜¯å¦åŒ¹é…ç›®æ ‡åŸŸå
                            if include_domains:
                                url_lower = result_obj.url.lower()
                                matched = any(domain.lower() in url_lower for domain in include_domains)
                                if matched:
                                    matched_domain = next((d for d in include_domains if d.lower() in url_lower), None)
                                    print(f"    âœ… åŒ¹é…ç›®æ ‡åŸŸå: {matched_domain}")
                                else:
                                    print(f"    âš ï¸ æœªåŒ¹é…ç›®æ ‡åŸŸå")
                    else:
                        print(f"[âš ï¸ å“åº”] queries ä¸ºç©º")
                else:
                    print(f"[âš ï¸ å“åº”] å“åº”æ ¼å¼å¼‚å¸¸ï¼Œç¼ºå°‘ queries å­—æ®µ")
                    print(f"[ğŸ“¥ å“åº”] å“åº”é”®: {list(result.keys()) if isinstance(result, dict) else 'N/A'}")
                
                print(f"[âœ… å®Œæˆ] è¿”å› {len(results)} ä¸ªç»“æœ")
                print(f"{'='*80}\n")
                return results
            else:
                error_text = response.text[:500] if hasattr(response, 'text') else 'N/A'
                print(f"[âŒ é”™è¯¯] æœç´¢ API è°ƒç”¨å¤±è´¥")
                print(f"[âŒ é”™è¯¯] çŠ¶æ€ç : {response.status_code}")
                print(f"[âŒ é”™è¯¯] é”™è¯¯å“åº”: {error_text}")
                raise ValueError(f"æœç´¢ API è°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
        except requests.exceptions.RequestException as e:
            print(f"[âŒ é”™è¯¯] æœç´¢ API è¯·æ±‚å¼‚å¸¸: {str(e)}")
            print(f"[âŒ é”™è¯¯] å¼‚å¸¸ç±»å‹: {type(e).__name__}")
            import traceback
            print(f"[âŒ é”™è¯¯] å¼‚å¸¸å †æ ˆ:\n{traceback.format_exc()}")
            raise ValueError(f"æœç´¢ API è¯·æ±‚å¼‚å¸¸: {str(e)}")


# ============================================================================
# æœç´¢è¯ç”Ÿæˆå™¨
# ============================================================================

# ============================================================================
# ç»“æœè¯„ä¼°å™¨ï¼ˆå¤ç”¨è§„åˆ™åŒ¹é…ï¼‰
# ============================================================================

class ResultEvaluator:
    """ç»“æœè¯„ä¼°å™¨ - ğŸ”’ å½“å‰å·²ç¦ç”¨ï¼ˆå¯é‡æ–°å¯ç”¨ï¼‰"""
    
    def __init__(self, llm_client: Optional[AIBuildersClient] = None):
        self.llm_client = llm_client or AIBuildersClient()
        print(f"    [âœ… ResultEvaluator] åˆå§‹åŒ–ï¼ˆè¯„ä¼°é€»è¾‘å·²ç¦ç”¨ï¼‰")
    
    def _classify_resource_type(self, title: str, url: str, snippet: str) -> str:
        """
        åŸºäºè§„åˆ™å’ŒLLMåˆ†ç±»èµ„æºç±»å‹
        è¿”å›ï¼šæ’­æ”¾åˆ—è¡¨ã€è§†é¢‘ã€æ•™æã€æ•™è¾…ã€ç»ƒä¹ é¢˜ã€å…¶ä»–
        """
        title_lower = title.lower()
        url_lower = url.lower()
        snippet_lower = snippet.lower() if snippet else ""
        combined_text = f"{title_lower} {url_lower} {snippet_lower}"

        # 0. æ’­æ”¾åˆ—è¡¨æ£€æŸ¥ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
        # âš ï¸ æ’é™¤åšä¸»çš„å…¨éƒ¨æ’­æ”¾åˆ—è¡¨é¡µé¢ï¼ˆä¸æ˜¯å•ä¸ªè§†é¢‘åˆé›†ï¼‰
        if any(exclude in url_lower for exclude in ['/playlists$', '/channel/', '/c/', '/user/']):
            # è¿™äº›æ˜¯åšä¸»çš„å…¨éƒ¨æ’­æ”¾åˆ—è¡¨é¡µé¢ï¼Œä¸æ˜¯å•ä¸ªè§†é¢‘åˆé›†
            # ä»ç„¶æ ‡è®°ä¸ºæ’­æ”¾åˆ—è¡¨ç±»å‹ï¼Œä½†ä¼šåœ¨åç»­è¿‡æ»¤ä¸­å¤„ç†
            return "å…¶ä»–"

        # æ£€æŸ¥URLä¸­çš„æ’­æ”¾åˆ—è¡¨ç‰¹å¾ï¼ˆå•ä¸ªå…·ä½“çš„æ’­æ”¾åˆ—è¡¨ï¼‰
        if any(indicator in url_lower for indicator in ['playlist?', 'list=', '/videos']):
            return "æ’­æ”¾åˆ—è¡¨"

        # æ£€æŸ¥æ ‡é¢˜ä¸­çš„æ’­æ”¾åˆ—è¡¨å…³é”®è¯
        playlist_keywords = [
            'playlist', 'play list',
            'complete course', 'full course', 'all lessons',
            'series', 'collection',
            'Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªØ´ØºÙŠÙ„', 'Ø³Ù„Ø³Ù„Ø©',  # é˜¿æ‹‰ä¼¯è¯­
            'æ’­æ”¾åˆ—è¡¨', 'ç³»åˆ—', 'å…¨å¥—', 'å®Œæ•´è¯¾ç¨‹'
        ]
        if any(kw in combined_text for kw in playlist_keywords):
            # å¦‚æœæ ‡é¢˜åŒ…å«æ’­æ”¾åˆ—è¡¨å…³é”®è¯ï¼Œä½†URLæ˜¯/playlistsé¡µé¢ï¼Œåˆ™æ’é™¤
            if '/playlists' in url_lower and not any(ind in url_lower for ind in ['list=', 'playlist?']):
                return "å…¶ä»–"
            return "æ’­æ”¾åˆ—è¡¨"

        # 1. è§†é¢‘ç›¸å…³å…³é”®è¯
        video_keywords = [
            'video', 'youtube.com', 'youtu.be', 'watch',
            'æ’­æ”¾', 'è§†é¢‘', 'video pembelajaran',
            'video lesson', 'tutorial', 'è¯¾ç¨‹è§†é¢‘', 'lecture', 'lesson',
            'vimeo.com', 'bilibili.com/video', 'dailymotion.com'
        ]
        if any(keyword in combined_text for keyword in video_keywords):
            return "è§†é¢‘"

        # 2. ç»ƒä¹ é¢˜ç›¸å…³å…³é”®è¯
        exercise_keywords = [
            'exercise', 'practice', 'quiz', 'test', 'exam', 'worksheet',
            'ç»ƒä¹ é¢˜', 'ç»ƒä¹ ', 'latihan', 'soal', 'ujian', 'kuis',
            'lembar kerja', 'lkpd', 'assess', 'assessment'
        ]
        if any(keyword in combined_text for keyword in exercise_keywords):
            return "ç»ƒä¹ é¢˜"

        # 3. æ•™æç›¸å…³å…³é”®è¯ï¼ˆä¼˜å…ˆçº§é«˜äºæ•™è¾…ï¼‰
        textbook_keywords = [
            'textbook', 'book', 'æ•™æ', 'æ•™ç§‘ä¹¦', 'buku', 'buku pelajaran',
            'modul', 'module', 'coursebook', 'student book',
            'buku siswa', 'buku guru', 'kurikulum'
        ]
        if any(keyword in combined_text for keyword in textbook_keywords):
            return "æ•™æ"

        # 4. æ•™è¾…ç›¸å…³å…³é”®è¯
        supplement_keywords = [
            'guide', 'handbook', 'manual', 'æ•™è¾…', 'å‚è€ƒä¹¦', 'panduan',
            'å‚è€ƒ', 'supplement', 'è¾…åŠ©ææ–™', 'supplementary material',
            'bahan ajar', 'teaching material'
        ]
        if any(keyword in combined_text for keyword in supplement_keywords):
            return "æ•™è¾…"

        # 5. PDFæ–‡ä»¶é€šå¸¸å±äºæ•™ææˆ–æ•™è¾…
        if '.pdf' in url_lower:
            # è¿›ä¸€æ­¥åˆ¤æ–­
            if any(kw in title_lower for kw in ['modul', 'buku', 'textbook', 'kurikulum']):
                return "æ•™æ"
            elif any(kw in title_lower for kw in ['panduan', 'guide', 'handbook']):
                return "æ•™è¾…"
            else:
                return "æ•™æ"

        # 6. å­¦ä¹ èµ„æ–™ç›¸å…³
        learning_keywords = [
            'material', 'resource', 'content', 'å­¦ä¹ èµ„æ–™', 'å­¦ä¹ èµ„æº',
            'materi', 'bahan ajar', 'learning material', 'study material'
        ]
        if any(keyword in combined_text for keyword in learning_keywords):
            return "å…¶ä»–"

        # 7. æ ¹æ®URLæ¨æ–­
        if 'slideshare.net' in url_lower or 'scribd.com' in url_lower:
            return "æ•™è¾…"
        if 'kemdikbud.go.id' in url_lower:
            return "æ•™æ"

        # é»˜è®¤è¿”å›"å…¶ä»–"
        return "å…¶ä»–"
    
    def evaluate_results(self, search_results: List[SearchResult],
                         country: str = "", grade: str = "", subject: str = "") -> List[SearchResult]:
        """
        è¯„ä¼°æœç´¢ç»“æœå¹¶åˆ†ç±»èµ„æºç±»å‹

        åŠŸèƒ½ï¼š
        - ä¸ºæ¯ä¸ªç»“æœåˆ†ç±»èµ„æºç±»å‹ï¼ˆè§†é¢‘ã€æ•™æã€æ•™è¾…ã€ç»ƒä¹ é¢˜ï¼‰
        - è®¾ç½®é»˜è®¤è¯„åˆ†
        """
        if not search_results:
            return search_results

        print(f"    [â„¹ï¸ è¯„ä¼°] å¼€å§‹è¯„ä¼°å’Œåˆ†ç±» {len(search_results)} ä¸ªç»“æœ...")

        for result in search_results:
            # åˆ†ç±»èµ„æºç±»å‹
            resource_type = self._classify_resource_type(result.title, result.url, result.snippet)
            result.resource_type = resource_type

            # è®¾ç½®é»˜è®¤è¯„åˆ†
            if not result.score or result.score == 0:
                result.score = 7.5
            if not result.recommendation_reason:
                result.recommendation_reason = "é»˜è®¤æ¨è"
            if not result.source:
                result.source = "è§„åˆ™"

        # ç»Ÿè®¡åˆ†ç±»ç»“æœ
        type_counts = {}
        for result in search_results:
            rtype = result.resource_type or "æœªåˆ†ç±»"
            type_counts[rtype] = type_counts.get(rtype, 0) + 1

        print(f"    [ğŸ“Š åˆ†ç±»ç»Ÿè®¡] {', '.join([f'{k}:{v}' for k,v in type_counts.items()])}")

        return search_results
    


# ============================================================================
# ä¸»æœç´¢å¼•æ“
# ============================================================================

class SearchEngineV2:
    """æ–°ç‰ˆæœç´¢å¼•æ“"""

    def __init__(self, llm_client: Optional[AIBuildersClient] = None):
        self.llm_client = llm_client or AIBuildersClient()
        self.config_manager = ConfigManager()  # ç”¨äºè¯»å–å›½å®¶é…ç½®

        # åˆå§‹åŒ–æœç´¢ç­–ç•¥ä»£ç†
        self.strategy_agent = SearchStrategyAgent(
            llm_client=self.llm_client,
            config_manager=self.config_manager
        )

        # åˆå§‹åŒ–ç»“æœè¯„ä¼°å™¨
        self.evaluator = ResultEvaluator(llm_client=self.llm_client)

        # ğŸ”¥ ç§»é™¤ QueryGeneratorï¼ˆå·²è¢« IntelligentQueryGenerator æ›¿ä»£ï¼ŒåŠŸèƒ½é‡å¤ï¼‰
        # IntelligentQueryGenerator ä½¿ç”¨æ›´æ–°çš„æ¨¡å‹ï¼ˆgemini-2.5-flash vs deepseekï¼‰ï¼Œæ•ˆæœæ›´å¥½
        # self.query_generator = QueryGenerator(
        #     llm_client=self.llm_client,
        #     config_manager=self.config_manager
        # )

        # ç®€å•çš„é…ç½®ç®¡ç†å™¨å ä½ç¬¦ï¼ˆç”¨äºå¹¶è¡Œæœç´¢é…ç½®ï¼‰
        class SimpleConfigManager:
            def get_search_config(self):
                return {
                    'edtech_domains': [
                        'khanacademy.org', 'coursera.org', 'edx.org',
                        'youtube.com', 'vimeo.com', 'dailymotion.com'
                    ],
                    'localization': {
                        'ar': 'ÙÙŠØ¯ÙŠÙˆ ØªØ¹Ù„ÙŠÙ…ÙŠ',
                        'en': 'Video lesson',
                        'id': 'Video pelajaran',
                        'zh': 'æ•™å­¦è§†é¢‘'
                    }
                }

        self.app_config = SimpleConfigManager()

        self.search_cache = get_search_cache()  # æœç´¢ç»“æœç¼“å­˜
        # è¯„åˆ†å™¨å°†åœ¨searchæ–¹æ³•ä¸­æ ¹æ®country_codeåŠ¨æ€åˆå§‹åŒ–ï¼ˆå¸¦çŸ¥è¯†åº“ï¼‰
        self.result_scorer = None  # å°†åœ¨searchæ—¶åˆå§‹åŒ–ä¸ºå¸¦çŸ¥è¯†åº“çš„è¯„åˆ†å™¨
        self.result_scorer_without_kb = get_result_scorer()  # æ— çŸ¥è¯†åº“çš„å¤‡ç”¨è¯„åˆ†å™¨
        self._scorer_cache = {}  # ç¼“å­˜å„å›½çš„è¯„åˆ†å™¨ {country_code: scorer}
        self.recommendation_generator = get_recommendation_generator()  # LLMæ¨èç†ç”±ç”Ÿæˆå™¨
        print(f"    [âœ…] æ™ºèƒ½è¯„åˆ†å™¨å·²åˆå§‹åŒ–ï¼ˆå°†åœ¨æœç´¢æ—¶åŠ è½½çŸ¥è¯†åº“ï¼‰")
        print(f"    [âœ…] LLMæ¨èç†ç”±ç”Ÿæˆå™¨å·²åˆå§‹åŒ–")

        # åˆå§‹åŒ–ç™¾åº¦æœç´¢å®¢æˆ·ç«¯ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
        self.baidu_search_enabled = False
        try:
            baidu_api_key = os.getenv("BAIDU_API_KEY")
            if baidu_api_key:
                from search_strategist import SearchHunter
                self.baidu_hunter = SearchHunter(search_engine="baidu", llm_client=None)
                self.baidu_search_enabled = True
                print(f"    [âœ…] ç™¾åº¦æœç´¢å·²å¯ç”¨")
            else:
                print(f"    [â„¹ï¸] ç™¾åº¦æœç´¢æœªé…ç½®ï¼ˆBAIDU_API_KEYæœªè®¾ç½®ï¼‰")
        except Exception as e:
            print(f"    [âš ï¸] ç™¾åº¦æœç´¢åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.baidu_search_enabled = False

        # åˆå§‹åŒ– Google æœç´¢å®¢æˆ·ç«¯ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
        self.google_search_enabled = False
        try:
            google_api_key = os.getenv("GOOGLE_API_KEY")
            google_cx = os.getenv("GOOGLE_CX")
            if google_api_key and google_cx:
                from search_strategist import SearchHunter
                self.google_hunter = SearchHunter(search_engine="google", llm_client=None)
                self.google_search_enabled = True
                print(f"    [âœ…] Google æœç´¢å·²å¯ç”¨")
            else:
                print(f"    [â„¹ï¸] Google æœç´¢æœªé…ç½®ï¼ˆéœ€è¦ GOOGLE_API_KEY å’Œ GOOGLE_CXï¼‰")
        except Exception as e:
            print(f"    [âš ï¸] Google æœç´¢åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.google_search_enabled = False

    def _get_memory_usage(self) -> str:
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        try:
            import resource
            import sys
            rss_kb = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
            if sys.platform == 'darwin':
                rss_mb = rss_kb / 1024 / 1024
            else:
                rss_mb = rss_kb / 1024
            return f"{rss_mb:.1f} MB"
        except:
            return "Unknown"

    def _cached_search(self, query: str, search_func, engine_name: str, max_results: int = 15,
                       include_domains: Optional[List[str]] = None) -> List[SearchResult]:
        """
        å¸¦ç¼“å­˜çš„æœç´¢åŒ…è£…å™¨

        Args:
            query: æœç´¢æŸ¥è¯¢
            search_func: å®é™…çš„æœç´¢å‡½æ•°
            engine_name: æœç´¢å¼•æ“åç§°ï¼ˆç”¨äºç¼“å­˜é”®ï¼‰
            max_results: æœ€å¤§ç»“æœæ•°
            include_domains: åŒ…å«çš„åŸŸååˆ—è¡¨

        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        # å°è¯•ä»ç¼“å­˜è·å–
        cache_key = f"{query}_{max_results}_{include_domains}"
        cached_result = self.search_cache.get(cache_key, engine_name)

        if cached_result is not None:
            logger.info(f"âœ… ç¼“å­˜å‘½ä¸­ [{engine_name}]: {query[:50]}...")
            # ä»ç¼“å­˜æ•°æ®é‡å»ºSearchResultå¯¹è±¡
            return [SearchResult(**item) for item in cached_result]

        # ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œå®é™…æœç´¢
        logger.info(f"âŒ ç¼“å­˜æœªå‘½ä¸­ [{engine_name}]: {query[:50]}...")
        results = search_func(query, max_results, include_domains)

        # å°†ç»“æœå­˜å…¥ç¼“å­˜
        results_dict = [result.model_dump() for result in results]
        self.search_cache.set(cache_key, results_dict, engine_name,
                             metadata={"query": query, "max_results": max_results})

        return results

    def _parallel_search(self, query: str, search_tasks: List[Dict[str, Any]],
                        timeout: int = 30, country_code: str = "CN") -> Dict[str, List[SearchResult]]:
        """
        å¹¶è¡Œæ‰§è¡Œå¤šä¸ªæœç´¢ä»»åŠ¡

        Args:
            query: é»˜è®¤æœç´¢æŸ¥è¯¢ï¼ˆå¦‚æœä»»åŠ¡æ²¡æœ‰æŒ‡å®šæŸ¥è¯¢ï¼Œåˆ™ä½¿ç”¨æ­¤æŸ¥è¯¢ï¼‰
            search_tasks: æœç´¢ä»»åŠ¡åˆ—è¡¨ï¼Œæ¯ä¸ªä»»åŠ¡åŒ…å«:
                - name: ä»»åŠ¡åç§°
                - query: ä»»åŠ¡ç‰¹å®šçš„æœç´¢æŸ¥è¯¢ï¼ˆå¯é€‰ï¼Œä¼˜å…ˆçº§é«˜äºé»˜è®¤queryï¼‰
                - func: æœç´¢å‡½æ•°
                - engine_name: æœç´¢å¼•æ“åç§°ï¼ˆç”¨äºç¼“å­˜ï¼‰
                - max_results: æœ€å¤§ç»“æœæ•°
                - include_domains: åŒ…å«çš„åŸŸåï¼ˆå¯é€‰ï¼‰
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            country_code: å›½å®¶ä»£ç ï¼ˆç”¨äºå…è´¹é¢åº¦ä¼˜å…ˆç­–ç•¥ï¼‰

        Returns:
            å­—å…¸ï¼Œé”®ä¸ºä»»åŠ¡åç§°ï¼Œå€¼ä¸ºæœç´¢ç»“æœåˆ—è¡¨
        """
        results = {}
        start_time = time.time()

        print(f"    [âš¡ å¹¶è¡Œæœç´¢] å¯åŠ¨ {len(search_tasks)} ä¸ªå¹¶è¡Œæœç´¢ä»»åŠ¡")
        print(f"    [âš™ï¸ å‚æ•°] è¶…æ—¶æ—¶é—´: {timeout}ç§’, å›½å®¶ä»£ç : {country_code}")

        def execute_search_task(task: Dict[str, Any]) -> tuple:
            """æ‰§è¡Œå•ä¸ªæœç´¢ä»»åŠ¡"""
            task_name = task['name']
            search_func = task['func']
            engine_name = task['engine_name']
            max_results = task.get('max_results', 15)
            include_domains = task.get('include_domains', None)
            # ä½¿ç”¨ä»»åŠ¡ç‰¹å®šçš„æŸ¥è¯¢ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤æŸ¥è¯¢
            task_query = task.get('query', query)

            try:
                task_start = time.time()

                # åˆ¤æ–­æ˜¯å¦æ˜¯ llm_client.searchï¼ˆæ”¯æŒ country_code å‚æ•°ï¼‰
                # æ£€æŸ¥æ˜¯å¦æ˜¯ UnifiedLLMClient çš„æ–¹æ³•
                is_llm_client_search = (
                    hasattr(search_func, '__self__') and
                    isinstance(search_func.__self__, UnifiedLLMClient) and
                    search_func.__name__ == 'search'
                )

                if is_llm_client_search:
                    # llm_client.search æ”¯æŒ country_code å‚æ•°ï¼ˆå…è´¹é¢åº¦ä¼˜å…ˆç­–ç•¥ï¼‰
                    task_results = self._cached_search(
                        query=task_query,
                        search_func=lambda q, mr, id: search_func(q, max_results=mr, include_domains=include_domains, country_code=country_code),
                        engine_name=engine_name,
                        max_results=max_results,
                        include_domains=include_domains
                    )
                else:
                    # å…¶ä»–æœç´¢å‡½æ•°ï¼ˆgoogle_hunter.search, baidu_hunter.searchï¼‰ä¸æ”¯æŒ country_code
                    task_results = self._cached_search(
                        query=task_query,
                        search_func=lambda q, mr, id: search_func(q, max_results=mr),
                        engine_name=engine_name,
                        max_results=max_results,
                        include_domains=include_domains
                    )

                task_elapsed = time.time() - task_start
                print(f"    [âœ… {task_name}] å®Œæˆ ({task_elapsed:.2f}ç§’, {len(task_results)}ä¸ªç»“æœ)")
                return (task_name, task_results)
            except Exception as e:
                print(f"    [âŒ {task_name}] å¤±è´¥: {str(e)}")
                logger.error(f"å¹¶è¡Œæœç´¢ä»»åŠ¡å¤±è´¥ [{task_name}]: {str(e)}")
                return (task_name, [])

        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œæ‰§è¡Œæœç´¢ï¼ˆTODOï¼šæœªæ¥è¿ç§»åˆ°aiohttpä»¥å®ç°çœŸæ­£çš„å¼‚æ­¥I/Oï¼‰
        # å½“å‰ä½¿ç”¨ThreadPoolExecutoråŒ…è£…åŒæ­¥requestsè°ƒç”¨ï¼Œå·²å¯å¹¶å‘æ‰§è¡Œä½†ä»æœ‰æ”¹è¿›ç©ºé—´
        # ä¼˜åŒ–å»ºè®®ï¼šä½¿ç”¨aiohttp + asyncioå®ç°å¼‚æ­¥HTTPè¯·æ±‚ï¼Œæ€§èƒ½å¯æå‡30%+
        with ThreadPoolExecutor(max_workers=min(len(search_tasks), 10)) as executor:  # å¢åŠ å¹¶å‘åº¦ï¼ˆP1ä¿®å¤ï¼‰
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_task = {
                executor.submit(execute_search_task, task): task
                for task in search_tasks
            }

            # æ”¶é›†å®Œæˆçš„ä»»åŠ¡ç»“æœï¼ˆæ·»åŠ è¶…æ—¶ä¿æŠ¤ï¼‰
            try:
                for future in as_completed(future_to_task, timeout=timeout):
                    try:
                        task_name, task_results = future.result(timeout=1.0)  # å•ä¸ªfutureç»“æœè·å–è¶…æ—¶
                        results[task_name] = task_results
                    except concurrent.futures.TimeoutError:
                        logger.warning(f"ä»»åŠ¡ {future_to_task[future].get('name', 'unknown')} ç»“æœè·å–è¶…æ—¶")
                        results[future_to_task[future].get('name', 'unknown')] = []
                    except Exception as e:
                        logger.error(f"ä»»åŠ¡ç»“æœå¤„ç†å¤±è´¥: {str(e)}")
                        results[future_to_task[future].get('name', 'unknown')] = []
            except concurrent.futures.TimeoutError:
                logger.warning(f"å¹¶è¡Œæœç´¢æ•´ä½“è¶…æ—¶ ({timeout}ç§’)ï¼Œå·²æ”¶é›†éƒ¨åˆ†ç»“æœ")
                # å°è¯•è·å–å·²å®Œæˆçš„ä»»åŠ¡ç»“æœ
                for future in future_to_task:
                    if future.done():
                        try:
                            task_name, task_results = future.result(timeout=0.5)
                            if task_name not in results:
                                results[task_name] = task_results
                        except:
                            pass

        elapsed_time = time.time() - start_time
        total_results = sum(len(r) for r in results.values())
        print(f"    [âš¡ å¹¶è¡Œæœç´¢] å®Œæˆï¼Œè€—æ—¶ {elapsed_time:.2f}ç§’ï¼Œå…± {total_results} ä¸ªç»“æœ")

        return results

    def _is_edtech_domain(self, url: str) -> bool:
        """
        æ£€æŸ¥URLæ˜¯å¦æ¥è‡ªEdTechå¹³å°ï¼ˆçŸ¥åæ•™è‚²å¹³å°ï¼‰

        Args:
            url: è¦æ£€æŸ¥çš„URL

        Returns:
            æ˜¯å¦æ¥è‡ªEdTechå¹³å°
        """
        try:
            search_config = self.app_config.get_search_config()
            edtech_domains = search_config.get('edtech_domains', [])

            url_lower = url.lower()
            for domain in edtech_domains:
                if domain.lower() in url_lower:
                    logger.debug(f"æ£€æµ‹åˆ°EdTechå¹³å°: {domain}")
                    return True

            return False
        except Exception as e:
            logger.warning(f"æ£€æŸ¥EdTechåŸŸåå¤±è´¥: {str(e)}")
            return False

    def _generate_fallback_query(self, request: SearchRequest) -> str:
        """
        ç”Ÿæˆé™çº§æœç´¢è¯ï¼ˆè§„åˆ™ç”Ÿæˆï¼Œä¸ä½¿ç”¨LLMï¼‰

        Args:
            request: æœç´¢è¯·æ±‚

        Returns:
            æœç´¢è¯
        """
        # è§„åˆ™ç”Ÿæˆé»˜è®¤æœç´¢è¯
        default_query = f"{request.subject} {request.grade} playlist"
        if request.semester:
            default_query += f" semester {request.semester}"

        logger.info(f"[ğŸ”„ è§„åˆ™ç”Ÿæˆ] ç”Ÿæˆé»˜è®¤æœç´¢è¯: \"{default_query}\"")
        return default_query

    def search(self, request: SearchRequest) -> SearchResponse:
        """
        æ‰§è¡Œæœç´¢

        Args:
            request: æœç´¢è¯·æ±‚

        Returns:
            æœç´¢å“åº”
        """
        # æ€§èƒ½ç›‘æ§ - å¼€å§‹è®¡æ—¶
        search_start_time = time.time()

        # ğŸ” è¯¦ç»†æ—¥å¿—ï¼šæœç´¢å¼€å§‹
        logger.info("="*80)
        logger.info(f"ğŸ” [æœç´¢å¼€å§‹] {request.country} - {request.grade} - {request.subject}")
        logger.info(f"   æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info(f"   å†…å­˜ä½¿ç”¨: {self._get_memory_usage()}")
        logger.info("="*80)

        print(f"\n{'='*80}")
        print(f"ğŸ” å¼€å§‹æœç´¢")
        print(f"{'='*80}")
        print(f"å›½å®¶: {request.country}")
        print(f"å¹´çº§: {request.grade}")
        print(f"å­¦æœŸ: {request.semester or 'ä¸æŒ‡å®š'}")
        print(f"å­¦ç§‘: {request.subject}")
        print(f"{'='*80}\n")

        # ========== å¹´çº§-å­¦ç§‘é…å¯¹éªŒè¯ ==========
        logger.info(f"[æ­¥éª¤ 0] å¹´çº§-å­¦ç§‘é…å¯¹éªŒè¯...")
        print(f"[éªŒè¯] æ£€æŸ¥å¹´çº§-å­¦ç§‘é…å¯¹...")
        try:
            validator = GradeSubjectValidator()
            validation_result = validator.validate(
                request.country,
                request.grade,
                request.subject
            )

            if not validation_result["valid"]:
                # é…å¯¹ä¸åˆæ³•ï¼Œæ˜¾ç¤ºè­¦å‘Šä½†ä»å…è®¸æœç´¢
                warning_msg = f"âš ï¸ {validation_result['reason']}"
                print(f"    {warning_msg}")
                if validation_result.get("suggestions"):
                    print(f"    ğŸ’¡ å»ºè®®: {', '.join(validation_result['suggestions'][:5])}")
                logger.warning(f"å¹´çº§-å­¦ç§‘é…å¯¹éªŒè¯å¤±è´¥: {request.country} {request.grade} {request.subject}")
            else:
                print(f"    âœ… å¹´çº§-å­¦ç§‘é…å¯¹éªŒè¯é€šè¿‡")
                logger.info(f"   âœ… é…å¯¹éªŒè¯é€šè¿‡")
        except Exception as e:
            print(f"    âš ï¸ éªŒè¯å¤±è´¥ï¼Œç»§ç»­æœç´¢: {str(e)}")
            logger.warning(f"é…å¯¹éªŒè¯å¼‚å¸¸: {str(e)}")
        # ========== éªŒè¯ç»“æŸ ==========

        # ========== ğŸ“š åˆå§‹åŒ–å¸¦çŸ¥è¯†åº“çš„è¯„åˆ†å™¨ ==========
        try:
            from core.result_scorer import IntelligentResultScorer

            # æ£€æŸ¥ç¼“å­˜ä¸­æ˜¯å¦å·²æœ‰è¯¥å›½å®¶çš„è¯„åˆ†å™¨
            country_code = request.country.upper()
            if country_code not in self._scorer_cache:
                # åˆ›å»ºå¸¦çŸ¥è¯†åº“çš„è¯„åˆ†å™¨
                self.result_scorer = IntelligentResultScorer(country_code=country_code)
                self._scorer_cache[country_code] = self.result_scorer
                logger.info(f"[ğŸ“š çŸ¥è¯†åº“] å·²åŠ è½½ {country_code} è¯„åˆ†å™¨ï¼ˆå¸¦çŸ¥è¯†åº“ï¼‰")
                print(f"    [âœ… çŸ¥è¯†åº“] å·²åŠ è½½ {country_code} æœç´¢çŸ¥è¯†åº“")
            else:
                # ä½¿ç”¨ç¼“å­˜çš„è¯„åˆ†å™¨
                self.result_scorer = self._scorer_cache[country_code]
                logger.debug(f"[ğŸ“š çŸ¥è¯†åº“] ä½¿ç”¨ç¼“å­˜çš„ {country_code} è¯„åˆ†å™¨")

        except Exception as e:
            # å¦‚æœçŸ¥è¯†åº“åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨ä¸å¸¦çŸ¥è¯†åº“çš„è¯„åˆ†å™¨
            logger.warning(f"[ğŸ“š çŸ¥è¯†åº“] åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨è¯„åˆ†å™¨: {str(e)}")
            self.result_scorer = self.result_scorer_without_kb
        # ========== è¯„åˆ†å™¨åˆå§‹åŒ–ç»“æŸ ==========

        try:
            # Step 0: ç”Ÿæˆæœç´¢ç­–ç•¥
            step0_start = time.time()
            logger.info(f"[æ­¥éª¤ 0] åˆ¶å®šæœç´¢ç­–ç•¥...")
            print(f"[æ­¥éª¤ 0] åˆ¶å®šæœç´¢ç­–ç•¥...")
            strategy = self.strategy_agent.generate_strategy(
                country=request.country,
                grade=request.grade,
                subject=request.subject,
                semester=request.semester
            )
            print(f"    [âœ… ç­–ç•¥] æœç´¢è¯­è¨€: {strategy.search_language}")
            print(f"    [âœ… ç­–ç•¥] ä½¿ç”¨ä¸­æ–‡æœç´¢å¼•æ“: {strategy.use_chinese_search_engine}")
            print(f"    [âœ… ç­–ç•¥] å¹³å°åˆ—è¡¨: {', '.join(strategy.platforms[:5])}")
            print(f"    [âœ… ç­–ç•¥] ä¼˜å…ˆåŸŸå: {', '.join(strategy.priority_domains[:5])}")
            if strategy.notes:
                print(f"    [ğŸ“ ç­–ç•¥è¯´æ˜] {strategy.notes}")
            
            # Step 1: ç”Ÿæˆæœç´¢è¯ï¼ˆä¼˜å…ˆä½¿ç”¨æ™ºèƒ½æŸ¥è¯¢ç”Ÿæˆå™¨ï¼‰
            print(f"\n[æ­¥éª¤ 1] ç”Ÿæˆæ™ºèƒ½æœç´¢è¯...")

            # å°è¯•ä½¿ç”¨IntelligentQueryGenerator
            try:
                from core.intelligent_query_generator import get_intelligent_query_generator
                intelligent_gen = get_intelligent_query_generator()

                query = intelligent_gen.generate_query(
                    country=request.country,
                    grade=request.grade,
                    subject=request.subject,
                    semester=request.semester
                )

                print(f"    [ğŸ¤– æ™ºèƒ½ç”Ÿæˆ] æœç´¢è¯: \"{query}\"")
                print(f"    [âœ… ä¼˜åŠ¿] LLMè‡ªåŠ¨è¯†åˆ«è¯­è¨€å’Œæœ¯è¯­ï¼Œæ”¯æŒå¤šç§è¾“å…¥æ ¼å¼")

                # å°†æ™ºèƒ½ç”Ÿæˆçš„æŸ¥è¯¢æ·»åŠ åˆ°ç­–ç•¥ä¸­
                strategy.search_queries.insert(0, query)

            except Exception as e:
                print(f"    [âš ï¸ æ™ºèƒ½ç”Ÿæˆå¤±è´¥ï¼Œé™çº§åˆ°ç­–ç•¥ç”Ÿæˆå™¨] {str(e)}")
                logger.warning(f"IntelligentQueryGeneratorå¤±è´¥: {str(e)}ï¼Œä½¿ç”¨ç­–ç•¥ç”Ÿæˆå™¨")

                # é™çº§ï¼šä½¿ç”¨ç­–ç•¥ä¸­çš„æœç´¢è¯æˆ–è§„åˆ™ç”Ÿæˆ
                if strategy.search_queries:
                    # ä½¿ç”¨ç­–ç•¥ä¸­çš„ç¬¬ä¸€ä¸ªæœç´¢è¯ä½œä¸ºä¸»æŸ¥è¯¢
                    query = strategy.search_queries[0]
                    print(f"    [âœ… ä½¿ç”¨ç­–ç•¥æœç´¢è¯] \"{query}\"")
                else:
                    # ğŸ”¥ å¦‚æœæ²¡æœ‰ç­–ç•¥æœç´¢è¯ï¼Œä½¿ç”¨è§„åˆ™ç”Ÿæˆï¼ˆç§»é™¤äº†QueryGeneratorï¼‰
                    # QueryGenerator å·²è¢« IntelligentQueryGenerator æ›¿ä»£ï¼ŒåŠŸèƒ½é‡å¤
                    query = self._generate_fallback_query(request)
                    print(f"    [âœ… ä½¿ç”¨è§„åˆ™ç”Ÿæˆæœç´¢è¯] \"{query}\"")
                    strategy.search_queries = [query]  # å°†ç”Ÿæˆçš„æŸ¥è¯¢æ·»åŠ åˆ°ç­–ç•¥ä¸­

            # æ˜¾ç¤ºæ‰€æœ‰æœç´¢è¯å˜ä½“
            if len(strategy.search_queries) > 1:
                print(f"    [ğŸ¯ æ’­æ”¾åˆ—è¡¨ä¼˜åŒ–] å…±æœ‰ {len(strategy.search_queries)} ä¸ªæœç´¢è¯å˜ä½“")
                for i, q in enumerate(strategy.search_queries, 1):
                    is_playlist_query = any(kw in q.lower() for kw in ['playlist', 'complete course', 'full series', 'koleksi', 'kursus lengkap', 'æ’­æ”¾åˆ—è¡¨', 'å®Œæ•´è¯¾ç¨‹', 'ç³»åˆ—'])
                    marker = "ğŸ [æ’­æ”¾åˆ—è¡¨]" if is_playlist_query else "ğŸ“¹ [å¸¸è§„]"
                    print(f"      {marker} {i}. \"{q}\"")

            # Step 2: æ‰§è¡Œæ··åˆæœç´¢ï¼ˆé€šç”¨æœç´¢ + æœ¬åœ°å®šå‘æœç´¢ï¼‰
            print(f"\n[æ­¥éª¤ 2] æ‰§è¡Œæ··åˆæœç´¢...")

            # ========== å¹¶è¡Œæœç´¢å®ç° (æ–°ç‰ˆæœ¬) ==========
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨å¹¶è¡Œæœç´¢ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
            use_parallel_search = os.getenv("ENABLE_PARALLEL_SEARCH", "true").lower() == "true"

            if use_parallel_search:
                print(f"    [âš¡ æ¨¡å¼] ä½¿ç”¨å¹¶è¡Œæœç´¢")

                # å‡†å¤‡å›½å®¶é…ç½®
                country_code_upper = request.country.upper()
                country_config = self.config_manager.get_country_config(country_code_upper)

                # ä½¿ç”¨ç­–ç•¥ä¸­çš„ä¼˜å…ˆåŸŸåï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é…ç½®ä¸­çš„åŸŸå
                if strategy.priority_domains:
                    selected_domains = strategy.priority_domains[:5]
                elif country_config and country_config.domains:
                    selected_domains = country_config.domains[:5]
                else:
                    selected_domains = []

                # æ„å»ºå¹¶è¡Œæœç´¢ä»»åŠ¡åˆ—è¡¨
                search_tasks = []

                # ä½¿ç”¨ç­–ç•¥ä¸­çš„å¤šä¸ªæœç´¢è¯è¿›è¡Œæœç´¢ï¼ˆä¼˜å…ˆæ’­æ”¾åˆ—è¡¨ç›¸å…³æŸ¥è¯¢ï¼‰
                # å–å‰3ä¸ªæœç´¢è¯ï¼Œç¡®ä¿è‡³å°‘åŒ…å«æ’­æ”¾åˆ—è¡¨æŸ¥è¯¢
                queries_to_use = strategy.search_queries[:3] if len(strategy.search_queries) >= 3 else strategy.search_queries
                print(f"    [ğŸ¯ å¤šæŸ¥è¯¢æœç´¢] å°†ä½¿ç”¨ {len(queries_to_use)} ä¸ªæœç´¢è¯è¿›è¡Œæœç´¢")

                # Googleæœç´¢ï¼ˆGoogleä¼˜å…ˆç­–ç•¥ï¼‰- å¯¹æ¯ä¸ªæŸ¥è¯¢éƒ½æ‰§è¡Œï¼ˆ3æ¬¡ï¼‰âœ… ä¸»è¦å¼•æ“
                if self.google_search_enabled:
                    for query_idx, search_query in enumerate(queries_to_use, 1):
                        is_playlist_focused = any(kw in search_query.lower() for kw in ['playlist', 'complete course', 'full series', 'koleksi', 'kursus lengkap', 'æ’­æ”¾åˆ—è¡¨', 'å®Œæ•´è¯¾ç¨‹', 'ç³»åˆ—'])
                        query_type = "æ’­æ”¾åˆ—è¡¨" if is_playlist_focused else "å¸¸è§„"

                        search_tasks.append({
                            'name': f'Googleæœç´¢ [{query_type}] #{query_idx}',
                            'query': search_query,  # ä½¿ç”¨ç‰¹å®šçš„æœç´¢è¯
                            'func': self.google_hunter.search,
                            'engine_name': 'Google',
                            'max_results': 10,  # å‡å°‘æ¯ä¸ªæŸ¥è¯¢çš„ç»“æœæ•°ï¼Œé¿å…è¿‡å¤šé‡å¤
                            'include_domains': None
                        })

                # Tavily/Metasoæœç´¢ - åªä½¿ç”¨ç¬¬ä¸€ä¸ªæŸ¥è¯¢ï¼ˆ1æ¬¡ï¼‰âœ… è¾…åŠ©å¼•æ“
                if len(queries_to_use) > 0:
                    search_tasks.append({
                        'name': 'Tavily/Metasoæœç´¢',
                        'query': queries_to_use[0],  # åªç”¨ç¬¬ä¸€ä¸ªæŸ¥è¯¢
                        'func': self.llm_client.search,  # å†…éƒ¨ä¼šæ ¹æ®å…è´¹é¢åº¦ä¼˜å…ˆé€‰æ‹©Tavilyæˆ–Metaso
                        'engine_name': 'Tavily/Metaso',
                        'max_results': 15,
                        'include_domains': None
                    })

                # ä»»åŠ¡3: ç™¾åº¦æœç´¢ï¼ˆå¦‚æœå¯ç”¨ä¸”éœ€è¦ä¸­æ–‡æœç´¢ï¼‰
                if strategy.use_chinese_search_engine and self.baidu_search_enabled and len(queries_to_use) > 0:
                    search_tasks.append({
                        'name': 'ç™¾åº¦æœç´¢',
                        'query': queries_to_use[0],  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæŸ¥è¯¢
                        'func': self.baidu_hunter.search,
                        'engine_name': 'Baidu',
                        'max_results': 15,
                        'include_domains': None
                    })

                # ä»»åŠ¡4: æœ¬åœ°å®šå‘æœç´¢ï¼ˆå¦‚æœæœ‰åŸŸåé…ç½®ï¼‰
                if selected_domains:
                    # æ„å»ºæœ¬åœ°æœç´¢æŸ¥è¯¢
                    base_query = query.replace("playlist", "").replace("Playlist", "").strip()

                    # ä»é…ç½®è¯»å–æœ¬åœ°åŒ–å…³é”®è¯
                    try:
                        search_config = self.app_config.get_search_config()
                        localization_keywords = search_config.get('localization', {})
                        country_language = country_config.language_code if country_config else "en"
                        local_keyword = localization_keywords.get(country_language, "Video lesson")
                        logger.debug(f"ä»é…ç½®è¯»å–æœ¬åœ°åŒ–å…³é”®è¯: {country_language} -> {local_keyword}")
                    except Exception as e:
                        # é™çº§ä¸ºç¡¬ç¼–ç æ˜ å°„
                        logger.warning(f"ä»é…ç½®è¯»å–æœ¬åœ°åŒ–å…³é”®è¯å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨ç¡¬ç¼–ç æ˜ å°„")
                        language_map = {
                            "id": "Video pembelajaran",
                            "en": "Video lesson",
                            "zh": "æ•™å­¦è§†é¢‘",
                            "ms": "Video pembelajaran",
                            "ar": "ÙÙŠØ¯ÙŠÙˆ ØªØ¹Ù„ÙŠÙ…ÙŠ",
                            "ru": "Ğ’Ğ¸Ğ´ĞµĞ¾ ÑƒÑ€Ğ¾Ğº",
                        }
                        country_language = country_config.language_code if country_config else "en"
                        local_keyword = language_map.get(country_language, "Video lesson")

                    # æ„å»ºçº¯å‡€æŸ¥è¯¢
                    clean_query_parts = []
                    if request.subject:
                        clean_query_parts.append(request.subject)
                    if request.grade:
                        clean_query_parts.append(request.grade)
                    if request.semester:
                        clean_query_parts.append(request.semester)

                    local_base_query = " ".join(clean_query_parts) if clean_query_parts else base_query
                    local_query = f"{local_base_query} {local_keyword}".strip()

                    search_tasks.append({
                        'name': f'æœ¬åœ°å®šå‘æœç´¢({country_code_upper})',
                        'func': self.llm_client.search,
                        'engine_name': f'Local-{country_code_upper}',
                        'max_results': 10,
                        'include_domains': selected_domains
                    })

                # æ‰§è¡Œå¹¶è¡Œæœç´¢ï¼ˆä¼ é€’ country_code ç”¨äºå…è´¹é¢åº¦ä¼˜å…ˆç­–ç•¥ï¼‰
                parallel_results = self._parallel_search(query, search_tasks, timeout=30, country_code=request.country)

                # åˆå¹¶æ‰€æœ‰ç»“æœ
                search_results_a = []
                search_results_b = []

                for task_name, results in parallel_results.items():
                    if 'æœ¬åœ°' in task_name or 'Local' in task_name:
                        search_results_b.extend(results)
                    else:
                        search_results_a.extend(results)

                # æ˜¾ç¤ºç»“æœè¯¦æƒ…
                if search_results_a:
                    print(f"    [ğŸ“‹ é€šç”¨æœç´¢ç»“æœ] å…± {len(search_results_a)} ä¸ª")
                    for idx, result in enumerate(search_results_a[:3], 1):
                        print(f"        {idx}. {result.title[:60]}...")

                if search_results_b:
                    print(f"    [ğŸ“‹ æœ¬åœ°æœç´¢ç»“æœ] å…± {len(search_results_b)} ä¸ª")
                    for idx, result in enumerate(search_results_b[:3], 1):
                        print(f"        {idx}. {result.title[:60]}...")

            else:
                # ========== ä¸²è¡Œæœç´¢å®ç° (åŸç‰ˆæœ¬) ==========
                print(f"    [ğŸ”„ æ¨¡å¼] ä½¿ç”¨ä¸²è¡Œæœç´¢")

                # æœç´¢ A: é€šç”¨æœç´¢ï¼ˆä¸»è¦è¦†ç›– YouTubeï¼‰
            # å¦‚æœç­–ç•¥è¦æ±‚ä½¿ç”¨ä¸­æ–‡æœç´¢å¼•æ“ï¼Œä¸”ç™¾åº¦æœç´¢å·²é…ç½®ï¼Œåˆ™ä½¿ç”¨ç™¾åº¦æœç´¢
            if strategy.use_chinese_search_engine and self.baidu_search_enabled:
                print(f"    [ğŸŒ ç­–ç•¥] æ£€æµ‹åˆ°éœ€è¦ä½¿ç”¨ä¸­æ–‡æœç´¢å¼•æ“ï¼Œä½¿ç”¨ç™¾åº¦æœç´¢")
                print(f"    [ğŸ” æœç´¢A-ç™¾åº¦æœç´¢] æŸ¥è¯¢: \"{query}\"")
                print(f"    [âš™ï¸ å‚æ•°] max_results=15")
                try:
                    baidu_results = self.baidu_hunter.search(query, max_results=15)
                    # è½¬æ¢ä¸ºSearchResultå¯¹è±¡
                    search_results_a = []
                    for item in baidu_results:
                        search_results_a.append(SearchResult(
                            title=item.title,
                            url=item.url,
                            snippet=item.snippet,
                            source="ç™¾åº¦æœç´¢",
                            search_engine="Baidu"
                        ))
                    print(f"    [âœ… æœç´¢A-ç™¾åº¦] æ‰¾åˆ° {len(search_results_a)} ä¸ªç»“æœ")
                except Exception as e:
                    print(f"    [âŒ é”™è¯¯] ç™¾åº¦æœç´¢å¤±è´¥: {str(e)}")
                    # é™çº§åˆ° Google æœç´¢ï¼ˆå¦‚æœå¯ç”¨ï¼‰æˆ– Tavily
                    if self.google_search_enabled:
                        print(f"    [ğŸ”„ é™çº§] åˆ‡æ¢åˆ° Google æœç´¢...")
                        try:
                            google_results = self.google_hunter.search(query, max_results=15)
                            search_results_a = []
                            for item in google_results:
                                search_results_a.append(SearchResult(
                                    title=item.title,
                                    url=item.url,
                                    snippet=item.snippet,
                                    source="Googleæœç´¢",
                                    search_engine="Google"
                                ))
                            print(f"    [âœ… æœç´¢A-Google] æ‰¾åˆ° {len(search_results_a)} ä¸ªç»“æœ")
                        except Exception as e2:
                            print(f"    [âŒ é”™è¯¯] Google æœç´¢ä¹Ÿå¤±è´¥: {str(e2)}")
                            print(f"    [ğŸ”„ é™çº§] åˆ‡æ¢åˆ° Tavily æœç´¢...")
                            search_results_a = self.llm_client.search(query, max_results=15)
                            print(f"    [âœ… æœç´¢A-Tavily] æ‰¾åˆ° {len(search_results_a)} ä¸ªç»“æœ")
                    else:
                        print(f"    [ğŸ”„ é™çº§] åˆ‡æ¢åˆ°Tavilyæœç´¢...")
                        search_results_a = self.llm_client.search(query, max_results=15)
                        print(f"    [âœ… æœç´¢A-Tavily] æ‰¾åˆ° {len(search_results_a)} ä¸ªç»“æœ")
            else:
                if strategy.use_chinese_search_engine:
                    print(f"    [ğŸŒ ç­–ç•¥] æ£€æµ‹åˆ°éœ€è¦ä½¿ç”¨ä¸­æ–‡æœç´¢å¼•æ“ï¼ˆå¦‚ç™¾åº¦ã€æœç‹—ï¼‰")
                    if not self.baidu_search_enabled:
                        print(f"    [âš ï¸ æ³¨æ„] ç™¾åº¦æœç´¢æœªé…ç½®ï¼Œä½¿ç”¨å…¶ä»–æœç´¢å¼•æ“ï¼Œå¯èƒ½æ— æ³•å®Œå…¨è¦†ç›–ä¸­æ–‡å†…å®¹")
                    else:
                        print(f"    [â„¹ï¸] ç™¾åº¦æœç´¢å·²é…ç½®ä½†æœªå¯ç”¨ï¼ˆå¯èƒ½ç­–ç•¥åˆ¤æ–­ä¸éœ€è¦ï¼‰")
                
                # å¯¹äºéä¸­æ–‡æœç´¢ï¼Œä¼˜å…ˆä½¿ç”¨ Googleï¼ˆå¦‚æœé…ç½®äº†ï¼‰ï¼Œå¦åˆ™ä½¿ç”¨ Tavily
                if self.google_search_enabled:
                    print(f"    [ğŸ” æœç´¢A-Google] æŸ¥è¯¢: \"{query}\"")
                    print(f"    [âš™ï¸ å‚æ•°] max_results=15")
                    try:
                        google_results = self.google_hunter.search(query, max_results=15)
                        search_results_a = []
                        for item in google_results:
                            search_results_a.append(SearchResult(
                                title=item.title,
                                url=item.url,
                                snippet=item.snippet,
                                source="Googleæœç´¢",
                                search_engine="Google"
                            ))
                        print(f"    [âœ… æœç´¢A-Google] æ‰¾åˆ° {len(search_results_a)} ä¸ªç»“æœ")
                    except Exception as e:
                        print(f"    [âŒ é”™è¯¯] Google æœç´¢å¤±è´¥: {str(e)}")
                        print(f"    [ğŸ”„ é™çº§] åˆ‡æ¢åˆ° Tavily æœç´¢...")
                        # ğŸ”¥ ä»llm_client.search()è¿”å›çš„Dictè½¬æ¢ä¸ºSearchResult
                        tavily_dicts = self.llm_client.search(query, max_results=15)
                        search_results_a = []
                        for item in tavily_dicts:
                            search_engine = item.get('search_engine', 'Tavily')
                            search_results_a.append(SearchResult(
                                title=item.get('title', ''),
                                url=item.get('url', ''),
                                snippet=item.get('snippet', ''),
                                source=item.get('source', 'Tavily'),
                                search_engine=search_engine
                            ))
                        print(f"    [âœ… æœç´¢A-Tavily] æ‰¾åˆ° {len(search_results_a)} ä¸ªç»“æœ")
                else:
                    print(f"    [ğŸ” æœç´¢A-é€šç”¨] æŸ¥è¯¢: \"{query}\"")
                    print(f"    [âš™ï¸ å‚æ•°] max_results=15")
                    # ğŸ”¥ ä»llm_client.search()è¿”å›çš„Dictè½¬æ¢ä¸ºSearchResult
                    search_dicts = self.llm_client.search(query, max_results=15)
                    search_results_a = []
                    for item in search_dicts:
                        search_engine = item.get('search_engine', 'Tavily')
                        search_results_a.append(SearchResult(
                            title=item.get('title', ''),
                            url=item.get('url', ''),
                            snippet=item.get('snippet', ''),
                            source=item.get('source', 'Tavily'),
                            search_engine=search_engine
                        ))
                    print(f"    [âœ… æœç´¢A-Tavily] æ‰¾åˆ° {len(search_results_a)} ä¸ªç»“æœ")
            if search_results_a:
                print(f"    [ğŸ“‹ æœç´¢Aç»“æœè¯¦æƒ…]")
                for idx, result in enumerate(search_results_a[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ª
                    print(f"        {idx}. {result.title[:60]}...")
                    print(f"           URL: {result.url}")
                if len(search_results_a) > 5:
                    print(f"        ... è¿˜æœ‰ {len(search_results_a) - 5} ä¸ªç»“æœ")
            
            # æœç´¢ B: æœ¬åœ°å®šå‘æœç´¢ï¼ˆå¦‚æœå›½å®¶é…ç½®ä¸­æœ‰åŸŸååˆ—è¡¨ï¼‰
            print(f"\n    [ğŸ” æœç´¢B-æœ¬åœ°] å¼€å§‹æ£€æŸ¥å›½å®¶é…ç½®...")
            search_results_b = []
            country_code_upper = request.country.upper()
            print(f"    [ğŸ“‹ è¾“å…¥] å›½å®¶ä»£ç : {country_code_upper}")
            country_config = self.config_manager.get_country_config(country_code_upper)
            
            if country_config:
                print(f"    [âœ… é…ç½®] æˆåŠŸè¯»å–å›½å®¶é…ç½®: {country_config.country_name}")
                print(f"    [ğŸ“‹ é…ç½®] åŸŸåæ•°é‡: {len(country_config.domains)}")
                if country_config.domains:
                    print(f"    [ğŸ“‹ é…ç½®] åŸŸååˆ—è¡¨:")
                    for idx, domain in enumerate(country_config.domains, 1):
                        print(f"        {idx}. {domain}")
            else:
                print(f"    [âš ï¸ é…ç½®] å›½å®¶é…ç½®ä¸å­˜åœ¨ï¼Œè·³è¿‡æœ¬åœ°æœç´¢")
            
            # ä½¿ç”¨ç­–ç•¥ä¸­çš„ä¼˜å…ˆåŸŸåï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é…ç½®ä¸­çš„åŸŸå
            if strategy.priority_domains:
                selected_domains = strategy.priority_domains[:5]
                print(f"\n    [âœ… ç­–ç•¥] ä½¿ç”¨ç­–ç•¥ä¸­çš„ä¼˜å…ˆåŸŸå: {', '.join(selected_domains)}")
            elif country_config and country_config.domains:
                selected_domains = country_config.domains[:5]
                print(f"\n    [âœ… é…ç½®] ä½¿ç”¨é…ç½®ä¸­çš„åŸŸå: {', '.join(selected_domains)}")
            else:
                selected_domains = []
            
            if selected_domains:
                # ä½¿ç”¨ç­–ç•¥ä¸­çš„ä¼˜å…ˆåŸŸåæˆ–é…ç½®ä¸­çš„åŸŸå
                print(f"\n    [ğŸ”§ å‡†å¤‡] å‡†å¤‡å¹³å°ç‰¹å®šæœç´¢...")
                print(f"    [ğŸ“‹ åŸŸååˆ—è¡¨] å…± {len(selected_domains)} ä¸ªåŸŸå:")
                for idx, domain in enumerate(selected_domains, 1):
                    print(f"        {idx}. {domain}")
                
                if selected_domains:
                    
                    # æ„å»ºæœ¬åœ°æœç´¢è¯ï¼ˆç§»é™¤playlistå…³é”®è¯ï¼Œä½¿ç”¨æœ¬åœ°åŒ–è¯æ±‡ï¼‰
                    print(f"\n    [ğŸ”§ æ„å»º] æ„å»ºæœ¬åœ°æœç´¢è¯...")
                    print(f"    [ğŸ“‹ åŸå§‹æŸ¥è¯¢] \"{query}\"")
                    
                    # ç§»é™¤playlistå…³é”®è¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                    base_query = query.replace("playlist", "").replace("Playlist", "").strip()
                    
                    # æ ¹æ®è¯­è¨€æ·»åŠ æœ¬åœ°åŒ–å…³é”®è¯
                    language_map = {
                        "id": "Video pembelajaran",  # å°å°¼è¯­
                        "en": "Video lesson",  # è‹±è¯­
                        "zh": "æ•™å­¦è§†é¢‘",  # ä¸­æ–‡
                        "ms": "Video pembelajaran",  # é©¬æ¥è¯­
                        "ar": "ÙÙŠØ¯ÙŠÙˆ ØªØ¹Ù„ÙŠÙ…ÙŠ",  # é˜¿æ‹‰ä¼¯è¯­
                        "ru": "Ğ’Ğ¸Ğ´ĞµĞ¾ ÑƒÑ€Ğ¾Ğº",  # ä¿„è¯­
                    }
                    country_language = country_config.language_code or "en"
                    local_keyword = language_map.get(country_language, "Video lesson")
                    
                    # æ„å»ºçº¯å‡€çš„æœç´¢è¯ï¼ˆå­¦ç§‘ + å¹´çº§ + å­¦æœŸï¼‰
                    clean_query_parts = []
                    if request.subject:
                        clean_query_parts.append(request.subject)
                    if request.grade:
                        clean_query_parts.append(request.grade)
                    if request.semester:
                        clean_query_parts.append(request.semester)
                    
                    # ä½¿ç”¨çº¯å‡€æŸ¥è¯¢ + æœ¬åœ°åŒ–å…³é”®è¯
                    local_base_query = " ".join(clean_query_parts) if clean_query_parts else base_query
                    local_base_query = f"{local_base_query} {local_keyword}".strip()
                    
                    # æ·»åŠ site:è¯­æ³•åˆ°æŸ¥è¯¢æœ«å°¾
                    domain_site_clause = " OR ".join([f"site:{domain}" for domain in selected_domains])
                    local_query = f"{local_base_query} ({domain_site_clause})"
                    
                    print(f"    [ğŸ”§ å¤„ç†] ç§»é™¤playlistå…³é”®è¯åçš„åŸºç¡€æŸ¥è¯¢: \"{base_query}\"")
                    print(f"    [ğŸ”§ å¤„ç†] æœ¬åœ°åŒ–å…³é”®è¯: \"{local_keyword}\"")
                    print(f"    [ğŸ”§ å¤„ç†] çº¯å‡€æŸ¥è¯¢: \"{local_base_query}\"")
                    print(f"    [ğŸ”§ å¤„ç†] æ·»åŠ site:è¯­æ³•åçš„æœ€ç»ˆæŸ¥è¯¢: \"{local_query}\"")
                    print(f"\n    [ğŸ” æœç´¢B-æœ¬åœ°] æŸ¥è¯¢: \"{local_query}\"")
                    print(f"    [ğŸ“ ç›®æ ‡å¹³å°] {', '.join(selected_domains)}")
                    print(f"    [âš™ï¸ å‚æ•°] max_results=10, include_domains={selected_domains}")
                    search_results_b = self.llm_client.search(local_query, max_results=10, include_domains=selected_domains)
                    print(f"    [âœ… æœç´¢B] æ‰¾åˆ° {len(search_results_b)} ä¸ªç»“æœ")
                    if search_results_b:
                        print(f"    [ğŸ“‹ æœç´¢Bç»“æœè¯¦æƒ…]")
                        for idx, result in enumerate(search_results_b, 1):
                            print(f"        {idx}. {result.title[:60]}...")
                            print(f"           URL: {result.url}")
                            # æ£€æŸ¥ URL æ˜¯å¦æ¥è‡ªç›®æ ‡å¹³å°
                            url_lower = result.url.lower()
                            matched_platform = None
                            for domain in selected_domains:
                                if domain.lower() in url_lower:
                                    matched_platform = domain
                                    break
                            if matched_platform:
                                print(f"           âœ… åŒ¹é…å¹³å°: {matched_platform}")
                            else:
                                print(f"           âš ï¸ æœªåŒ¹é…åˆ°ç›®æ ‡å¹³å°")
                    else:
                        print(f"    [âš ï¸ æœç´¢B] æœªæ‰¾åˆ°ä»»ä½•ç»“æœ")
                else:
                    print(f"    [âš ï¸ é…ç½®] åŸŸååˆ—è¡¨ä¸ºç©ºï¼Œè·³è¿‡æœ¬åœ°æœç´¢")
            
            # åˆå¹¶ç»“æœå¹¶å»é‡ï¼ˆåŸºäº URLï¼‰
            print(f"\n    [ğŸ”§ åˆå¹¶] å¼€å§‹åˆå¹¶å’Œå»é‡...")
            all_results = search_results_a + search_results_b
            print(f"    [ğŸ“Š åˆå¹¶å‰] é€šç”¨: {len(search_results_a)} ä¸ª, æœ¬åœ°: {len(search_results_b)} ä¸ª, æ€»è®¡: {len(all_results)} ä¸ª")
            
            seen_urls = set()
            unique_results = []
            duplicate_count = 0
            
            for result in all_results:
                if result.url not in seen_urls:
                    seen_urls.add(result.url)
                    unique_results.append(result)
                else:
                    duplicate_count += 1
                    print(f"        [-] å»é‡: {result.url[:80]}...")
            
            search_results = unique_results
            print(f"    [ğŸ“Š åˆå¹¶å] å»é‡: {duplicate_count} ä¸ª, ä¿ç•™: {len(search_results)} ä¸ª")
            print(f"    [ğŸ“Š ç»Ÿè®¡] é€šç”¨: {len(search_results_a)}, æœ¬åœ°: {len(search_results_b)}, æœ€ç»ˆ: {len(search_results)}")
            
            # Step 3: è¯„ä¼°ç»“æœ
            step3_start = time.time()
            logger.info(f"[æ­¥éª¤ 3] è¯„ä¼°ç»“æœ... (å†…å­˜: {self._get_memory_usage()})")
            print(f"\n[æ­¥éª¤ 3] è¯„ä¼°ç»“æœ...")
            evaluated_results = self.evaluator.evaluate_results(
                search_results,
                country=request.country,
                grade=request.grade,
                subject=request.subject
            )
            step3_elapsed = time.time() - step3_start
            logger.info(f"   âœ… æ­¥éª¤3å®Œæˆ: {step3_elapsed:.2f}ç§’, {len(evaluated_results)}ä¸ªç»“æœ (å†…å­˜: {self._get_memory_usage()})")

            # Step 3.5: æ™ºèƒ½è¯„åˆ†å’Œç”Ÿæˆæ¨èç†ç”±
            step35_start = time.time()
            logger.info(f"[æ­¥éª¤ 3.5] æ™ºèƒ½è¯„åˆ†å¼€å§‹... (å†…å­˜: {self._get_memory_usage()})")
            print(f"\n[æ­¥éª¤ 3.5] æ™ºèƒ½è¯„åˆ†...")

            # å¿«é€Ÿè·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯ï¼ˆç”¨äºè¯„åˆ†ï¼‰
            def get_playlist_info_fast(url: str) -> Optional[Dict[str, Any]]:
                """å¿«é€Ÿè·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯ï¼ˆè§†é¢‘æ•°é‡å’Œæ€»æ—¶é•¿ï¼‰"""
                if not url or 'list=' not in url:
                    return None

                try:
                    import yt_dlp

                    ydl_opts = {
                        'quiet': True,
                        'no_warnings': True,
                        'extract_flat': True,  # å¿«é€Ÿæå–
                        'http_headers': {
                            'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X)',
                        },
                        'extractor_args': {
                            'youtube': {
                                'player_client': ['ios'],
                            }
                        },
                    }

                    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                        info = ydl.extract_info(url, download=False)

                    if not info:
                        return None

                    entries = info.get('entries', [])
                    if not entries:
                        return None

                    video_count = len(entries)

                    # è®¡ç®—æ€»æ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰
                    total_duration_seconds = 0
                    for entry in entries:
                        duration = entry.get('duration', 0)
                        if duration:
                            total_duration_seconds += duration

                    total_duration_minutes = total_duration_seconds / 60 if total_duration_seconds > 0 else 0

                    return {
                        'video_count': video_count,
                        'total_duration_minutes': total_duration_minutes
                    }

                except Exception as e:
                    logger.warning(f"è·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯å¤±è´¥: {str(e)[:100]}")
                    return None

            # ğŸš€ å¹¶å‘è·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯ï¼ˆä¼˜åŒ–æ€§èƒ½ï¼‰
            print(f"\n[æ­¥éª¤ 3.5.1] å¹¶å‘è·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯...")

            # ç¬¬ä¸€æ­¥ï¼šå°†SearchResultå¯¹è±¡è½¬æ¢ä¸ºå­—å…¸ï¼Œå¹¶è¯†åˆ«æ’­æ”¾åˆ—è¡¨
            results_dicts = []
            playlist_results = []  # å­˜å‚¨éœ€è¦è·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯çš„ç»“æœ

            for result in evaluated_results:
                result_dict = {
                    'title': result.title,
                    'url': result.url,
                    'snippet': result.snippet,
                    'source': result.source,
                    'resource_type': getattr(result, 'resource_type', 'unknown')
                }

                # å¦‚æœæ˜¯æ’­æ”¾åˆ—è¡¨URLï¼Œæ ‡è®°ä¸ºéœ€è¦è·å–ä¿¡æ¯
                if 'list=' in result.url:
                    playlist_results.append(result_dict)
                else:
                    # éæ’­æ”¾åˆ—è¡¨ï¼Œç›´æ¥æ·»åŠ 
                    results_dicts.append(result_dict)

            # ç¬¬äºŒæ­¥ï¼šå¹¶å‘è·å–æ‰€æœ‰æ’­æ”¾åˆ—è¡¨ä¿¡æ¯
            if playlist_results:
                import concurrent.futures

                print(f"    [âš¡ å¹¶å‘] å‘ç° {len(playlist_results)} ä¸ªæ’­æ”¾åˆ—è¡¨ï¼Œå¼€å§‹å¹¶å‘è·å–ä¿¡æ¯...")

                # è®¾ç½®å¹¶å‘å‚æ•°
                MAX_PLAYLIST_WORKERS = 20  # æœ€å¤š20ä¸ªå¹¶å‘ï¼ˆä¿®å¤ï¼šP1 - N+1æŸ¥è¯¢ä¼˜åŒ–ï¼‰
                SINGLE_TIMEOUT = 8  # å•ä¸ªæ’­æ”¾åˆ—è¡¨8ç§’è¶…æ—¶

                success_count = 0
                fail_count = 0

                with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_PLAYLIST_WORKERS) as executor:
                    # æäº¤æ‰€æœ‰ä»»åŠ¡
                    future_to_result = {
                        executor.submit(get_playlist_info_fast, r['url']): r
                        for r in playlist_results
                    }

                    # ğŸ”§ ä¿®å¤ï¼šç§»é™¤æ•´ä½“è¶…æ—¶ï¼Œé¿å…éƒ¨åˆ†è¶…æ—¶å¯¼è‡´æ•´ä¸ªæœç´¢å¤±è´¥
                    # æ”¶é›†ç»“æœï¼ˆç­‰å¾…æ‰€æœ‰futureå®Œæˆï¼‰
                    for future in concurrent.futures.as_completed(future_to_result):
                        result_dict = future_to_result[future]

                        try:
                            # å•ä¸ªè¶…æ—¶æ§åˆ¶
                            playlist_info = future.result(timeout=SINGLE_TIMEOUT)

                            if playlist_info:
                                result_dict['playlist_info'] = playlist_info
                                print(f"    [âœ… æˆåŠŸ] {result_dict['title'][:40]}... - {playlist_info['video_count']}ä¸ªè§†é¢‘, {playlist_info['total_duration_minutes']:.0f}åˆ†é’Ÿ")
                                success_count += 1
                            else:
                                print(f"    [âš ï¸ å¤±è´¥] {result_dict['title'][:40]}... - æ— æ³•è·å–ä¿¡æ¯")
                                fail_count += 1

                        except concurrent.futures.TimeoutError:
                            print(f"    [â±ï¸ è¶…æ—¶] {result_dict['title'][:40]}... - è·å–è¶…æ—¶({SINGLE_TIMEOUT}ç§’)")
                            fail_count += 1
                        except Exception as e:
                            print(f"    [âŒ å¼‚å¸¸] {result_dict['title'][:40]}... - {str(e)[:50]}")
                            fail_count += 1

                        # æ— è®ºå¦‚ä½•éƒ½æ·»åŠ åˆ°ç»“æœåˆ—è¡¨
                        results_dicts.append(result_dict)

                print(f"    [ğŸ“Š ç»Ÿè®¡] æˆåŠŸ: {success_count}, å¤±è´¥: {fail_count}, æ€»è®¡: {len(playlist_results)}")
            else:
                print(f"    [â„¹ï¸ è·³è¿‡] æ²¡æœ‰æ’­æ”¾åˆ—è¡¨éœ€è¦è·å–ä¿¡æ¯")

            # ========== Step 3.5: è§†è§‰å¿«é€Ÿè¯„ä¼°ï¼ˆTOP 20ï¼‰ ==========
            # âš ï¸ ä¸´æ—¶ç¦ç”¨ï¼šè§†è§‰è¯„ä¼°ä¼šå¯¼è‡´è¯·æ±‚è¶…æ—¶ï¼ˆé”™è¯¯ä»£ç 5ï¼‰
            # åŸå› ï¼šTOP 20ä¸ªç»“æœä¸²è¡Œå¤„ç†éœ€è¦5-10åˆ†é’Ÿï¼Œè¶…è¿‡HTTPè¯·æ±‚è¶…æ—¶é™åˆ¶
            # TODO: éœ€è¦æ”¹ä¸ºåå°å¼‚æ­¥å¤„ç†æˆ–å¤§å¹…å‡å°‘è¯„ä¼°æ•°é‡ï¼ˆTOP 5ï¼‰

            # è¯»å–ç¯å¢ƒå˜é‡æ§åˆ¶æ˜¯å¦å¯ç”¨ï¼ˆé»˜è®¤ç¦ç”¨ï¼‰
            ENABLE_VISUAL_EVALUATION = os.getenv('ENABLE_VISUAL_EVALUATION', 'false').lower() == 'true'

            # è¯»å–ç¯å¢ƒå˜é‡æ§åˆ¶LLMè¯„åˆ†æ•°é‡ï¼ˆé»˜è®¤TOP 10ï¼Œé¿å…è¶…æ—¶ï¼‰
            LLM_SCORE_TOP_N = int(os.getenv('LLM_SCORE_TOP_N', '10'))

            if not ENABLE_VISUAL_EVALUATION:
                print(f"\n[æ­¥éª¤ 3.5] è§†è§‰è¯„ä¼°å·²ç¦ç”¨ï¼ˆä½¿ç”¨å¿«é€ŸLLMè¯„åˆ†æ¨¡å¼ï¼‰")
                print(f"    [â„¹ï¸  æç¤º] å¦‚éœ€å¯ç”¨è§†è§‰è¯„ä¼°ï¼Œè®¾ç½®ç¯å¢ƒå˜é‡: ENABLE_VISUAL_EVALUATION=true")
                print(f"    [âš¡ æ€§èƒ½ä¼˜åŒ–] åªå¯¹TOP {LLM_SCORE_TOP_N}ä¸ªç»“æœè¿›è¡ŒLLMè¯„åˆ†")

                # âš¡ ä¼˜åŒ–ï¼šåªå¯¹TOP Nä¸ªç»“æœè¿›è¡ŒLLMè¯„åˆ†ï¼Œé¿å…è¶…æ—¶
                if len(results_dicts) > LLM_SCORE_TOP_N:
                    top_n_results = results_dicts[:LLM_SCORE_TOP_N]
                    remaining_results = results_dicts[LLM_SCORE_TOP_N:]

                    # å¯¹TOP Nè¿›è¡ŒLLMè¯„åˆ†
                    print(f"    [ğŸ“Š] TOP {len(top_n_results)} ä¸ªç»“æœå°†è¿›è¡ŒLLMè¯„åˆ†")
                    quickly_scored_results = top_n_results
                    # å‰©ä½™ç»“æœä½¿ç”¨é»˜è®¤åˆ†æ•°ï¼ˆä¸è¿›è¡ŒLLMè¯„åˆ†ï¼‰
                    quickly_scored_results.extend([{
                        **r,
                        'score': 5.0,  # é»˜è®¤ä¸­ç­‰åˆ†æ•°
                        'recommendation_reason': 'æœªè¯„åˆ†ï¼ˆè¶…å‡ºTOP Né™åˆ¶ï¼‰'
                    } for r in remaining_results])
                else:
                    # ç»“æœæ•°å°‘äºTOP Nï¼Œå…¨éƒ¨è¯„åˆ†
                    quickly_scored_results = results_dicts.copy()

                visually_scored_results = []
            else:
                print(f"\n[æ­¥éª¤ 3.5] è§†è§‰å¿«é€Ÿè¯„ä¼°ï¼ˆTOP 5ï¼‰...")

                # æå–TOP 5ä¸ªç»“æœè¿›è¡Œè§†è§‰è¯„ä¼°ï¼ˆå‡å°‘æ•°é‡é¿å…è¶…æ—¶ï¼‰
                TOP_N = 5
                top_results = results_dicts[:TOP_N]
                remaining_results = results_dicts[TOP_N:]

                print(f"    [ğŸ“Š] TOP {len(top_results)} ä¸ªç»“æœå°†è¿›è¡Œè§†è§‰è¯„ä¼°")
                print(f"    [ğŸ“Š] å‰©ä½™ {len(remaining_results)} ä¸ªç»“æœå°†ä½¿ç”¨å¿«é€Ÿè¯„åˆ†")

                # å¹¶å‘æˆªå›¾TOP 5
                screenshot_results = {}
                successful_screenshots = 0

                if top_results:
                    try:
                        # å¯¼å…¥æˆªå›¾æœåŠ¡
                        import asyncio
                        from core.screenshot_service import get_screenshot_service

                        # å‡†å¤‡URLåˆ—è¡¨
                        urls_to_screenshot = [r['url'] for r in top_results]

                        print(f"    [ğŸ“¸] å¼€å§‹å¹¶å‘æˆªå›¾ {len(urls_to_screenshot)} ä¸ªURL...")

                        # å¼‚æ­¥æ‰¹é‡æˆªå›¾ï¼ˆå¢åŠ è¶…æ—¶ä¿æŠ¤ + è‡ªåŠ¨èµ„æºé‡Šæ”¾ + å¤šå±‚ä¿é™©ï¼‰
                        async def capture_screenshots_async():
                            service = None
                            browser = None
                            try:
                                # åˆ›å»ºæˆªå›¾æœåŠ¡
                                service = await get_screenshot_service()
                                browser = service.browser if hasattr(service, 'browser') else None

                                # æ·»åŠ 60ç§’æ€»è¶…æ—¶ä¿æŠ¤
                                result = await asyncio.wait_for(
                                    service.capture_batch(
                                        urls=urls_to_screenshot,
                                        wait_for='domcontentloaded',  # ä½¿ç”¨æ›´å¿«çš„ç­‰å¾…ç­–ç•¥ï¼Œé¿å…YouTubeè¶…æ—¶
                                        full_page=False
                                    ),
                                    timeout=60.0  # æœ€å¤šç­‰å¾…60ç§’
                                )
                                return result
                            except asyncio.TimeoutError:
                                logger.warning("æˆªå›¾è¶…æ—¶(60ç§’)ï¼Œéƒ¨åˆ†æˆªå›¾å¯èƒ½å¤±è´¥")
                                return {}
                            except Exception as e:
                                logger.warning(f"æˆªå›¾æœåŠ¡å¼‚å¸¸: {str(e)[:100]}")
                                return {}
                            finally:
                                # ğŸ”¥ å…³é”®ï¼šå¤šå±‚ä¿é™©ç¡®ä¿èµ„æºé‡Šæ”¾ï¼ˆä¿®å¤ï¼šP1 - å†…å­˜æ³„æ¼ï¼‰
                                # 1. å…³é—­æµè§ˆå™¨å®ä¾‹
                                if browser is not None:
                                    try:
                                        await browser.close()
                                        logger.debug("ğŸ—‘ï¸ æµè§ˆå™¨å®ä¾‹å·²å…³é—­")
                                    except Exception as e:
                                        logger.debug(f"å…³é—­æµè§ˆå™¨å®ä¾‹å¤±è´¥ï¼ˆå¯å¿½ç•¥ï¼‰: {str(e)[:50]}")

                                # 2. åœæ­¢æˆªå›¾æœåŠ¡
                                if service is not None:
                                    try:
                                        await service.stop()
                                        logger.debug("ğŸ—‘ï¸ æˆªå›¾æœåŠ¡å·²å…³é—­")
                                    except Exception as e:
                                        logger.debug(f"å…³é—­æˆªå›¾æœåŠ¡å¤±è´¥ï¼ˆå¯å¿½ç•¥ï¼‰: {str(e)[:50]}")

                                # 3. å¼ºåˆ¶åƒåœ¾å›æ”¶ï¼Œç¡®ä¿å†…å­˜é‡Šæ”¾
                                try:
                                    import gc
                                    gc.collect()
                                    logger.debug("â™»ï¸ å·²å¼ºåˆ¶åƒåœ¾å›æ”¶")
                                except Exception:
                                    pass

                        # è¿è¡Œå¼‚æ­¥ä»»åŠ¡
                        screenshot_results = asyncio.run(capture_screenshots_async())

                        # ç»Ÿè®¡æˆåŠŸæ•°é‡
                        successful_screenshots = sum(1 for path in screenshot_results.values() if path is not None)
                        print(f"    [âœ… æˆªå›¾å®Œæˆ] {successful_screenshots}/{len(urls_to_screenshot)} æˆåŠŸ")

                    except Exception as e:
                        logger.error(f"æˆªå›¾æµç¨‹å¼‚å¸¸: {str(e)}")
                        print(f"    [âŒ æˆªå›¾å¤±è´¥] {str(e)[:100]}")
                        print(f"    [âš ï¸ å°†é™çº§åˆ°å¿«é€Ÿè¯„åˆ†æ¨¡å¼")
                        # ç¡®ä¿screenshot_resultsæ˜¯å­—å…¸
                        if 'screenshot_results' not in locals() or not isinstance(screenshot_results, dict):
                            screenshot_results = {}

                # å¯¹æœ‰æˆªå›¾çš„ç»“æœä½¿ç”¨è§†è§‰è¯„ä¼°
                visually_scored_results = []
                quickly_scored_results = remaining_results.copy()

                for result_dict in top_results:
                    url = result_dict['url']
                    screenshot_path = screenshot_results.get(url)

                    if screenshot_path:
                        # æœ‰æˆªå›¾ï¼Œä½¿ç”¨è§†è§‰è¯„ä¼°ï¼ˆæ·»åŠ è¶…æ—¶ä¿æŠ¤ï¼‰
                        try:
                            import signal

                            # å‡†å¤‡metadata
                            country_config = self.config_manager.get_country_config(request.country.upper()) if self.config_manager else None
                            metadata = {
                                'country_name': country_config.name if country_config else '',
                                'grade_name': request.grade,
                                'subject_name': request.subject,
                                'language_code': country_config.language_code if country_config else 'en'
                            }

                            # è°ƒç”¨è§†è§‰è¯„ä¼°ï¼ˆè¶…æ—¶ä¿æŠ¤30ç§’ï¼‰
                            def timeout_handler(signum, frame):
                                raise TimeoutError("è§†è§‰è¯„ä¼°è¶…æ—¶")

                            # è®¾ç½®è¶…æ—¶ï¼ˆä»…Unixç³»ç»Ÿï¼‰
                            if hasattr(signal, 'SIGALRM'):
                                signal.signal(signal.SIGALRM, timeout_handler)
                                signal.alarm(30)  # 30ç§’è¶…æ—¶

                            try:
                                visual_evaluation = self.result_scorer.evaluate_with_visual(
                                    result=result_dict,
                                    screenshot_path=screenshot_path,
                                    query=query,
                                    metadata=metadata
                                )
                            finally:
                                if hasattr(signal, 'SIGALRM'):
                                    signal.alarm(0)  # å–æ¶ˆè¶…æ—¶

                            if visual_evaluation:
                                # è§†è§‰è¯„ä¼°æˆåŠŸ
                                result_dict['score'] = visual_evaluation['score']
                                result_dict['recommendation_reason'] = visual_evaluation['recommendation_reason']
                                result_dict['evaluation_method'] = 'Visual'
                                result_dict['evaluation_details'] = visual_evaluation.get('evaluation_details', {})
                                result_dict['screenshot_path'] = screenshot_path
                                visually_scored_results.append(result_dict)
                                print(f"    [âœ… è§†è§‰è¯„ä¼°] {result_dict['title'][:40]}... - {visual_evaluation['score']}/10")
                            else:
                                # è§†è§‰è¯„ä¼°å¤±è´¥ï¼Œé™çº§åˆ°å¿«é€Ÿè¯„åˆ†
                                quickly_scored_results.append(result_dict)
                                print(f"    [âš ï¸ é™çº§] {result_dict['title'][:40]}... - è§†è§‰è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨å¿«é€Ÿè¯„åˆ†")

                        except TimeoutError:
                            logger.warning(f"è§†è§‰è¯„ä¼°è¶…æ—¶: {result_dict['title'][:40]}...")
                            print(f"    [â±ï¸ è¶…æ—¶] {result_dict['title'][:40]}... - è§†è§‰è¯„ä¼°è¶…æ—¶ï¼Œä½¿ç”¨å¿«é€Ÿè¯„åˆ†")
                            quickly_scored_results.append(result_dict)
                        except Exception as e:
                            logger.warning(f"è§†è§‰è¯„ä¼°å¼‚å¸¸: {str(e)[:100]}")
                            quickly_scored_results.append(result_dict)
                    else:
                        # æ²¡æœ‰æˆªå›¾ï¼Œä½¿ç”¨å¿«é€Ÿè¯„åˆ†
                        quickly_scored_results.append(result_dict)

            # å¯¹å¿«é€Ÿè¯„åˆ†ç»“æœä½¿ç”¨åŸæœ‰çš„LLM/è§„åˆ™è¯„åˆ†
            if quickly_scored_results:
                llm_start = time.time()
                logger.info(f"[LLMè¯„åˆ†] å¼€å§‹: {len(quickly_scored_results)}ä¸ªç»“æœ (å†…å­˜: {self._get_memory_usage()})")
                print(f"    [ğŸ“Š] å¯¹ {len(quickly_scored_results)} ä¸ªç»“æœè¿›è¡Œå¿«é€Ÿè¯„åˆ†ï¼ˆLLM/è§„åˆ™ï¼‰...")

                # è·å–å›½å®¶è¯­è¨€ä»£ç 
                language_code = None
                if self.config_manager:
                    country_config = self.config_manager.get_country_config(request.country.upper())
                    if country_config:
                        language_code = country_config.language_code

                quickly_scored = self.result_scorer.score_results(
                    results=quickly_scored_results,
                    query=query,
                    metadata={
                        'country': request.country,
                        'grade': request.grade,
                        'subject': request.subject,
                        'language_code': language_code
                    }
                )

                # åˆå¹¶ç»“æœ
                results_dicts = visually_scored_results + quickly_scored

                llm_elapsed = time.time() - llm_start
                logger.info(f"   âœ… LLMè¯„åˆ†å®Œæˆ: {llm_elapsed:.2f}ç§’, {len(quickly_scored)}ä¸ªç»“æœ (å†…å­˜: {self._get_memory_usage()})")
            else:
                results_dicts = visually_scored_results

            print(f"    [âœ… è¯„ä¼°å®Œæˆ] æ€»è®¡ {len(results_dicts)} ä¸ªç»“æœ (è§†è§‰: {len(visually_scored_results)}, å¿«é€Ÿ: {len(quickly_scored_results)})")

            step35_elapsed = time.time() - step35_start
            logger.info(f"   âœ… æ­¥éª¤3.5å®Œæˆ: {step35_elapsed:.2f}ç§’ (å†…å­˜: {self._get_memory_usage()})")
            logger.info(f"   ğŸ“Š è¯„åˆ†ç»“æœ: è§†è§‰={len(visually_scored_results)}, å¿«é€Ÿ={len(quickly_scored_results)}")

            # æ˜¾ç¤ºè¯„åˆ†ç»Ÿè®¡
            if results_dicts:
                scores = [r.get('score', 0) for r in results_dicts]
                avg_score = sum(scores) / len(scores) if scores else 0
                high_score_count = sum(1 for s in scores if s >= 8.0)
                visual_count = sum(1 for r in results_dicts if r.get('evaluation_method') == 'Visual')
                print(f"    [ğŸ“Š è¯„åˆ†ç»Ÿè®¡] å¹³å‡åˆ†: {avg_score:.2f}, é«˜åˆ†(â‰¥8): {high_score_count} ä¸ª, è§†è§‰è¯„ä¼°: {visual_count} ä¸ª")
                print(f"    [ğŸ“Š å‰3åè¯„åˆ†]:")
                for i, r in enumerate(results_dicts[:3], 1):
                    method = r.get('evaluation_method', 'Unknown')
                    print(f"        {i}. {r.get('score', 0):.1f}/10 [{method}] - {r.get('title', 'N/A')[:50]}...")

            # å°†è¯„åˆ†ä¿¡æ¯æ·»åŠ å›SearchResultå¯¹è±¡
            # âœ… ä¿®å¤ï¼šä½¿ç”¨original_indexæ¥æ­£ç¡®åŒ¹é…ç»“æœå’Œè¯„åˆ†ï¼ˆå› ä¸ºresults_dictså·²è¢«æ’åºï¼‰
            final_results = []
            scored_dict_by_index = {r.get('original_index'): r for r in results_dicts}

            for i, result in enumerate(evaluated_results):
                # ä½¿ç”¨original_indexæŸ¥æ‰¾å¯¹åº”çš„è¯„åˆ†ç»“æœ
                # å¦‚æœæ²¡æœ‰original_indexï¼Œå›é€€åˆ°é¡ºåºåŒ¹é…ï¼ˆå¯èƒ½ä¸å‡†ç¡®ï¼‰
                scored_dict = scored_dict_by_index.get(i, results_dicts[i] if i < len(results_dicts) else None)

                if scored_dict:
                    # æ›´æ–°SearchResultå¯¹è±¡
                    result.score = scored_dict.get('score', 0)
                    result.recommendation_reason = scored_dict.get('recommendation_reason', '')
                    # âœ… ä¿ç•™evaluation_methodï¼ˆä½¿ç”¨model_dumpæ–¹å¼é¿å…å­—æ®µä¸å­˜åœ¨çš„é”™è¯¯ï¼‰
                    # æ³¨æ„ï¼šSearchResultå¯èƒ½æ²¡æœ‰evaluation_methodå­—æ®µï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸ç›´æ¥èµ‹å€¼
                    # è€Œæ˜¯åœ¨å­—å…¸ä¸­ä¿ç•™è¿™ä¸ªä¿¡æ¯

                # âœ… å°†è¯„åˆ†ä¿¡æ¯ä¿å­˜ä¸ºå­—å…¸ï¼ˆä¿ç•™evaluation_methodï¼‰
                result_dict = result.model_dump()
                result_dict['evaluation_method'] = scored_dict.get('evaluation_method', 'LLM')
                final_results.append(SearchResult(**result_dict))

            evaluated_results = final_results

            # âœ… åœ¨æ­£ç¡®åŒ¹é…åˆ†æ•°åï¼ŒæŒ‰è¯„åˆ†é™åºæ’åº
            evaluated_results.sort(key=lambda x: x.score, reverse=True)
            logger.info(f"âœ… ç»“æœå·²æŒ‰è¯„åˆ†é™åºæ’åº (æœ€é«˜åˆ†: {evaluated_results[0].score if evaluated_results else 0:.1f})")

            # Step 4: ç»Ÿè®¡
            # æ’­æ”¾åˆ—è¡¨ï¼šYouTubeæ’­æ”¾åˆ—è¡¨æˆ–åŒ…å«list=çš„URL
            playlist_count = sum(1 for r in evaluated_results if 
                               "youtube.com/playlist" in r.url.lower() or 
                               ("youtube.com/watch" in r.url.lower() and "list=" in r.url.lower()))
            
            # è§†é¢‘ï¼šYouTubeè§†é¢‘ã€Bç«™è§†é¢‘æˆ–å…¶ä»–è§†é¢‘å¹³å°
            video_count = sum(1 for r in evaluated_results if 
                            "youtube.com/watch" in r.url.lower() or
                            "bilibili.com/video" in r.url.lower() or
                            "/video/" in r.url.lower())
            
            print(f"\n[æ­¥éª¤ 4] ç»Ÿè®¡ç»“æœ...")
            print(f"    [ğŸ“Š ç»Ÿè®¡] æ’­æ”¾åˆ—è¡¨: {playlist_count} ä¸ª")
            print(f"    [ğŸ“Š ç»Ÿè®¡] è§†é¢‘: {video_count} ä¸ª")
            print(f"    [ğŸ“Š ç»Ÿè®¡] æ€»è®¡: {len(evaluated_results)} ä¸ª")

            # æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡
            cache_stats = self.search_cache.get_stats()
            print(f"\n[ğŸ’¾ ç¼“å­˜ç»Ÿè®¡]")
            print(f"    [ğŸ“Š ç»Ÿè®¡] å‘½ä¸­æ¬¡æ•°: {cache_stats['hits']}")
            print(f"    [ğŸ“Š ç»Ÿè®¡] æœªå‘½ä¸­æ¬¡æ•°: {cache_stats['misses']}")
            print(f"    [ğŸ“Š ç»Ÿè®¡] æ€»æŸ¥è¯¢æ¬¡æ•°: {cache_stats['total_queries']}")
            print(f"    [ğŸ“Š ç»Ÿè®¡] å‘½ä¸­ç‡: {cache_stats['hit_rate']:.1%}")
            print(f"    [ğŸ“Š ç»Ÿè®¡] ç¼“å­˜æ–‡ä»¶æ•°: {cache_stats['cache_files_count']}")

            # æ€§èƒ½ç›‘æ§ - è®°å½•æˆåŠŸçš„æœç´¢
            search_duration = time.time() - search_start_time
            perf_monitor.record_metric(
                operation=f"search_{request.country.lower()}",
                duration=search_duration,
                success=True,
                metadata={
                    "country": request.country,
                    "grade": request.grade,
                    "subject": request.subject,
                    "result_count": len(evaluated_results),
                    "playlist_count": playlist_count,
                    "video_count": video_count,
                    "query": query
                }
            )

            # ğŸ”§ ä¿®å¤ï¼šå°†SearchResultå¯¹è±¡è½¬æ¢ä¸ºå­—å…¸ï¼ˆé¿å…PydanticéªŒè¯é”™è¯¯ï¼‰
            results_as_dicts = [r.model_dump() if hasattr(r, 'model_dump') else r.dict() for r in evaluated_results]

            # ========== ğŸ¤– æ™ºèƒ½ä¼˜åŒ–å¾ªç¯ï¼ˆè´¨é‡è¯„ä¼° + ä¼˜åŒ–å»ºè®®ï¼‰ ==========
            quality_report = None
            optimization_request = None

            try:
                # æ£€æŸ¥æ˜¯å¦å¯ç”¨æ™ºèƒ½ä¼˜åŒ–ï¼ˆç¯å¢ƒå˜é‡æ§åˆ¶ï¼‰
                enable_intelligent_optimization = os.getenv("ENABLE_INTELLIGENT_OPTIMIZATION", "true").lower() == "true"

                if enable_intelligent_optimization:
                    print(f"\n[ğŸ¤– æ™ºèƒ½ä¼˜åŒ–] å¼€å§‹è´¨é‡è¯„ä¼°...")

                    # 1. è´¨é‡è¯„ä¼°
                    evaluator = QualityEvaluator()
                    search_params = {
                        'country': request.country,
                        'grade': request.grade,
                        'subject': request.subject,
                        'semester': request.semester
                    }
                    quality_report = evaluator.evaluate_single_search(results_as_dicts, search_params)

                    print(f"    [ğŸ“Š è´¨é‡åˆ†æ•°] {quality_report['overall_quality_score']:.1f}/100")
                    print(f"    [ğŸ¯ è´¨é‡ç­‰çº§] {quality_report['quality_level']}")
                    print(f"    [ğŸ“ˆ å¹³å‡åˆ†] {quality_report['basic_stats']['avg_score']:.2f}/10")

                    # 2. åˆ¤æ–­æ˜¯å¦éœ€è¦ä¼˜åŒ–
                    optimizer = IntelligentSearchOptimizer(search_engine=self)
                    should_opt, issues = optimizer.should_optimize(results_as_dicts, quality_report)

                    if should_opt:
                        print(f"    [âš ï¸ æ£€æµ‹åˆ°é—®é¢˜] {len(issues)}ä¸ª")
                        for i, issue in enumerate(issues, 1):
                            print(f"      {i}. {issue}")

                        # 3. ç”Ÿæˆä¼˜åŒ–æ–¹æ¡ˆ
                        opt_request = optimizer.create_optimization_request(
                            results_as_dicts, quality_report, search_params, issues
                        )

                        # 4. å­˜å‚¨ä¼˜åŒ–è¯·æ±‚åˆ°å®¡æ‰¹ç®¡ç†å™¨ (å·²ç¦ç”¨ - SISåŠŸèƒ½)
                        # approval_manager = get_approval_manager()
                        # stored_request = approval_manager.create_request(opt_request)
                        # print(f"    [âœ… ä¼˜åŒ–è¯·æ±‚å·²åˆ›å»º] ID: {stored_request['request_id']}")
                        # print(f"    [ğŸ“‹ å¾…å®¡æ‰¹æ–¹æ¡ˆ] {len(stored_request['optimization_plans'])}ä¸ª")
                        # optimization_request = stored_request
                        optimization_request = None
                    else:
                        print(f"    [âœ… è´¨é‡è‰¯å¥½] æ— éœ€ä¼˜åŒ–")

            except Exception as opt_error:
                print(f"    [âš ï¸ æ™ºèƒ½ä¼˜åŒ–å¤±è´¥] {str(opt_error)}")
                logger.warning(f"æ™ºèƒ½ä¼˜åŒ–å¤±è´¥: {str(opt_error)}", exc_info=True)
            # ========== æ™ºèƒ½ä¼˜åŒ–å¾ªç¯ç»“æŸ ==========

            # ğŸ” è¯¦ç»†æ—¥å¿—ï¼šæœç´¢å®Œæˆ
            total_elapsed = time.time() - search_start_time
            logger.info("="*80)
            logger.info(f"âœ… [æœç´¢å®Œæˆ] {request.country} - {request.grade} - {request.subject}")
            logger.info(f"   æ€»è€—æ—¶: {total_elapsed:.2f}ç§’")
            logger.info(f"   ç»“æœæ•°: {len(evaluated_results)}")
            logger.info(f"   å†…å­˜ä½¿ç”¨: {self._get_memory_usage()}")
            logger.info(f"   æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            if quality_report:
                logger.info(f"   è´¨é‡åˆ†æ•°: {quality_report['overall_quality_score']:.1f}/100")
            logger.info("="*80)

            return SearchResponse(
                success=True,
                query=query,
                results=results_as_dicts,
                total_count=len(evaluated_results),
                playlist_count=playlist_count,
                video_count=video_count,
                message="æœç´¢æˆåŠŸ",
                quality_report=quality_report,
                optimization_request=optimization_request
            )
            
        except Exception as e:
            print(f"\n[âŒ é”™è¯¯] æœç´¢å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()

            # æ€§èƒ½ç›‘æ§ - è®°å½•å¤±è´¥çš„æœç´¢
            search_duration = time.time() - search_start_time
            perf_monitor.record_metric(
                operation=f"search_{request.country.lower()}",
                duration=search_duration,
                success=False,
                metadata={
                    "country": request.country,
                    "grade": request.grade,
                    "subject": request.subject,
                    "error": str(e)
                }
            )

            return SearchResponse(
                success=False,
                query="",
                results=[],
                message=f"æœç´¢å¤±è´¥: {str(e)}"
            )

        except Exception as e:
            # ğŸ” è¯¦ç»†æ—¥å¿—ï¼šæœç´¢å¤±è´¥
            total_elapsed = time.time() - search_start_time
            logger.error("="*80)
            logger.error(f"âŒ [æœç´¢å¤±è´¥] {request.country} - {request.grade} - {request.subject}")
            logger.error(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
            logger.error(f"   é”™è¯¯ä¿¡æ¯: {str(e)[:200]}")
            logger.error(f"   è€—æ—¶: {total_elapsed:.2f}ç§’")
            logger.error(f"   å†…å­˜ä½¿ç”¨: {self._get_memory_usage()}")
            logger.error(f"   æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            logger.error("="*80)
            import traceback
            logger.error(f"å †æ ˆä¿¡æ¯:\n{traceback.format_exc()}")