#!/usr/bin/env python3
"""
æ–°ç‰ˆæœç´¢å¼•æ“ - åŸºäºå›½å®¶/å¹´çº§/å­¦æœŸæœç´¢
ä½¿ç”¨ AI ç”Ÿæˆæœ¬åœ°è¯­è¨€çš„æœç´¢è¯

TODO é‡æ„ä»»åŠ¡ï¼ˆP1 - ä»£ç è´¨é‡æ”¹è¿›ï¼‰:
- [008] è¶…é•¿å‡½æ•°ï¼šsearch()æ–¹æ³•éœ€è¦æ‹†åˆ†ä¸ºå¤šä¸ªå°å‡½æ•°ï¼ˆå½“å‰çº¦1000+è¡Œï¼‰
- [009] å…¨å±€å˜é‡ï¼šå‡å°‘globalå…³é”®å­—ä½¿ç”¨ï¼Œæ”¹ç”¨ä¾èµ–æ³¨å…¥æ¨¡å¼
- [010] ç¡¬ç¼–ç è·¯å¾„ï¼šåˆ›å»ºPathManagerç»Ÿä¸€ç®¡ç†è·¯å¾„é…ç½®
"""

import os
import json
import time
import re
import threading  # ğŸ”’ P1çº¿ç¨‹å®‰å…¨: æ·»åŠ çº¿ç¨‹é”æ”¯æŒ
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass
from pydantic import BaseModel, Field
from datetime import datetime, timezone
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed, TimeoutError as FuturesTimeoutError
import concurrent.futures
from utils.config_manager import ConfigManager
from utils.logger_utils import get_logger
from utils.json_utils import extract_json_array
from search_strategy_agent import SearchStrategyAgent
from core.search_cache import get_search_cache
from core.multi_level_cache import get_cache as get_multi_level_cache
from core.config_loader import get_config
from core.performance_monitor import get_performance_monitor
from core.result_scorer import get_result_scorer
from core.recommendation_generator import get_recommendation_generator
from core.grade_subject_validator import GradeSubjectValidator
from core.text_utils import clean_title, clean_snippet, extract_video_info
from core.quality_evaluator import QualityEvaluator
from core.intelligent_search_optimizer import IntelligentSearchOptimizer
# from core.optimization_approval import get_approval_manager  # å·²ç¦ç”¨ - SISåŠŸèƒ½
# æ—¥å¿—è„±æ•å·¥å…·ï¼ˆå®‰å…¨ä¿®å¤ï¼šP1 - é˜²æ­¢æ•æ„Ÿä¿¡æ¯æ³„éœ²ï¼‰
from utils.log_sanitizer import safe_log, safe_log_json

# åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨
logger = get_logger('search_engine')

# åˆå§‹åŒ–æ€§èƒ½ç›‘æ§å™¨
perf_monitor = get_performance_monitor()

# æ”¯æŒä» .env æ–‡ä»¶è¯»å–ç¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    def load_dotenv():
        env_file = os.path.join(os.path.dirname(__file__), '.env')
        if os.path.exists(env_file):
            with open(env_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#') and '=' in line:
                        key, value = line.split('=', 1)
                        os.environ[key.strip()] = value.strip().strip('"').strip("'")
    load_dotenv()


# ============================================================================
# é…ç½®å¸¸é‡
# ============================================================================
DEFAULT_MAX_RESULTS = 50  # ğŸ”§ P0-2: é»˜è®¤è¿”å›50ä¸ªç»“æœï¼ˆåŸ20ä¸ªï¼‰
MIN_SCORE_THRESHOLD = 5.0  # ğŸ”§ P0-3: æœ€ä½è¯„åˆ†é˜ˆå€¼ï¼ˆåŸ6.0ï¼‰

# ============================================================================
# å®‰å…¨å·¥å…·å‡½æ•° (P1 - SSRFé˜²æŠ¤)
# ============================================================================
import ipaddress
from urllib.parse import urlparse

def is_safe_url(url: str) -> bool:
    """
    éªŒè¯URLä»¥é˜²æ­¢SSRFæ”»å‡»

    Args:
        url: å¾…éªŒè¯çš„URLå­—ç¬¦ä¸²

    Returns:
        bool: Trueè¡¨ç¤ºURLå®‰å…¨ï¼ŒFalseè¡¨ç¤ºURLä¸å®‰å…¨
    """
    try:
        parsed = urlparse(url)

        # æ£€æŸ¥åè®® - åªå…è®¸HTTPå’ŒHTTPS
        if parsed.scheme not in ['http', 'https']:
            logger.warning(f"Blocked URL with unsafe scheme: {parsed.scheme}")
            return False

        # è§£æä¸»æœºå
        hostname = parsed.hostname
        if not hostname:
            logger.warning(f"Blocked URL with no hostname: {url}")
            return False

        # é˜»æ­¢ç§æœ‰/å†…éƒ¨IPåœ°å€
        try:
            ip = ipaddress.ip_address(hostname)
            if ip.is_private:
                logger.warning(f"Blocked private IP: {hostname}")
                return False
            if ip.is_loopback:
                logger.warning(f"Blocked loopback IP: {hostname}")
                return False
            if ip.is_link_local:
                logger.warning(f"Blocked link-local IP: {hostname}")
                return False
            if ip.is_reserved:
                logger.warning(f"Blocked reserved IP: {hostname}")
                return False
        except ValueError:
            # ä¸æ˜¯IPåœ°å€ï¼Œç»§ç»­æ£€æŸ¥ä¸»æœºå
            pass

        # é˜»æ­¢localhostå’Œæœ¬åœ°åŸŸå
        blocked_domains = [
            'localhost', '127.0.0.1', '0.0.0.0',
            'metadata.google.internal',  # GCP
            '169.254.169.254',           # AWS/Azureå…ƒæ•°æ®ç«¯ç‚¹
            'instance-data',             # AWSå…ƒæ•°æ®åŸŸå
        ]

        if hostname.lower() in blocked_domains:
            logger.warning(f"Blocked internal domain: {hostname}")
            return False

        # é˜»æ­¢å†…éƒ¨ä¸»æœºåæ¨¡å¼
        if hostname.endswith('.local') or hostname.endswith('.internal'):
            logger.warning(f"Blocked internal hostname pattern: {hostname}")
            return False

        return True

    except Exception as e:
        logger.warning(f"URL validation error for {url}: {str(e)}")
        return False


def sanitize_search_query(query: str) -> str:
    """
    æ¸…ç†æœç´¢æŸ¥è¯¢ä»¥é˜²æ­¢æ³¨å…¥æ”»å‡»

    Args:
        query: åŸå§‹æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²

    Returns:
        str: æ¸…ç†åçš„å®‰å…¨æŸ¥è¯¢å­—ç¬¦ä¸²
    """
    if not query:
        return ""

    # ç§»é™¤å±é™©çš„æœç´¢è¿ç®—ç¬¦ï¼ˆå¯èƒ½è¢«ç”¨äºSSRFæˆ–ä¿¡æ¯æ³„éœ²ï¼‰
    dangerous_patterns = [
        r'site:\s*[^\s\)]+',      # site: è¿ç®—ç¬¦ï¼ˆå¯èƒ½ç”¨äºSSRFï¼‰
        r'filetype:\s*\w+',        # filetype: è¿ç®—ç¬¦
        r'cache:\s*[^\s\)]+',      # cache: è¿ç®—ç¬¦
        r'link:\s*[^\s\)]+',       # link: è¿ç®—ç¬¦
        r'info:\s*[^\s\)]+',       # info: è¿ç®—ç¬¦
        r'loc:\s*[^\s\)]+',        # location è¿ç®—ç¬¦
    ]

    original_query = query
    for pattern in dangerous_patterns:
        query = re.sub(pattern, '', query, flags=re.IGNORECASE)

    # å¦‚æœæŸ¥è¯¢è¢«ä¿®æ”¹ï¼Œè®°å½•æ—¥å¿—
    if query != original_query:
        logger.info(f"Sanitized search query (removed dangerous operators): {original_query[:100]} -> {query[:100]}")

    # é™åˆ¶æŸ¥è¯¢é•¿åº¦ï¼ˆé˜²æ­¢DoSï¼‰
    query = query[:500]

    # ç§»é™¤å¤šä½™çš„ç©ºæ ¼
    query = ' '.join(query.split())

    return query.strip()


def validate_api_key(api_key: Optional[str], key_name: str = "API Key") -> str:
    """
    éªŒè¯APIå¯†é’¥çš„æœ‰æ•ˆæ€§

    Args:
        api_key: å¾…éªŒè¯çš„APIå¯†é’¥
        key_name: å¯†é’¥åç§°ï¼ˆç”¨äºé”™è¯¯æ¶ˆæ¯ï¼‰

    Returns:
        str: éªŒè¯åçš„APIå¯†é’¥

    Raises:
        ValueError: å¦‚æœAPIå¯†é’¥æ— æ•ˆ
    """
    if not api_key:
        raise ValueError(f"{key_name} cannot be empty or None")

    api_key = api_key.strip()

    # æ£€æŸ¥æœ€å°é•¿åº¦ï¼ˆé˜²æ­¢ç©ºå­—ç¬¦ä¸²æˆ–è¿‡çŸ­çš„å¯†é’¥ï¼‰
    if len(api_key) < 10:
        raise ValueError(f"{key_name} is too short (minimum 10 characters)")

    # æ£€æŸ¥æœ€å¤§é•¿åº¦ï¼ˆé˜²æ­¢DoSï¼‰
    if len(api_key) > 500:
        raise ValueError(f"{key_name} is too long (maximum 500 characters)")

    # æ£€æŸ¥æ˜¯å¦åŒ…å«ç©ºç™½å­—ç¬¦ï¼ˆAPIå¯†é’¥ä¸åº”è¯¥æœ‰ç©ºç™½ï¼‰
    if ' ' in api_key or '\t' in api_key or '\n' in api_key:
        raise ValueError(f"{key_name} contains whitespace characters")

    # æ£€æŸ¥æ˜¯å¦æ˜¯å¸¸è§çš„å ä½ç¬¦æˆ–ç¤ºä¾‹å€¼
    placeholders = [
        'your_api_key', 'your-key-here', 'replace_with_key',
        'example_key', 'test_key', 'xxx', 'placeholder',
        'api_key_here', 'secret_key_here'
    ]
    if api_key.lower() in placeholders:
        raise ValueError(f"{key_name} appears to be a placeholder value")

    return api_key


def validate_env_bool(env_var: Optional[str], var_name: str, default: bool = False) -> bool:
    """
    éªŒè¯å¹¶è§£æå¸ƒå°”å‹ç¯å¢ƒå˜é‡

    Args:
        env_var: ç¯å¢ƒå˜é‡çš„å€¼
        var_name: å˜é‡åç§°ï¼ˆç”¨äºé”™è¯¯æ¶ˆæ¯ï¼‰
        default: é»˜è®¤å€¼

    Returns:
        bool: è§£æåçš„å¸ƒå°”å€¼
    """
    if not env_var:
        return default

    env_var = env_var.strip().lower()

    if env_var in ('true', '1', 'yes', 'on', 'enabled'):
        return True
    elif env_var in ('false', '0', 'no', 'off', 'disabled'):
        return False
    else:
        logger.warning(f"Invalid boolean value for {var_name}: '{env_var}', using default: {default}")
        return default


def validate_env_int(env_var: Optional[str], var_name: str, default: int,
                    min_val: Optional[int] = None, max_val: Optional[int] = None) -> int:
    """
    éªŒè¯å¹¶è§£ææ•´æ•°å‹ç¯å¢ƒå˜é‡

    Args:
        env_var: ç¯å¢ƒå˜é‡çš„å€¼
        var_name: å˜é‡åç§°ï¼ˆç”¨äºé”™è¯¯æ¶ˆæ¯ï¼‰
        default: é»˜è®¤å€¼
        min_val: æœ€å°å€¼ï¼ˆå¯é€‰ï¼‰
        max_val: æœ€å¤§å€¼ï¼ˆå¯é€‰ï¼‰

    Returns:
        int: è§£æåçš„æ•´æ•°å€¼
    """
    if not env_var:
        return default

    try:
        value = int(env_var)

        # æ£€æŸ¥èŒƒå›´
        if min_val is not None and value < min_val:
            logger.warning(f"{var_name} value {value} is below minimum {min_val}, using {min_val}")
            return min_val

        if max_val is not None and value > max_val:
            logger.warning(f"{var_name} value {value} is above maximum {max_val}, using {max_val}")
            return max_val

        return value

    except ValueError:
        logger.warning(f"Invalid integer value for {var_name}: '{env_var}', using default: {default}")
        return default


# ============================================================================
# æ•°æ®æ¨¡å‹å®šä¹‰
# ============================================================================

class SearchRequest(BaseModel):
    """æœç´¢è¯·æ±‚"""
    country: str = Field(description="å›½å®¶ä»£ç ï¼ˆå¦‚ï¼šID, CN, USï¼‰")
    grade: str = Field(description="å¹´çº§ï¼ˆå¦‚ï¼š1, 2, 3 æˆ– Kelas 1, Grade 1ï¼‰")
    semester: Optional[str] = Field(description="å­¦æœŸï¼ˆå¦‚ï¼š1, 2 æˆ– Semester 1ï¼‰", default=None)
    subject: str = Field(description="å­¦ç§‘ï¼ˆå¦‚ï¼šMatematika, Mathematics, æ•°å­¦ï¼‰")
    language: Optional[str] = Field(description="æœç´¢è¯­è¨€ï¼ˆå¦‚ï¼šid, en, zhï¼‰", default=None)


class SearchResult(BaseModel):
    """å•ä¸ªæœç´¢ç»“æœ"""
    title: str = Field(description="æœç´¢ç»“æœæ ‡é¢˜")
    url: str = Field(description="ç»“æœURL")
    snippet: str = Field(description="ç»“æœæ‘˜è¦", default="")
    source: str = Field(description="æ¥æºï¼ˆè§„åˆ™/LLMï¼‰", default="è§„åˆ™")
    search_engine: str = Field(description="æœç´¢å¼•æ“æ¥æºï¼ˆTavily/Google/Baiduï¼‰", default="Unknown")
    score: float = Field(description="è¯„ä¼°åˆ†æ•°ï¼ˆ0-10åˆ†ï¼‰", default=0.0)
    recommendation_reason: str = Field(description="æ¨èç†ç”±", default="")
    evaluation_method: Optional[str] = Field(description="è¯„ä¼°æ–¹æ³•ï¼ˆMCP Tools/Rule-based/LLMï¼‰", default=None)
    resource_type: Optional[str] = Field(description="èµ„æºç±»å‹ï¼ˆè§†é¢‘ã€æ•™æã€æ•™è¾…ã€å­¦ä¹ èµ„æ–™ã€ç»ƒä¹ é¢˜ç­‰ï¼‰", default=None)
    is_selected: bool = Field(description="æ˜¯å¦è¢«äººå·¥é€‰ä¸­", default=False)
    evaluation_status: Optional[str] = Field(description="è¯„ä¼°çŠ¶æ€ï¼ˆpending/evaluating/completed/failedï¼‰", default=None)
    evaluation_result: Optional[Dict[str, Any]] = Field(description="è§†é¢‘è¯„ä¼°ç»“æœï¼ˆå¦‚æœå·²è¯„ä¼°ï¼‰", default=None)


class SearchQueryMetadata(BaseModel):
    """å•ä¸ªæœç´¢æŸ¥è¯¢çš„å…ƒæ•°æ®"""
    query: str = Field(description="æœç´¢è¯")
    engine: str = Field(description="æœç´¢å¼•æ“ï¼ˆTavily/Google/Baiduï¼‰")
    result_count: int = Field(description="è¯¥æœç´¢è¿”å›çš„ç»“æœæ•°é‡")
    timestamp: str = Field(description="æœç´¢æ—¶é—´")
    duration_ms: float = Field(description="æœç´¢è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰")
    reasoning: str = Field(description="ç”Ÿæˆæ­¤æœç´¢è¯çš„ç†ç”±", default="")


class SearchTransparencyMetadata(BaseModel):
    """æœç´¢é€æ˜åº¦å…ƒæ•°æ®"""
    # æœç´¢ç­–ç•¥ä¿¡æ¯
    search_strategy: Dict[str, Any] = Field(description="æœç´¢ç­–ç•¥è¯¦æƒ…", default_factory=dict)

    # æœç´¢æ‰§è¡Œè®°å½•ï¼ˆåŒ…å«æ‰€æœ‰æ‰§è¡Œçš„æœç´¢ï¼‰
    search_executions: List[Dict[str, Any]] = Field(description="æ‰€æœ‰æ‰§è¡Œçš„æœç´¢æŸ¥è¯¢", default_factory=list)

    # æœç´¢æ‰§è¡Œç»Ÿè®¡
    total_raw_results: int = Field(description="åŸå§‹æœç´¢ç»“æœæ€»æ•°", default=0)
    total_searches: int = Field(description="æ‰§è¡Œçš„æœç´¢æ¬¡æ•°", default=0)
    total_duration_ms: float = Field(description="æ€»æœç´¢è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰", default=0.0)

    # è¿‡æ»¤æµæ°´çº¿
    filtering_pipeline: List[Dict[str, Any]] = Field(description="è¿‡æ»¤æµæ°´çº¿å„é˜¶æ®µ", default_factory=list)
    filtered_samples: List[Dict[str, Any]] = Field(description="è¢«è¿‡æ»¤çš„ç»“æœæ ·æœ¬", default_factory=list)

    # è¯„åˆ†åˆ†å¸ƒ
    score_distribution: Dict[str, int] = Field(description="åˆ†æ•°åˆ†å¸ƒï¼ˆå¦‚{'8-10': 15, '6-8': 30}ï¼‰", default_factory=dict)


class SearchResponse(BaseModel):
    """æœç´¢å“åº”"""
    success: bool = Field(description="æ˜¯å¦æˆåŠŸ")
    query: str = Field(description="ä½¿ç”¨çš„æœç´¢è¯")
    results: List[SearchResult] = Field(description="æœç´¢ç»“æœåˆ—è¡¨", default_factory=list)
    total_count: int = Field(description="ç»“æœæ€»æ•°", default=0)
    playlist_count: int = Field(description="æ’­æ”¾åˆ—è¡¨æ•°é‡", default=0)
    video_count: int = Field(description="è§†é¢‘æ•°é‡", default=0)
    message: str = Field(description="æ¶ˆæ¯", default="")
    timestamp: str = Field(description="æ—¶é—´æˆ³", default_factory=lambda: datetime.now(timezone.utc).isoformat())
    quality_report: Optional[Dict[str, Any]] = Field(description="è´¨é‡è¯„ä¼°æŠ¥å‘Š", default=None)
    optimization_request: Optional[Dict[str, Any]] = Field(description="ä¼˜åŒ–è¯·æ±‚ï¼ˆå¦‚æœæ£€æµ‹åˆ°è´¨é‡é—®é¢˜ï¼‰", default=None)

    # ğŸ” é€æ˜åº¦å…ƒæ•°æ®ï¼ˆæ–°å¢ï¼‰
    transparency: Optional[SearchTransparencyMetadata] = Field(description="æœç´¢é€æ˜åº¦ä¿¡æ¯", default=None)


# ============================================================================
# AI Builders å®¢æˆ·ç«¯ (ä½¿ç”¨ç»Ÿä¸€LLMå®¢æˆ·ç«¯ï¼Œæ”¯æŒåŒAPIç³»ç»Ÿ)
# ============================================================================

# å¯¼å…¥ç»Ÿä¸€LLMå®¢æˆ·ç«¯
try:
    from llm_client import UnifiedLLMClient, AIBuildersAPIClient
    HAS_UNIFIED_CLIENT = True
except ImportError:
    HAS_UNIFIED_CLIENT = False
    print("[âš ï¸] è­¦å‘Š: æ— æ³•å¯¼å…¥ç»Ÿä¸€LLMå®¢æˆ·ç«¯ï¼Œå°†ä½¿ç”¨åŸæœ‰å®ç°")

class AIBuildersClient:
    """
    AI Builders API å®¢æˆ·ç«¯ï¼ˆå…¼å®¹æ€§åŒ…è£…å™¨ï¼‰
    å†…éƒ¨ä½¿ç”¨ç»Ÿä¸€LLMå®¢æˆ·ç«¯ï¼Œæ”¯æŒå…¬å¸å†…éƒ¨APIå’ŒAI Builders APIçš„fallbackæœºåˆ¶
    """
    
    def __init__(self, api_token: Optional[str] = None):
        # ğŸ”’ P1 ç¯å¢ƒå˜é‡éªŒè¯: è·å–å¹¶éªŒè¯API token
        api_token_raw = api_token or os.getenv("AI_BUILDER_TOKEN")

        # åªæœ‰åœ¨æä¾›äº†tokenæ—¶æ‰éªŒè¯ï¼ˆå…è®¸Noneç”¨äºæŸäº›åœºæ™¯ï¼‰
        if api_token_raw:
            try:
                self.api_token = validate_api_key(api_token_raw, "AI_BUILDER_TOKEN")
            except ValueError as e:
                logger.error(f"Invalid AI_BUILDER_TOKEN: {str(e)}")
                raise ValueError(f"Invalid AI_BUILDER_TOKEN: {str(e)}")
        else:
            self.api_token = None

        # å°è¯•ä½¿ç”¨ç»Ÿä¸€LLMå®¢æˆ·ç«¯
        if HAS_UNIFIED_CLIENT:
            try:
                # è·å–å…¬å¸å†…éƒ¨APIå¯†é’¥ï¼ˆå¯é€‰ï¼‰
                internal_api_key_raw = os.getenv("INTERNAL_API_KEY")
                internal_api_key = None
                if internal_api_key_raw:
                    try:
                        internal_api_key = validate_api_key(internal_api_key_raw, "INTERNAL_API_KEY")
                    except ValueError as e:
                        logger.warning(f"Invalid INTERNAL_API_KEY, will not use internal API: {str(e)}")

                self.unified_client = UnifiedLLMClient(
                    internal_api_key=internal_api_key,
                    ai_builder_token=self.api_token
                )
                self.use_unified_client = True
                print("[âœ…] ä½¿ç”¨ç»Ÿä¸€LLMå®¢æˆ·ç«¯ï¼ˆæ”¯æŒåŒAPIç³»ç»Ÿï¼‰")
            except Exception as e:
                print(f"[âš ï¸] ç»Ÿä¸€LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}ï¼Œå›é€€åˆ°åŸæœ‰å®ç°")
                self.use_unified_client = False
                # å›é€€åˆ°åŸæœ‰å®ç°
                if not self.api_token:
                    raise ValueError("è¯·è®¾ç½® AI_BUILDER_TOKEN ç¯å¢ƒå˜é‡")
        else:
            self.use_unified_client = False
            if not self.api_token:
                raise ValueError("è¯·è®¾ç½® AI_BUILDER_TOKEN ç¯å¢ƒå˜é‡")

        # ä¿ç•™åŸæœ‰å±æ€§ä»¥ä¿æŒå…¼å®¹æ€§
        self.base_url = "https://space.ai-builders.com/backend"
        self.headers = {
            "Authorization": f"Bearer {self.api_token or ''}",
            "Content-Type": "application/json"
        }
    
    def call_llm(self, prompt: str, system_prompt: Optional[str] = None,
                 max_tokens: int = 8000, temperature: float = 0.3,  # [ä¿®å¤] 2026-01-20: ä»2000å¢åŠ åˆ°8000
                 model: str = "deepseek") -> str:
        """è°ƒç”¨ LLM"""
        # å¦‚æœä½¿ç”¨ç»Ÿä¸€å®¢æˆ·ç«¯ï¼Œç›´æ¥è°ƒç”¨
        if self.use_unified_client:
            return self.unified_client.call_llm(
                prompt=prompt,
                system_prompt=system_prompt,
                max_tokens=max_tokens,
                temperature=temperature,
                model=model
            )
        
        # å¦åˆ™ä½¿ç”¨åŸæœ‰å®ç°
        endpoint = f"{self.base_url}/v1/chat/completions"
        
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})
        
        payload = {
            "model": model,
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": temperature
            # ä¸è®¾ç½® tool_choice å’Œ toolsï¼Œè®© API ä½¿ç”¨é»˜è®¤è¡Œä¸º
        }
        
        # è¯¦ç»†æ—¥å¿—ï¼šLLMè°ƒç”¨è¾“å…¥ï¼ˆä½¿ç”¨è„±æ•é˜²æ­¢æ•æ„Ÿä¿¡æ¯æ³„éœ²ï¼‰
        print(f"\n{'='*80}")
        print(f"[ğŸ¤– LLMè°ƒç”¨] å¼€å§‹è°ƒç”¨ {model}")
        print(f"{'='*80}")
        print(f"[ğŸ“¤ è¾“å…¥] Endpoint: {endpoint}")
        print(f"[ğŸ“¤ è¾“å…¥] Model: {model}")
        print(f"[ğŸ“¤ è¾“å…¥] Max Tokens: {max_tokens}")
        print(f"[ğŸ“¤ è¾“å…¥] Temperature: {temperature}")
        print(f"[ğŸ“¤ è¾“å…¥] System Prompt é•¿åº¦: {len(system_prompt) if system_prompt else 0} å­—ç¬¦")
        print(f"[ğŸ“¤ è¾“å…¥] User Prompt é•¿åº¦: {len(prompt)} å­—ç¬¦")
        if system_prompt:
            print(f"[ğŸ“¤ è¾“å…¥] System Prompt (å‰500å­—ç¬¦):\n{safe_log(system_prompt[:500])}...")
        print(f"[ğŸ“¤ è¾“å…¥] User Prompt (å‰500å­—ç¬¦):\n{safe_log(prompt[:500])}...")
        print(f"[ğŸ“¤ è¾“å…¥] å®Œæ•´ User Prompt:\n{safe_log(prompt)}")
        print(f"[ğŸ“¤ è¾“å…¥] Payload (å·²è„±æ•):\n{safe_log_json(payload)}")
        
        try:
            import time
            from llm_client import get_proxy_config
            start_time = time.time()
            response = requests.post(
                endpoint,
                headers=self.headers,
                json=payload,
                params={"debug": "true"},
                timeout=300,
                proxies=None  # [ä¿®å¤] 2026-01-20: AI Builders æ˜¯å†…ç½‘ APIï¼Œä¸éœ€è¦ä»£ç†
            )
            elapsed_time = time.time() - start_time
            
            # è¯¦ç»†æ—¥å¿—ï¼šAPIå“åº”ï¼ˆä½¿ç”¨è„±æ•é˜²æ­¢æ•æ„Ÿä¿¡æ¯æ³„éœ²ï¼‰
            print(f"\n[ğŸ“¥ å“åº”] HTTP çŠ¶æ€ç : {response.status_code}")
            print(f"[ğŸ“¥ å“åº”] å“åº”æ—¶é—´: {elapsed_time:.2f} ç§’")

            if response.status_code == 200:
                result = response.json()
                print(f"[ğŸ“¥ å“åº”] å“åº”ç±»å‹: {type(result).__name__}")
                print(f"[ğŸ“¥ å“åº”] å“åº”é”®: {list(result.keys()) if isinstance(result, dict) else 'N/A'}")

                # æ‰“å°å®Œæ•´çš„APIå“åº”ï¼ˆç”¨äºè°ƒè¯•ï¼Œå·²è„±æ•ï¼‰
                print(f"[ğŸ“¥ å“åº”] å®Œæ•´ API å“åº” (å·²è„±æ•):\n{safe_log_json(result)}")
                
                if "choices" in result and len(result["choices"]) > 0:
                    choice = result["choices"][0]
                    message = choice.get("message", {})
                    content = message.get("content", "")
                    finish_reason = choice.get("finish_reason", "unknown")
                    
                    print(f"[ğŸ“¥ å“åº”] Finish Reason: {finish_reason}")
                    print(f"[ğŸ“¥ å“åº”] Content é•¿åº¦: {len(content) if content else 0} å­—ç¬¦")
                    
                    # æ‰“å° usage ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                    if "usage" in result:
                        usage = result["usage"]
                        print(f"[ğŸ“¥ å“åº”] Token ä½¿ç”¨:")
                        print(f"    - Prompt Tokens: {usage.get('prompt_tokens', 'N/A')}")
                        print(f"    - Completion Tokens: {usage.get('completion_tokens', 'N/A')}")
                        print(f"    - Total Tokens: {usage.get('total_tokens', 'N/A')}")
                    
                    # æ‰“å° orchestrator_traceï¼ˆå¦‚æœå­˜åœ¨ï¼Œç”¨äºè°ƒè¯•ï¼Œå·²è„±æ•ï¼‰
                    if "orchestrator_trace" in result:
                        trace = result["orchestrator_trace"]
                        print(f"[ğŸ“¥ å“åº”] Orchestrator Trace å­˜åœ¨ï¼Œé•¿åº¦: {len(json.dumps(trace))} å­—ç¬¦")
                        print(f"[ğŸ“¥ å“åº”] Orchestrator Trace (å·²è„±æ•):\n{safe_log_json(trace)}")
                    
                    if content and content.strip():
                        print(f"[ğŸ“¥ å“åº”] Content (å‰1000å­—ç¬¦):\n{content[:1000]}...")
                        print(f"[ğŸ“¥ å“åº”] å®Œæ•´ Content:\n{content}")
                        print(f"{'='*80}\n")
                        return content.strip()
                    else:
                        # å¦‚æœ deepseek å¤±è´¥ï¼Œå°è¯• gemini
                        if model == "deepseek":
                            print(f"    [âš ï¸ è­¦å‘Š] DeepSeek è¿”å›ç©ºå†…å®¹ï¼Œå°è¯• Gemini...")
                            return self.call_llm(prompt, system_prompt, max_tokens, temperature, "gemini-2.5-pro")
                        raise ValueError("API å“åº”ä¸­ content ä¸ºç©ºå­—ç¬¦ä¸²")
                else:
                    print(f"[âŒ é”™è¯¯] API å“åº”æ ¼å¼å¼‚å¸¸ï¼Œç¼ºå°‘ choices å­—æ®µ")
                    raise ValueError(f"API å“åº”æ ¼å¼å¼‚å¸¸")
            else:
                # ğŸ”’ P1å®‰å…¨ä¿®å¤ï¼šä½¿ç”¨loggerå’Œè„±æ•ï¼Œé¿å…æš´éœ²æ•æ„Ÿé”™è¯¯ä¿¡æ¯
                error_text = response.text[:200] if hasattr(response, 'text') else 'N/A'  # å‡å°‘åˆ°200å­—ç¬¦
                sanitized_error = safe_log(error_text)  # è„±æ•é”™è¯¯ä¿¡æ¯
                logger.error(f"API call failed: {response.status_code}, error: {sanitized_error}")
                print(f"[âŒ é”™è¯¯] API è°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                raise ValueError(f"API è°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
        except requests.exceptions.RequestException as e:
            # ğŸ”’ P1 å®‰å…¨ä¿®å¤: ä¸æš´éœ²è¯¦ç»†çš„å¼‚å¸¸ä¿¡æ¯å’Œå †æ ˆè·Ÿè¸ª
            logger.error(f"API request failed: {type(e).__name__}")
            print(f"[âŒ é”™è¯¯] API è¯·æ±‚å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–è”ç³»ç®¡ç†å‘˜")
            raise ValueError(f"API è¯·æ±‚å¼‚å¸¸ï¼Œè¯·ç¨åé‡è¯•")
            
    def search(self, query: str, max_results: int = 10, include_domains: list = None, country_code: str = None) -> list:
        """
        æ‰§è¡Œæœç´¢ (é€‚é… Tavily/Metaso)
        [ä¿®å¤] 2026-01-20: æ·»åŠ  country_code å‚æ•°æ”¯æŒ
        """
        # 1. ä¼˜å…ˆä½¿ç”¨ UnifiedClient çš„ search æ–¹æ³•ï¼ˆæ”¯æŒ Google/Tavily/Metasoï¼‰
        if self.use_unified_client:
            try:
                # ä½¿ç”¨ç»Ÿä¸€å®¢æˆ·ç«¯çš„ search æ–¹æ³•ï¼Œå®ƒä¼šè‡ªåŠ¨é€‰æ‹©æœ€ä½³çš„æœç´¢å¼•æ“
                results_dicts = self.unified_client.search(
                    query=query,
                    max_results=max_results,
                    include_domains=include_domains,
                    country_code=country_code or "CN"  # é»˜è®¤ä½¿ç”¨ä¸­å›½ï¼Œå¯ä»¥ä¼ å…¥å…¶ä»–ä»£ç 
                )
                # Convert dicts to SearchResult objects
                results = []
                for item in results_dicts:
                    url = item.get('url', '')
                    # ğŸ”’ P1 SSRFé˜²æŠ¤: éªŒè¯URLå®‰å…¨æ€§
                    if not is_safe_url(url):
                        logger.warning(f"Blocked unsafe URL from search results: {url}")
                        continue  # è·³è¿‡ä¸å®‰å…¨çš„URL

                    results.append(SearchResult(
                        title=item.get('title', ''),
                        url=url,
                        snippet=item.get('snippet', item.get('content', '')),
                        source=item.get('search_engine', 'Unknown'),
                        search_engine=item.get('search_engine', 'Unknown')
                    ))
                return results
            except Exception as e:
                # ğŸ”’ P1 å®‰å…¨ä¿®å¤: ä¸æš´éœ²è¯¦ç»†çš„å¼‚å¸¸ä¿¡æ¯å’Œå †æ ˆè·Ÿè¸ª
                logger.error(f"UnifiedClient search failed: {type(e).__name__}")
                print(f"[âš ï¸ æœç´¢å¤±è´¥] UnifiedClient æœç´¢å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•")
        # 2. Fallbackï¼šè¿”å›ç©ºåˆ—è¡¨
        print(f"[âŒ æœç´¢å¤±è´¥] æ— å¯ç”¨çš„æœç´¢å¼•æ“")
        return []


# ============================================================================
# æœç´¢è¯ç”Ÿæˆå™¨
# ============================================================================

# ============================================================================
# ç»“æœè¯„ä¼°å™¨ï¼ˆå¤ç”¨è§„åˆ™åŒ¹é…ï¼‰
# ============================================================================

class ResultEvaluator:
    """ç»“æœè¯„ä¼°å™¨ - ğŸ”’ å½“å‰å·²ç¦ç”¨ï¼ˆå¯é‡æ–°å¯ç”¨ï¼‰"""
    
    def __init__(self, llm_client: Optional[AIBuildersClient] = None):
        self.llm_client = llm_client or AIBuildersClient()
        print(f"    [âœ… ResultEvaluator] åˆå§‹åŒ–ï¼ˆè¯„ä¼°é€»è¾‘å·²ç¦ç”¨ï¼‰")
    
    def _classify_resource_type(self, title: str, url: str, snippet: str) -> str:
        """
        åŸºäºè§„åˆ™å’ŒLLMåˆ†ç±»èµ„æºç±»å‹
        è¿”å›ï¼šæ’­æ”¾åˆ—è¡¨ã€è§†é¢‘ã€æ•™æã€æ•™è¾…ã€ç»ƒä¹ é¢˜ã€å…¶ä»–
        """
        title_lower = title.lower()
        url_lower = url.lower()
        snippet_lower = snippet.lower() if snippet else ""
        combined_text = f"{title_lower} {url_lower} {snippet_lower}"

        # 0. æ’­æ”¾åˆ—è¡¨æ£€æŸ¥ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
        # âš ï¸ æ’é™¤åšä¸»çš„å…¨éƒ¨æ’­æ”¾åˆ—è¡¨é¡µé¢ï¼ˆä¸æ˜¯å•ä¸ªè§†é¢‘åˆé›†ï¼‰
        if any(exclude in url_lower for exclude in ['/playlists$', '/channel/', '/c/', '/user/']):
            # è¿™äº›æ˜¯åšä¸»çš„å…¨éƒ¨æ’­æ”¾åˆ—è¡¨é¡µé¢ï¼Œä¸æ˜¯å•ä¸ªè§†é¢‘åˆé›†
            # ä»ç„¶æ ‡è®°ä¸ºæ’­æ”¾åˆ—è¡¨ç±»å‹ï¼Œä½†ä¼šåœ¨åç»­è¿‡æ»¤ä¸­å¤„ç†
            return "å…¶ä»–"

        # æ£€æŸ¥URLä¸­çš„æ’­æ”¾åˆ—è¡¨ç‰¹å¾ï¼ˆå•ä¸ªå…·ä½“çš„æ’­æ”¾åˆ—è¡¨ï¼‰
        if any(indicator in url_lower for indicator in ['playlist?', 'list=', '/videos']):
            return "æ’­æ”¾åˆ—è¡¨"

        # æ£€æŸ¥æ ‡é¢˜ä¸­çš„æ’­æ”¾åˆ—è¡¨å…³é”®è¯
        playlist_keywords = [
            'playlist', 'play list',
            'complete course', 'full course', 'all lessons',
            'series', 'collection',
            'Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªØ´ØºÙŠÙ„', 'Ø³Ù„Ø³Ù„Ø©',  # é˜¿æ‹‰ä¼¯è¯­
            'æ’­æ”¾åˆ—è¡¨', 'ç³»åˆ—', 'å…¨å¥—', 'å®Œæ•´è¯¾ç¨‹'
        ]
        if any(kw in combined_text for kw in playlist_keywords):
            # å¦‚æœæ ‡é¢˜åŒ…å«æ’­æ”¾åˆ—è¡¨å…³é”®è¯ï¼Œä½†URLæ˜¯/playlistsé¡µé¢ï¼Œåˆ™æ’é™¤
            if '/playlists' in url_lower and not any(ind in url_lower for ind in ['list=', 'playlist?']):
                return "å…¶ä»–"
            return "æ’­æ”¾åˆ—è¡¨"

        # 1. è§†é¢‘ç›¸å…³å…³é”®è¯
        video_keywords = [
            'video', 'youtube.com', 'youtu.be', 'watch',
            'æ’­æ”¾', 'è§†é¢‘', 'video pembelajaran',
            'video lesson', 'tutorial', 'è¯¾ç¨‹è§†é¢‘', 'lecture', 'lesson',
            'vimeo.com', 'bilibili.com/video', 'dailymotion.com'
        ]
        if any(keyword in combined_text for keyword in video_keywords):
            return "è§†é¢‘"

        # 2. ç»ƒä¹ é¢˜ç›¸å…³å…³é”®è¯
        exercise_keywords = [
            'exercise', 'practice', 'quiz', 'test', 'exam', 'worksheet',
            'ç»ƒä¹ é¢˜', 'ç»ƒä¹ ', 'latihan', 'soal', 'ujian', 'kuis',
            'lembar kerja', 'lkpd', 'assess', 'assessment'
        ]
        if any(keyword in combined_text for keyword in exercise_keywords):
            return "ç»ƒä¹ é¢˜"

        # 3. æ•™æç›¸å…³å…³é”®è¯ï¼ˆä¼˜å…ˆçº§é«˜äºæ•™è¾…ï¼‰
        textbook_keywords = [
            'textbook', 'book', 'æ•™æ', 'æ•™ç§‘ä¹¦', 'buku', 'buku pelajaran',
            'modul', 'module', 'coursebook', 'student book',
            'buku siswa', 'buku guru', 'kurikulum'
        ]
        if any(keyword in combined_text for keyword in textbook_keywords):
            return "æ•™æ"

        # 4. æ•™è¾…ç›¸å…³å…³é”®è¯
        supplement_keywords = [
            'guide', 'handbook', 'manual', 'æ•™è¾…', 'å‚è€ƒä¹¦', 'panduan',
            'å‚è€ƒ', 'supplement', 'è¾…åŠ©ææ–™', 'supplementary material',
            'bahan ajar', 'teaching material'
        ]
        if any(keyword in combined_text for keyword in supplement_keywords):
            return "æ•™è¾…"

        # 5. PDFæ–‡ä»¶é€šå¸¸å±äºæ•™ææˆ–æ•™è¾…
        if '.pdf' in url_lower:
            # è¿›ä¸€æ­¥åˆ¤æ–­
            if any(kw in title_lower for kw in ['modul', 'buku', 'textbook', 'kurikulum']):
                return "æ•™æ"
            elif any(kw in title_lower for kw in ['panduan', 'guide', 'handbook']):
                return "æ•™è¾…"
            else:
                return "æ•™æ"

        # 6. å­¦ä¹ èµ„æ–™ç›¸å…³
        learning_keywords = [
            'material', 'resource', 'content', 'å­¦ä¹ èµ„æ–™', 'å­¦ä¹ èµ„æº',
            'materi', 'bahan ajar', 'learning material', 'study material'
        ]
        if any(keyword in combined_text for keyword in learning_keywords):
            return "å…¶ä»–"

        # 7. æ ¹æ®URLæ¨æ–­
        if 'slideshare.net' in url_lower or 'scribd.com' in url_lower:
            return "æ•™è¾…"
        if 'kemdikbud.go.id' in url_lower:
            return "æ•™æ"

        # é»˜è®¤è¿”å›"å…¶ä»–"
        return "å…¶ä»–"
    
    def evaluate_results(self, search_results: List[SearchResult],
                         country: str = "", grade: str = "", subject: str = "") -> List[SearchResult]:
        """
        è¯„ä¼°æœç´¢ç»“æœå¹¶åˆ†ç±»èµ„æºç±»å‹

        åŠŸèƒ½ï¼š
        - ä¸ºæ¯ä¸ªç»“æœåˆ†ç±»èµ„æºç±»å‹ï¼ˆè§†é¢‘ã€æ•™æã€æ•™è¾…ã€ç»ƒä¹ é¢˜ï¼‰
        - è®¾ç½®é»˜è®¤è¯„åˆ†
        """
        if not search_results:
            return search_results

        print(f"    [â„¹ï¸ è¯„ä¼°] å¼€å§‹è¯„ä¼°å’Œåˆ†ç±» {len(search_results)} ä¸ªç»“æœ...")

        for result in search_results:
            # åˆ†ç±»èµ„æºç±»å‹
            resource_type = self._classify_resource_type(result.title, result.url, result.snippet)
            result.resource_type = resource_type

            # è®¾ç½®é»˜è®¤è¯„åˆ† (ä¿®å¤: ç§»é™¤è™šå‡çš„é»˜è®¤è¯„åˆ†)
            # if not result.score or result.score == 0:
            #     result.score = 7.5
            # if not result.recommendation_reason:
            #     result.recommendation_reason = "é»˜è®¤æ¨è"
            if not result.source:
                result.source = "è§„åˆ™"

        # ç»Ÿè®¡åˆ†ç±»ç»“æœ
        type_counts = {}
        for result in search_results:
            rtype = result.resource_type or "æœªåˆ†ç±»"
            type_counts[rtype] = type_counts.get(rtype, 0) + 1

        print(f"    [ğŸ“Š åˆ†ç±»ç»Ÿè®¡] {', '.join([f'{k}:{v}' for k,v in type_counts.items()])}")

        return search_results
    


# ============================================================================
# ä¸»æœç´¢å¼•æ“
# ============================================================================

@dataclass
class CountrySearchContext:
    """
    å›½å®¶æœç´¢ä¸Šä¸‹æ–‡

    å°è£…å›½å®¶ç›¸å…³çš„æœç´¢é…ç½®ä¿¡æ¯ï¼Œæ¶ˆé™¤é‡å¤çš„å›½å®¶é…ç½®è·å–ä»£ç 
    """
    country_code: str  # å›½å®¶ä»£ç ï¼ˆå¤§å†™ï¼Œå¦‚ "ID", "CN"ï¼‰
    language_code: str  # è¯­è¨€ä»£ç ï¼ˆå¦‚ "id", "zh"ï¼‰
    domains: List[str]  # ä¼˜å…ˆåŸŸååˆ—è¡¨
    config: Any  # å›½å®¶é…ç½®å¯¹è±¡ï¼ˆå¯é€‰ï¼‰


class SearchEngineV2:
    """æ–°ç‰ˆæœç´¢å¼•æ“"""

    def __init__(self, llm_client: Optional[AIBuildersClient] = None, log_collector=None):
        self.llm_client = llm_client or AIBuildersClient()
        self.log_collector = log_collector  # ä¿å­˜æ—¥å¿—æ”¶é›†å™¨å¼•ç”¨
        self.config_manager = ConfigManager()  # ç”¨äºè¯»å–å›½å®¶é…ç½®

        # åˆå§‹åŒ–æœç´¢ç­–ç•¥ä»£ç†
        self.strategy_agent = SearchStrategyAgent(
            llm_client=self.llm_client,
            config_manager=self.config_manager
        )

        # åˆå§‹åŒ–ç»“æœè¯„ä¼°å™¨
        self.evaluator = ResultEvaluator(llm_client=self.llm_client)

        # ğŸ”¥ ç§»é™¤ QueryGeneratorï¼ˆå·²è¢« IntelligentQueryGenerator æ›¿ä»£ï¼ŒåŠŸèƒ½é‡å¤ï¼‰
        # IntelligentQueryGenerator ä½¿ç”¨æ›´æ–°çš„æ¨¡å‹ï¼ˆgemini-2.5-flash vs deepseekï¼‰ï¼Œæ•ˆæœæ›´å¥½
        # self.query_generator = QueryGenerator(
        #     llm_client=self.llm_client,
        #     config_manager=self.config_manager
        # )

        # ç®€å•çš„é…ç½®ç®¡ç†å™¨å ä½ç¬¦ï¼ˆç”¨äºå¹¶è¡Œæœç´¢é…ç½®ï¼‰
        class SimpleConfigManager:
            def get_search_config(self):
                return {
                    'edtech_domains': [
                        'khanacademy.org', 'coursera.org', 'edx.org',
                        'youtube.com', 'vimeo.com', 'dailymotion.com'
                    ],
                    'localization': {
                        'ar': 'ÙÙŠØ¯ÙŠÙˆ ØªØ¹Ù„ÙŠÙ…ÙŠ',
                        'en': 'Video lesson',
                        'id': 'Video pelajaran',
                        'zh': 'æ•™å­¦è§†é¢‘'
                    }
                }

        self.app_config = SimpleConfigManager()

        self.search_cache = get_search_cache()  # æ—§ç‰ˆå•çº§ç¼“å­˜ï¼ˆå…¼å®¹ä¿ç•™ï¼‰
        self.multi_cache = get_multi_level_cache()  # æ–°ç‰ˆä¸‰çº§ç¼“å­˜ï¼ˆL1å†…å­˜+L2Redis+L3ç£ç›˜ï¼‰
        # è¯„åˆ†å™¨å°†åœ¨searchæ–¹æ³•ä¸­æ ¹æ®country_codeåŠ¨æ€åˆå§‹åŒ–ï¼ˆå¸¦çŸ¥è¯†åº“ï¼‰
        self.result_scorer = None  # å°†åœ¨searchæ—¶åˆå§‹åŒ–ä¸ºå¸¦çŸ¥è¯†åº“çš„è¯„åˆ†å™¨
        self.result_scorer_without_kb = get_result_scorer()  # æ— çŸ¥è¯†åº“çš„å¤‡ç”¨è¯„åˆ†å™¨
        self._scorer_cache = {}  # ç¼“å­˜å„å›½çš„è¯„åˆ†å™¨ {country_code: scorer}
        self._scorer_cache_lock = threading.Lock()  # ğŸ”’ P1çº¿ç¨‹å®‰å…¨: è¯„åˆ†å™¨ç¼“å­˜çš„çº¿ç¨‹é”
        self._playlist_cache = {}  # ğŸš€ P1æ€§èƒ½ä¼˜åŒ–: ç¼“å­˜æ’­æ”¾åˆ—è¡¨ä¿¡æ¯ {playlist_url: {video_count, duration}}
        self.recommendation_generator = get_recommendation_generator()  # LLMæ¨èç†ç”±ç”Ÿæˆå™¨
        print(f"    [âœ…] æ™ºèƒ½è¯„åˆ†å™¨å·²åˆå§‹åŒ–ï¼ˆå°†åœ¨æœç´¢æ—¶åŠ è½½çŸ¥è¯†åº“ï¼‰")
        print(f"    [âœ…] LLMæ¨èç†ç”±ç”Ÿæˆå™¨å·²åˆå§‹åŒ–")
        print(f"    [âœ…] ä¸‰çº§ç¼“å­˜ç³»ç»Ÿå·²å¯ç”¨ (L1:å†…å­˜100æ¡/5åˆ†é’Ÿ + L2:Redis/1å°æ—¶ + L3:ç£ç›˜/24å°æ—¶)")

        # ğŸ” åˆå§‹åŒ–æœç´¢é€æ˜åº¦æ”¶é›†å™¨
        from core.search_transparency_collector import get_transparency_collector
        self.transparency_collector = get_transparency_collector()
        logger.debug("    [âœ…] æœç´¢é€æ˜åº¦æ”¶é›†å™¨å·²åˆå§‹åŒ–")

        # åˆå§‹åŒ–ç™¾åº¦æœç´¢å®¢æˆ·ç«¯ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
        self.baidu_search_enabled = False
        try:
            baidu_api_key_raw = os.getenv("BAIDU_API_KEY")
            if baidu_api_key_raw:
                # ğŸ”’ P1 ç¯å¢ƒå˜é‡éªŒè¯: éªŒè¯ç™¾åº¦APIå¯†é’¥
                try:
                    baidu_api_key = validate_api_key(baidu_api_key_raw, "BAIDU_API_KEY")
                    from search_strategist import SearchHunter
                    self.baidu_hunter = SearchHunter(search_engine="baidu", llm_client=None)
                    self.baidu_search_enabled = True
                    print(f"    [âœ…] ç™¾åº¦æœç´¢å·²å¯ç”¨")
                except ValueError as e:
                    logger.warning(f"BAIDU_API_KEY validation failed, skipping Baidu search: {str(e)}")
                    print(f"    [âš ï¸] ç™¾åº¦APIå¯†é’¥éªŒè¯å¤±è´¥ï¼Œè·³è¿‡ç™¾åº¦æœç´¢: {str(e)}")
            else:
                print(f"    [â„¹ï¸] ç™¾åº¦æœç´¢æœªé…ç½®ï¼ˆBAIDU_API_KEYæœªè®¾ç½®ï¼‰")
        except Exception as e:
            print(f"    [âš ï¸] ç™¾åº¦æœç´¢åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.baidu_search_enabled = False

        # åˆå§‹åŒ– Google æœç´¢å®¢æˆ·ç«¯ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
        self.google_search_enabled = False
        try:
            google_api_key_raw = os.getenv("GOOGLE_API_KEY")
            google_cx_raw = os.getenv("GOOGLE_CX")
            if google_api_key_raw and google_cx_raw:
                # ğŸ”’ P1 ç¯å¢ƒå˜é‡éªŒè¯: éªŒè¯Google APIå¯†é’¥å’ŒCX
                try:
                    google_api_key = validate_api_key(google_api_key_raw, "GOOGLE_API_KEY")
                    # CXéœ€è¦ç‰¹æ®ŠéªŒè¯ï¼ˆé€šå¸¸è¾ƒçŸ­ï¼‰
                    if len(google_cx_raw.strip()) < 5:
                        raise ValueError("GOOGLE_CX is too short")
                    google_cx = google_cx_raw.strip()

                    from search_strategist import SearchHunter
                    self.google_hunter = SearchHunter(search_engine="google", llm_client=None)
                    self.google_search_enabled = True
                    print(f"    [âœ…] Google æœç´¢å·²å¯ç”¨")
                except ValueError as e:
                    logger.warning(f"Google API credentials validation failed: {str(e)}")
                    print(f"    [âš ï¸] Google APIå‡­è¯éªŒè¯å¤±è´¥ï¼Œè·³è¿‡Googleæœç´¢: {str(e)}")
            else:
                print(f"    [â„¹ï¸] Google æœç´¢æœªé…ç½®ï¼ˆéœ€è¦ GOOGLE_API_KEY å’Œ GOOGLE_CXï¼‰")
        except Exception as e:
            print(f"    [âš ï¸] Google æœç´¢åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.google_search_enabled = False

    def _get_memory_usage(self) -> str:
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        try:
            import resource
            import sys
            rss_kb = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
            if sys.platform == 'darwin':
                rss_mb = rss_kb / 1024 / 1024
            else:
                rss_mb = rss_kb / 1024
            return f"{rss_mb:.1f} MB"
        except:
            return "Unknown"

    def _log_step(self, message: str, level: str = "info", emoji: str = "âœ…") -> None:
        """
        ç»Ÿä¸€çš„æ­¥éª¤æ—¥å¿—è¾“å‡º

        åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ—¥å¿—æ–‡ä»¶ï¼Œæ¶ˆé™¤é‡å¤ä»£ç 

        Args:
            message: æ—¥å¿—æ¶ˆæ¯
            level: æ—¥å¿—çº§åˆ«
            emoji: è¡¨æƒ…ç¬¦å·
        """
        formatted_msg = f"    [{emoji} {message}]"
        print(formatted_msg)

        logger_func = getattr(logger, level.lower(), logger.info)
        logger_func(f"[{message}]")

    def _get_country_context(self, country: str) -> CountrySearchContext:
        """
        è·å–å›½å®¶æœç´¢ä¸Šä¸‹æ–‡

        å°è£…é‡å¤çš„å›½å®¶é…ç½®è·å–é€»è¾‘

        Args:
            country: å›½å®¶åç§°æˆ–ä»£ç 

        Returns:
            CountrySearchContext å¯¹è±¡
        """
        country_code = country.upper()
        config = self.config_manager.get_country_config(country_code)

        return CountrySearchContext(
            country_code=country_code,
            language_code=config.language_code if config else "en",
            domains=config.domains[:5] if config else [],
            config=config
        )

    def _setup_visual_evaluation_timeout(self, timeout_seconds: int = 30) -> None:
        """
        è®¾ç½®è§†è§‰è¯„ä¼°è¶…æ—¶

        Args:
            timeout_seconds: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        """
        import signal

        def timeout_handler(signum, frame):
            raise TimeoutError("è§†è§‰è¯„ä¼°è¶…æ—¶")

        if hasattr(signal, 'SIGALRM'):
            signal.signal(signal.SIGALRM, timeout_handler)
            signal.alarm(timeout_seconds)

    def _clear_visual_evaluation_timeout(self) -> None:
        """æ¸…é™¤è§†è§‰è¯„ä¼°è¶…æ—¶"""
        import signal
        if hasattr(signal, 'SIGALRM'):
            signal.alarm(0)

    def _evaluate_with_visual_timeout(
        self,
        result_dict: dict,
        screenshot_path: str,
        query: str,
        metadata: dict,
        timeout_seconds: int = 30
    ) -> Optional[dict]:
        """
        å¸¦è¶…æ—¶ä¿æŠ¤çš„è§†è§‰è¯„ä¼°

        Args:
            result_dict: ç»“æœå­—å…¸
            screenshot_path: æˆªå›¾è·¯å¾„
            query: æœç´¢æŸ¥è¯¢
            metadata: å…ƒæ•°æ®
            timeout_seconds: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

        Returns:
            è§†è§‰è¯„ä¼°ç»“æœå­—å…¸ï¼Œå¤±è´¥è¿”å› None
        """
        try:
            # è®¾ç½®è¶…æ—¶
            self._setup_visual_evaluation_timeout(timeout_seconds)

            try:
                visual_evaluation = self.result_scorer.evaluate_with_visual(
                    result=result_dict,
                    screenshot_path=screenshot_path,
                    query=query,
                    metadata=metadata
                )
                return visual_evaluation
            finally:
                # æ¸…é™¤è¶…æ—¶
                self._clear_visual_evaluation_timeout()

        except TimeoutError:
            logger.warning(f"è§†è§‰è¯„ä¼°è¶…æ—¶: {result_dict.get('title', '')[:40]}...")
            return None
        except Exception as e:
            logger.warning(f"è§†è§‰è¯„ä¼°å¼‚å¸¸: {str(e)[:100]}")
            return None

    def _validate_grade_subject_pair(self, request: SearchRequest) -> None:
        """
        éªŒè¯å¹´çº§-å­¦ç§‘é…å¯¹

        Args:
            request: æœç´¢è¯·æ±‚
        """
        from core.grade_subject_validator import GradeSubjectValidator

        logger.info("[æ­¥éª¤ 0] å¹´çº§-å­¦ç§‘é…å¯¹éªŒè¯...")
        print("[éªŒè¯] æ£€æŸ¥å¹´çº§-å­¦ç§‘é…å¯¹...")
        try:
            validator = GradeSubjectValidator()
            validation_result = validator.validate(
                request.country,
                request.grade,
                request.subject
            )

            if not validation_result["valid"]:
                warning_msg = f"âš ï¸ {validation_result['reason']}"
                print(f"    {warning_msg}")
                if validation_result.get("suggestions"):
                    print(f"    ğŸ’¡ å»ºè®®: {', '.join(validation_result['suggestions'][:5])}")
                logger.warning(f"å¹´çº§-å­¦ç§‘é…å¯¹éªŒè¯å¤±è´¥: {request.country} {request.grade} {request.subject}")
            else:
                print(f"    âœ… å¹´çº§-å­¦ç§‘é…å¯¹éªŒè¯é€šè¿‡")
                logger.info(f"   âœ… é…å¯¹éªŒè¯é€šè¿‡")
        except Exception as e:
            print(f"    âš ï¸ éªŒè¯å¤±è´¥ï¼Œç»§ç»­æœç´¢: {str(e)}")
            logger.warning(f"é…å¯¹éªŒè¯å¼‚å¸¸: {str(e)}")

    def _initialize_scorer_for_search(self, request: SearchRequest) -> None:
        """
        ä¸ºæœç´¢åˆå§‹åŒ–è¯„åˆ†å™¨

        Args:
            request: æœç´¢è¯·æ±‚
        """
        from core.result_scorer import IntelligentResultScorer

        country_code = request.country.upper()
        if country_code not in self._scorer_cache:
            self.result_scorer = IntelligentResultScorer(
                country_code=country_code,
                log_collector=self.log_collector
            )
            self._scorer_cache[country_code] = self.result_scorer
            logger.info(f"[ğŸ“š çŸ¥è¯†åº“] å·²åŠ è½½ {country_code} è¯„åˆ†å™¨ï¼ˆå¸¦çŸ¥è¯†åº“å’Œæ—¥å¿—è®°å½•ï¼‰")
            print(f"    [âœ… çŸ¥è¯†åº“] å·²åŠ è½½ {country_code} æœç´¢çŸ¥è¯†åº“")
        else:
            self.result_scorer = self._scorer_cache[country_code]
            if self.log_collector:
                self.result_scorer.log_collector = self.log_collector
            logger.debug(f"[ğŸ“š çŸ¥è¯†åº“] ä½¿ç”¨ç¼“å­˜çš„ {country_code} è¯„åˆ†å™¨")

    def _generate_default_search_queries(
        self,
        request: SearchRequest,
        language_code: str
    ) -> List[str]:
        """
        ç”Ÿæˆé»˜è®¤æœç´¢æŸ¥è¯¢

        Args:
            request: æœç´¢è¯·æ±‚
            language_code: è¯­è¨€ä»£ç 

        Returns:
            æœç´¢æŸ¥è¯¢åˆ—è¡¨
        """
        playlist_keywords_map = {
            "id": ["playlist", "complete course", "full series", "koleksi lengkap", "kursus lengkap"],
            "en": ["playlist", "complete course", "full series", "video collection"],
            "zh": ["æ’­æ”¾åˆ—è¡¨", "å®Œæ•´è¯¾ç¨‹", "ç³»åˆ—æ•™ç¨‹"],
            "ms": ["playlist", "kursus lengkap", "siri lengkap"],
            "ar": ["Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªØ´ØºÙŠÙ„", "Ø¯ÙˆØ±Ø© ÙƒØ§Ù…Ù„Ø©"],
            "ru": ["Ğ¿Ğ»ĞµĞ¹Ğ»Ğ¸ÑÑ‚", "Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ ĞºÑƒÑ€Ñ"],
        }
        playlist_keywords = playlist_keywords_map.get(language_code, ["playlist", "complete course"])

        return [
            f"site:youtube.com {request.subject} {request.grade} {playlist_keywords[0]}",
            f"{request.subject} {request.grade} {playlist_keywords[1] if len(playlist_keywords) > 1 else 'complete course'}",
            f"site:youtube.com \"{request.subject}\" \"{request.grade}\" playlist",
            f"{request.subject} {request.grade} video lesson chapter",
            f"{request.grade} {request.subject} full course curriculum",
            f"{request.subject} for {request.grade} students tutorial",
            f"{request.grade} {request.subject} learning series complete"
        ]

    def _get_default_search_strategy(self, request: SearchRequest) -> 'SearchStrategy':
        """
        ç”Ÿæˆé»˜è®¤æœç´¢ç­–ç•¥

        Args:
            request: æœç´¢è¯·æ±‚

        Returns:
            SearchStrategy å¯¹è±¡
        """
        from search_strategy_agent import SearchStrategy

        ctx = self._get_country_context(request.country)

        search_queries = self._generate_default_search_queries(request, ctx.language_code)

        strategy = SearchStrategy(
            search_language=ctx.language_code,
            use_chinese_search_engine=(ctx.country_code == "CN"),
            platforms=["youtube.com"] + ctx.domains[:3],
            search_queries=search_queries,
            priority_domains=ctx.domains[:5],
            notes=f"é»˜è®¤æœç´¢ç­–ç•¥ï¼ˆè§„åˆ™ç”Ÿæˆï¼‰ï¼šä½¿ç”¨{ctx.language_code}è¯­è¨€ï¼Œä¼˜å…ˆæœç´¢YouTubeæ’­æ”¾åˆ—è¡¨ï¼ˆ7ä¸ªå·®å¼‚åŒ–æŸ¥è¯¢ï¼‰"
        )

        return strategy

    def _cached_search(self, query: str, search_func, engine_name: str, max_results: int = 15,
                       include_domains: Optional[List[str]] = None) -> List[SearchResult]:
        """
        å¸¦å¤šçº§ç¼“å­˜çš„æœç´¢åŒ…è£…å™¨

        ä½¿ç”¨ä¸‰çº§ç¼“å­˜ç³»ç»Ÿï¼ˆL1å†…å­˜+L2Redis+L3ç£ç›˜ï¼‰æå‡æ€§èƒ½
        [ä¿®å¤] 2026-01-20: æ·»åŠ ç¯å¢ƒå˜é‡ ENABLE_MULTI_CACHE æ§åˆ¶ç¼“å­˜å¼€å…³

        Args:
            query: æœç´¢æŸ¥è¯¢
            search_func: å®é™…çš„æœç´¢å‡½æ•°
            engine_name: æœç´¢å¼•æ“åç§°ï¼ˆç”¨äºç¼“å­˜é”®ï¼‰
            max_results: æœ€å¤§ç»“æœæ•°
            include_domains: åŒ…å«çš„åŸŸååˆ—è¡¨

        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        # ğŸ”’ P1 ç¯å¢ƒå˜é‡éªŒè¯: æ£€æŸ¥æ˜¯å¦å¯ç”¨å¤šçº§ç¼“å­˜
        enable_multi_cache = validate_env_bool(
            os.getenv("ENABLE_MULTI_CACHE"),
            "ENABLE_MULTI_CACHE",
            default=False
        )

        if enable_multi_cache:
            # ä½¿ç”¨å¤šçº§ç¼“å­˜ç³»ç»Ÿï¼ˆå¸¦æŸ¥è¯¢è§„èŒƒåŒ–ï¼‰
            cached_result = self.multi_cache.get(
                query=query,
                engine=engine_name,
                max_results=max_results,
                include_domains=include_domains
            )
        else:
            # ç¦ç”¨ç¼“å­˜ï¼Œç›´æ¥æ‰§è¡Œæœç´¢
            cached_result = None

        if cached_result is not None:
            cache_stats = self.multi_cache.get_stats()
            logger.info(
                f"âœ… å¤šçº§ç¼“å­˜å‘½ä¸­ [{engine_name}]: {query[:50]}... "
                f"(å‘½ä¸­ç‡: {cache_stats['hit_rate']:.1f}%, "
                f"L1:{cache_stats['l1_hit_rate']:.1f}% "
                f"L2:{cache_stats['l2_hit_rate']:.1f}% "
                f"L3:{cache_stats['l3_hit_rate']:.1f}%)"
            )
            # ä»ç¼“å­˜æ•°æ®é‡å»ºSearchResultå¯¹è±¡
            return [SearchResult(**item) for item in cached_result]

        # ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œå®é™…æœç´¢
        if not enable_multi_cache:
            logger.info(f"âš ï¸ å¤šçº§ç¼“å­˜å·²ç¦ç”¨ [{engine_name}]: {query[:50]}...")
        else:
            logger.info(f"âŒ å¤šçº§ç¼“å­˜æœªå‘½ä¸­ [{engine_name}]: {query[:50]}...")
        results = search_func(query, max_results, include_domains)

        # å°†ç»“æœå­˜å…¥å¤šçº§ç¼“å­˜ï¼ˆä»…åœ¨å¯ç”¨æ—¶ï¼‰
        if enable_multi_cache:
            results_dict = [result.model_dump() for result in results]
            self.multi_cache.set(
                query=query,
                engine=engine_name,
                data=results_dict,
                ttl=3600,  # 1å°æ—¶TTL
                max_results=max_results,
                include_domains=include_domains
            )
        return results

    def _parallel_search(self, query: str, search_tasks: List[Dict[str, Any]],
                        timeout: int = 30, country_code: str = "CN") -> Dict[str, List[SearchResult]]:
        """
        å¹¶è¡Œæ‰§è¡Œå¤šä¸ªæœç´¢ä»»åŠ¡

        Args:
            query: é»˜è®¤æœç´¢æŸ¥è¯¢ï¼ˆå¦‚æœä»»åŠ¡æ²¡æœ‰æŒ‡å®šæŸ¥è¯¢ï¼Œåˆ™ä½¿ç”¨æ­¤æŸ¥è¯¢ï¼‰
            search_tasks: æœç´¢ä»»åŠ¡åˆ—è¡¨ï¼Œæ¯ä¸ªä»»åŠ¡åŒ…å«:
                - name: ä»»åŠ¡åç§°
                - query: ä»»åŠ¡ç‰¹å®šçš„æœç´¢æŸ¥è¯¢ï¼ˆå¯é€‰ï¼Œä¼˜å…ˆçº§é«˜äºé»˜è®¤queryï¼‰
                - func: æœç´¢å‡½æ•°
                - engine_name: æœç´¢å¼•æ“åç§°ï¼ˆç”¨äºç¼“å­˜ï¼‰
                - max_results: æœ€å¤§ç»“æœæ•°
                - include_domains: åŒ…å«çš„åŸŸåï¼ˆå¯é€‰ï¼‰
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            country_code: å›½å®¶ä»£ç ï¼ˆç”¨äºå…è´¹é¢åº¦ä¼˜å…ˆç­–ç•¥ï¼‰

        Returns:
            å­—å…¸ï¼Œé”®ä¸ºä»»åŠ¡åç§°ï¼Œå€¼ä¸ºæœç´¢ç»“æœåˆ—è¡¨
        """
        results = {}
        start_time = time.time()

        print(f"    [âš¡ å¹¶è¡Œæœç´¢] å¯åŠ¨ {len(search_tasks)} ä¸ªå¹¶è¡Œæœç´¢ä»»åŠ¡")
        print(f"    [âš™ï¸ å‚æ•°] è¶…æ—¶æ—¶é—´: {timeout}ç§’, å›½å®¶ä»£ç : {country_code}")

        def execute_search_task(task: Dict[str, Any]) -> tuple:
            """æ‰§è¡Œå•ä¸ªæœç´¢ä»»åŠ¡"""
            task_name = task['name']
            search_func = task['func']
            engine_name = task['engine_name']
            max_results = task.get('max_results', 15)
            include_domains = task.get('include_domains', None)
            # ä½¿ç”¨ä»»åŠ¡ç‰¹å®šçš„æŸ¥è¯¢ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤æŸ¥è¯¢
            task_query = task.get('query', query)

            try:
                task_start = time.time()

                # åˆ¤æ–­æ˜¯å¦æ˜¯ llm_client.searchï¼ˆæ”¯æŒ country_code å‚æ•°ï¼‰
                # æ£€æŸ¥æ˜¯å¦æ˜¯ UnifiedLLMClient çš„æ–¹æ³•
                is_llm_client_search = (
                    hasattr(search_func, '__self__') and
                    isinstance(search_func.__self__, UnifiedLLMClient) and
                    search_func.__name__ == 'search'
                )

                if is_llm_client_search:
                    # llm_client.search æ”¯æŒ country_code å‚æ•°ï¼ˆå…è´¹é¢åº¦ä¼˜å…ˆç­–ç•¥ï¼‰
                    task_results = self._cached_search(
                        query=task_query,
                        search_func=lambda q, mr, id: search_func(q, max_results=mr, include_domains=include_domains, country_code=country_code),
                        engine_name=engine_name,
                        max_results=max_results,
                        include_domains=include_domains
                    )
                else:
                    # âœ¨ ä¿®å¤ï¼šæ£€æŸ¥æœç´¢å‡½æ•°æ˜¯å¦æ”¯æŒ country_code å‚æ•°
                    # åªç»™ Google Hunter ä¼ é€’ country_codeï¼ˆç”¨äºæœ¬åœ°åŒ–æœç´¢ï¼‰
                    # Tavily/Metaso/Baidu ä¸æ”¯æŒæ­¤å‚æ•°
                    import inspect
                    func_name = search_func.__name__ if hasattr(search_func, '__name__') else str(search_func)
                    if hasattr(search_func, '__self__') and 'google_hunter' in str(type(search_func.__self__)):
                        # Google Hunter æ”¯æŒ country_code å‚æ•°
                        task_results = self._cached_search(
                            query=task_query,
                            search_func=lambda q, mr, id: search_func(q, max_results=mr, country_code=country_code),
                            engine_name=engine_name,
                            max_results=max_results,
                            include_domains=include_domains
                        )
                    else:
                        # å…¶ä»–æœç´¢å¼•æ“ä¸æ”¯æŒ country_code å‚æ•°
                        task_results = self._cached_search(
                            query=task_query,
                            search_func=lambda q, mr, id: search_func(q, max_results=mr),
                            engine_name=engine_name,
                            max_results=max_results,
                            include_domains=include_domains
                        )

                task_elapsed = time.time() - task_start
                print(f"    [âœ… {task_name}] å®Œæˆ ({task_elapsed:.2f}ç§’, {len(task_results)}ä¸ªç»“æœ)")

                # ========== ğŸ” è®°å½•æœç´¢æ‰§è¡Œåˆ°é€æ˜åº¦æ”¶é›†å™¨ï¼ˆP0-1ï¼‰ ==========
                self.transparency_collector.record_search_execution(
                    query=task_query,
                    engine=engine_name,
                    result_count=len(task_results),
                    duration_ms=task_elapsed * 1000,  # è½¬æ¢ä¸ºæ¯«ç§’
                    reasoning=f"ä»»åŠ¡{task_name}ï¼Œæœç´¢{task_query}"
                )
                logger.debug(f"[ğŸ” é€æ˜åº¦] å·²è®°å½•æœç´¢æ‰§è¡Œ: {engine_name} - {len(task_results)}ä¸ªç»“æœ")
                # ========== æœç´¢æ‰§è¡Œè®°å½•ç»“æŸ ==========

                return (task_name, task_results)
            except Exception as e:
                print(f"    [âŒ {task_name}] å¤±è´¥: {str(e)}")
                logger.error(f"å¹¶è¡Œæœç´¢ä»»åŠ¡å¤±è´¥ [{task_name}]: {str(e)}")
                return (task_name, [])

        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œæ‰§è¡Œæœç´¢ï¼ˆTODOï¼šæœªæ¥è¿ç§»åˆ°aiohttpä»¥å®ç°çœŸæ­£çš„å¼‚æ­¥I/Oï¼‰
        # å½“å‰ä½¿ç”¨ThreadPoolExecutoråŒ…è£…åŒæ­¥requestsè°ƒç”¨ï¼Œå·²å¯å¹¶å‘æ‰§è¡Œä½†ä»æœ‰æ”¹è¿›ç©ºé—´
        # ä¼˜åŒ–å»ºè®®ï¼šä½¿ç”¨aiohttp + asyncioå®ç°å¼‚æ­¥HTTPè¯·æ±‚ï¼Œæ€§èƒ½å¯æå‡30%+
        with ThreadPoolExecutor(max_workers=min(len(search_tasks), 10)) as executor:  # å¢åŠ å¹¶å‘åº¦ï¼ˆP1ä¿®å¤ï¼‰
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_task = {
                executor.submit(execute_search_task, task): task
                for task in search_tasks
            }

            # æ”¶é›†å®Œæˆçš„ä»»åŠ¡ç»“æœï¼ˆæ·»åŠ è¶…æ—¶ä¿æŠ¤ï¼‰
            try:
                for future in as_completed(future_to_task, timeout=timeout):
                    try:
                        task_name, task_results = future.result(timeout=1.0)  # å•ä¸ªfutureç»“æœè·å–è¶…æ—¶
                        results[task_name] = task_results
                    except concurrent.futures.TimeoutError:
                        logger.warning(f"ä»»åŠ¡ {future_to_task[future].get('name', 'unknown')} ç»“æœè·å–è¶…æ—¶")
                        results[future_to_task[future].get('name', 'unknown')] = []
                    except Exception as e:
                        logger.error(f"ä»»åŠ¡ç»“æœå¤„ç†å¤±è´¥: {str(e)}")
                        results[future_to_task[future].get('name', 'unknown')] = []
            except concurrent.futures.TimeoutError:
                logger.warning(f"å¹¶è¡Œæœç´¢æ•´ä½“è¶…æ—¶ ({timeout}ç§’)ï¼Œå·²æ”¶é›†éƒ¨åˆ†ç»“æœ")
                # å°è¯•è·å–å·²å®Œæˆçš„ä»»åŠ¡ç»“æœ
                for future in future_to_task:
                    if future.done():
                        try:
                            task_name, task_results = future.result(timeout=0.5)
                            if task_name not in results:
                                results[task_name] = task_results
                        except:
                            pass

        elapsed_time = time.time() - start_time
        total_results = sum(len(r) for r in results.values())
        print(f"    [âš¡ å¹¶è¡Œæœç´¢] å®Œæˆï¼Œè€—æ—¶ {elapsed_time:.2f}ç§’ï¼Œå…± {total_results} ä¸ªç»“æœ")

        return results

    def _is_edtech_domain(self, url: str) -> bool:
        """
        æ£€æŸ¥URLæ˜¯å¦æ¥è‡ªEdTechå¹³å°ï¼ˆçŸ¥åæ•™è‚²å¹³å°ï¼‰

        Args:
            url: è¦æ£€æŸ¥çš„URL

        Returns:
            æ˜¯å¦æ¥è‡ªEdTechå¹³å°
        """
        try:
            search_config = self.app_config.get_search_config()
            edtech_domains = search_config.get('edtech_domains', [])

            url_lower = url.lower()
            for domain in edtech_domains:
                if domain.lower() in url_lower:
                    logger.debug(f"æ£€æµ‹åˆ°EdTechå¹³å°: {domain}")
                    return True

            return False
        except Exception as e:
            logger.warning(f"æ£€æŸ¥EdTechåŸŸåå¤±è´¥: {str(e)}")
            return False

    def _generate_fallback_query(self, request: SearchRequest) -> str:
        """
        ç”Ÿæˆé™çº§æœç´¢è¯ï¼ˆè§„åˆ™ç”Ÿæˆï¼Œä¸ä½¿ç”¨LLMï¼‰

        Args:
            request: æœç´¢è¯·æ±‚

        Returns:
            æœç´¢è¯
        """
        # è§„åˆ™ç”Ÿæˆé»˜è®¤æœç´¢è¯
        default_query = f"{request.subject} {request.grade} playlist"
        if request.semester:
            default_query += f" semester {request.semester}"

        # ğŸ”’ P1 SSRFé˜²æŠ¤: æ¸…ç†æœç´¢æŸ¥è¯¢ï¼Œç§»é™¤å±é™©è¿ç®—ç¬¦
        sanitized_query = sanitize_search_query(default_query)

        logger.info(f"[ğŸ”„ è§„åˆ™ç”Ÿæˆ] ç”Ÿæˆé»˜è®¤æœç´¢è¯: \"{sanitized_query}\"")
        return sanitized_query

    def incremental_search(self, request: SearchRequest) -> SearchResponse:
        """
        æ¸è¿›å¼æœç´¢ï¼ˆä¼˜åŒ–æ–¹æ¡ˆä¸€ï¼‰

        ç‰¹ç‚¹ï¼š
        - ç”Ÿæˆ1ä¸ªæœ€ä¼˜æŸ¥è¯¢ï¼ˆè€Œé5-7ä¸ªï¼‰
        - æ ¹æ®è´¨é‡åŠ¨æ€å†³å®šæ˜¯å¦è¡¥å……æœç´¢
        - é«˜è´¨é‡ç›´æ¥è¿”å›ï¼Œä¸­ä½è´¨é‡è¿›è¡Œè¡¥å……æœç´¢æˆ–é‡è¯•
        - æ˜¾è‘—é™ä½APIè°ƒç”¨æ¬¡æ•°å’Œå“åº”æ—¶é—´

        Args:
            request: æœç´¢è¯·æ±‚

        Returns:
            æœç´¢å“åº”
        """
        search_start_time = time.time()

        logger.info("="*80)
        logger.info(f"ğŸ¯ [æ¸è¿›å¼æœç´¢] {request.country} - {request.grade} - {request.subject}")
        logger.info("="*80)

        print(f"\n{'='*80}")
        print(f"ğŸ¯ æ¸è¿›å¼æœç´¢ï¼ˆä¼˜åŒ–æ–¹æ¡ˆä¸€ï¼‰")
        print(f"{'='*80}\n")

        # ========== Step 1: ç”Ÿæˆæœ€ä¼˜æŸ¥è¯¢ ==========
        print(f"[Step 1] ç”Ÿæˆæœ€ä¼˜æŸ¥è¯¢...")
        logger.info(f"[Step 1] ç”Ÿæˆæœ€ä¼˜æŸ¥è¯¢...")

        try:
            best_query = self.strategy_agent.generate_best_query(
                country=request.country,
                grade=request.grade,
                subject=request.subject,
                semester=request.semester
            )
            print(f"    [âœ… æœ€ä¼˜æŸ¥è¯¢] \"{best_query}\"")
            logger.info(f"[âœ… æœ€ä¼˜æŸ¥è¯¢] \"{best_query}\"")
        except Exception as e:
            logger.warning(f"[âš ï¸ LLMæŸ¥è¯¢ç”Ÿæˆå¤±è´¥] {str(e)}ï¼Œä½¿ç”¨è§„åˆ™ç”Ÿæˆ")
            best_query = self._generate_fallback_query(request)
            print(f"    [âœ… è§„åˆ™æŸ¥è¯¢] \"{best_query}\"")

        # ========== Step 2: åˆå§‹æœç´¢ ==========
        print(f"\n[Step 2] æ‰§è¡Œåˆå§‹æœç´¢...")
        logger.info(f"[Step 2] æ‰§è¡Œåˆå§‹æœç´¢...")

        initial_results = self._perform_initial_search(best_query, request.country)

        if not initial_results:
            logger.warning("[âš ï¸ åˆå§‹æœç´¢æ— ç»“æœ]ï¼Œå°è¯•é™çº§ç­–ç•¥")
            return self._handle_empty_results(request, best_query)

        print(f"    [âœ… åˆå§‹ç»“æœ] {len(initial_results)} ä¸ª")
        logger.info(f"[âœ… åˆå§‹ç»“æœ] {len(initial_results)} ä¸ª")

        # ========== Step 3: å¿«é€Ÿè´¨é‡è¯„ä¼° ==========
        print(f"\n[Step 3] å¿«é€Ÿè´¨é‡è¯„ä¼°...")
        logger.info(f"[Step 3] å¿«é€Ÿè´¨é‡è¯„ä¼°...")

        # ä½¿ç”¨è§„åˆ™è¯„åˆ†è¿›è¡Œå¿«é€Ÿè´¨é‡è¯„ä¼°
        self._ensure_result_scorer(request.country)
        scored_results = self.result_scorer.score_results(
            initial_results,
            best_query,
            metadata={'country': request.country, 'grade': request.grade, 'subject': request.subject}
        )

        # è®¡ç®—å‰10ä¸ªç»“æœçš„å¹³å‡åˆ†
        top_10 = scored_results[:10]
        avg_score = sum(r.get('score', 0) for r in top_10) / len(top_10) if top_10 else 0.0

        print(f"    [ğŸ“Š è´¨é‡è¯„ä¼°] å¹³å‡åˆ†: {avg_score:.2f}")
        logger.info(f"[ğŸ“Š è´¨é‡è¯„ä¼°] å¹³å‡åˆ†: {avg_score:.2f}")

        # ========== Step 4-5: æ ¹æ®è´¨é‡å†³å®šåç»­ç­–ç•¥ ==========
        if avg_score >= 7.0:
            # é«˜è´¨é‡ï¼šç›´æ¥è¿”å›
            print(f"    [âœ… é«˜è´¨é‡] ç›´æ¥è¿”å›å‰20ä¸ªç»“æœ")
            logger.info(f"[âœ… é«˜è´¨é‡] ç›´æ¥è¿”å›å‰20ä¸ªç»“æœ")
            return self._build_response(best_query, scored_results[:DEFAULT_MAX_RESULTS], search_start_time, request)

        elif avg_score >= 5.0:
            # ä¸­ç­‰è´¨é‡ï¼šè¡¥å……æœç´¢
            print(f"    [âš ï¸ ä¸­ç­‰è´¨é‡] æ‰§è¡Œè¡¥å……æœç´¢...")
            logger.info(f"[âš ï¸ ä¸­ç­‰è´¨é‡] æ‰§è¡Œè¡¥å……æœç´¢...")

            supplementary_results = self._perform_supplementary_search(
                best_query, request.country
            )

            if supplementary_results:
                print(f"    [âœ… è¡¥å……ç»“æœ] {len(supplementary_results)} ä¸ª")
                logger.info(f"[âœ… è¡¥å……ç»“æœ] {len(supplementary_results)} ä¸ª")

                # åˆå¹¶å¹¶é‡æ–°è¯„åˆ†
                all_results = self._merge_and_deduplicate(
                    scored_results, supplementary_results, best_query, request
                )
                return self._build_response(best_query, all_results[:DEFAULT_MAX_RESULTS], search_start_time, request)
            else:
                print(f"    [âš ï¸ è¡¥å……æœç´¢æ— ç»“æœ]ï¼Œè¿”å›åˆå§‹ç»“æœ")
                return self._build_response(best_query, scored_results[:DEFAULT_MAX_RESULTS], search_start_time, request)

        else:
            # ä½è´¨é‡ï¼šæŸ¥è¯¢é‡è¯•
            print(f"    [âŒ ä½è´¨é‡] å°è¯•æŸ¥è¯¢é‡è¯•...")
            logger.info(f"[âŒ ä½è´¨é‡] å°è¯•æŸ¥è¯¢é‡è¯•...")

            # ç”Ÿæˆå¤‡é€‰æŸ¥è¯¢å¹¶é‡è¯•
            for attempt in range(1, 4):  # æœ€å¤šé‡è¯•3æ¬¡
                try:
                    alt_query = self.strategy_agent.generate_alternative_query(
                        country=request.country,
                        grade=request.grade,
                        subject=request.subject,
                        semester=request.semester,
                        attempt_number=attempt
                    )

                    print(f"    [ğŸ”„ é‡è¯• {attempt}] ä½¿ç”¨å¤‡é€‰æŸ¥è¯¢: \"{alt_query}\"")
                    logger.info(f"[ğŸ”„ é‡è¯• {attempt}] å¤‡é€‰æŸ¥è¯¢: \"{alt_query}\"")

                    retry_results = self._perform_initial_search(alt_query, request.country)

                    if retry_results:
                        retry_scored = self.result_scorer.score_results(
                            retry_results,
                            alt_query,
                            metadata={'country': request.country, 'grade': request.grade, 'subject': request.subject}
                        )

                        retry_top_10 = retry_scored[:10]
                        retry_avg = sum(r.get('score', 0) for r in retry_top_10) / len(retry_top_10)

                        print(f"    [ğŸ“Š é‡è¯•è´¨é‡] å¹³å‡åˆ†: {retry_avg:.2f}")
                        logger.info(f"[ğŸ“Š é‡è¯•è´¨é‡] å¹³å‡åˆ†: {retry_avg:.2f}")

                        if retry_avg >= 5.0:
                            print(f"    [âœ… é‡è¯•æˆåŠŸ] è¿”å›é‡è¯•ç»“æœ")
                            logger.info(f"[âœ… é‡è¯•æˆåŠŸ] è¿”å›é‡è¯•ç»“æœ")
                            return self._build_response(alt_query, retry_scored[:DEFAULT_MAX_RESULTS], search_start_time, request)

                except Exception as e:
                    logger.warning(f"[âš ï¸ é‡è¯• {attempt} å¤±è´¥]: {str(e)}")
                    continue

            # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œè¿”å›åˆå§‹ç»“æœ
            print(f"    [âš ï¸ æ‰€æœ‰é‡è¯•å¤±è´¥]ï¼Œè¿”å›åˆå§‹æœ€ä½³ç»“æœ")
            logger.warning(f"[âš ï¸ æ‰€æœ‰é‡è¯•å¤±è´¥]ï¼Œè¿”å›åˆå§‹æœ€ä½³ç»“æœ")
            return self._build_response(best_query, scored_results[:DEFAULT_MAX_RESULTS], search_start_time, request)

    def _perform_initial_search(self, query: str, country_code: str) -> List[Dict]:
        """æ‰§è¡Œåˆå§‹æœç´¢ï¼ˆä½¿ç”¨Tavily/Metasoï¼‰"""
        try:
            results = self.llm_client.search(
                query=query,
                max_results=30,
                country_code=country_code
            )

            # è½¬æ¢ä¸ºSearchResultæ ¼å¼
            search_results = []
            for r in results:
                url = r.get('url', '')
                # ğŸ”’ P1 SSRFé˜²æŠ¤: éªŒè¯URLå®‰å…¨æ€§
                if not is_safe_url(url):
                    logger.warning(f"Blocked unsafe URL from initial search: {url}")
                    continue  # è·³è¿‡ä¸å®‰å…¨çš„URL

                search_results.append(SearchResult(
                    title=r.get('title', ''),
                    url=url,
                    snippet=r.get('content', r.get('snippet', '')),
                    source='è§„åˆ™',
                    search_engine=r.get('engine', 'Tavily/Metaso'),
                    score=0.0
                ))

            return search_results

        except Exception as e:
            logger.error(f"[âŒ åˆå§‹æœç´¢å¤±è´¥]: {str(e)}")
            return []

    def _perform_supplementary_search(self, query: str, country_code: str) -> List[Dict]:
        """æ‰§è¡Œè¡¥å……æœç´¢ï¼ˆä½¿ç”¨Googleï¼‰"""
        if not self.google_search_enabled:
            logger.info("[â„¹ï¸ Googleæœç´¢æœªå¯ç”¨ï¼Œè·³è¿‡è¡¥å……æœç´¢]")
            return []

        try:
            results = self.google_hunter.search(
                query=query,
                max_results=20
            )

            # è½¬æ¢ä¸ºSearchResultæ ¼å¼
            search_results = []
            for r in results:
                url = r.get('url', '')
                # ğŸ”’ P1 SSRFé˜²æŠ¤: éªŒè¯URLå®‰å…¨æ€§
                if not is_safe_url(url):
                    logger.warning(f"Blocked unsafe URL from supplementary search: {url}")
                    continue  # è·³è¿‡ä¸å®‰å…¨çš„URL

                search_results.append(SearchResult(
                    title=r.get('title', ''),
                    url=url,
                    snippet=r.get('snippet', ''),
                    source='è§„åˆ™',
                    search_engine='Google',
                    score=0.0
                ))

            return search_results

        except Exception as e:
            logger.error(f"[âŒ è¡¥å……æœç´¢å¤±è´¥]: {str(e)}")
            return []

    def _merge_and_deduplicate(self, initial_results: List[Dict],
                             supplementary_results: List[Dict],
                             query: str, request: SearchRequest) -> List[Dict]:
        """åˆå¹¶ç»“æœå¹¶å»é‡"""
        seen_urls = {r['url'] for r in initial_results}
        merged = list(initial_results)

        for result in supplementary_results:
            if result['url'] not in seen_urls:
                merged.append(result)
                seen_urls.add(result['url'])

        # é‡æ–°è¯„åˆ†åˆå¹¶åçš„ç»“æœ
        scored = self.result_scorer.score_results(
            merged,
            query,
            metadata={'country': request.country, 'grade': request.grade, 'subject': request.subject}
        )

        # æŒ‰åˆ†æ•°æ’åº
        scored.sort(key=lambda x: x.get('score', 0), reverse=True)
        return scored

    def _handle_empty_results(self, request: SearchRequest, query: str) -> SearchResponse:
        """å¤„ç†ç©ºç»“æœçš„æƒ…å†µ"""
        logger.warning(f"[âš ï¸ ç©ºç»“æœ] å°è¯•ä½¿ç”¨å¤‡é€‰æŸ¥è¯¢...")

        # å°è¯•ä½¿ç”¨å¤‡é€‰æŸ¥è¯¢
        for attempt in range(1, 4):
            try:
                alt_query = self.strategy_agent.generate_alternative_query(
                    country=request.country,
                    grade=request.grade,
                    subject=request.subject,
                    semester=request.semester,
                    attempt_number=attempt
                )

                logger.info(f"[ğŸ”„ ç©ºç»“æœé‡è¯• {attempt}]: \"{alt_query}\"")
                results = self._perform_initial_search(alt_query, request.country)

                if results:
                    scored = self.result_scorer.score_results(
                        results,
                        alt_query,
                        metadata={'country': request.country, 'grade': request.grade, 'subject': request.subject}
                    )
                    return self._build_response(alt_query, scored[:DEFAULT_MAX_RESULTS], time.time(), request)

            except Exception as e:
                logger.warning(f"[âš ï¸ ç©ºç»“æœé‡è¯• {attempt} å¤±è´¥]: {str(e)}")
                continue

        # æ‰€æœ‰å°è¯•éƒ½å¤±è´¥ï¼Œè¿”å›ç©ºå“åº”
        return SearchResponse(
            success=False,
            query=query,
            results=[],
            total_count=0,
            playlist_count=0,
            video_count=0,
            message="æœªæ‰¾åˆ°ç›¸å…³æœç´¢ç»“æœï¼Œè¯·å°è¯•è°ƒæ•´æœç´¢å…³é”®è¯"
        )

    def _build_response(self, query: str, results: List[SearchResult],
                       start_time: float, request: SearchRequest) -> SearchResponse:
        """æ„å»ºæœç´¢å“åº”"""
        elapsed = time.time() - start_time

        # ç»Ÿè®¡æ’­æ”¾åˆ—è¡¨å’Œè§†é¢‘æ•°é‡
        playlist_count = sum(1 for r in results if 'playlist' in r.title.lower())
        video_count = len(results) - playlist_count

        logger.info(f"[âœ… æœç´¢å®Œæˆ] è€—æ—¶: {elapsed:.2f}ç§’, ç»“æœ: {len(results)}ä¸ª")
        print(f"    [âœ… å®Œæˆ] è€—æ—¶: {elapsed:.2f}ç§’, è¿”å›: {len(results)}ä¸ªç»“æœ\n")

        return SearchResponse(
            success=True,
            query=query,
            results=results,
            total_count=len(results),
            playlist_count=playlist_count,
            video_count=video_count,
            message=f"æœç´¢å®Œæˆï¼Œè€—æ—¶ {elapsed:.2f} ç§’"
        )

    def _ensure_result_scorer(self, country_code: str):
        """
        ç¡®ä¿å·²åˆå§‹åŒ–å¸¦çŸ¥è¯†åº“çš„è¯„åˆ†å™¨ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰

        Args:
            country_code: å›½å®¶ä»£ç 
        """
        # ğŸ”’ P1çº¿ç¨‹å®‰å…¨: é¦–å…ˆæ£€æŸ¥æ— é”æƒ…å†µï¼ˆå¿«é€Ÿè·¯å¾„ï¼‰
        if country_code in self._scorer_cache:
            self.result_scorer = self._scorer_cache[country_code]
            return

        # ğŸ”’ P1çº¿ç¨‹å®‰å…¨: ä½¿ç”¨é”é˜²æ­¢ç«æ€æ¡ä»¶
        with self._scorer_cache_lock:
            # åŒé‡æ£€æŸ¥ï¼šå¯èƒ½åœ¨ç­‰å¾…é”æ—¶å…¶ä»–çº¿ç¨‹å·²ç»åˆå§‹åŒ–
            if country_code in self._scorer_cache:
                self.result_scorer = self._scorer_cache[country_code]
                return

            try:
                from core.result_scorer import get_result_scorer_with_kb
                scorer = get_result_scorer_with_kb(country_code)
                self._scorer_cache[country_code] = scorer
                logger.info(f"[âœ… è¯„åˆ†å™¨] å·²åŠ è½½ {country_code} çŸ¥è¯†åº“è¯„åˆ†å™¨")
            except Exception as e:
                logger.warning(f"[âš ï¸ è¯„åˆ†å™¨] æ— æ³•åŠ è½½çŸ¥è¯†åº“è¯„åˆ†å™¨: {e}")
                self._scorer_cache[country_code] = self.result_scorer_without_kb

            self.result_scorer = self._scorer_cache.get(country_code, self.result_scorer_without_kb)

    def _validate_grade_subject_pair(self, request: SearchRequest) -> None:
        """
        éªŒè¯å¹´çº§-å­¦ç§‘é…å¯¹æ˜¯å¦åˆæ³•

        Args:
            request: æœç´¢è¯·æ±‚
        """
        print(f"[éªŒè¯] æ£€æŸ¥å¹´çº§-å­¦ç§‘é…å¯¹...")
        try:
            validator = GradeSubjectValidator()
            validation_result = validator.validate(
                request.country,
                request.grade,
                request.subject
            )

            if not validation_result["valid"]:
                # é…å¯¹ä¸åˆæ³•ï¼Œæ˜¾ç¤ºè­¦å‘Šä½†ä»å…è®¸æœç´¢
                warning_msg = f"âš ï¸ {validation_result['reason']}"
                print(f"    {warning_msg}")
                if validation_result.get("suggestions"):
                    print(f"    ğŸ’¡ å»ºè®®: {', '.join(validation_result['suggestions'][:5])}")
                logger.warning(f"å¹´çº§-å­¦ç§‘é…å¯¹éªŒè¯å¤±è´¥: {request.country} {request.grade} {request.subject}")
            else:
                print(f"    âœ… å¹´çº§-å­¦ç§‘é…å¯¹éªŒè¯é€šè¿‡")
                logger.info(f"   âœ… é…å¯¹éªŒè¯é€šè¿‡")
        except Exception as e:
            print(f"    âš ï¸ éªŒè¯å¤±è´¥ï¼Œç»§ç»­æœç´¢: {str(e)}")
            logger.warning(f"é…å¯¹éªŒè¯å¼‚å¸¸: {str(e)}")

    def _initialize_transparency_collector(self) -> None:
        """åˆå§‹åŒ–æœç´¢é€æ˜åº¦æ”¶é›†å™¨"""
        self.transparency_collector.reset()
        self.transparency_collector.start_search()
        logger.debug("[ğŸ” é€æ˜åº¦] æ”¶é›†å™¨å·²é‡ç½®å¹¶å¼€å§‹è®°å½•")

    def _initialize_intelligent_scorer(self, country_code: str) -> None:
        """
        åˆå§‹åŒ–å¸¦çŸ¥è¯†åº“çš„æ™ºèƒ½è¯„åˆ†å™¨ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰

        Args:
            country_code: å›½å®¶ä»£ç 
        """
        # ğŸ”’ P1çº¿ç¨‹å®‰å…¨: é¦–å…ˆæ£€æŸ¥æ— é”æƒ…å†µï¼ˆå¿«é€Ÿè·¯å¾„ï¼‰
        if country_code in self._scorer_cache:
            self.result_scorer = self._scorer_cache[country_code]
            # æ›´æ–° log_collectorï¼ˆå¯èƒ½æ˜¯æ–°çš„æœç´¢è¯·æ±‚ï¼‰
            if self.log_collector:
                self.result_scorer.log_collector = self.log_collector
            logger.debug(f"[ğŸ“š çŸ¥è¯†åº“] ä½¿ç”¨ç¼“å­˜çš„ {country_code} è¯„åˆ†å™¨")
            return

        # ğŸ”’ P1çº¿ç¨‹å®‰å…¨: ä½¿ç”¨é”é˜²æ­¢ç«æ€æ¡ä»¶
        with self._scorer_cache_lock:
            # åŒé‡æ£€æŸ¥ï¼šå¯èƒ½åœ¨ç­‰å¾…é”æ—¶å…¶ä»–çº¿ç¨‹å·²ç»åˆå§‹åŒ–
            if country_code in self._scorer_cache:
                self.result_scorer = self._scorer_cache[country_code]
                # æ›´æ–° log_collectorï¼ˆå¯èƒ½æ˜¯æ–°çš„æœç´¢è¯·æ±‚ï¼‰
                if self.log_collector:
                    self.result_scorer.log_collector = self.log_collector
                logger.debug(f"[ğŸ“š çŸ¥è¯†åº“] ä½¿ç”¨ç¼“å­˜çš„ {country_code} è¯„åˆ†å™¨")
                return

            try:
                from core.result_scorer import IntelligentResultScorer

                # åˆ›å»ºå¸¦çŸ¥è¯†åº“çš„è¯„åˆ†å™¨ï¼ˆä¼ é€’ log_collectorï¼‰
                self.result_scorer = IntelligentResultScorer(
                    country_code=country_code,
                    log_collector=self.log_collector
                )
                self._scorer_cache[country_code] = self.result_scorer
                logger.info(f"[ğŸ“š çŸ¥è¯†åº“] å·²åŠ è½½ {country_code} è¯„åˆ†å™¨ï¼ˆå¸¦çŸ¥è¯†åº“å’Œæ—¥å¿—è®°å½•ï¼‰")
                print(f"    [âœ… çŸ¥è¯†åº“] å·²åŠ è½½ {country_code} æœç´¢çŸ¥è¯†åº“")

            except Exception as e:
                # å¦‚æœçŸ¥è¯†åº“åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨ä¸å¸¦çŸ¥è¯†åº“çš„è¯„åˆ†å™¨
                logger.warning(f"[ğŸ“š çŸ¥è¯†åº“] åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨è¯„åˆ†å™¨: {str(e)}")
                self.result_scorer = self.result_scorer_without_kb
                self._scorer_cache[country_code] = self.result_scorer_without_kb

            # ä¹Ÿæ›´æ–° log_collector
            if self.log_collector:
                self.result_scorer.log_collector = self.log_collector

    def get_playlist_info_fast(self, url: str) -> Optional[Dict[str, Any]]:
        """
        å¿«é€Ÿè·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯ï¼ˆå¸¦ç¼“å­˜ï¼‰- P1æ€§èƒ½ä¼˜åŒ–

        Args:
            url: æ’­æ”¾åˆ—è¡¨URL

        Returns:
            åŒ…å«video_countå’Œtotal_duration_minutesçš„å­—å…¸ï¼Œæˆ–None
        """
        if not url or 'list=' not in url:
            return None

        # ğŸ”’ P1 SSRFé˜²æŠ¤: éªŒè¯URLå®‰å…¨æ€§
        if not is_safe_url(url):
            logger.warning(f"Blocked unsafe URL in playlist info extraction: {url}")
            return None

        # ğŸš€ P1æ€§èƒ½ä¼˜åŒ–: æ£€æŸ¥ç¼“å­˜
        if url in self._playlist_cache:
            logger.debug(f"Playlist info cache hit for: {url[:50]}...")
            return self._playlist_cache[url]

        try:
            import yt_dlp

            ydl_opts = {
                'quiet': True,
                'no_warnings': True,
                'extract_flat': True,  # å¿«é€Ÿæå–
                'http_headers': {
                    'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X)',
                },
                'extractor_args': {
                    'youtube': {
                        'player_client': ['ios'],
                    }
                },
            }

            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                info = ydl.extract_info(url, download=False)

            if not info:
                return None

            entries = info.get('entries', [])
            if not entries:
                return None

            video_count = len(entries)

            # è®¡ç®—æ€»æ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰
            total_duration_seconds = 0
            for entry in entries:
                duration = entry.get('duration', 0)
                if duration:
                    total_duration_seconds += duration

            total_duration_minutes = total_duration_seconds / 60 if total_duration_seconds > 0 else 0

            result = {
                'video_count': video_count,
                'total_duration_minutes': total_duration_minutes
            }

            # ğŸš€ P1æ€§èƒ½ä¼˜åŒ–: å­˜å…¥ç¼“å­˜
            self._playlist_cache[url] = result
            logger.info(f"Cached playlist info: {video_count} videos, {total_duration_minutes:.1f} minutes")

            return result

        except Exception as e:
            logger.warning(f"è·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯å¤±è´¥: {str(e)[:100]}")
            return None

    def search(self, request: SearchRequest) -> SearchResponse:
        """
        æ‰§è¡Œæœç´¢

        Args:
            request: æœç´¢è¯·æ±‚

        Returns:
            æœç´¢å“åº”
        """
        # æ€§èƒ½ç›‘æ§ - å¼€å§‹è®¡æ—¶
        search_start_time = time.time()

        # ğŸ” è¯¦ç»†æ—¥å¿—ï¼šæœç´¢å¼€å§‹
        logger.info("="*80)
        logger.info(f"ğŸ” [æœç´¢å¼€å§‹] {request.country} - {request.grade} - {request.subject}")
        logger.info(f"   æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info(f"   å†…å­˜ä½¿ç”¨: {self._get_memory_usage()}")
        logger.info("="*80)

        print(f"\n{'='*80}")
        print(f"ğŸ” å¼€å§‹æœç´¢")
        print(f"{'='*80}")
        print(f"å›½å®¶: {request.country}")
        print(f"å¹´çº§: {request.grade}")
        print(f"å­¦æœŸ: {request.semester or 'ä¸æŒ‡å®š'}")
        print(f"å­¦ç§‘: {request.subject}")
        print(f"{'='*80}\n")

        # ========== åˆå§‹åŒ–æ­¥éª¤ ==========
        # å¹´çº§-å­¦ç§‘é…å¯¹éªŒè¯
        logger.info(f"[æ­¥éª¤ 0] å¹´çº§-å­¦ç§‘é…å¯¹éªŒè¯...")
        self._validate_grade_subject_pair(request)

        # åˆå§‹åŒ–é€æ˜åº¦æ”¶é›†å™¨
        self._initialize_transparency_collector()

        # åˆå§‹åŒ–æ™ºèƒ½è¯„åˆ†å™¨
        country_code = request.country.upper()
        self._initialize_intelligent_scorer(country_code)
        # ========== åˆå§‹åŒ–æ­¥éª¤ç»“æŸ ==========

        try:
            # Step 0: è·å–æœç´¢ç­–ç•¥ï¼ˆå·²è·³è¿‡LLMç”Ÿæˆï¼Œç›´æ¥ä½¿ç”¨é»˜è®¤ç­–ç•¥ï¼‰
            # [ä¼˜åŒ–] 2026-01-20: è·³è¿‡LLMç­–ç•¥ç”Ÿæˆï¼Œç›´æ¥ä½¿ç”¨é»˜è®¤è§„åˆ™ç­–ç•¥ï¼Œæå‡å“åº”é€Ÿåº¦
            step0_start = time.time()
            logger.info(f"[æ­¥éª¤ 0] è·å–æœç´¢ç­–ç•¥ï¼ˆä½¿ç”¨é»˜è®¤è§„åˆ™ç­–ç•¥ï¼‰...")
            print(f"[æ­¥éª¤ 0] è·å–æœç´¢ç­–ç•¥ï¼ˆå·²è·³è¿‡LLMç”Ÿæˆï¼Œä½¿ç”¨é»˜è®¤è§„åˆ™ç­–ç•¥ï¼‰...")

            # ç›´æ¥ä½¿ç”¨é»˜è®¤ç­–ç•¥ï¼Œè·³è¿‡LLMç”Ÿæˆ
            from search_strategy_agent import SearchStrategy
            country_config = self.config_manager.get_country_config(request.country.upper())
            language_code = country_config.language_code if country_config else "en"
            domains = country_config.domains[:5] if country_config else []

            # æ„å»ºé»˜è®¤æœç´¢è¯ï¼ˆè§„åˆ™ç”Ÿæˆï¼Œä¸ä½¿ç”¨LLMï¼‰
            default_query = f"{request.subject} {request.grade} playlist"
            if request.semester:
                default_query += f" semester {request.semester}"

            # ğŸ”’ P1 SSRFé˜²æŠ¤: æ¸…ç†æœç´¢æŸ¥è¯¢ï¼Œç§»é™¤å±é™©è¿ç®—ç¬¦
            default_query = sanitize_search_query(default_query)

            # ç”Ÿæˆå¤šä¸ªæ’­æ”¾åˆ—è¡¨ä¼˜å…ˆçš„æœç´¢æŸ¥è¯¢ï¼ˆ7ä¸ªé«˜åº¦å·®å¼‚åŒ–çš„å˜ä½“ï¼‰
            playlist_keywords_map = {
                "id": ["playlist", "complete course", "full series", "koleksi lengkap", "kursus lengkap"],
                "en": ["playlist", "complete course", "full series", "video collection"],
                "zh": ["æ’­æ”¾åˆ—è¡¨", "å®Œæ•´è¯¾ç¨‹", "ç³»åˆ—æ•™ç¨‹"],
                "ms": ["playlist", "kursus lengkap", "siri lengkap"],
                "ar": ["Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªØ´ØºÙŠÙ„", "Ø¯ÙˆØ±Ø© ÙƒØ§Ù…Ù„Ø©"],
                "ru": ["Ğ¿Ğ»ĞµĞ¹Ğ»Ğ¸ÑÑ‚", "Ğ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ ĞºÑƒÑ€Ñ"],
            }
            playlist_keywords = playlist_keywords_map.get(language_code, ["playlist", "complete course"])

            # ç”Ÿæˆ7ä¸ªå·®å¼‚åŒ–æœç´¢æŸ¥è¯¢
            search_queries = [
                f"site:youtube.com {request.subject} {request.grade} {playlist_keywords[0]}",
                f"{request.subject} {request.grade} {playlist_keywords[1] if len(playlist_keywords) > 1 else 'complete course'}",
                f"site:youtube.com \"{request.subject}\" \"{request.grade}\" playlist",
                f"{request.subject} {request.grade} video lesson chapter",
                f"{request.grade} {request.subject} full course curriculum",
                f"{request.subject} for {request.grade} students tutorial",
                f"{request.grade} {request.subject} learning series complete"
            ]

            # åˆ›å»ºç­–ç•¥å¯¹è±¡ï¼ˆä¸ä½¿ç”¨LLMï¼‰
            strategy = SearchStrategy(
                search_language=language_code,
                use_chinese_search_engine=(request.country.upper() == "CN"),
                platforms=["youtube.com"] + domains[:3],
                search_queries=search_queries,
                priority_domains=domains[:5],
                notes=f"é»˜è®¤æœç´¢ç­–ç•¥ï¼ˆè§„åˆ™ç”Ÿæˆï¼‰ï¼šä½¿ç”¨{language_code}è¯­è¨€ï¼Œä¼˜å…ˆæœç´¢YouTubeæ’­æ”¾åˆ—è¡¨ï¼ˆ7ä¸ªå·®å¼‚åŒ–æŸ¥è¯¢ï¼‰"
            )

            print(f"    [âœ… ç­–ç•¥] æœç´¢è¯­è¨€: {strategy.search_language}")
            print(f"    [âœ… ç­–ç•¥] ä½¿ç”¨ä¸­æ–‡æœç´¢å¼•æ“: {strategy.use_chinese_search_engine}")
            print(f"    [âœ… ç­–ç•¥] å¹³å°åˆ—è¡¨: {', '.join(strategy.platforms[:5])}")
            print(f"    [âœ… ç­–ç•¥] ä¼˜å…ˆåŸŸå: {', '.join(strategy.priority_domains[:5])}")
            print(f"    [âš¡ ä¼˜åŒ–] è·³è¿‡LLMç”Ÿæˆï¼Œä½¿ç”¨é»˜è®¤è§„åˆ™ç­–ç•¥ï¼Œæå‡å“åº”é€Ÿåº¦")

            # ========== ğŸ” è®°å½•æœç´¢ç­–ç•¥åˆ°é€æ˜åº¦æ”¶é›†å™¨ï¼ˆP0-1ï¼‰ ==========
            self.transparency_collector.record_strategy({
                "search_language": strategy.search_language,
                "use_chinese_search_engine": strategy.use_chinese_search_engine,
                "platforms": strategy.platforms,
                "search_queries": strategy.search_queries,
                "priority_domains": strategy.priority_domains,
                "notes": strategy.notes
            })
            logger.debug(f"[ğŸ” é€æ˜åº¦] å·²è®°å½•æœç´¢ç­–ç•¥: {len(strategy.search_queries)} ä¸ªæŸ¥è¯¢")
            # ========== ç­–ç•¥è®°å½•ç»“æŸ ==========

            # Step 1: ä½¿ç”¨æœç´¢ç­–ç•¥ä¸­çš„æœç´¢è¯
            print(f"\n[æ­¥éª¤ 1] ä½¿ç”¨æœç´¢ç­–ç•¥ç”Ÿæˆçš„é«˜è´¨é‡æœç´¢è¯...")

            # ç›´æ¥ä½¿ç”¨ç­–ç•¥ç”Ÿæˆçš„æœç´¢è¯ï¼ˆå·²åŒ…å«å¤šä¸ªå˜ä½“ï¼ŒåŒ…æ‹¬playlistç­‰ä¼˜åŒ–ï¼‰
            if strategy.search_queries:
                query = strategy.search_queries[0]
                print(f"    [âœ… ä½¿ç”¨ç­–ç•¥æœç´¢è¯] \"{query}\"")
                print(f"    [âœ… ä¼˜åŠ¿] ç­–ç•¥å·²ç”Ÿæˆ {len(strategy.search_queries)} ä¸ªé«˜è´¨é‡å˜ä½“")
            else:
                # é™çº§ï¼šå¦‚æœç­–ç•¥ä¸­æ²¡æœ‰æœç´¢è¯ï¼Œä½¿ç”¨è§„åˆ™ç”Ÿæˆ
                query = self._generate_fallback_query(request)
                print(f"    [âœ… ä½¿ç”¨è§„åˆ™ç”Ÿæˆæœç´¢è¯] \"{query}\"")
                strategy.search_queries = [query]  # å°†ç”Ÿæˆçš„æŸ¥è¯¢æ·»åŠ åˆ°ç­–ç•¥ä¸­

            # æ˜¾ç¤ºæ‰€æœ‰æœç´¢è¯å˜ä½“
            if len(strategy.search_queries) > 1:
                print(f"    [ğŸ¯ æ’­æ”¾åˆ—è¡¨ä¼˜åŒ–] å…±æœ‰ {len(strategy.search_queries)} ä¸ªæœç´¢è¯å˜ä½“")
                for i, q in enumerate(strategy.search_queries, 1):
                    is_playlist_query = any(kw in q.lower() for kw in ['playlist', 'complete course', 'full series', 'koleksi', 'kursus lengkap', 'æ’­æ”¾åˆ—è¡¨', 'å®Œæ•´è¯¾ç¨‹', 'ç³»åˆ—'])
                    marker = "ğŸ [æ’­æ”¾åˆ—è¡¨]" if is_playlist_query else "ğŸ“¹ [å¸¸è§„]"
                    print(f"      {marker} {i}. \"{q}\"")

            # Step 2: æ‰§è¡Œæ··åˆæœç´¢ï¼ˆé€šç”¨æœç´¢ + æœ¬åœ°å®šå‘æœç´¢ï¼‰
            print(f"\n[æ­¥éª¤ 2] æ‰§è¡Œæ··åˆæœç´¢...")

            # ========== å¹¶è¡Œæœç´¢å®ç° (æ–°ç‰ˆæœ¬) ==========
            # ğŸ”’ P1 ç¯å¢ƒå˜é‡éªŒè¯: æ£€æŸ¥æ˜¯å¦å¯ç”¨å¹¶è¡Œæœç´¢ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
            use_parallel_search = validate_env_bool(
                os.getenv("ENABLE_PARALLEL_SEARCH"),
                "ENABLE_PARALLEL_SEARCH",
                default=True
            )

            if use_parallel_search:
                print(f"    [âš¡ æ¨¡å¼] ä½¿ç”¨å¹¶è¡Œæœç´¢")

                # å‡†å¤‡å›½å®¶é…ç½®
                country_code_upper = request.country.upper()
                country_config = self.config_manager.get_country_config(country_code_upper)

                # ä½¿ç”¨ç­–ç•¥ä¸­çš„ä¼˜å…ˆåŸŸåï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é…ç½®ä¸­çš„åŸŸå
                if strategy.priority_domains:
                    selected_domains = strategy.priority_domains[:5]
                elif country_config and country_config.domains:
                    selected_domains = country_config.domains[:5]
                else:
                    selected_domains = []

                # æ„å»ºå¹¶è¡Œæœç´¢ä»»åŠ¡åˆ—è¡¨
                search_tasks = []

                # ğŸš€ P1æ€§èƒ½ä¼˜åŒ–ï¼šå‡å°‘APIè°ƒç”¨æ¬¡æ•°ï¼ˆä»7-8æ¬¡å‡å°‘åˆ°2-3æ¬¡ï¼‰
                # ä½¿ç”¨ç­–ç•¥ä¸­çš„æœ€ä¼˜è´¨2-3ä¸ªæœç´¢è¯è¿›è¡Œæœç´¢
                # ä¼˜å…ˆçº§ï¼š1) YouTubeæ’­æ”¾åˆ—è¡¨æœç´¢ 2) é€šç”¨æ’­æ”¾åˆ—è¡¨æœç´¢ 3) ç²¾ç¡®åŒ¹é…æœç´¢
                queries_to_use = strategy.search_queries[:3] if len(strategy.search_queries) >= 3 else strategy.search_queries
                print(f"    [ğŸ¯ ä¼˜åŒ–æœç´¢] å°†ä½¿ç”¨ {len(queries_to_use)} ä¸ªé«˜è´¨é‡æœç´¢è¯ï¼ˆå‡å°‘APIè°ƒç”¨ï¼‰")

                # Tavily/Metasoæœç´¢ - åªå¯¹å‰2ä¸ªæœ€ä½³æŸ¥è¯¢æ‰§è¡Œï¼ˆ2æ¬¡ï¼‰âœ… ä¸»è¦å¼•æ“ï¼ˆé«˜è´¨é‡ï¼Œavg 4.65ï¼‰
                # ğŸš€ P1ä¼˜åŒ–ï¼šå‡å°‘æŸ¥è¯¢æ•°é‡ï¼Œä»5ä¸ªé™ä½åˆ°2ä¸ªï¼Œå‡å°‘60%çš„APIè°ƒç”¨
                for query_idx, search_query in enumerate(queries_to_use[:2], 1):
                    is_playlist_focused = any(kw in search_query.lower() for kw in ['playlist', 'complete course', 'full series', 'koleksi', 'kursus lengkap', 'æ’­æ”¾åˆ—è¡¨', 'å®Œæ•´è¯¾ç¨‹', 'ç³»åˆ—'])
                    query_type = "æ’­æ”¾åˆ—è¡¨" if is_playlist_focused else "å¸¸è§„"

                    search_tasks.append({
                        'name': f'Tavily/Metasoæœç´¢ [{query_type}] #{query_idx}',
                        'query': search_query,  # ä½¿ç”¨ç‰¹å®šçš„æœç´¢è¯
                        'func': self.llm_client.search,  # å†…éƒ¨ä¼šæ ¹æ®å…è´¹é¢åº¦ä¼˜å…ˆé€‰æ‹©Tavilyæˆ–Metaso
                        'engine_name': 'Tavily/Metaso',
                        'max_results': 30,  # å¢åŠ åˆ°30ï¼Œè·å–æ›´å¤šç»“æœ
                        'include_domains': None
                    })

                # ğŸš€ P1ä¼˜åŒ–ï¼šç§»é™¤Googleæœç´¢ï¼ˆä½è´¨é‡ï¼Œavg 1.50ï¼‰ï¼Œå‡å°‘ä¸å¿…è¦çš„APIè°ƒç”¨
                # Googleæœç´¢ç»“æœè´¨é‡è¿œä½äºTavily/Metasoï¼Œæ€§ä»·æ¯”ä½
                # if self.google_search_enabled and len(queries_to_use) > 0:
                #     search_tasks.append({...})

                # ä»»åŠ¡3: ç™¾åº¦æœç´¢ï¼ˆå¦‚æœå¯ç”¨ä¸”éœ€è¦ä¸­æ–‡æœç´¢ï¼‰
                if strategy.use_chinese_search_engine and self.baidu_search_enabled and len(queries_to_use) > 0:
                    search_tasks.append({
                        'name': 'ç™¾åº¦æœç´¢',
                        'query': queries_to_use[0],  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæŸ¥è¯¢
                        'func': self.baidu_hunter.search,
                        'engine_name': 'Baidu',
                        'max_results': 30,  # å¢åŠ åˆ°30
                        'include_domains': None
                    })

                # ğŸš€ P1ä¼˜åŒ–ï¼šæœ¬åœ°å®šå‘æœç´¢ï¼ˆæ¡ä»¶æ€§å¯ç”¨ï¼Œä»…åœ¨Tavily/Metasoç»“æœä¸è¶³æ—¶ï¼‰
                # ç­–ç•¥ï¼šå…ˆæ‰§è¡Œä¸»æœç´¢ï¼Œå¦‚æœç»“æœæ•°é‡<30ï¼Œå†å¯ç”¨æœ¬åœ°å®šå‘æœç´¢ä½œä¸ºè¡¥å……
                # è¿™æ ·å¯ä»¥é¿å…ä¸å¿…è¦çš„APIè°ƒç”¨ï¼Œæå‡æ€§èƒ½
                # if selected_domains:
                #     # ... æœ¬åœ°å®šå‘æœç´¢é€»è¾‘ ...
                # æ³¨æ„ï¼šæœ¬åœ°å®šå‘æœç´¢å·²ç§»è‡³ä¸»æœç´¢ä¹‹åï¼Œæ ¹æ®ç»“æœæ•°é‡åŠ¨æ€å†³å®šæ˜¯å¦æ‰§è¡Œ

                # æ‰§è¡Œå¹¶è¡Œæœç´¢ï¼ˆä¼ é€’ country_code ç”¨äºå…è´¹é¢åº¦ä¼˜å…ˆç­–ç•¥ï¼‰
                parallel_results = self._parallel_search(query, search_tasks, timeout=30, country_code=request.country)

                # åˆå¹¶æ‰€æœ‰ç»“æœ
                search_results_a = []
                search_results_b = []

                for task_name, results in parallel_results.items():
                    if 'æœ¬åœ°' in task_name or 'Local' in task_name:
                        search_results_b.extend(results)
                    else:
                        search_results_a.extend(results)

                # æ˜¾ç¤ºç»“æœè¯¦æƒ…
                if search_results_a:
                    print(f"    [ğŸ“‹ é€šç”¨æœç´¢ç»“æœ] å…± {len(search_results_a)} ä¸ª")
                    for idx, result in enumerate(search_results_a[:3], 1):
                        print(f"        {idx}. {result.title[:60]}...")

                if search_results_b:
                    print(f"    [ğŸ“‹ æœ¬åœ°æœç´¢ç»“æœ] å…± {len(search_results_b)} ä¸ª")
                    for idx, result in enumerate(search_results_b[:3], 1):
                        print(f"        {idx}. {result.title[:60]}...")

            else:
                # ========== ä¸²è¡Œæœç´¢å®ç° (åŸç‰ˆæœ¬) ==========
                print(f"    [ğŸ”„ æ¨¡å¼] ä½¿ç”¨ä¸²è¡Œæœç´¢")

                # æœç´¢ A: é€šç”¨æœç´¢ï¼ˆä¸»è¦è¦†ç›– YouTubeï¼‰
            # å¦‚æœç­–ç•¥è¦æ±‚ä½¿ç”¨ä¸­æ–‡æœç´¢å¼•æ“ï¼Œä¸”ç™¾åº¦æœç´¢å·²é…ç½®ï¼Œåˆ™ä½¿ç”¨ç™¾åº¦æœç´¢
            if strategy.use_chinese_search_engine and self.baidu_search_enabled:
                print(f"    [ğŸŒ ç­–ç•¥] æ£€æµ‹åˆ°éœ€è¦ä½¿ç”¨ä¸­æ–‡æœç´¢å¼•æ“ï¼Œä½¿ç”¨ç™¾åº¦æœç´¢")
                print(f"    [ğŸ” æœç´¢A-ç™¾åº¦æœç´¢] æŸ¥è¯¢: \"{query}\"")
                print(f"    [âš™ï¸ å‚æ•°] max_results=30")
                try:
                    baidu_results = self.baidu_hunter.search(query, max_results=30)
                    # è½¬æ¢ä¸ºSearchResultå¯¹è±¡
                    search_results_a = []
                    for item in baidu_results:
                        search_results_a.append(SearchResult(
                            title=item.title,
                            url=item.url,
                            snippet=item.snippet,
                            source="ç™¾åº¦æœç´¢",
                            search_engine="Baidu"
                        ))
                    print(f"    [âœ… æœç´¢A-ç™¾åº¦] æ‰¾åˆ° {len(search_results_a)} ä¸ªç»“æœ")
                except Exception as e:
                    print(f"    [âŒ é”™è¯¯] ç™¾åº¦æœç´¢å¤±è´¥: {str(e)}")
                    # é™çº§åˆ° Google æœç´¢ï¼ˆå¦‚æœå¯ç”¨ï¼‰æˆ– Tavily
                    if self.google_search_enabled:
                        print(f"    [ğŸ”„ é™çº§] åˆ‡æ¢åˆ° Google æœç´¢...")
                        try:
                            google_results = self.google_hunter.search(query, max_results=30, country_code=country_code_upper)
                            search_results_a = []
                            for item in google_results:
                                search_results_a.append(SearchResult(
                                    title=item.title,
                                    url=item.url,
                                    snippet=item.snippet,
                                    source="Googleæœç´¢",
                                    search_engine="Google"
                                ))
                            print(f"    [âœ… æœç´¢A-Google] æ‰¾åˆ° {len(search_results_a)} ä¸ªç»“æœ")
                        except Exception as e2:
                            print(f"    [âŒ é”™è¯¯] Google æœç´¢ä¹Ÿå¤±è´¥: {str(e2)}")
                            print(f"    [ğŸ”„ é™çº§] åˆ‡æ¢åˆ° Tavily æœç´¢...")
                            search_results_a = self.llm_client.search(query, max_results=30, country_code=country_code_upper)
                            print(f"    [âœ… æœç´¢A-Tavily] æ‰¾åˆ° {len(search_results_a)} ä¸ªç»“æœ")
                    else:
                        print(f"    [ğŸ”„ é™çº§] åˆ‡æ¢åˆ°Tavilyæœç´¢...")
                        search_results_a = self.llm_client.search(query, max_results=30, country_code=country_code_upper)
                        print(f"    [âœ… æœç´¢A-Tavily] æ‰¾åˆ° {len(search_results_a)} ä¸ªç»“æœ")
            else:
                if strategy.use_chinese_search_engine:
                    print(f"    [ğŸŒ ç­–ç•¥] æ£€æµ‹åˆ°éœ€è¦ä½¿ç”¨ä¸­æ–‡æœç´¢å¼•æ“ï¼ˆå¦‚ç™¾åº¦ã€æœç‹—ï¼‰")
                    if not self.baidu_search_enabled:
                        print(f"    [âš ï¸ æ³¨æ„] ç™¾åº¦æœç´¢æœªé…ç½®ï¼Œä½¿ç”¨å…¶ä»–æœç´¢å¼•æ“ï¼Œå¯èƒ½æ— æ³•å®Œå…¨è¦†ç›–ä¸­æ–‡å†…å®¹")
                    else:
                        print(f"    [â„¹ï¸] ç™¾åº¦æœç´¢å·²é…ç½®ä½†æœªå¯ç”¨ï¼ˆå¯èƒ½ç­–ç•¥åˆ¤æ–­ä¸éœ€è¦ï¼‰")
                
                # å¯¹äºéä¸­æ–‡æœç´¢ï¼Œä¼˜å…ˆä½¿ç”¨ Tavilyï¼ˆé«˜è´¨é‡ï¼Œavg 4.65ï¼‰ï¼ŒGoogleä½œä¸ºé™çº§é€‰é¡¹ï¼ˆä½è´¨é‡ï¼Œavg 1.50ï¼‰
                print(f"    [ğŸ” æœç´¢A-Tavily] æŸ¥è¯¢: \"{query}\"")
                print(f"    [âš™ï¸ å‚æ•°] max_results=30")
                try:
                    # ğŸ”¥ ä»llm_client.search()è¿”å›çš„Dictæˆ–SearchResultè½¬æ¢ä¸ºSearchResult
                    search_dicts = self.llm_client.search(query, max_results=30, country_code=country_code_upper)
                    search_results_a = []
                    for item in search_dicts:
                        # [ä¿®å¤] 2026-01-20: å¤„ç†å­—å…¸å’ŒSearchResultå¯¹è±¡ä¸¤ç§ç±»å‹
                        if isinstance(item, dict):
                            # å¦‚æœæ˜¯å­—å…¸ï¼Œä½¿ç”¨.get()æ–¹æ³•
                            url = item.get('url', '')
                            # ğŸ”’ P1 SSRFé˜²æŠ¤: éªŒè¯URLå®‰å…¨æ€§
                            if not is_safe_url(url):
                                logger.warning(f"Blocked unsafe URL from search A: {url}")
                                continue  # è·³è¿‡ä¸å®‰å…¨çš„URL

                            search_engine = item.get('search_engine', 'Tavily')
                            search_results_a.append(SearchResult(
                                title=item.get('title', ''),
                                url=url,
                                snippet=item.get('snippet', ''),
                                source=item.get('source', 'Tavily'),
                                search_engine=search_engine
                            ))
                        else:
                            # å¦‚æœæ˜¯SearchResultå¯¹è±¡ï¼Œç›´æ¥ä½¿ç”¨å±æ€§è®¿é—®
                            # ğŸ”’ P1 SSRFé˜²æŠ¤: éªŒè¯URLå®‰å…¨æ€§
                            if not is_safe_url(item.url):
                                logger.warning(f"Blocked unsafe URL from search A (SearchResult): {item.url}")
                                continue  # è·³è¿‡ä¸å®‰å…¨çš„URL

                            search_results_a.append(item)
                    print(f"    [âœ… æœç´¢A-Tavily] æ‰¾åˆ° {len(search_results_a)} ä¸ªç»“æœ")
                except Exception as e:
                    print(f"    [âŒ é”™è¯¯] Tavily æœç´¢å¤±è´¥: {str(e)}")
                    # é™çº§åˆ° Google æœç´¢ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                    if self.google_search_enabled:
                        print(f"    [ğŸ”„ é™çº§] åˆ‡æ¢åˆ° Google æœç´¢...")
                        try:
                            google_results = self.google_hunter.search(query, max_results=30, country_code=country_code_upper)
                            search_results_a = []
                            for item in google_results:
                                search_results_a.append(SearchResult(
                                    title=item.title,
                                    url=item.url,
                                    snippet=item.snippet,
                                    source="Googleæœç´¢",
                                    search_engine="Google"
                                ))
                            print(f"    [âœ… æœç´¢A-Google] æ‰¾åˆ° {len(search_results_a)} ä¸ªç»“æœ")
                        except Exception as e2:
                            print(f"    [âŒ é”™è¯¯] Google æœç´¢ä¹Ÿå¤±è´¥: {str(e2)}")
                            search_results_a = []
                    else:
                        print(f"    [âŒ é”™è¯¯] Google æœç´¢æœªé…ç½®ï¼Œæ— æ³•é™çº§")
                        search_results_a = []
            if search_results_a:
                print(f"    [ğŸ“‹ æœç´¢Aç»“æœè¯¦æƒ…]")
                for idx, result in enumerate(search_results_a[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ª
                    print(f"        {idx}. {result.title[:60]}...")
                    print(f"           URL: {result.url}")
                if len(search_results_a) > 5:
                    print(f"        ... è¿˜æœ‰ {len(search_results_a) - 5} ä¸ªç»“æœ")
            
            # æœç´¢ B: æœ¬åœ°å®šå‘æœç´¢ï¼ˆå¦‚æœå›½å®¶é…ç½®ä¸­æœ‰åŸŸååˆ—è¡¨ï¼‰
            print(f"\n    [ğŸ” æœç´¢B-æœ¬åœ°] å¼€å§‹æ£€æŸ¥å›½å®¶é…ç½®...")
            search_results_b = []
            country_code_upper = request.country.upper()
            print(f"    [ğŸ“‹ è¾“å…¥] å›½å®¶ä»£ç : {country_code_upper}")
            country_config = self.config_manager.get_country_config(country_code_upper)
            
            if country_config:
                print(f"    [âœ… é…ç½®] æˆåŠŸè¯»å–å›½å®¶é…ç½®: {country_config.country_name}")
                print(f"    [ğŸ“‹ é…ç½®] åŸŸåæ•°é‡: {len(country_config.domains)}")
                if country_config.domains:
                    print(f"    [ğŸ“‹ é…ç½®] åŸŸååˆ—è¡¨:")
                    for idx, domain in enumerate(country_config.domains, 1):
                        print(f"        {idx}. {domain}")
            else:
                print(f"    [âš ï¸ é…ç½®] å›½å®¶é…ç½®ä¸å­˜åœ¨ï¼Œè·³è¿‡æœ¬åœ°æœç´¢")
            
            # ä½¿ç”¨ç­–ç•¥ä¸­çš„ä¼˜å…ˆåŸŸåï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é…ç½®ä¸­çš„åŸŸå
            if strategy.priority_domains:
                selected_domains = strategy.priority_domains[:5]
                print(f"\n    [âœ… ç­–ç•¥] ä½¿ç”¨ç­–ç•¥ä¸­çš„ä¼˜å…ˆåŸŸå: {', '.join(selected_domains)}")
            elif country_config and country_config.domains:
                selected_domains = country_config.domains[:5]
                print(f"\n    [âœ… é…ç½®] ä½¿ç”¨é…ç½®ä¸­çš„åŸŸå: {', '.join(selected_domains)}")
            else:
                selected_domains = []
            
            if selected_domains:
                # ä½¿ç”¨ç­–ç•¥ä¸­çš„ä¼˜å…ˆåŸŸåæˆ–é…ç½®ä¸­çš„åŸŸå
                print(f"\n    [ğŸ”§ å‡†å¤‡] å‡†å¤‡å¹³å°ç‰¹å®šæœç´¢...")
                print(f"    [ğŸ“‹ åŸŸååˆ—è¡¨] å…± {len(selected_domains)} ä¸ªåŸŸå:")
                for idx, domain in enumerate(selected_domains, 1):
                    print(f"        {idx}. {domain}")
                
                if selected_domains:
                    
                    # æ„å»ºæœ¬åœ°æœç´¢è¯ï¼ˆç§»é™¤playlistå…³é”®è¯ï¼Œä½¿ç”¨æœ¬åœ°åŒ–è¯æ±‡ï¼‰
                    print(f"\n    [ğŸ”§ æ„å»º] æ„å»ºæœ¬åœ°æœç´¢è¯...")
                    print(f"    [ğŸ“‹ åŸå§‹æŸ¥è¯¢] \"{query}\"")
                    
                    # ç§»é™¤playlistå…³é”®è¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                    base_query = query.replace("playlist", "").replace("Playlist", "").strip()
                    
                    # æ ¹æ®è¯­è¨€æ·»åŠ æœ¬åœ°åŒ–å…³é”®è¯
                    language_map = {
                        "id": "Video pembelajaran",  # å°å°¼è¯­
                        "en": "Video lesson",  # è‹±è¯­
                        "zh": "æ•™å­¦è§†é¢‘",  # ä¸­æ–‡
                        "ms": "Video pembelajaran",  # é©¬æ¥è¯­
                        "ar": "ÙÙŠØ¯ÙŠÙˆ ØªØ¹Ù„ÙŠÙ…ÙŠ",  # é˜¿æ‹‰ä¼¯è¯­
                        "ru": "Ğ’Ğ¸Ğ´ĞµĞ¾ ÑƒÑ€Ğ¾Ğº",  # ä¿„è¯­
                    }
                    country_language = country_config.language_code if country_config else "en"
                    local_keyword = language_map.get(country_language, "Video lesson")
                    
                    # æ„å»ºçº¯å‡€çš„æœç´¢è¯ï¼ˆå­¦ç§‘ + å¹´çº§ + å­¦æœŸï¼‰
                    clean_query_parts = []
                    if request.subject:
                        clean_query_parts.append(request.subject)
                    if request.grade:
                        clean_query_parts.append(request.grade)
                    if request.semester:
                        clean_query_parts.append(request.semester)
                    
                    # ä½¿ç”¨çº¯å‡€æŸ¥è¯¢ + æœ¬åœ°åŒ–å…³é”®è¯
                    local_base_query = " ".join(clean_query_parts) if clean_query_parts else base_query
                    local_base_query = f"{local_base_query} {local_keyword}".strip()
                    
                    # æ·»åŠ site:è¯­æ³•åˆ°æŸ¥è¯¢æœ«å°¾
                    domain_site_clause = " OR ".join([f"site:{domain}" for domain in selected_domains])
                    local_query = f"{local_base_query} ({domain_site_clause})"
                    
                    print(f"    [ğŸ”§ å¤„ç†] ç§»é™¤playlistå…³é”®è¯åçš„åŸºç¡€æŸ¥è¯¢: \"{base_query}\"")
                    print(f"    [ğŸ”§ å¤„ç†] æœ¬åœ°åŒ–å…³é”®è¯: \"{local_keyword}\"")
                    print(f"    [ğŸ”§ å¤„ç†] çº¯å‡€æŸ¥è¯¢: \"{local_base_query}\"")
                    print(f"    [ğŸ”§ å¤„ç†] æ·»åŠ site:è¯­æ³•åçš„æœ€ç»ˆæŸ¥è¯¢: \"{local_query}\"")
                    print(f"\n    [ğŸ” æœç´¢B-æœ¬åœ°] æŸ¥è¯¢: \"{local_query}\"")
                    print(f"    [ğŸ“ ç›®æ ‡å¹³å°] {', '.join(selected_domains)}")
                    print(f"    [âš™ï¸ å‚æ•°] max_results=10, include_domains={selected_domains}")
                    search_results_b = self.llm_client.search(local_query, max_results=10, include_domains=selected_domains)
                    print(f"    [âœ… æœç´¢B] æ‰¾åˆ° {len(search_results_b)} ä¸ªç»“æœ")
                    if search_results_b:
                        print(f"    [ğŸ“‹ æœç´¢Bç»“æœè¯¦æƒ…]")
                        for idx, result in enumerate(search_results_b, 1):
                            print(f"        {idx}. {result.title[:60]}...")
                            print(f"           URL: {result.url}")
                            # æ£€æŸ¥ URL æ˜¯å¦æ¥è‡ªç›®æ ‡å¹³å°
                            url_lower = result.url.lower()
                            matched_platform = None
                            for domain in selected_domains:
                                if domain.lower() in url_lower:
                                    matched_platform = domain
                                    break
                            if matched_platform:
                                print(f"           âœ… åŒ¹é…å¹³å°: {matched_platform}")
                            else:
                                print(f"           âš ï¸ æœªåŒ¹é…åˆ°ç›®æ ‡å¹³å°")
                    else:
                        print(f"    [âš ï¸ æœç´¢B] æœªæ‰¾åˆ°ä»»ä½•ç»“æœ")
                else:
                    print(f"    [âš ï¸ é…ç½®] åŸŸååˆ—è¡¨ä¸ºç©ºï¼Œè·³è¿‡æœ¬åœ°æœç´¢")
            
            # åˆå¹¶ç»“æœå¹¶å»é‡ï¼ˆåŸºäº URLï¼‰
            print(f"\n    [ğŸ”§ åˆå¹¶] å¼€å§‹åˆå¹¶å’Œå»é‡...")
            all_results = search_results_a + search_results_b
            print(f"    [ğŸ“Š åˆå¹¶å‰] é€šç”¨: {len(search_results_a)} ä¸ª, æœ¬åœ°: {len(search_results_b)} ä¸ª, æ€»è®¡: {len(all_results)} ä¸ª")
            
            seen_urls = set()
            unique_results = []
            duplicate_count = 0
            
            for result in all_results:
                if result.url not in seen_urls:
                    seen_urls.add(result.url)
                    unique_results.append(result)
                else:
                    duplicate_count += 1
                    print(f"        [-] å»é‡: {result.url[:80]}...")
            
            search_results = unique_results
            print(f"    [ğŸ“Š åˆå¹¶å] å»é‡: {duplicate_count} ä¸ª, ä¿ç•™: {len(search_results)} ä¸ª")
            print(f"    [ğŸ“Š ç»Ÿè®¡] é€šç”¨: {len(search_results_a)}, æœ¬åœ°: {len(search_results_b)}, æœ€ç»ˆ: {len(search_results)}")

            # ========== ğŸ” è®°å½•å»é‡è¿‡æ»¤é˜¶æ®µåˆ°é€æ˜åº¦æ”¶é›†å™¨ï¼ˆP0-1ï¼‰ ==========
            # æ”¶é›†è¢«è¿‡æ»¤çš„æ ·æœ¬ï¼ˆé‡å¤URLï¼‰
            duplicate_samples = []
            seen_urls_set = set()
            for result in all_results:
                if result.url in seen_urls_set:
                    duplicate_samples.append({
                        "title": result.title[:80],
                        "url": result.url[:100],
                        "reason": "URLé‡å¤"
                    })
                    if len(duplicate_samples) >= 3:  # æœ€å¤š3ä¸ªæ ·æœ¬
                        break
                seen_urls_set.add(result.url)

            self.transparency_collector.record_filtering_stage(
                stage_name="å»é‡",
                input_count=len(all_results),
                output_count=len(search_results),
                filter_reason=f"ç§»é™¤ {duplicate_count} ä¸ªé‡å¤URL",
                filtered_samples=duplicate_samples
            )
            logger.debug(f"[ğŸ” é€æ˜åº¦] å·²è®°å½•å»é‡è¿‡æ»¤: {len(all_results)} â†’ {len(search_results)}")
            # ========== å»é‡è¿‡æ»¤è®°å½•ç»“æŸ ==========
            
            # Step 3: è¯„ä¼°ç»“æœ
            step3_start = time.time()
            logger.info(f"[æ­¥éª¤ 3] è¯„ä¼°ç»“æœ... (å†…å­˜: {self._get_memory_usage()})")
            print(f"\n[æ­¥éª¤ 3] è¯„ä¼°ç»“æœ...")
            evaluated_results = self.evaluator.evaluate_results(
                search_results,
                country=request.country,
                grade=request.grade,
                subject=request.subject
            )
            step3_elapsed = time.time() - step3_start
            logger.info(f"   âœ… æ­¥éª¤3å®Œæˆ: {step3_elapsed:.2f}ç§’, {len(evaluated_results)}ä¸ªç»“æœ (å†…å­˜: {self._get_memory_usage()})")

            # Step 3.5: æ™ºèƒ½è¯„åˆ†å’Œç”Ÿæˆæ¨èç†ç”±
            step35_start = time.time()
            logger.info(f"[æ­¥éª¤ 3.5] æ™ºèƒ½è¯„åˆ†å¼€å§‹... (å†…å­˜: {self._get_memory_usage()})")
            print(f"\n[æ­¥éª¤ 3.5] æ™ºèƒ½è¯„åˆ†...")

            # ğŸš€ å¹¶å‘è·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯ï¼ˆä¼˜åŒ–æ€§èƒ½ï¼Œä½¿ç”¨ç±»æ–¹æ³•å¸¦ç¼“å­˜ï¼‰
            print(f"\n[æ­¥éª¤ 3.5.1] å¹¶å‘è·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯...")

            # ç¬¬ä¸€æ­¥ï¼šå°†SearchResultå¯¹è±¡è½¬æ¢ä¸ºå­—å…¸ï¼Œå¹¶è¯†åˆ«æ’­æ”¾åˆ—è¡¨
            results_dicts = []
            playlist_results = []  # å­˜å‚¨éœ€è¦è·å–æ’­æ”¾åˆ—è¡¨ä¿¡æ¯çš„ç»“æœ

            for result in evaluated_results:
                result_dict = {
                    'title': result.title,
                    'url': result.url,
                    'snippet': result.snippet,
                    'source': result.source,
                    'resource_type': getattr(result, 'resource_type', 'unknown')
                }

                # å¦‚æœæ˜¯æ’­æ”¾åˆ—è¡¨URLï¼Œæ ‡è®°ä¸ºéœ€è¦è·å–ä¿¡æ¯
                if 'list=' in result.url:
                    playlist_results.append(result_dict)
                else:
                    # éæ’­æ”¾åˆ—è¡¨ï¼Œç›´æ¥æ·»åŠ 
                    results_dicts.append(result_dict)

            # ç¬¬äºŒæ­¥ï¼šå¹¶å‘è·å–æ‰€æœ‰æ’­æ”¾åˆ—è¡¨ä¿¡æ¯
            if playlist_results:
                import concurrent.futures

                print(f"    [âš¡ å¹¶å‘] å‘ç° {len(playlist_results)} ä¸ªæ’­æ”¾åˆ—è¡¨ï¼Œå¼€å§‹å¹¶å‘è·å–ä¿¡æ¯...")

                # è®¾ç½®å¹¶å‘å‚æ•°
                MAX_PLAYLIST_WORKERS = 20  # æœ€å¤š20ä¸ªå¹¶å‘ï¼ˆä¿®å¤ï¼šP1 - N+1æŸ¥è¯¢ä¼˜åŒ–ï¼‰
                SINGLE_TIMEOUT = 3  # å•ä¸ªæ’­æ”¾åˆ—è¡¨3ç§’è¶…æ—¶ï¼ˆä¼˜åŒ–ï¼šä»8ç§’é™ä½åˆ°3ç§’ï¼Œ2.6å€æé€Ÿï¼‰

                success_count = 0
                fail_count = 0

                with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_PLAYLIST_WORKERS) as executor:
                    # æäº¤æ‰€æœ‰ä»»åŠ¡ï¼ˆä½¿ç”¨ç±»æ–¹æ³•å¸¦ç¼“å­˜ï¼‰
                    future_to_result = {
                        executor.submit(self.get_playlist_info_fast, r['url']): r
                        for r in playlist_results
                    }

                    # ğŸ”§ ä¿®å¤ï¼šç§»é™¤æ•´ä½“è¶…æ—¶ï¼Œé¿å…éƒ¨åˆ†è¶…æ—¶å¯¼è‡´æ•´ä¸ªæœç´¢å¤±è´¥
                    # æ”¶é›†ç»“æœï¼ˆç­‰å¾…æ‰€æœ‰futureå®Œæˆï¼‰
                    for future in concurrent.futures.as_completed(future_to_result):
                        result_dict = future_to_result[future]

                        try:
                            # å•ä¸ªè¶…æ—¶æ§åˆ¶
                            playlist_info = future.result(timeout=SINGLE_TIMEOUT)

                            if playlist_info:
                                result_dict['playlist_info'] = playlist_info
                                print(f"    [âœ… æˆåŠŸ] {result_dict['title'][:40]}... - {playlist_info['video_count']}ä¸ªè§†é¢‘, {playlist_info['total_duration_minutes']:.0f}åˆ†é’Ÿ")
                                success_count += 1
                            else:
                                print(f"    [âš ï¸ å¤±è´¥] {result_dict['title'][:40]}... - æ— æ³•è·å–ä¿¡æ¯")
                                fail_count += 1

                        except concurrent.futures.TimeoutError:
                            print(f"    [â±ï¸ è¶…æ—¶] {result_dict['title'][:40]}... - è·å–è¶…æ—¶({SINGLE_TIMEOUT}ç§’)")
                            fail_count += 1
                        except Exception as e:
                            print(f"    [âŒ å¼‚å¸¸] {result_dict['title'][:40]}... - {str(e)[:50]}")
                            fail_count += 1

                        # æ— è®ºå¦‚ä½•éƒ½æ·»åŠ åˆ°ç»“æœåˆ—è¡¨
                        results_dicts.append(result_dict)

                print(f"    [ğŸ“Š ç»Ÿè®¡] æˆåŠŸ: {success_count}, å¤±è´¥: {fail_count}, æ€»è®¡: {len(playlist_results)}")
            else:
                print(f"    [â„¹ï¸ è·³è¿‡] æ²¡æœ‰æ’­æ”¾åˆ—è¡¨éœ€è¦è·å–ä¿¡æ¯")

            # ========== Step 3.5: è§†è§‰å¿«é€Ÿè¯„ä¼°ï¼ˆTOP 20ï¼‰ ==========
            # âš ï¸ ä¸´æ—¶ç¦ç”¨ï¼šè§†è§‰è¯„ä¼°ä¼šå¯¼è‡´è¯·æ±‚è¶…æ—¶ï¼ˆé”™è¯¯ä»£ç 5ï¼‰
            # åŸå› ï¼šTOP 20ä¸ªç»“æœä¸²è¡Œå¤„ç†éœ€è¦5-10åˆ†é’Ÿï¼Œè¶…è¿‡HTTPè¯·æ±‚è¶…æ—¶é™åˆ¶
            # TODO: éœ€è¦æ”¹ä¸ºåå°å¼‚æ­¥å¤„ç†æˆ–å¤§å¹…å‡å°‘è¯„ä¼°æ•°é‡ï¼ˆTOP 5ï¼‰
            #
            # [ä¿®å¤] 2026-01-20: å¯ç”¨è§†è§‰è¯„ä¼°ï¼ˆé»˜è®¤trueï¼‰ï¼Œä½†é™åˆ¶è¯„ä¼°æ•°é‡ä¸ºTOP 5é¿å…è¶…æ—¶

            # ğŸ”’ P1 ç¯å¢ƒå˜é‡éªŒè¯: è¯»å–ç¯å¢ƒå˜é‡æ§åˆ¶æ˜¯å¦å¯ç”¨ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
            ENABLE_VISUAL_EVALUATION = validate_env_bool(
                os.getenv('ENABLE_VISUAL_EVALUATION'),
                'ENABLE_VISUAL_EVALUATION',
                default=True
            )

            # ğŸ”’ P1 ç¯å¢ƒå˜é‡éªŒè¯: è¯»å–ç¯å¢ƒå˜é‡æ§åˆ¶LLMè¯„åˆ†æ•°é‡ï¼ˆé»˜è®¤TOP 10ï¼Œé¿å…è¶…æ—¶ï¼‰
            LLM_SCORE_TOP_N = validate_env_int(
                os.getenv('LLM_SCORE_TOP_N'),
                'LLM_SCORE_TOP_N',
                default=10,
                min_val=1,
                max_val=50
            )

            if not ENABLE_VISUAL_EVALUATION:
                print(f"\n[æ­¥éª¤ 3.5] è§†è§‰è¯„ä¼°å·²ç¦ç”¨ï¼ˆä½¿ç”¨å¿«é€ŸLLMè¯„åˆ†æ¨¡å¼ï¼‰")
                print(f"    [â„¹ï¸  æç¤º] å¦‚éœ€å¯ç”¨è§†è§‰è¯„ä¼°ï¼Œè®¾ç½®ç¯å¢ƒå˜é‡: ENABLE_VISUAL_EVALUATION=true")
                print(f"    [âš¡ æ€§èƒ½ä¼˜åŒ–] åªå¯¹TOP {LLM_SCORE_TOP_N}ä¸ªç»“æœè¿›è¡ŒLLMè¯„åˆ†")

                # âš¡ ä¼˜åŒ–ï¼šåªå¯¹TOP Nä¸ªç»“æœè¿›è¡ŒLLMè¯„åˆ†ï¼Œé¿å…è¶…æ—¶
                if len(results_dicts) > LLM_SCORE_TOP_N:
                    top_n_results = results_dicts[:LLM_SCORE_TOP_N]
                    remaining_results = results_dicts[LLM_SCORE_TOP_N:]

                    # å¯¹TOP Nè¿›è¡ŒLLMè¯„åˆ†
                    print(f"    [ğŸ“Š] TOP {len(top_n_results)} ä¸ªç»“æœå°†è¿›è¡ŒLLMè¯„åˆ†")
                    quickly_scored_results = top_n_results
                    # å‰©ä½™ç»“æœä½¿ç”¨é»˜è®¤åˆ†æ•°ï¼ˆä¸è¿›è¡ŒLLMè¯„åˆ†ï¼‰
                    quickly_scored_results.extend([{
                        **r,
                        'score': 5.0,  # é»˜è®¤ä¸­ç­‰åˆ†æ•°
                        'recommendation_reason': 'æœªè¯„åˆ†ï¼ˆè¶…å‡ºTOP Né™åˆ¶ï¼‰'
                    } for r in remaining_results])
                else:
                    # ç»“æœæ•°å°‘äºTOP Nï¼Œå…¨éƒ¨è¯„åˆ†
                    quickly_scored_results = results_dicts.copy()

                visually_scored_results = []
            else:
                print(f"\n[æ­¥éª¤ 3.5] è§†è§‰å¿«é€Ÿè¯„ä¼°ï¼ˆTOP 5ï¼‰...")

                # æå–TOP 5ä¸ªç»“æœè¿›è¡Œè§†è§‰è¯„ä¼°ï¼ˆå‡å°‘æ•°é‡é¿å…è¶…æ—¶ï¼‰
                TOP_N = 5
                top_results = results_dicts[:TOP_N]
                remaining_results = results_dicts[TOP_N:]

                print(f"    [ğŸ“Š] TOP {len(top_results)} ä¸ªç»“æœå°†è¿›è¡Œè§†è§‰è¯„ä¼°")
                print(f"    [ğŸ“Š] å‰©ä½™ {len(remaining_results)} ä¸ªç»“æœå°†ä½¿ç”¨å¿«é€Ÿè¯„åˆ†")

                # å¹¶å‘æˆªå›¾TOP 5
                screenshot_results = {}
                successful_screenshots = 0

                if top_results:
                    try:
                        # å¯¼å…¥æˆªå›¾æœåŠ¡
                        import asyncio
                        from core.screenshot_service import get_screenshot_service

                        # å‡†å¤‡URLåˆ—è¡¨
                        urls_to_screenshot = [r['url'] for r in top_results]

                        print(f"    [ğŸ“¸] å¼€å§‹å¹¶å‘æˆªå›¾ {len(urls_to_screenshot)} ä¸ªURL...")

                        # å¼‚æ­¥æ‰¹é‡æˆªå›¾ï¼ˆå¢åŠ è¶…æ—¶ä¿æŠ¤ + é¿å…èµ„æºæ³„æ¼ï¼‰
                        async def capture_screenshots_async():
                            """ğŸ”’ P1ä¿®å¤ï¼šé¿å…å…³é—­å…¨å±€å•ä¾‹çš„browser"""
                            try:
                                # è·å–æˆªå›¾æœåŠ¡ï¼ˆå…¨å±€å•ä¾‹ï¼Œä¸è¦å…³é—­ï¼‰
                                service = await get_screenshot_service()

                                # æ·»åŠ 60ç§’æ€»è¶…æ—¶ä¿æŠ¤
                                result = await asyncio.wait_for(
                                    service.capture_batch(
                                        urls=urls_to_screenshot,
                                        wait_for='domcontentloaded',  # ä½¿ç”¨æ›´å¿«çš„ç­‰å¾…ç­–ç•¥ï¼Œé¿å…YouTubeè¶…æ—¶
                                        full_page=False
                                    ),
                                    timeout=60.0  # æœ€å¤šç­‰å¾…60ç§’
                                )
                                return result
                            except asyncio.TimeoutError:
                                logger.warning("æˆªå›¾è¶…æ—¶(60ç§’)ï¼Œéƒ¨åˆ†æˆªå›¾å¯èƒ½å¤±è´¥")
                                return {}
                            except Exception as e:
                                logger.warning(f"æˆªå›¾æœåŠ¡å¼‚å¸¸: {str(e)[:100]}")
                                return {}
                            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šç§»é™¤finallyå—ï¼Œä¸è¦å…³é—­å…¨å±€å•ä¾‹çš„browser
                            # ScreenshotServiceä½¿ç”¨å…¨å±€å•ä¾‹æ¨¡å¼ï¼Œç”±ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨è´Ÿè´£æ¸…ç†

                        # è¿è¡Œå¼‚æ­¥ä»»åŠ¡
                        screenshot_results = asyncio.run(capture_screenshots_async())

                        # ç»Ÿè®¡æˆåŠŸæ•°é‡
                        successful_screenshots = sum(1 for path in screenshot_results.values() if path is not None)
                        print(f"    [âœ… æˆªå›¾å®Œæˆ] {successful_screenshots}/{len(urls_to_screenshot)} æˆåŠŸ")

                    except Exception as e:
                        logger.error(f"æˆªå›¾æµç¨‹å¼‚å¸¸: {str(e)}")
                        print(f"    [âŒ æˆªå›¾å¤±è´¥] {str(e)[:100]}")
                        print(f"    [âš ï¸ å°†é™çº§åˆ°å¿«é€Ÿè¯„åˆ†æ¨¡å¼")
                        # ç¡®ä¿screenshot_resultsæ˜¯å­—å…¸
                        if 'screenshot_results' not in locals() or not isinstance(screenshot_results, dict):
                            screenshot_results = {}

                # å¯¹æœ‰æˆªå›¾çš„ç»“æœä½¿ç”¨è§†è§‰è¯„ä¼°
                visually_scored_results = []
                quickly_scored_results = remaining_results.copy()

                for result_dict in top_results:
                    url = result_dict['url']
                    screenshot_path = screenshot_results.get(url)

                    if screenshot_path:
                        # æœ‰æˆªå›¾ï¼Œä½¿ç”¨è§†è§‰è¯„ä¼°ï¼ˆæ·»åŠ è¶…æ—¶ä¿æŠ¤ï¼‰
                        try:
                            import signal

                            # å‡†å¤‡metadata
                            country_config = self.config_manager.get_country_config(request.country.upper()) if self.config_manager else None
                            metadata = {
                                'country_name': country_config.name if country_config else '',
                                'grade_name': request.grade,
                                'subject_name': request.subject,
                                'language_code': country_config.language_code if country_config else 'en'
                            }

                            # è°ƒç”¨è§†è§‰è¯„ä¼°ï¼ˆè¶…æ—¶ä¿æŠ¤30ç§’ï¼‰
                            def timeout_handler(signum, frame):
                                raise TimeoutError("è§†è§‰è¯„ä¼°è¶…æ—¶")

                            # è®¾ç½®è¶…æ—¶ï¼ˆä»…Unixç³»ç»Ÿï¼‰
                            if hasattr(signal, 'SIGALRM'):
                                signal.signal(signal.SIGALRM, timeout_handler)
                                signal.alarm(30)  # 30ç§’è¶…æ—¶

                            try:
                                visual_evaluation = self.result_scorer.evaluate_with_visual(
                                    result=result_dict,
                                    screenshot_path=screenshot_path,
                                    query=query,
                                    metadata=metadata
                                )
                            finally:
                                if hasattr(signal, 'SIGALRM'):
                                    signal.alarm(0)  # å–æ¶ˆè¶…æ—¶

                            if visual_evaluation:
                                # è§†è§‰è¯„ä¼°æˆåŠŸ
                                result_dict['score'] = visual_evaluation['score']
                                result_dict['recommendation_reason'] = visual_evaluation['recommendation_reason']
                                result_dict['evaluation_method'] = 'Visual'
                                result_dict['evaluation_details'] = visual_evaluation.get('evaluation_details', {})
                                result_dict['screenshot_path'] = screenshot_path
                                visually_scored_results.append(result_dict)
                                print(f"    [âœ… è§†è§‰è¯„ä¼°] {result_dict['title'][:40]}... - {visual_evaluation['score']}/10")
                            else:
                                # è§†è§‰è¯„ä¼°å¤±è´¥ï¼Œé™çº§åˆ°å¿«é€Ÿè¯„åˆ†
                                quickly_scored_results.append(result_dict)
                                print(f"    [âš ï¸ é™çº§] {result_dict['title'][:40]}... - è§†è§‰è¯„ä¼°å¤±è´¥ï¼Œä½¿ç”¨å¿«é€Ÿè¯„åˆ†")

                        except TimeoutError:
                            logger.warning(f"è§†è§‰è¯„ä¼°è¶…æ—¶: {result_dict['title'][:40]}...")
                            print(f"    [â±ï¸ è¶…æ—¶] {result_dict['title'][:40]}... - è§†è§‰è¯„ä¼°è¶…æ—¶ï¼Œä½¿ç”¨å¿«é€Ÿè¯„åˆ†")
                            quickly_scored_results.append(result_dict)
                        except Exception as e:
                            logger.warning(f"è§†è§‰è¯„ä¼°å¼‚å¸¸: {str(e)[:100]}")
                            quickly_scored_results.append(result_dict)
                    else:
                        # æ²¡æœ‰æˆªå›¾ï¼Œä½¿ç”¨å¿«é€Ÿè¯„åˆ†
                        quickly_scored_results.append(result_dict)

            # å¯¹å¿«é€Ÿè¯„åˆ†ç»“æœä½¿ç”¨åŸæœ‰çš„LLM/è§„åˆ™è¯„åˆ†
            if quickly_scored_results:
                llm_start = time.time()
                logger.info(f"[LLMè¯„åˆ†] å¼€å§‹: {len(quickly_scored_results)}ä¸ªç»“æœ (å†…å­˜: {self._get_memory_usage()})")
                print(f"    [ğŸ“Š] å¯¹ {len(quickly_scored_results)} ä¸ªç»“æœè¿›è¡Œå¿«é€Ÿè¯„åˆ†ï¼ˆLLM/è§„åˆ™ï¼‰...")

                # è·å–å›½å®¶è¯­è¨€ä»£ç 
                language_code = None
                if self.config_manager:
                    country_config = self.config_manager.get_country_config(request.country.upper())
                    if country_config:
                        language_code = country_config.language_code

                quickly_scored = self.result_scorer.score_results(
                    results=quickly_scored_results,
                    query=query,
                    metadata={
                        'country': request.country,
                        'grade': request.grade,
                        'subject': request.subject,
                        'language_code': language_code
                    }
                )

                # åˆå¹¶ç»“æœ
                results_dicts = visually_scored_results + quickly_scored

                llm_elapsed = time.time() - llm_start
                logger.info(f"   âœ… LLMè¯„åˆ†å®Œæˆ: {llm_elapsed:.2f}ç§’, {len(quickly_scored)}ä¸ªç»“æœ (å†…å­˜: {self._get_memory_usage()})")
            else:
                results_dicts = visually_scored_results

            print(f"    [âœ… è¯„ä¼°å®Œæˆ] æ€»è®¡ {len(results_dicts)} ä¸ªç»“æœ (è§†è§‰: {len(visually_scored_results)}, å¿«é€Ÿ: {len(quickly_scored_results)})")

            step35_elapsed = time.time() - step35_start
            logger.info(f"   âœ… æ­¥éª¤3.5å®Œæˆ: {step35_elapsed:.2f}ç§’ (å†…å­˜: {self._get_memory_usage()})")
            logger.info(f"   ğŸ“Š è¯„åˆ†ç»“æœ: è§†è§‰={len(visually_scored_results)}, å¿«é€Ÿ={len(quickly_scored_results)}")

            # æ˜¾ç¤ºè¯„åˆ†ç»Ÿè®¡
            if results_dicts:
                scores = [r.get('score', 0) for r in results_dicts]
                avg_score = sum(scores) / len(scores) if scores else 0
                high_score_count = sum(1 for s in scores if s >= 8.0)
                visual_count = sum(1 for r in results_dicts if r.get('evaluation_method') == 'Visual')
                print(f"    [ğŸ“Š è¯„åˆ†ç»Ÿè®¡] å¹³å‡åˆ†: {avg_score:.2f}, é«˜åˆ†(â‰¥8): {high_score_count} ä¸ª, è§†è§‰è¯„ä¼°: {visual_count} ä¸ª")
                print(f"    [ğŸ“Š å‰3åè¯„åˆ†]:")
                for i, r in enumerate(results_dicts[:3], 1):
                    method = r.get('evaluation_method', 'Unknown')
                    print(f"        {i}. {r.get('score', 0):.1f}/10 [{method}] - {r.get('title', 'N/A')[:50]}...")

            # âœ… æ–°é€»è¾‘ï¼šé€šè¿‡URLåŒ¹é…è¯„åˆ†å’Œç»“æœï¼ˆ2025-01-16ï¼‰
            # é—®é¢˜ï¼šresults_dictså’Œevaluated_resultsçš„é¡ºåºå¯èƒ½ä¸ä¸€è‡´
            # è§£å†³ï¼šé€šè¿‡URLè¿›è¡Œä¸€ä¸€å¯¹åº”åŒ¹é…
            logger.info(f"[ğŸ“Š URLåŒ¹é…] å¼€å§‹é€šè¿‡URLåŒ¹é…è¯„åˆ†ï¼ˆ{len(results_dicts)}ä¸ªè¯„åˆ†ï¼Œ{len(evaluated_results)}ä¸ªç»“æœï¼‰")

            # 1. æ„å»ºURLåˆ°è¯„åˆ†çš„æ˜ å°„
            url_to_score = {}
            for scored_dict in results_dicts:
                if 'url' in scored_dict and 'score' in scored_dict:
                    url = scored_dict['url']
                    url_to_score[url] = {
                        'score': scored_dict['score'],
                        'recommendation_reason': scored_dict.get('recommendation_reason', ''),
                        'evaluation_method': scored_dict.get('evaluation_method', 'LLM')
                    }

            # 2. é€šè¿‡URLåŒ¹é…ï¼Œå°†è¯„åˆ†èµ‹å€¼ç»™å¯¹åº”çš„ç»“æœ
            matched_count = 0
            for result in evaluated_results:
                result_url = result.url
                if result_url in url_to_score:
                    # æ‰¾åˆ°åŒ¹é…çš„è¯„åˆ†
                    score_info = url_to_score[result_url]
                    result.score = score_info['score']
                    result.recommendation_reason = score_info['recommendation_reason']
                    matched_count += 1
                else:
                    # æœªæ‰¾åˆ°è¯„åˆ†ï¼Œè®¾ç½®é»˜è®¤å€¼
                    logger.warning(f"[âš ï¸ æœªæ‰¾åˆ°è¯„åˆ†] URL: {result_url[:60]}...")
                    result.score = 0.0
                    result.recommendation_reason = 'æœªæ‰¾åˆ°è¯„åˆ†'

            logger.info(f"[âœ… URLåŒ¹é…å®Œæˆ] åŒ¹é…æˆåŠŸ: {matched_count}/{len(evaluated_results)}")

            # 3. æŒ‰è¯„åˆ†é™åºæ’åº
            evaluated_results.sort(key=lambda x: x.score, reverse=True)
            logger.info(f"âœ… ç»“æœå·²æŒ‰è¯„åˆ†é™åºæ’åº (æœ€é«˜åˆ†: {evaluated_results[0].score if evaluated_results else 0:.1f})")

            # Step 4: ç»Ÿè®¡
            # æ’­æ”¾åˆ—è¡¨ï¼šYouTubeæ’­æ”¾åˆ—è¡¨æˆ–åŒ…å«list=çš„URL
            playlist_count = sum(1 for r in evaluated_results if 
                               "youtube.com/playlist" in r.url.lower() or 
                               ("youtube.com/watch" in r.url.lower() and "list=" in r.url.lower()))
            
            # è§†é¢‘ï¼šYouTubeè§†é¢‘ã€Bç«™è§†é¢‘æˆ–å…¶ä»–è§†é¢‘å¹³å°
            video_count = sum(1 for r in evaluated_results if 
                            "youtube.com/watch" in r.url.lower() or
                            "bilibili.com/video" in r.url.lower() or
                            "/video/" in r.url.lower())
            
            print(f"\n[æ­¥éª¤ 4] ç»Ÿè®¡ç»“æœ...")
            print(f"    [ğŸ“Š ç»Ÿè®¡] æ’­æ”¾åˆ—è¡¨: {playlist_count} ä¸ª")
            print(f"    [ğŸ“Š ç»Ÿè®¡] è§†é¢‘: {video_count} ä¸ª")
            print(f"    [ğŸ“Š ç»Ÿè®¡] æ€»è®¡: {len(evaluated_results)} ä¸ª")

            # æ˜¾ç¤ºå¤šçº§ç¼“å­˜ç»Ÿè®¡
            cache_stats = self.multi_cache.get_stats()
            print(f"\n[ğŸ’¾ å¤šçº§ç¼“å­˜ç»Ÿè®¡]")
            print(f"    [ğŸ“Š L1å†…å­˜] å‘½ä¸­: {cache_stats['l1_hits']}æ¬¡ ({cache_stats['l1_hit_rate']:.1f}%)")
            print(f"    [ğŸ“Š L2 Redis] å‘½ä¸­: {cache_stats['l2_hits']}æ¬¡ ({cache_stats['l2_hit_rate']:.1f}%)")
            print(f"    [ğŸ“Š L3ç£ç›˜] å‘½ä¸­: {cache_stats['l3_hits']}æ¬¡ ({cache_stats['l3_hit_rate']:.1f}%)")
            print(f"    [ğŸ“Š æ€»è®¡] æŸ¥è¯¢: {cache_stats['total']}æ¬¡ | å‘½ä¸­ç‡: {cache_stats['hit_rate']:.1f}%")

            # æ€§èƒ½ç›‘æ§ - è®°å½•æˆåŠŸçš„æœç´¢
            search_duration = time.time() - search_start_time
            perf_monitor.record_metric(
                operation=f"search_{request.country.lower()}",
                duration=search_duration,
                success=True,
                metadata={
                    "country": request.country,
                    "grade": request.grade,
                    "subject": request.subject,
                    "result_count": len(evaluated_results),
                    "playlist_count": playlist_count,
                    "video_count": video_count,
                    "query": query
                }
            )

            # ğŸ”§ ä¿®å¤ï¼šå°†SearchResultå¯¹è±¡è½¬æ¢ä¸ºå­—å…¸ï¼ˆé¿å…PydanticéªŒè¯é”™è¯¯ï¼‰
            results_as_dicts = [r.model_dump() if hasattr(r, 'model_dump') else r.dict() for r in evaluated_results]

            # ========== ğŸ¤– æ™ºèƒ½ä¼˜åŒ–å¾ªç¯ï¼ˆè´¨é‡è¯„ä¼° + ä¼˜åŒ–å»ºè®®ï¼‰ ==========
            quality_report = None
            optimization_request = None

            try:
                # ğŸ”’ P1 ç¯å¢ƒå˜é‡éªŒè¯: æ£€æŸ¥æ˜¯å¦å¯ç”¨æ™ºèƒ½ä¼˜åŒ–ï¼ˆç¯å¢ƒå˜é‡æ§åˆ¶ï¼‰
                enable_intelligent_optimization = validate_env_bool(
                    os.getenv("ENABLE_INTELLIGENT_OPTIMIZATION"),
                    "ENABLE_INTELLIGENT_OPTIMIZATION",
                    default=True
                )

                if enable_intelligent_optimization:
                    print(f"\n[ğŸ¤– æ™ºèƒ½ä¼˜åŒ–] å¼€å§‹è´¨é‡è¯„ä¼°...")

                    # 1. è´¨é‡è¯„ä¼°
                    evaluator = QualityEvaluator()
                    search_params = {
                        'country': request.country,
                        'grade': request.grade,
                        'subject': request.subject,
                        'semester': request.semester
                    }
                    quality_report = evaluator.evaluate_single_search(results_as_dicts, search_params)

                    print(f"    [ğŸ“Š è´¨é‡åˆ†æ•°] {quality_report['overall_quality_score']:.1f}/100")
                    print(f"    [ğŸ¯ è´¨é‡ç­‰çº§] {quality_report['quality_level']}")
                    print(f"    [ğŸ“ˆ å¹³å‡åˆ†] {quality_report['basic_stats']['avg_score']:.2f}/10")

                    # 2. åˆ¤æ–­æ˜¯å¦éœ€è¦ä¼˜åŒ–
                    optimizer = IntelligentSearchOptimizer(search_engine=self)
                    should_opt, issues = optimizer.should_optimize(results_as_dicts, quality_report)

                    if should_opt:
                        print(f"    [âš ï¸ æ£€æµ‹åˆ°é—®é¢˜] {len(issues)}ä¸ª")
                        for i, issue in enumerate(issues, 1):
                            print(f"      {i}. {issue}")

                        # 3. ç”Ÿæˆä¼˜åŒ–æ–¹æ¡ˆ
                        opt_request = optimizer.create_optimization_request(
                            results_as_dicts, quality_report, search_params, issues
                        )

                        # 4. å­˜å‚¨ä¼˜åŒ–è¯·æ±‚åˆ°å®¡æ‰¹ç®¡ç†å™¨ (å·²ç¦ç”¨ - SISåŠŸèƒ½)
                        # approval_manager = get_approval_manager()
                        # stored_request = approval_manager.create_request(opt_request)
                        # print(f"    [âœ… ä¼˜åŒ–è¯·æ±‚å·²åˆ›å»º] ID: {stored_request['request_id']}")
                        # print(f"    [ğŸ“‹ å¾…å®¡æ‰¹æ–¹æ¡ˆ] {len(stored_request['optimization_plans'])}ä¸ª")
                        # optimization_request = stored_request
                        optimization_request = None
                    else:
                        print(f"    [âœ… è´¨é‡è‰¯å¥½] æ— éœ€ä¼˜åŒ–")

            except Exception as opt_error:
                # ğŸ”’ P1å®‰å…¨ä¿®å¤ï¼šä¸æš´éœ²å¼‚å¸¸ç»†èŠ‚ç»™ç”¨æˆ·
                logger.warning(f"æ™ºèƒ½ä¼˜åŒ–å¤±è´¥: {type(opt_error).__name__}", exc_info=True)
                print(f"    [âš ï¸ æ™ºèƒ½ä¼˜åŒ–å¤±è´¥] å°†ä½¿ç”¨é»˜è®¤æ’åº")
            # ========== æ™ºèƒ½ä¼˜åŒ–å¾ªç¯ç»“æŸ ==========

            # ========== ğŸ” è®°å½•è¯„åˆ†åˆ†å¸ƒå’Œè¿‡æ»¤åˆ°é€æ˜åº¦æ”¶é›†å™¨ï¼ˆP0-1ï¼‰ ==========
            # è®°å½•è¯„åˆ†åˆ†å¸ƒ
            scores = [r.score for r in evaluated_results if hasattr(r, 'score')]
            self.transparency_collector.record_score_distribution(scores)
            
            # è®°å½•é˜ˆå€¼è¿‡æ»¤ï¼ˆå¦‚æœæœ‰ï¼‰
            if MIN_SCORE_THRESHOLD:
                above_threshold = [r for r in evaluated_results if hasattr(r, 'score') and r.score >= MIN_SCORE_THRESHOLD]
                below_threshold = [r for r in evaluated_results if hasattr(r, 'score') and r.score < MIN_SCORE_THRESHOLD]
                
                # æ”¶é›†è¢«è¿‡æ»¤çš„ä½åˆ†æ ·æœ¬
                filtered_low_score_samples = [{
                    "title": r.title[:80] if hasattr(r, 'title') else '',
                    "url": r.url[:100] if hasattr(r, 'url') else '',
                    "score": r.score if hasattr(r, 'score') else 0,
                    "reason": f"è¯„åˆ† {r.score:.1f} < {MIN_SCORE_THRESHOLD}"
                } for r in below_threshold[:5]]  # æœ€å¤š5ä¸ªæ ·æœ¬
                
                self.transparency_collector.record_filtering_stage(
                    stage_name="è¯„åˆ†é˜ˆå€¼è¿‡æ»¤",
                    input_count=len(evaluated_results),
                    output_count=len(above_threshold),
                    filter_reason=f"è¯„åˆ†ä½äº {MIN_SCORE_THRESHOLD} åˆ†",
                    filtered_samples=filtered_low_score_samples
                )
                logger.debug(f"[ğŸ” é€æ˜åº¦] å·²è®°å½•è¯„åˆ†é˜ˆå€¼è¿‡æ»¤: {len(evaluated_results)} â†’ {len(above_threshold)}")
            # ========== è¯„åˆ†åˆ†å¸ƒå’Œè¿‡æ»¤è®°å½•ç»“æŸ ==========

            # ğŸ” è¯¦ç»†æ—¥å¿—ï¼šæœç´¢å®Œæˆ
            total_elapsed = time.time() - search_start_time
            logger.info("="*80)
            logger.info(f"âœ… [æœç´¢å®Œæˆ] {request.country} - {request.grade} - {request.subject}")
            logger.info(f"   æ€»è€—æ—¶: {total_elapsed:.2f}ç§’")
            logger.info(f"   ç»“æœæ•°: {len(evaluated_results)}")
            logger.info(f"   å†…å­˜ä½¿ç”¨: {self._get_memory_usage()}")
            logger.info(f"   æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            if quality_report:
                logger.info(f"   è´¨é‡åˆ†æ•°: {quality_report['overall_quality_score']:.1f}/100")
            logger.info("="*80)

            # ========== ğŸ” é™„åŠ é€æ˜åº¦å…ƒæ•°æ®åˆ°å“åº”ï¼ˆP0-1ï¼‰ ==========
            transparency_metadata = self.transparency_collector.get_transparency_metadata()
            logger.debug(f"[ğŸ” é€æ˜åº¦] å‡†å¤‡è¿”å›é€æ˜åº¦å…ƒæ•°æ®: {len(transparency_metadata.get('search_executions', []))} æ¬¡æœç´¢, "
                       f"{transparency_metadata.get('total_raw_results', 0)} ä¸ªåŸå§‹ç»“æœ")
            
            # å¯é€‰ï¼šæ‰“å°é€æ˜åº¦æ‘˜è¦ï¼ˆè°ƒè¯•ç”¨ï¼‰
            # self.transparency_collector.print_summary()
            # ========== é€æ˜åº¦å…ƒæ•°æ®é™„åŠ ç»“æŸ ==========

            return SearchResponse(
                success=True,
                query=query,
                results=results_as_dicts,
                total_count=len(evaluated_results),
                playlist_count=playlist_count,
                video_count=video_count,
                message="æœç´¢æˆåŠŸ",
                quality_report=quality_report,
                optimization_request=optimization_request,
                transparency=transparency_metadata  # ğŸ” æ–°å¢é€æ˜åº¦å­—æ®µ
            )

        except Exception as e:
            # ğŸ”’ P1 å®‰å…¨ä¿®å¤: ä¸æš´éœ²è¯¦ç»†çš„å¼‚å¸¸ä¿¡æ¯å’Œå †æ ˆè·Ÿè¸ª
            logger.error(f"Search failed for {request.country}/{request.grade}/{request.subject}: {type(e).__name__}")
            print(f"\n[âŒ é”™è¯¯] æœç´¢å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•")
            print(f"    [ğŸ’¡ æç¤º] å¦‚æœé—®é¢˜æŒç»­å­˜åœ¨ï¼Œè¯·è”ç³»ç®¡ç†å‘˜å¹¶æä¾›ä»¥ä¸‹ä¿¡æ¯:")
            print(f"           å›½å®¶: {request.country}, å¹´çº§: {request.grade}, å­¦ç§‘: {request.subject}")

            # æ€§èƒ½ç›‘æ§ - è®°å½•å¤±è´¥çš„æœç´¢
            search_duration = time.time() - search_start_time
            perf_monitor.record_metric(
                operation=f"search_{request.country.lower()}",
                duration=search_duration,
                success=False,
                metadata={
                    "country": request.country,
                    "grade": request.grade,
                    "subject": request.subject,
                    "error": str(e)
                }
            )

            return SearchResponse(
                success=False,
                query="",
                results=[],
                message=f"æœç´¢å¤±è´¥: {str(e)}"
            )

        except Exception as e:
            # ğŸ” è¯¦ç»†æ—¥å¿—ï¼šæœç´¢å¤±è´¥
            total_elapsed = time.time() - search_start_time
            logger.error("="*80)
            logger.error(f"âŒ [æœç´¢å¤±è´¥] {request.country} - {request.grade} - {request.subject}")
            logger.error(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
            # ğŸ”’ P1 å®‰å…¨ä¿®å¤: åªè®°å½•ç®€çŸ­çš„é”™è¯¯ä¿¡æ¯ï¼Œä¸è®°å½•å †æ ˆè·Ÿè¸ª
            error_msg = str(e)[:200] if str(e) else "No error message"
            logger.error(f"   é”™è¯¯ä¿¡æ¯: {error_msg}")
            logger.error(f"   è€—æ—¶: {total_elapsed:.2f}ç§’")
            logger.error(f"   å†…å­˜ä½¿ç”¨: {self._get_memory_usage()}")
            logger.error(f"   æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            logger.error("="*80)

# ============================================================================
# ğŸ¤– Agent Native Interface - P1ä¼˜åŒ–
# ============================================================================
"""
Agent-friendlyæœç´¢æ¥å£ï¼Œæ— éœ€HTTPå±‚

è¿™ä¸ªæ¨¡å—æä¾›äº†Agentå¯ä»¥ç›´æ¥è°ƒç”¨çš„æœç´¢åŠŸèƒ½ï¼Œé¿å…äº†é€šè¿‡Flask HTTP APIçš„ç´§è€¦åˆã€‚

ä½¿ç”¨ç¤ºä¾‹:
    from search_engine_v2 import agent_search
    
    # åŒæ­¥æœç´¢
    results = agent_search(
        country="ID",
        grade="Kelas 1",
        subject="Matematika"
    )
    
    # å¸¦å‚æ•°çš„æœç´¢
    results = agent_search(
        country="CN",
        grade="åˆä¸€",
        subject="æ•°å­¦",
        semester="ç¬¬ä¸€å­¦æœŸ",
        language="zh"
    )
"""

import gc
from typing import Optional, Dict, Any, List


def agent_search(
    country: str,
    grade: str,
    subject: str,
    semester: Optional[str] = None,
    language: Optional[str] = None,
    timeout: Optional[int] = 200,
    enable_transparency: bool = False
) -> Dict[str, Any]:
    """
    AgentåŸç”Ÿçš„æœç´¢æ¥å£
    
    ğŸ”¥ å…³é”®ä¼˜åŠ¿ï¼š
    - æ— éœ€HTTPå±‚ï¼Œç›´æ¥Pythonè°ƒç”¨
    - è‡ªåŠ¨å†…å­˜ç®¡ç†
    - æ¸…æ™°çš„é”™è¯¯å¤„ç†
    - æ”¯æŒé€æ˜åº¦æ—¥å¿—
    
    Args:
        country: å›½å®¶ä»£ç  (å¦‚: "ID", "CN", "US")
        grade: å¹´çº§ (å¦‚: "Kelas 1", "åˆä¸€", "Grade 8")
        subject: å­¦ç§‘ (å¦‚: "Matematika", "æ•°å­¦", "Mathematics")
        semester: å­¦æœŸï¼Œå¯é€‰ (å¦‚: "ç¬¬ä¸€å­¦æœŸ", "Semester 1")
        language: è¯­è¨€ä»£ç ï¼Œå¯é€‰ (å¦‚: "zh", "id", "en")
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤200ç§’
        enable_transparency: æ˜¯å¦å¯ç”¨é€æ˜åº¦æ—¥å¿—ï¼Œé»˜è®¤False
    
    Returns:
        Dict[str, Any]: æœç´¢ç»“æœå­—å…¸
        {
            "success": bool,
            "query": str,
            "results": List[Dict],
            "total_count": int,
            "playlist_count": int,
            "video_count": int,
            "message": str,
            "quality_report": Optional[Dict],
            "transparency": Optional[Dict]  # å¦‚æœenable_transparency=True
        }
    
    Raises:
        ValueError: è¾“å…¥å‚æ•°æ— æ•ˆ
        TimeoutError: æœç´¢è¶…æ—¶
    
    Example:
        >>> results = agent_search("ID", "Kelas 1", "Matematika")
        >>> if results["success"]:
        ...     for r in results["results"]:
        ...         print(f"{r['title']}: {r['url']}")
    """
    # è¾“å…¥éªŒè¯
    if not country or not grade or not subject:
        raise ValueError("country, grade, and subject are required")
    
    # æ¸…ç†è¾“å…¥ï¼ˆç§»é™¤å‰åç©ºæ ¼ï¼‰
    country = country.strip()
    grade = grade.strip()
    subject = subject.strip()
    if semester:
        semester = semester.strip()
    
    logger.info(f"[ğŸ¤– Agentæ¥å£] å¼€å§‹æœç´¢: {country}/{grade}/{subject}")
    
    # åˆ›å»ºæœç´¢è¯·æ±‚
    search_request = SearchRequest(
        country=country,
        grade=grade,
        subject=subject,
        semester=semester,
        language=language
    )
    
    # åˆ›å»ºæœç´¢å¼•æ“å®ä¾‹
    search_engine = None
    
    try:
        # åˆ›å»ºæœç´¢å¼•æ“ï¼ˆå¯é€‰é€æ˜åº¦æ—¥å¿—ï¼‰
        if enable_transparency:
            from core.search_transparency_collector import SearchTransparencyCollector
            transparency_collector = SearchTransparencyCollector()
            search_engine = SearchEngineV2(transparency_collector=transparency_collector)
        else:
            search_engine = SearchEngineV2()
        
        # æ‰§è¡Œæœç´¢
        logger.info(f"[ğŸ¤– Agentæ¥å£] æ‰§è¡Œæœç´¢...")
        response = search_engine.search(search_request)
        
        # æ¸…ç†èµ„æº
        del search_engine
        gc.collect()
        
        # è½¬æ¢ä¸ºå­—å…¸è¿”å›
        result_dict = {
            "success": response.success,
            "query": response.query,
            "results": response.results,
            "total_count": response.total_count,
            "playlist_count": response.playlist_count,
            "video_count": response.video_count,
            "message": response.message,
            "quality_report": response.quality_report,
            "transparency": response.transparency if enable_transparency else None
        }
        
        logger.info(f"[ğŸ¤– Agentæ¥å£] æœç´¢å®Œæˆ: {result_dict['total_count']} ä¸ªç»“æœ")
        return result_dict
        
    except ValueError as e:
        # è¾“å…¥éªŒè¯é”™è¯¯
        logger.error(f"[ğŸ¤– Agentæ¥å£] è¾“å…¥éªŒè¯å¤±è´¥: {str(e)}")
        raise
    except Exception as e:
        # æœç´¢å¤±è´¥
        logger.error(f"[ğŸ¤– Agentæ¥å£] æœç´¢å¤±è´¥: {type(e).__name__}: {str(e)[:100]}")
        
        # ç¡®ä¿æ¸…ç†èµ„æº
        if search_engine is not None:
            try:
                del search_engine
                gc.collect()
            except:
                pass
        
        # è¿”å›é”™è¯¯ç»“æœ
        return {
            "success": False,
            "query": f"{country} {grade} {subject}",
            "results": [],
            "total_count": 0,
            "playlist_count": 0,
            "video_count": 0,
            "message": f"æœç´¢å¤±è´¥: {str(e)[:200]}",
            "quality_report": None,
            "transparency": None
        }


class AgentSearchClient:
    """
    Agentæœç´¢å®¢æˆ·ç«¯ï¼ˆé¢å‘å¯¹è±¡æ¥å£ï¼‰
    
    æä¾›æ›´é«˜çº§çš„åŠŸèƒ½ï¼Œå¦‚æ‰¹é‡æœç´¢ã€ç¼“å­˜ç­‰
    
    Example:
        >>> client = AgentSearchClient()
        >>> results = client.search("ID", "Kelas 1", "Matematika")
        >>> client.cleanup()  # æ¸…ç†èµ„æº
    """
    
    def __init__(self, enable_cache: bool = False):
        """
        åˆå§‹åŒ–Agentæœç´¢å®¢æˆ·ç«¯
        
        Args:
            enable_cache: æ˜¯å¦å¯ç”¨ç»“æœç¼“å­˜
        """
        self._search_engine = None
        self._enable_cache = enable_cache
        self._cache = {}
        logger.info(f"[ğŸ¤– Agentå®¢æˆ·ç«¯] åˆå§‹åŒ–å®Œæˆ (ç¼“å­˜: {enable_cache})")
    
    def search(
        self,
        country: str,
        grade: str,
        subject: str,
        semester: Optional[str] = None,
        language: Optional[str] = None,
        use_cache: bool = True
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œæœç´¢ï¼ˆé¢å‘å¯¹è±¡æ¥å£ï¼‰
        
        Args:
            country: å›½å®¶ä»£ç 
            grade: å¹´çº§
            subject: å­¦ç§‘
            semester: å­¦æœŸï¼Œå¯é€‰
            language: è¯­è¨€ï¼Œå¯é€‰
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜ï¼Œé»˜è®¤True
        
        Returns:
            æœç´¢ç»“æœå­—å…¸
        """
        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = f"{country}:{grade}:{subject}:{semester}:{language}"
        
        # æ£€æŸ¥ç¼“å­˜
        if self._enable_cache and use_cache and cache_key in self._cache:
            logger.info(f"[ğŸ¤– Agentå®¢æˆ·ç«¯] ç¼“å­˜å‘½ä¸­: {cache_key}")
            return self._cache[cache_key]
        
        # æ‰§è¡Œæœç´¢
        result = agent_search(
            country=country,
            grade=grade,
            subject=subject,
            semester=semester,
            language=language,
            enable_transparency=False
        )
        
        # å­˜å…¥ç¼“å­˜
        if self._enable_cache and result["success"]:
            self._cache[cache_key] = result
            logger.info(f"[ğŸ¤– Agentå®¢æˆ·ç«¯] ç»“æœå·²ç¼“å­˜: {cache_key}")
        
        return result
    
    def batch_search(
        self,
        queries: List[Dict[str, Any]],
        max_concurrent: int = 3
    ) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡æœç´¢ï¼ˆå¹¶å‘æ‰§è¡Œï¼‰
        
        Args:
            queries: æŸ¥è¯¢åˆ—è¡¨ [{"country": "ID", "grade": "Kelas 1", "subject": "Matematika"}, ...]
            max_concurrent: æœ€å¤§å¹¶å‘æ•°ï¼Œé»˜è®¤3
        
        Returns:
            ç»“æœåˆ—è¡¨
        """
        import concurrent.futures
        
        results = []
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_concurrent) as executor:
            # æäº¤æ‰€æœ‰æœç´¢ä»»åŠ¡
            future_to_query = {
                executor.submit(
                    self.search,
                    q["country"],
                    q["grade"],
                    q.get("subject"),
                    q.get("semester"),
                    q.get("language"),
                    q.get("use_cache", True)
                ): q for q in queries
            }
            
            # æ”¶é›†ç»“æœ
            for future in concurrent.futures.as_completed(future_to_query):
                query = future_to_query[future]
                try:
                    result = future.result(timeout=300)  # 5åˆ†é’Ÿè¶…æ—¶
                    results.append(result)
                except Exception as e:
                    logger.error(f"[ğŸ¤– Agentå®¢æˆ·ç«¯] æ‰¹é‡æœç´¢å¤±è´¥: {query} -> {str(e)[:100]}")
                    results.append({
                        "success": False,
                        "message": f"æ‰¹é‡æœç´¢å¤±è´¥: {str(e)[:200]}",
                        "results": [],
                        "total_count": 0
                    })
        
        return results
    
    def clear_cache(self):
        """æ¸…ç©ºç¼“å­˜"""
        self._cache.clear()
        logger.info("[ğŸ¤– Agentå®¢æˆ·ç«¯] ç¼“å­˜å·²æ¸…ç©º")
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.clear_cache()
        if self._search_engine is not None:
            try:
                del self._search_engine
                gc.collect()
            except:
                pass
        logger.info("[ğŸ¤– Agentå®¢æˆ·ç«¯] èµ„æºå·²æ¸…ç†")
    
    def __enter__(self):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ”¯æŒ"""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ¸…ç†"""
        self.cleanup()


# ä¾¿æ·å‡½æ•°
def quick_search(country: str, grade: str, subject: str) -> List[Dict[str, Any]]:
    """
    å¿«é€Ÿæœç´¢ï¼ˆåªè¿”å›ç»“æœåˆ—è¡¨ï¼‰
    
    Args:
        country: å›½å®¶ä»£ç 
        grade: å¹´çº§
        subject: å­¦ç§‘
    
    Returns:
        ç»“æœåˆ—è¡¨ï¼Œå¤±è´¥è¿”å›ç©ºåˆ—è¡¨
    
    Example:
        >>> results = quick_search("ID", "Kelas 1", "Matematika")
        >>> for r in results:
        ...     print(f"{r['title']}: {r['url']}")
    """
    response = agent_search(country, grade, subject)
    
    if response["success"]:
        return response["results"]
    else:
        logger.warning(f"[å¿«é€Ÿæœç´¢] æœç´¢å¤±è´¥: {response['message']}")
        return []


# å¯¼å‡ºæ¥å£
__all__ = [
    "agent_search",
    "AgentSearchClient", 
    "quick_search"
]
