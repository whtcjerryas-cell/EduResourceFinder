#!/usr/bin/env python3
"""
Metaso (ç§˜å¡”AIæœç´¢) å®¢æˆ·ç«¯
å®šä»·ï¼šÂ¥0.03/æ¬¡ï¼ˆçº¦ $0.004/æ¬¡ï¼‰
å…è´¹é¢åº¦ï¼šæ–°ç”¨æˆ· 5,000 æ¬¡

å®˜æ–¹ç½‘ç«™ï¼šhttps://metaso.cn
APIç«¯ç‚¹ï¼šhttps://metaso.cn/api/mcp (MCP JSON-RPC 2.0 åè®®)

æ”¯æŒå…­ç§æœç´¢ç±»å‹ï¼š
- webpage: ç½‘é¡µæœç´¢
- document: æ–‡åº“æœç´¢
- paper: å­¦æœ¯è®ºæ–‡æœç´¢
- image: å›¾ç‰‡æœç´¢
- video: è§†é¢‘æœç´¢
- podcast: æ’­å®¢æœç´¢
"""

import os
import json
import time
import requests
from typing import Optional, List, Dict, Any
from logger_utils import get_logger

logger = get_logger('metaso_client')


class MetasoSearchClient:
    """ç§˜å¡”AIæœç´¢å®¢æˆ·ç«¯ï¼ˆMCP JSON-RPC 2.0 åè®®ï¼‰"""

    def __init__(self, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ– Metaso å®¢æˆ·ç«¯

        Args:
            api_key: Metaso API Keyï¼Œå¦‚æœä¸æä¾›åˆ™ä»ç¯å¢ƒå˜é‡è¯»å–
        """
        self.api_key = api_key or os.getenv("METASO_API_KEY")
        if not self.api_key:
            raise ValueError("METASO_API_KEY not found in environment or arguments")

        # Metaso API ç«¯ç‚¹ï¼ˆå®˜æ–¹ MCP ç«¯ç‚¹ï¼‰
        self.base_url = os.getenv("METASO_API_BASE", "https://metaso.cn/api/mcp")

        self.usage_count = 0  # ä½¿ç”¨è®¡æ•°å™¨
        self.free_tier_limit = 5000  # å…è´¹é¢åº¦

        logger.info(f"[âœ… Metaso] å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        logger.info(f"[ğŸ“Š Metaso] å…è´¹é¢åº¦: {self.free_tier_limit:,} æ¬¡")
        logger.info(f"[ğŸ’° Metaso] è¶…å‡ºåå®šä»·: Â¥0.03/æ¬¡")

    def search(
        self,
        query: str,
        max_results: int = 10,
        search_scope: str = "webpage",  # webpage, document, paper, image, video, podcast
        include_summary: bool = False,
        include_raw_content: bool = False,
        timeout: int = 30,
        include_domains: Optional[List[str]] = None,  # å…¼å®¹æ€§å‚æ•°ï¼Œé€šè¿‡åè¿‡æ»¤å®ç°
        search_mode: Optional[str] = None  # å…¼å®¹æ€§å‚æ•°ï¼šsimple, deep, research
    ) -> List[Dict[str, Any]]:
        """
        æ‰§è¡Œæœç´¢ï¼ˆä½¿ç”¨ MCP JSON-RPC 2.0 åè®®ï¼‰

        Args:
            query: æœç´¢æŸ¥è¯¢
            max_results: æœ€å¤§ç»“æœæ•°
            search_scope: æœç´¢ç±»å‹ï¼ˆwebpage/document/paper/image/video/podcastï¼‰
            include_summary: æ˜¯å¦åŒ…å« AI æ‘˜è¦
            include_raw_content: æ˜¯å¦åŒ…å«åŸå§‹å†…å®¹
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            include_domains: åŸŸåè¿‡æ»¤åˆ—è¡¨ï¼ˆå…¼å®¹æ€§å‚æ•°ï¼Œé€šè¿‡åè¿‡æ»¤å®ç°ï¼‰
            search_mode: æœç´¢æ¨¡å¼ï¼ˆå…¼å®¹æ€§å‚æ•°ï¼šsimple/deep/researchï¼‰
                         - simple -> ç½‘é¡µæœç´¢
                         - deep -> ç½‘é¡µæœç´¢ + æ‘˜è¦
                         - research -> å­¦æœ¯æœç´¢

        Returns:
            æœç´¢ç»“æœåˆ—è¡¨ï¼Œæ ¼å¼ï¼š
            [
                {
                    "title": "ç»“æœæ ‡é¢˜",
                    "url": "ç»“æœURL",
                    "snippet": "ç»“æœæ‘˜è¦",
                    "source": "Metasoæœç´¢",
                    "search_engine": "Metaso"
                },
                ...
            ]
        """
        try:
            # æ˜ å°„ search_mode åˆ° Metaso å‚æ•°
            if search_mode:
                mode_mapping = {
                    "simple": ("webpage", False),
                    "deep": ("webpage", True),
                    "research": ("paper", True)
                }
                if search_mode in mode_mapping:
                    search_scope, include_summary = mode_mapping[search_mode]
                    logger.info(f"[ğŸ”„ æ¨¡å¼æ˜ å°„] search_mode='{search_mode}' -> scope='{search_scope}', include_summary={include_summary}")

            logger.info(f"[ğŸ” Metaso] å¼€å§‹æœç´¢...")
            logger.info(f"[ğŸ“ æŸ¥è¯¢] {query}")
            logger.info(f"[âš™ï¸ å‚æ•°] max_results={max_results}, scope={search_scope}")

            # ä½¿ç”¨ MCP JSON-RPC 2.0 åè®®
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }

            # æ„é€  JSON-RPC 2.0 è¯·æ±‚
            payload = {
                "jsonrpc": "2.0",
                "id": 1,
                "method": "tools/call",
                "params": {
                    "name": "metaso_web_search",
                    "arguments": {
                        "q": query,
                        "size": min(max_results, 20),
                        "scope": search_scope,
                        "includeSummary": include_summary,
                        "includeRawContent": include_raw_content
                    }
                }
            }

            logger.info(f"[ğŸ“¤ è¯·æ±‚] JSON-RPC 2.0")
            logger.debug(f"[ğŸ“„ Payload] {json.dumps(payload, ensure_ascii=False)}")

            # å‘é€è¯·æ±‚
            start_time = time.time()
            with requests.Session() as session:
                session.trust_env = False  # å¼ºåˆ¶ç¦ç”¨ä»£ç†
                response = session.post(
                    self.base_url,
                    headers=headers,
                    json=payload,
                    timeout=timeout
                )
            elapsed_time = time.time() - start_time

            logger.info(f"[ğŸ“¥ å“åº”] çŠ¶æ€ç : {response.status_code}, è€—æ—¶: {elapsed_time:.2f}s")

            # æ£€æŸ¥å“åº”çŠ¶æ€
            if response.status_code == 401:
                logger.error(f"[âŒ é”™è¯¯] API Key æ— æ•ˆæˆ–å·²è¿‡æœŸ")
                return []
            elif response.status_code == 429:
                logger.error(f"[âŒ é”™è¯¯] è¶…å‡ºé€Ÿç‡é™åˆ¶æˆ–é…é¢")
                return []
            elif response.status_code != 200:
                logger.error(f"[âŒ é”™è¯¯] HTTP {response.status_code}: {response.text}")
                return []

            # è§£æ JSON-RPC å“åº”
            data = response.json()

            # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
            if "error" in data:
                error_info = data["error"]
                logger.error(f"[âŒ é”™è¯¯] JSON-RPC é”™è¯¯: {error_info}")
                return []

            # æå–ç»“æœ
            result = data.get("result", {})
            if not result:
                logger.warning(f"[âš ï¸ è­¦å‘Š] å“åº”ä¸­æ²¡æœ‰ result å­—æ®µ")
                return []

            # è§£ææœç´¢ç»“æœ
            # Metaso MCP å“åº”æ ¼å¼: result.content[0].text æ˜¯ JSON å­—ç¬¦ä¸²
            content_list = result.get("content", [])
            if not content_list or len(content_list) == 0:
                logger.warning(f"[âš ï¸ è­¦å‘Š] å“åº”ä¸­æ²¡æœ‰ content å­—æ®µæˆ–ä¸ºç©º")
                return []

            # æå– content[0].textï¼ˆJSON å­—ç¬¦ä¸²ï¼‰
            result_text = content_list[0].get("text", "") if isinstance(content_list[0], dict) else ""
            if not result_text:
                logger.warning(f"[âš ï¸ è­¦å‘Š] content[0] ä¸­æ²¡æœ‰ text å­—æ®µ")
                return []

            # è§£æ JSON å­—ç¬¦ä¸²
            try:
                result_data = json.loads(result_text)
            except json.JSONDecodeError as e:
                logger.error(f"[âŒ è§£æ] JSON è§£æå¤±è´¥: {e}")
                logger.debug(f"[ğŸ“„ åŸå§‹æ–‡æœ¬] {result_text[:500]}")
                return []

            # æå– webpages æ•°ç»„
            webpages = result_data.get("webpages", [])
            if not webpages:
                logger.warning(f"[âš ï¸ è­¦å‘Š] ç»“æœä¸­æ²¡æœ‰ webpages å­—æ®µ")
                logger.debug(f"[ğŸ“„ ç»“æœæ•°æ®] {json.dumps(result_data, ensure_ascii=False)[:500]}")
                return []

            logger.info(f"[ğŸ“Š åŸå§‹ç»“æœ] æ‰¾åˆ° {len(webpages)} ä¸ªç½‘é¡µ")

            # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
            results = []
            for item in webpages:
                result = {
                    "title": item.get("title", ""),
                    "url": item.get("link", ""),  # Metaso ä½¿ç”¨ "link" å­—æ®µ
                    "snippet": item.get("snippet", ""),
                    "source": "Metasoæœç´¢",
                    "search_engine": "Metaso"
                }
                results.append(result)

            # åŸŸåè¿‡æ»¤ï¼ˆå¦‚æœæŒ‡å®šï¼‰
            # [ä¿®å¤] 2026-01-20: é‡æ–°å¯ç”¨åŸŸåè¿‡æ»¤ï¼Œç¡®ä¿æœç´¢ç»“æœæ¥è‡ªä¼˜å…ˆåŸŸå
            if include_domains:
                original_count = len(results)
                results = [
                    r for r in results
                    if any(domain.lower() in r.get("url", "").lower() for domain in include_domains)
                ]
                logger.info(f"[ğŸ” è¿‡æ»¤] åŸŸåè¿‡æ»¤: ä» {original_count} ä¸ªç»“æœè¿‡æ»¤åˆ° {len(results)} ä¸ª")
                logger.info(f"[ğŸ“‹ ç›®æ ‡åŸŸå] {', '.join(include_domains[:5])}")

                # å¦‚æœè¿‡æ»¤åæ²¡æœ‰ç»“æœï¼Œè®°å½•è­¦å‘Šä½†ä¸è¿‡æ»¤ï¼ˆå›é€€åˆ°å…¨éƒ¨ç»“æœï¼‰
                if len(results) == 0:
                    logger.warning(f"[âš ï¸ è­¦å‘Š] åŸŸåè¿‡æ»¤åæ— ç»“æœï¼Œä½¿ç”¨åŸå§‹æœç´¢ç»“æœï¼ˆå…± {original_count} ä¸ªï¼‰")
                    results = webpages  # å›é€€åˆ°æœªè¿‡æ»¤çš„ç»“æœ
                    for item in results:
                        result = {
                            "title": item.get("title", ""),
                            "url": item.get("link", ""),
                            "snippet": item.get("snippet", ""),
                            "source": "Metasoæœç´¢",
                            "search_engine": "Metaso"
                        }
                    results = results[:original_count]

            # æ›´æ–°ä½¿ç”¨è®¡æ•°
            self.usage_count += 1

            # è®¡ç®—æˆæœ¬
            if self.usage_count <= self.free_tier_limit:
                cost = 0.0
                tier = "å…è´¹"
            else:
                cost = (self.usage_count - self.free_tier_limit) * 0.03
                tier = "ä»˜è´¹"

            logger.info(f"[âœ… Metaso] æœç´¢æˆåŠŸ")
            logger.info(f"[ğŸ“Š ç»Ÿè®¡] ç¬¬ {self.usage_count:,} æ¬¡è°ƒç”¨")
            logger.info(f"[ğŸ’° æˆæœ¬] Â¥{cost:.2f} ({tier})")
            logger.info(f"[ğŸ“‹ ç»“æœ] è¿”å› {len(results)} ä¸ªç»“æœ")

            return results

        except requests.exceptions.Timeout:
            logger.error(f"[âŒ è¶…æ—¶] è¯·æ±‚è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰")
            return []
        except requests.exceptions.RequestException as e:
            logger.error(f"[âŒ ç½‘ç»œ] è¯·æ±‚å¤±è´¥: {str(e)}")
            return []
        except json.JSONDecodeError as e:
            logger.error(f"[âŒ è§£æ] JSON è§£æå¤±è´¥: {str(e)}")
            return []
        except Exception as e:
            logger.error(f"[âŒ æœªçŸ¥] æœç´¢å¤±è´¥: {str(e)}")
            return []

    def get_usage_stats(self) -> Dict[str, Any]:
        """
        è·å–ä½¿ç”¨ç»Ÿè®¡

        Returns:
            ä½¿ç”¨ç»Ÿè®¡å­—å…¸
        """
        if self.usage_count <= self.free_tier_limit:
            remaining = self.free_tier_limit - self.usage_count
            cost = 0.0
        else:
            remaining = 0
            cost = (self.usage_count - self.free_tier_limit) * 0.03

        return {
            "usage_count": self.usage_count,
            "free_tier_limit": self.free_tier_limit,
            "remaining_free": remaining,
            "total_cost": cost,
            "cost_per_search": 0.03,
            "tier": "å…è´¹" if self.usage_count <= self.free_tier_limit else "ä»˜è´¹"
        }

    def reset_usage_count(self):
        """é‡ç½®ä½¿ç”¨è®¡æ•°å™¨ï¼ˆç”¨äºæµ‹è¯•æˆ–æ–°è®¡è´¹å‘¨æœŸï¼‰"""
        old_count = self.usage_count
        self.usage_count = 0
        logger.info(f"[ğŸ”„ Metaso] ä½¿ç”¨è®¡æ•°å™¨å·²é‡ç½®ï¼ˆåŸè®¡æ•°: {old_count:,}ï¼‰")


# ä¾¿æ·å‡½æ•°
def create_metaso_client() -> Optional[MetasoSearchClient]:
    """
    åˆ›å»º Metaso å®¢æˆ·ç«¯çš„ä¾¿æ·å‡½æ•°

    Returns:
        MetasoSearchClient å®ä¾‹ï¼Œå¦‚æœåˆå§‹åŒ–å¤±è´¥åˆ™è¿”å› None
    """
    try:
        return MetasoSearchClient()
    except Exception as e:
        logger.warning(f"[âš ï¸ Metaso] å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
        return None


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("=" * 60)
    print("Metaso æœç´¢å®¢æˆ·ç«¯æµ‹è¯•ï¼ˆMCP JSON-RPC 2.0 åè®®ï¼‰")
    print("=" * 60)

    try:
        client = MetasoSearchClient()

        # æµ‹è¯•æœç´¢
        print("\næµ‹è¯• 1: ä¸­æ–‡æœç´¢")
        results = client.search("Python æ•™ç¨‹", max_results=5)
        print(f"ç»“æœ: {len(results)} ä¸ª")
        for i, result in enumerate(results[:3], 1):
            print(f"{i}. {result['title']}")
            print(f"   {result['url']}")

        print("\nä½¿ç”¨ç»Ÿè®¡:")
        stats = client.get_usage_stats()
        print(f"- ä½¿ç”¨æ¬¡æ•°: {stats['usage_count']:,}")
        print(f"- å‰©ä½™å…è´¹: {stats['remaining_free']:,}")
        print(f"- æ€»æˆæœ¬: Â¥{stats['total_cost']:.2f}")
        print(f"- å½“å‰å±‚çº§: {stats['tier']}")

    except Exception as e:
        print(f"\næµ‹è¯•å¤±è´¥: {e}")
        print("\næç¤ºï¼š")
        print("1. è¯·ç¡®ä¿å·²è®¾ç½® METASO_API_KEY ç¯å¢ƒå˜é‡")
        print("2. Metaso ä½¿ç”¨ MCP JSON-RPC 2.0 åè®®")
        print("3. API ç«¯ç‚¹: https://metaso.cn/api/mcp")
